<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-23T14:59:33-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Complex Eigenvalues</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_approx_eigenvalues.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_det_properties.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_approx_eigenvalues.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_det_properties.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="chapter" id="chap_complex_eigenvalues"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span>
</h2>
<section class="introduction" id="introduction-336"><article class="objectives goal-like" id="objectives-21"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-337"><p id="p-3503">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-602"><p id="p-3504">What properties do complex eigenvalues of a real matrix satisfy?</p></li>
<li id="li-603"><p id="p-3505">What properties do complex eigenvectors of a real matrix satisfy?</p></li>
<li id="li-604"><p id="p-3506">What is a rotation-scaling matrix?</p></li>
<li id="li-605"><p id="p-3507">How do we find a rotation-scaling matrix within a matrix with complex eigenvalues?</p></li>
</ul></article></section><section class="section" id="sec_appl_gershgorin"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: The Gershgorin Disk Theorem</span>
</h3>
<p id="p-3508">We have now seen different methods for calculating/approximating eigenvalues of a matrix. The algebraic method using the characteristic polynomial can provide exact values, but only in cases where the size of the matrix is small. Methods like the power method allow us to approximate eigenvalues in many, but not all, cases. These approximation techniques can be made more efficient if we have some idea of where the eigenvalues are. The Gershgorin Disc Theorem is a useful tool that can quickly provide bounds on the location of eigenvalues using elementary calculations. For example, using the Gershsgorin Disk Theorem we can quickly tell that the real parts of the eigenvalues of the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_Gershgorin_1.html">
\begin{equation*}
\left[ \begin{array}{ccr} 3\amp 1\amp -1 \\ 0\amp -1+i\amp i \\ 2\amp 1\amp -2i \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">lie between <span class="process-math">\(-4\)</span> and 5 and the imaginary parts lie between <span class="process-math">\(-5\)</span> and 2. Even more, we can say that the eigenvalues lie in the disks (called <dfn class="terminology">Gershgorin disks</dfn>) shown in <a href="" class="xref" data-knowl="./knowl/F_Gershgorin_1.html" title="Figure 21.1">Figure 21.1</a>.</p>
<figure class="figure figure-like" id="F_Gershgorin_1"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/Gershgorin_1.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">21.1<span class="period">.</span></span><span class="space"> </span>Gershgorin disks.</figcaption></figure><p id="p-3509">We will learn more details about the Gershgorin Disk Theorem at the end of this section.</p></section><section class="section" id="sec_comp_eigen_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-3510">So far we have worked with real matrices whose eigenvalues are all real. However, the characteristic polynomial of a matrix with real entries can have complex roots. In this section we investigate the properties of these complex roots and their corresponding eigenvectors, how these complex eigenvectors are found, and the geometric interpretation of the transformations defined by matrices with complex eigenvalues. Although we can consider matrices that have complex numbers as entries, we will restrict ourselves to matrices with real entries.</p>
<article class="exploration project-like" id="pa_4_e"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">21.1</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-338"><p id="p-3511">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 2\amp 4 \\ -2\amp 2 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1166"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3512">Find the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1167"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3513">Find the eigenvalues of <span class="process-math">\(A\text{.}\)</span> You should get two complex numbers. How are these complex numbers related?</p></article><article class="task exercise-like" id="task-1168"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3514">Find an eigenvector corresponding to each eigenvalue of <span class="process-math">\(A\text{.}\)</span> You should obtain vectors with complex entries.</p></article></article></section><section class="section" id="sec_comp_eigen"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Complex Eigenvalues</span>
</h3>
<p id="p-3515">As you noticed in <a href="" class="xref" data-knowl="./knowl/pa_4_e.html" title="Preview Activity 21.1">Preview Activity 21.1</a>, the complex roots of the characteristic equation of a real matrix <span class="process-math">\(A\)</span> come in complex conjugate pairs. This should come as no surprise since we know through our use of the quadratic formula that complex roots of (real) quadratic polynomials come in complex conjugate pairs. More generally, if <span class="process-math">\(p(x)=a_0+a_1x+a_2x^2 + \cdots + a_nx^n\)</span> is a polynomial with real coefficients and <span class="process-math">\(z\)</span> is a root of this polynomial, meaning <span class="process-math">\(p(z)=0\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_4_e.html">
\begin{equation*}
0=\overline{p(z)} = \overline{a_0+a_1z+a_2z^2 + \cdots + a_nz^n} = a_0 + a_1 \overline{z} + a_2 \overline{z}^2 + \cdots + a_n \overline{z}^n = p(\overline{z})\,\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, <span class="process-math">\(\overline{z}\)</span> is also a root of <span class="process-math">\(p(x)\text{.}\)</span></p>
<article class="activity project-like" id="act_4e_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">21.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-339"><p id="p-3516">Let <span class="process-math">\(A=\left[ \begin{array}{cr} 0\amp -1 \\ 1\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1169"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3517">The matrix transformation <span class="process-math">\(T:\R^2 \to \R^2\)</span> defined by <span class="process-math">\(T(\vx)=A\vx\)</span> is a rotation transformation. What is the angle of rotation?</p></article><article class="task exercise-like" id="task-1170"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3518">Find the eigenvalues of <span class="process-math">\(A\text{.}\)</span> For each eigenvalue, find an eigenvector.</p></article></article><p id="p-3519">In <a href="" class="xref" data-knowl="./knowl/pa_4_e.html" title="Preview Activity 21.1">Preview Activity 21.1</a> and in <a href="" class="xref" data-knowl="./knowl/act_4e_1.html" title="Activity 21.2">Activity 21.2</a>, you found that if <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\)</span> corresponding to <span class="process-math">\(\lambda\text{,}\)</span> then <span class="process-math">\(\overline{\vv}\)</span> obtained by taking the complex conjugate of each entry in <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\)</span> corresponding to <span class="process-math">\(\overline{\lambda}\text{.}\)</span> Specifically, if <span class="process-math">\(\vv=\vu+i\vw\)</span> where both <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> are real vectors is an eigenvector of <span class="process-math">\(A\text{,}\)</span> then so is <span class="process-math">\(\overline{\vv} = \vu-i\vw\text{.}\)</span> We can justify this property using matrix algebra as follows:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_4_e.html ./knowl/act_4e_1.html">
\begin{equation*}
A\overline{\vv} = \overline{A}\overline{\vv} = \overline{A\vv} = \overline{\lambda \vv} = \overline{\lambda} \overline{\vv} \,\text{.}
\end{equation*}
</div>
<p id="p-3520">In the first equality, we used the fact that <span class="process-math">\(A\)</span> is a real matrix, so <span class="process-math">\(\overline{A}=A\text{.}\)</span> In all the other equalities, we used the properties of the conjugation operation in complex numbers.</p></section><section class="section" id="sec_mtx_rotate_scale"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Rotation and Scaling Matrices</span>
</h3>
<p id="p-3521">Recall that a rotation matrix is of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4e_1.html">
\begin{equation*}
R_\theta= \left[ \begin{array}{cr} \cos(\theta)\amp -\sin(\theta) \\ \sin(\theta)\amp \cos(\theta) \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">where the rotation is counterclockwise about the origin by an angle of <span class="process-math">\(\theta\)</span> radians. In <a href="" class="xref" data-knowl="./knowl/act_4e_1.html" title="Activity 21.2">Activity 21.2</a>, we considered the rotation matrix with angle <span class="process-math">\(\pi/2\)</span> in counterclockwise direction. We will soon see that rotation matrices play an important role in the geometry of a matrix transformation for a matrix that has complex eigenvalues. In this activity, we will restrict ourselves to the <span class="process-math">\(2 \times 2\)</span> case, but similar arguments can be made in higher dimensions.</p>
<article class="activity project-like" id="act_4e_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">21.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-340"><p id="p-3522">Let <span class="process-math">\(A=\left[ \begin{array}{rc} 1\amp 1 \\ -1\amp 1 \end{array}  \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1171"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3523">Explain why <span class="process-math">\(A\)</span> is not a rotation matrix.</p></article><article class="task exercise-like" id="task-1172"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3524">Although <span class="process-math">\(A\)</span> is not a rotation matrix, there is a rotation matrix <span class="process-math">\(B\)</span> inside <span class="process-math">\(A\text{.}\)</span> To find the matrix <span class="process-math">\(B\text{,}\)</span> factor out <span class="process-math">\(\sqrt{2}\)</span> from all entries of <span class="process-math">\(A\text{.}\)</span> In other words, write <span class="process-math">\(A\)</span> as a product of two matrices in the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{cc} \sqrt{2} \amp 0 \\ 0\amp \sqrt{2} \end{array}  \right] B \;\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1173"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3525">The <span class="process-math">\(B\)</span> matrix is a rotation matrix with an appropriate <span class="process-math">\(\theta\text{.}\)</span> Find this <span class="process-math">\(\theta\text{.}\)</span></p></article><article class="task exercise-like" id="task-1174"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3526">If we think about the product of two matrices as applying one transformation after another, describe the effect of the matrix transformation defined by <span class="process-math">\(A\)</span> geometrically.</p></article></article><p id="p-3527">More generally, if we have a matrix <span class="process-math">\(A\)</span> of the form <span class="process-math">\(A=\left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array}  \right]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{cc} \sqrt{a^2+b^2} \amp 0 \\ 0\amp \sqrt{a^2+b^2} \end{array}  \right] \left[ \begin{array}{cc} \frac{a}{\sqrt{a^2+b^2}}\amp \frac{-b}{\sqrt{a^2+b^2}} \\ \frac{b}{\sqrt{a^2+b^2}}\amp \frac{a}{\sqrt{a^2+b^2}} \end{array}  \right] \,\text{.}
\end{equation*}
</div>
<p id="p-3528"> The first matrix in the decomposition is a scaling matrix with a scaling factor of <span class="process-math">\(s=\sqrt{a^2+b^2}\text{.}\)</span> So if <span class="process-math">\(s&gt;1\text{,}\)</span> the transformation stretches vectors, and if <span class="process-math">\(s\lt 1\text{,}\)</span> the transformation shrinks vectors. The second matrix in the decomposition is a rotation matrix with angle <span class="process-math">\(\theta\)</span> such that <span class="process-math">\(\cos(\theta)=\frac{a}{\sqrt{a^2+b^2}}\)</span> and <span class="process-math">\(\sin(\theta)=\frac{b}{\sqrt{a^2+b^2}}\text{.}\)</span> This angle is also the angle between the positive <span class="process-math">\(x\)</span>-axis and the vector <span class="process-math">\(\vv=\left[ \begin{array}{c} a\\ b \end{array} \right]\text{.}\)</span> We will refer to the matrices of the form <span class="process-math">\(\left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array} \right]\)</span> as <dfn class="terminology">rotation-scaling matrices</dfn>.</p></section><section class="section" id="sec_mtx_comp_eigen"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Matrices with Complex Eigenvalues</span>
</h3>
<p id="p-3529">Now we will investigate how a general <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalues can be seen to be similar (both in a linear algebra and a colloquial meaning) to a rotation-scaling matrix.</p>
<article class="activity project-like" id="act_4e_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">21.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-341"><p id="p-3530">Let <span class="process-math">\(B=\left[ \begin{array}{cr} 1\amp -5\\2\amp 3 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(B\)</span> are <span class="process-math">\(2\pm 3i\text{.}\)</span> An eigenvector for the eigenvalue <span class="process-math">\(2-3i\)</span> is <span class="process-math">\(\vv=\left[ \begin{array}{c} -5 \\ 1-3i \end{array} \right]\text{.}\)</span> We will use this eigenvector to show that <span class="process-math">\(B\)</span> is similar to a rotation-scaling matrix.</p></div>
<article class="task exercise-like" id="task-1175"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3531">Any complex vector <span class="process-math">\(\vv\)</span> can be written as <span class="process-math">\(\vv=\vu+i\vw\)</span> where both <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> are real vectors. What are these real vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> for the eigenvector <span class="process-math">\(\vv\)</span> above?</p></article><article class="task exercise-like" id="task-1176"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3532">Let <span class="process-math">\(P=[ \vu \ \vw ]\)</span> be the matrix whose first column is the real part of <span class="process-math">\(\vv\)</span> and whose second column is the imaginary part of <span class="process-math">\(\vv\)</span> (without the <span class="process-math">\(i\)</span>). Find <span class="process-math">\(R=P^{-1}BP\text{.}\)</span></p></article><article class="task exercise-like" id="task-1177"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3533">Express <span class="process-math">\(R\)</span> as a product of a rotation and a scaling matrix. What is the factor of scaling? What is the rotation angle?</p></article></article><p id="p-3534">In <a href="" class="xref" data-knowl="./knowl/act_4e_3.html" title="Activity 21.4">Activity 21.4</a>, we saw that the matrix <span class="process-math">\(B\)</span> with complex eigenvalues <span class="process-math">\(2\pm 3i\)</span> is similar to a rotation-scaling matrix. Specifically <span class="process-math">\(R=P^{-1}BP\text{,}\)</span> where the columns of <span class="process-math">\(P\)</span> are the real and imaginary parts of an eigenvector of <span class="process-math">\(B\text{,}\)</span> is the rotation-scaling matrix with a factor of scaling by <span class="process-math">\(\sqrt{2^2+3^2}\)</span> and a rotation by angle <span class="process-math">\(\theta=\arccos(\frac{2}{\sqrt{2^2+3^2}})\text{.}\)</span></p>
<p id="p-3535">Does a similar decomposition result hold for a general <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalues? We investigate this question in the next activity.</p>
<article class="activity project-like" id="act_4e_4"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">21.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-342"><p id="p-3536">Let <span class="process-math">\(A\)</span> be a <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalue <span class="process-math">\(\lambda=a-bi\text{,}\)</span> <span class="process-math">\(b\neq 0\text{,}\)</span> and corresponding complex eigenvector <span class="process-math">\(\vv=\vu+i\vw\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1178"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3537">Explain why <span class="process-math">\(A\vv = A\vu+iA\vw\text{.}\)</span></p></article><article class="task exercise-like" id="task-1179"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3538">Explain why <span class="process-math">\(\lambda\vv = (a\vu+b\vw)+i (a\vw-b\vu)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1180"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3539">Use the previous two results to explain why</p>
<ul class="disc">
<li id="li-606"><p id="p-3540"><span class="process-math">\(A\vu=a\vu+b\vw\)</span> and</p></li>
<li id="li-607"><p id="p-3541"><span class="process-math">\(A\vw = a\vw - b\vu\text{.}\)</span></p></li>
</ul></article><article class="task exercise-like" id="task-1181"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<div class="introduction" id="introduction-343"><p id="p-3542">Let <span class="process-math">\(P=[ \vu \ \vw ]\text{.}\)</span> We will now show that <span class="process-math">\(AP=PR\)</span> where <span class="process-math">\(R=\left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array}  \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1182"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3543">Without any calculation, explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AP = [ A\vu \  A\vw ]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1183"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3544">Recall that if <span class="process-math">\(M\)</span> is an <span class="process-math">\(m \times n\)</span> matrix and <span class="process-math">\(\vx\)</span> is an <span class="process-math">\(n \times 1\)</span> vector, then the matrix product <span class="process-math">\(M\vx\)</span> is a linear combination of the columns of <span class="process-math">\(M\)</span> with weights the corresponding entries of the vector <span class="process-math">\(\vx\text{.}\)</span> Use this idea to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
PR = [ a\vu + b\vw \  -b\vu + a\vw ]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1184"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3545">Now explain why <span class="process-math">\(AP = PR\text{.}\)</span></p></article><article class="task exercise-like" id="task-1185"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-3546">Assume for the moment that <span class="process-math">\(P\)</span> is an invertible matrix. Show that <span class="process-math">\(A = PRP^{-1}\text{.}\)</span></p></article></article></article><p id="p-3547">Your work in <a href="" class="xref" data-knowl="./knowl/act_4e_4.html" title="Activity 21.5">Activity 21.5</a> shows that any <span class="process-math">\(2\times 2\)</span> matrix is similar to a rotation-scaling matrix with a factor of scaling by <span class="process-math">\(\sqrt{a^2+b^2}\)</span> and a rotation by angle <span class="process-math">\(\theta=\arccos(\frac{a}{\sqrt{a^2+b^2}})\)</span> if <span class="process-math">\(b\geq 0\text{,}\)</span> and <span class="process-math">\(\theta=-\arccos(\frac{a}{\sqrt{a^2+b^2}})\)</span> if <span class="process-math">\(b\lt 0\text{.}\)</span> Geometrically, this means that every <span class="process-math">\(2 \times 2\)</span> real matrix with complex eigenvalues is just a scaled rotation (<span class="process-math">\(R\)</span>) with respect to the basis <span class="process-math">\(\B\)</span> formed by <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> from the complex eigenvector <span class="process-math">\(\vv\text{.}\)</span> Multiplying by <span class="process-math">\(P^{-1}\)</span> and <span class="process-math">\(P\)</span> simply provides the change of basis from the standard basis to the basis <span class="process-math">\(\B\text{,}\)</span> as we will see in detail when we learn about linear transformations.</p>
<article class="theorem theorem-like" id="theorem-44"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">21.2</span><span class="period">.</span>
</h4>
<p id="p-3548">Let <span class="process-math">\(A\)</span> be a real <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalue <span class="process-math">\(a-bi\)</span> and corresponding eigenvector <span class="process-math">\(\vv=\vu+i\vw\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=PRP^{-1} \; , \text{ where }  P=[ \vu \ \vw ] \; \text{ and }  R= \left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array}  \right] \,\text{.}
\end{equation*}
</div></article><p id="p-3549">The one fact that we have not yet addressed is why the matrix <span class="process-math">\(P = [ \vu \ \vw ]\)</span> is invertible. We do that now to complete the argument.</p>
<p id="p-3550">Let <span class="process-math">\(A\)</span> be a real <span class="process-math">\(2 \times 2\)</span> matrix with <span class="process-math">\(A \vv = \lambda \vv\text{,}\)</span> where <span class="process-math">\(\lambda = a-bi\text{,}\)</span> <span class="process-math">\(b \neq 0\)</span> and <span class="process-math">\(\vv=\vu+i\vw\)</span> (where <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are in <span class="process-math">\(\R^2\)</span>) with <span class="process-math">\(\vw \neq \vzero\text{.}\)</span> From <a href="" class="xref" data-knowl="./knowl/act_4e_4.html" title="Activity 21.5">Activity 21.5</a> we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4e_4.html">
\begin{equation*}
A\vu = a\vu + b\vw \ \text{ and }  \ A\vw = a\vw - b \vu\text{.}
\end{equation*}
</div>
<p id="p-3551">To show that <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> are linearly independent, we need to show that no nontrivial linear combination of <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> can be the zero vector. Suppose</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1\vu + x_2\vw = \vzero
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\)</span> and <span class="process-math">\(x_2\text{.}\)</span> We will show that <span class="process-math">\(x_1 = x_2 = 0\text{.}\)</span> Assume to the contrary that one of <span class="process-math">\(x_1, x_2\)</span> is not zero. First, assume <span class="process-math">\(x_1 \neq 0\text{.}\)</span> Then <span class="process-math">\(\vu = -\frac{x_2}{x_1} \vw\text{.}\)</span> Let <span class="process-math">\(c = -\frac{x_2}{x_1}\text{.}\)</span> From this we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-145">
\begin{align*}
A \vu \amp = A(c\vw)\\
A \vu \amp = cA \vw\\
a\vu + b\vw \amp = c(a \vw - b \vu)\\
(a+cb)\vu \amp = (ca-b)\vw\\
(a+cb)(c\vw) \amp = (ca-b)\vw\text{.}
\end{align*}
</div>
<p id="p-3552">Since <span class="process-math">\(\vw \neq \vzero\)</span> we must have <span class="process-math">\((a+cb)c = ca-b\text{.}\)</span> A little algebra shows that <span class="process-math">\((c^2+1)b = 0\text{.}\)</span> Since <span class="process-math">\(b \neq 0\text{,}\)</span> we conclude that <span class="process-math">\(c^2+1=0\text{,}\)</span> which is impossible for a real constant <span class="process-math">\(c\text{.}\)</span> Therefore, we cannot have <span class="process-math">\(x_1 \neq 0\text{.}\)</span> A similar argument (left to the reader) shows that <span class="process-math">\(x_2 = 0\text{.}\)</span> Thus we can conclude that <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vw\)</span> are linearly independent.</p></section><section class="section" id="sec_comp_eigen_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-3553">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-42"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">21.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-344"><p id="p-3554">Let <span class="process-math">\(A = \left[ \begin{array}{rcr} 0\amp 1\amp 0 \\ -1\amp 0\amp -1 \\ 1\amp 1\amp 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1186"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3555">Without doing any computations, explain why not all of the eigenvalues of <span class="process-math">\(A\)</span> can be complex.</p>
<div class="solution solution-like" id="solution-127">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3556">Since complex eigenvalues occur in conjugate pairs, the complex eigenvalues with nonzero imaginary parts occur in pairs. Since <span class="process-math">\(A\)</span> can have at most 3 different eigenvalues, at most two of them can have nonzero imaginary parts. So at least one eigenvalue of <span class="process-math">\(A\)</span> is real.</p>
</div></article><article class="task exercise-like" id="task-1187"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3557">Find all of the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-128">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3558">For this matrix <span class="process-math">\(A\)</span> we have <span class="process-math">\(A - \lambda I_3 = \left[ \begin{array}{rrc} -\lambda\amp 1\amp 0 \\ -1\amp -\lambda\amp -1 \\ 1\amp 1\amp -\lambda+1 \end{array}  \right]\text{.}\)</span> Using a cofactor expansion along the first row gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-146">
\begin{align*}
\det(A - \lambda I_3) \amp = (-\lambda)\left((-\lambda)(1-\lambda)+1\right) - \left((-1)(1-\lambda)+1\right)\\
\amp = -\lambda^3 + \lambda^2 - \lambda +1 - \lambda -1\\
\amp = \lambda^3 + \lambda^2 - 2\lambda\\
\amp = -\lambda(\lambda^2 -\lambda + 2)\text{.}
\end{align*}
</div>
<p class="continuation">The roots of the characteristic polynomial are <span class="process-math">\(\lambda = 0\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\lambda = \frac{1 \pm \sqrt{1-4(2)}}{2} = \frac{1}{2}(1 \pm \sqrt{7}i)\text{.}
\end{equation*}
</div>
</div></article></article><article class="example example-like" id="example-43"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">21.4</span><span class="period">.</span>
</h4>
<p id="p-3559">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 1\amp 2\\-1\amp 3 \end{array} \right]\text{.}\)</span> Find a rotation scaling matrix <span class="process-math">\(R\)</span> that is similar to <span class="process-math">\(A\text{.}\)</span> Identify the rotation and scaling factor.</p>
<div class="solution solution-like" id="solution-129">
<h4 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h4>
<p id="p-3560">The eigenvalues of <span class="process-math">\(A\)</span> are the roots of the characteristic polynomial</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-147">
\begin{align*}
p(\lambda) \amp = \det(A - \lambda I_2)\\
\amp = \det\left(\left[ \begin{array}{rc} 1-\lambda\amp 2\\
-1\amp 3-\lambda \end{array} \right]\right)\\
\amp = (1-\lambda)(3-\lambda) + 2\\
\amp = \lambda^2 -4\lambda + 5\text{.}
\end{align*}
</div>
<p id="p-3561">The quadratic formula shows that the roots of <span class="process-math">\(p(\lambda)\)</span> are</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{4 \pm \sqrt{-4}}{2} = 2 \pm i\text{.}
\end{equation*}
</div>
<p id="p-3562">To find an eigenvector for <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(2-i\text{,}\)</span> we row reduce</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A - (2-i) I_3 =   \left[ \begin{array}{cc} -1+i\amp 2\\-1\amp 1+i \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">to</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} 1\amp -i-1\\0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3563">An eigenvector for <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(2-i\)</span> is then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[ 1+i \  \ 1]^{\tr} = [1 \ 1]^{\tr} + i[1 \ 0]^{\tr}\text{.}
\end{equation*}
</div>
<p id="p-3564">Letting <span class="process-math">\(P = \left[  \begin{array}{cc} 1\amp 1\\1\amp 0 \end{array}  \right]\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
R = P^{-1}AP = \left[ \begin{array}{cr} 2\amp -1\\1\amp 2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3565">The scaling is determined by the determinant of <span class="process-math">\(R\)</span> which is <span class="process-math">\(5\text{,}\)</span> and the angle <span class="process-math">\(\theta\)</span> of rotation satisfies <span class="process-math">\(\sin(\theta) = \frac{1}{5}\text{.}\)</span> This makes <span class="process-math">\(\theta \approx 0.2014\)</span> radians or approximately <span class="process-math">\(11.5370^{\circ}\)</span> counterclockwise.</p>
</div></article></section><section class="section" id="sec_comp_eigen_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-608"><p id="p-3566">For a real matrix, complex eigenvalues appear in conjugate pairs. Specifically, if <span class="process-math">\(\lambda=a+ib\)</span> is an eigenvalue of a real matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\overline{\lambda}=a-ib\)</span> is also an eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-609"><p id="p-3567">For a real matrix, if a <span class="process-math">\(\vv\)</span> is an eigenvector corresponding to <span class="process-math">\(\lambda\text{,}\)</span> then the vector <span class="process-math">\(\overline{\vv}\)</span> obtained by taking the complex conjugate of each entry in <span class="process-math">\(\vv\)</span> is an eigenvector corresponding to <span class="process-math">\(\overline{\lambda}\text{.}\)</span></p></li>
<li id="li-610">
<p id="p-3568">The rotation-scaling matrix <span class="process-math">\(A=\left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array}  \right]\)</span> can be written as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} \sqrt{a^2+b^2} \amp 0 \\ 0\amp \sqrt{a^2+b^2} \end{array}  \right] \left[ \begin{array}{cc} \frac{a}{\sqrt{a^2+b^2}}\amp \frac{-b}{\sqrt{a^2+b^2}} \\ \frac{b}{\sqrt{a^2+b^2}}\amp \frac{a}{\sqrt{a^2+b^2}} \end{array}  \right] \,\text{.}
\end{equation*}
</div>
<p class="continuation">This decomposition geometrically means that the transformation corresponding to <span class="process-math">\(A\)</span> can be viewed as a rotation by angle <span class="process-math">\(\theta=\arccos\left(\frac{a}{\sqrt{a^2+b^2}}\right)\)</span> if <span class="process-math">\(b\geq 0\text{,}\)</span> or <span class="process-math">\(\theta=-\arccos\left(\frac{a}{\sqrt{a^2+b^2}}\right)\)</span> if <span class="process-math">\(b\lt 0\text{,}\)</span> followed by a scaling by factor <span class="process-math">\(\sqrt{a^2+b^2}\text{.}\)</span></p>
</li>
<li id="li-611">
<p id="p-3569">If <span class="process-math">\(A\)</span> is a real <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalue <span class="process-math">\(a-bi\)</span> and corresponding eigenvector <span class="process-math">\(\vv=\vu+i\vw\text{,}\)</span> then <span class="process-math">\(A\)</span> is similar to the rotation-scaling matrix <span class="process-math">\(R=\left[ \begin{array}{cr} a\amp -b \\ b\amp a \end{array}  \right]\text{.}\)</span> More specifically,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=PRP^{-1} \; , \text{ where }  P=[ \vu \ \vw ]\,\text{.}
\end{equation*}
</div>
</li>
</ul></section><section class="exercises" id="sec_comp_eigen_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-200"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-345"><p id="p-3570">Find eigenvalues and eigenvectors of each of the following matrices.</p></div>
<article class="task exercise-like" id="task-1188"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3571"><span class="process-math">\(\left[ \begin{array}{rc} 2\amp 4 \\ -2\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1189"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3573"><span class="process-math">\(\left[ \begin{array}{rc} 3\amp 2 \\ -1\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1190"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3575"><span class="process-math">\(\left[ \begin{array}{cr} 1\amp -2 \\ 4\amp -3 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-201"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-3577">Find a rotation-scaling matrix where the rotation angle is <span class="process-math">\(\theta=3\pi/4\)</span> and scaling factor is less than 1.</p></article><article class="exercise exercise-like" id="exercise-202"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-3578">Determine which rotation-scaling matrices have determinant equal to 1. Be as specific as possible.</p></article><article class="exercise exercise-like" id="exercise-203"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-3580">Determine the rotation-scaling matrix inside the matrix <span class="process-math">\(\left[ \begin{array}{rc} 2\amp 4 \\ -2\amp 2 \end{array} \right]\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-204"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-3581">Find a real <span class="process-math">\(2\times 2\)</span> matrix with eigenvalue <span class="process-math">\(1+2i\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-205"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-3583">Find a real <span class="process-math">\(2\times 2\)</span> matrix which is not a rotation-scaling matrix with eigenvalue <span class="process-math">\(-1+2i\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-206"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-346"><p id="p-3584">We have seen how to find the characteristic polynomial of an <span class="process-math">\(n \times n\)</span> matrix. In this exercise we consider the reverse question. That is, given a polynomial <span class="process-math">\(p(\lambda)\)</span> of degree <span class="process-math">\(n\text{,}\)</span> can we find an <span class="process-math">\(n \times n\)</span> matrix whose characteristic polynomial is <span class="process-math">\(p(\lambda)\text{?}\)</span></p></div>
<article class="task exercise-like" id="task-1191"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3585">Find the characteristic polynomial of the <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(C = \left[ \begin{array}{cc} 0\amp -a_0\\1\amp -a_1 \end{array} \right]\text{.}\)</span> Use this result to find a real valued matrix whose eigenvalues are <span class="process-math">\(1+i\)</span> and <span class="process-math">\(1-i\text{.}\)</span></p></article><article class="task exercise-like" id="task-1192"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3587">Repeat part (a) by showing that <span class="process-math">\(p(\lambda) = -\left(\lambda^3+a_2\lambda^2+a_1\lambda+a_0\right)\)</span> is the characteristic polynomial of the <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(C = \left[ \begin{array}{ccc} 0\amp 0\amp -a_0\\1\amp 0\amp -a_1\\0\amp 1\amp -a_2 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-1193"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3589">We can generalize this argument. Prove, using mathematical induction, that the polynomial</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(\lambda) =(-1)^n\left( \lambda^n + a_{n-1}\lambda^{n-1} + a_{n-2}\lambda^{n-2} + \cdots + a_1 \lambda + a_0\right)
\end{equation*}
</div>
<p class="continuation">is the characteristic polynomial of the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
C = \left[ \begin{array}{cccccc} 0\amp 0\amp 0\amp \cdots\amp 0\amp -a_{0}\\ 1\amp 0\amp 0\amp \cdots\amp 0\amp -a_{1} \\ 0\amp 1\amp 0\amp \cdots\amp 0\amp -a_2 \\ \vdots \amp  \vdots \amp \vdots\amp  \ddots \amp  \vdots   \amp  \vdots   \\ 0 \amp  0 \amp  0\amp  \cdots \amp   1 \amp  -a_{n-1} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">The matrix <span class="process-math">\(C\)</span> is called the <dfn class="terminology">companion matrix</dfn> for <span class="process-math">\(p(\lambda)\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-207"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-347"><p id="p-3590">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1194"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3591">If <span class="process-math">\(3-4i\)</span> is an eigenvalue of a real matrix, then so is <span class="process-math">\(3+4i\text{.}\)</span></p></article><article class="task exercise-like" id="task-1195"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3593">If <span class="process-math">\(2+3i\)</span> is an eigenvalue of a <span class="process-math">\(3\times 3\)</span> real matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(A\)</span> has three distinct eigenvalues.</p></article><article class="task exercise-like" id="task-1196"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3594">Every <span class="process-math">\(2\times 2\)</span> real matrix with complex eigenvalues is a rotation-scaling matrix.</p></article><article class="task exercise-like" id="task-1197"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3596">Every square matrix with real entries has real number eigenvalues.</p></article><article class="task exercise-like" id="task-1198"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3597">If <span class="process-math">\(A\)</span> is a <span class="process-math">\(2\times 2\)</span> matrix with complex eigenvalues similar to a rotation-scaling matrix <span class="process-math">\(R\text{,}\)</span> the eigenvalues of <span class="process-math">\(A\)</span> and <span class="process-math">\(R\)</span> are the same.</p></article><article class="task exercise-like" id="task-1199"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3599">If <span class="process-math">\(A\)</span> is a real matrix with complex eigenvalues, all eigenvectors of <span class="process-math">\(A\)</span> must be non-real.</p></article></article></section><section class="section" id="sec_proj_gershgorin"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Understanding the Gershgorin Disk Theorem</span>
</h3>
<p id="p-3600">To understand the Gershgorin Disk Theorem, we need to recall how to visualize a complex number in the plane. Recall that a complex number <span class="process-math">\(z\)</span> is a number of the form <span class="process-math">\(z = a+bi\)</span> where <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> are real numbers and <span class="process-math">\(i^2 = -1\text{.}\)</span> The number <span class="process-math">\(a\)</span> is the real part of <span class="process-math">\(z\text{,}\)</span> denoted as <span class="process-math">\(\text{ Re } (z)\text{,}\)</span> and <span class="process-math">\(b\)</span> is the imaginary part of <span class="process-math">\(z\text{,}\)</span> denoted <span class="process-math">\(\text{ Im } (z)\text{.}\)</span> The set of all complex numbers is denoted <span class="process-math">\(\C\text{.}\)</span> We define addition and multiplication on <span class="process-math">\(\C\)</span> as follows. For <span class="process-math">\(a+bi, c+di \in \C\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(a+bi) + (c+di) = (a+c) + (b+d)i \ \ \ \ \ \text{ and }  \ \ \ \ \ (a+bi)(c+di) = (ac-bd) + (ad+bc)i\text{.}
\end{equation*}
</div>
<p id="p-3601">Note that the product is what we would expect if we “expanded” the product in the normal way and used the fact that <span class="process-math">\(i^2=-1\text{.}\)</span> The set of complex numbers forms a field — that is, <span class="process-math">\(\C\)</span> satisfies all of the same properties as <span class="process-math">\(\R\)</span> as stated in <a href="" class="xref" data-knowl="./knowl/thm_1_d_reals.html" title="Theorem 4.3">Theorem 4.3</a>.</p>
<p id="p-3602">We can visualize the complex number <span class="process-math">\(a+bi\)</span> in the plane as the point <span class="process-math">\((a,b)\text{.}\)</span> Here we are viewing the horizontal axis as the real axis and the vertical axis as the imaginary axis. The length (or magnitude) of the complex number <span class="process-math">\(z = a+bi\text{,}\)</span> which we denote as <span class="process-math">\(|z|\text{,}\)</span> is the distance from the origin to <span class="process-math">\(z\text{.}\)</span> So by the Pythagorean Theorem we have <span class="process-math">\(|a+bi| = \sqrt{a^2+b^2}\text{.}\)</span> Note that the magnitude of <span class="process-math">\(z = a+bi\)</span> can be written as a complex product</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|z| = \sqrt{(a+bi)(a-bi)}\text{.}
\end{equation*}
</div>
<p id="p-3603">The complex number <span class="process-math">\(a-bi\)</span> is called the <dfn class="terminology">complex conjugate</dfn> of <span class="process-math">\(z=a+bi\)</span> and is denoted as <span class="process-math">\(\overline{z}\text{.}\)</span> A few important properties of real numbers and their conjugates are the following. Let <span class="process-math">\(z = a+bi\)</span> and <span class="process-math">\(w = c+di\)</span> be complex numbers. Then</p>
<ul class="disc">
<li id="li-612"><p id="p-3604"><span class="process-math">\(\overline{z+w} = \overline{(a+c) + (b+d)i} = (a+c)-(b+d)i = (a-bi) + (c-di) = \overline{z} + \overline{w}\text{,}\)</span></p></li>
<li id="li-613"><p id="p-3605"><span class="process-math">\(\overline{zw} = \overline{(ac-bd) + (ad+bc)i} = (ac-bd)-(ad+bc)i = (a-bi)(c-di) = \overline{z} \overline{w}\text{,}\)</span></p></li>
<li id="li-614"><p id="p-3606"><span class="process-math">\(\overline{\overline{z}} = z\text{,}\)</span></p></li>
<li id="li-615"><p id="p-3607"><span class="process-math">\(|z| = \sqrt{a^2+b^2} \geq \sqrt{a^2} = |a| = |\text{ Re } (z)|\text{,}\)</span></p></li>
<li id="li-616"><p id="p-3608"><span class="process-math">\(|z| = \sqrt{a^2+b^2} \geq \sqrt{b^2} = |b| = |\text{ Im } (z)|\text{,}\)</span></p></li>
<li id="li-617"><p id="p-3609"><span class="process-math">\(\left| \overline{z} \right| = |z|\text{,}\)</span></p></li>
<li id="li-618"><p id="p-3610"><span class="process-math">\(|z| = 0\)</span> if and only if <span class="process-math">\(z = 0\text{,}\)</span></p></li>
<li id="li-619"><p id="p-3611">If <span class="process-math">\(p(x)\)</span> is a polynomial with real coefficients and the complex number <span class="process-math">\(z\)</span> satisfies <span class="process-math">\(p(z) = 0\text{,}\)</span> then <span class="process-math">\(p\left(\overline{z}\right) = 0\)</span> as well.</p></li>
</ul>
<p id="p-3612">Using these facts we can show that the triangle inequality is true for complex numbers. That is,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|z+w| \leq |z| + |w|\text{.}
\end{equation*}
</div>
<p id="p-3613">To see why, notice that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-148">
\begin{align*}
|z+w|^2 \amp = (z+w)(\overline{z+w})\\
\amp = (z+w)(\overline{z} + \overline{w})\\
\amp = z\overline{z} + z\overline{w} + w \overline{z} + w \overline{w}\\
\amp = z\overline{z} + z\overline{w} + \overline{zw\overline{w}} + w \overline{w}\\
\amp = |z|^2 + 2\text{ Re } (z\overline{w}) + |w|^2\\
\amp \leq |z|^2 + 2|zw| + |w|^2\\
\amp = |z|^2 + 2|z| |w| + |w|^2\\
\amp = (|z|+|w|)^2\text{.}
\end{align*}
</div>
<p id="p-3614">Since <span class="process-math">\(|z+w|\text{,}\)</span> <span class="process-math">\(|z|\text{,}\)</span> and <span class="process-math">\(|w|\)</span> are all non-negative, taking square roots of both sides gives us <span class="process-math">\(|z+w| \leq |z| + |w|\)</span> as desired. We can extend this triangle inequality to any number of complex numbers. That is, if <span class="process-math">\(z_1\text{,}\)</span> <span class="process-math">\(z_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(z_k\)</span> are complex numbers, then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_general_triangle_inequaltity">
\begin{equation}
|z_1+z_2+ \cdots + z_k| \leq |z_1| + |z_2| + \cdots + |z_k|\text{.}\tag{21.1}
\end{equation}
</div>
<p id="p-3615">We can prove Equation <a href="" class="xref" data-knowl="./knowl/eq_general_triangle_inequaltity.html" title="Equation 21.1">(21.1)</a> by mathematical induction. We have already done the <span class="process-math">\(k=2\)</span> case and so we assume that Equation <a href="" class="xref" data-knowl="./knowl/eq_general_triangle_inequaltity.html" title="Equation 21.1">(21.1)</a> is true for any sum of <span class="process-math">\(k\)</span> complex numbers. Now suppose that <span class="process-math">\(z_1\text{,}\)</span> <span class="process-math">\(z_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(z_k\text{,}\)</span> <span class="process-math">\(z_{k+1}\)</span> are complex numbers. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_general_triangle_inequaltity.html ./knowl/eq_general_triangle_inequaltity.html" id="md-149">
\begin{align*}
|z_1+z_2+ \cdots + z_k + z_{k+1}| \amp = |(z_1+z_2+ \cdots + z_k) + z_{k+1}|\\
\amp \leq |z_1+z_2+ \cdots + z_k| + |z_{k+1}|\\
\amp \leq (|z_1| + |z_2| + \cdots + |z_k|) + |z_{k+1}|\\
\amp = |z_1| + |z_2| + \cdots + |z_k| + |z_{k+1}|\text{.}
\end{align*}
</div>
<p id="p-3616">To prove the Gershgorin Disk Theorem, we will use the Levy-Desplanques Theorem, which gives conditions that guarantee that a matrix is invertible. We illustrate with an example in the following activity.</p>
<article class="project project-like" id="act_Gershgorin_1"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">21.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-348">
<p id="p-3617">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 3\amp 2 \\ -1\amp 4 \end{array}  \right]\text{.}\)</span> Since <span class="process-math">\(\det(A) \neq 0\text{,}\)</span> we know that <span class="process-math">\(A\)</span> is an invertible matrix. Let us assume for a moment that we don't know that <span class="process-math">\(A\)</span> is invertible and try to determine if 0 is an eigenvalue of <span class="process-math">\(A\text{.}\)</span> In other words, we want to know if there is a nonzero vector <span class="process-math">\(\vv\)</span> so that <span class="process-math">\(A \vv = \vzero\text{.}\)</span> Assuming the existence of such a vector <span class="process-math">\(\vv = [v_1 \ v_2]^{\tr}\text{,}\)</span> for <span class="process-math">\(A \vv\)</span> to be <span class="process-math">\(\vzero\)</span> it must be the case that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
3v_1 + 2v_2 = 0\ \text{ and }  \ -v_1 + 4v_2 = 0\text{.}
\end{equation*}
</div>
<p id="p-3618">Since the vector <span class="process-math">\(\vv\)</span> is not the zero vector, at least one of <span class="process-math">\(v_1\text{,}\)</span> <span class="process-math">\(v_2\)</span> is not zero. Note that if one of <span class="process-math">\(v_1\text{,}\)</span> <span class="process-math">\(v_2\)</span> is zero, the so is the other. So we can assume that <span class="process-math">\(v_1\)</span> and <span class="process-math">\(v_2\)</span> are nonzero.</p>
</div>
<article class="task exercise-like" id="task-1200"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3619">Use the fact that <span class="process-math">\(3v_1+2v_2 = 0\)</span> to show that <span class="process-math">\(|v_2| &gt; |v_1|\text{.}\)</span></p></article><article class="task exercise-like" id="task-1201"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3620">Use the fact that <span class="process-math">\(-v_1 + 4v_2 = 0\)</span> to show that <span class="process-math">\(|v_1| &gt; |v_2|\text{.}\)</span> What conclusion can we draw about whether 0 is an eigenvalue of <span class="process-math">\(A\text{?}\)</span> Why does this mean that <span class="process-math">\(A\)</span> is invertible?</p></article></article><p id="p-3621">What makes the arguments work in <a href="" class="xref" data-knowl="./knowl/act_Gershgorin_1.html" title="Project Activity 21.6">Project Activity 21.6</a> is that <span class="process-math">\(|3| &gt; |2|\)</span> and <span class="process-math">\(|4| &gt; |-1|\text{.}\)</span> This argument can be extended to larger matrices, as described in the following theorem.</p>
<article class="theorem theorem-like" id="theorem-45"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">21.5</span><span class="period">.</span><span class="space"> </span><span class="title">Levy-Desplanques Theorem.</span>
</h4>
<p id="p-3622">Any square matrix <span class="process-math">\(A = [a_{ij}]\)</span> satisfying <span class="process-math">\(|a_{ii}| &gt; \sum_{j \neq i} |a_{ij}|\)</span> for all <span class="process-math">\(i\)</span> is invertible.</p></article><article class="proof" id="proof-7"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-3623">Let <span class="process-math">\(A = [a_{ij}]\)</span> be an <span class="process-math">\(n \times n\)</span> matrix satisfying <span class="process-math">\(|a_{ii}| &gt; \sum_{j \neq i} |a_{ij}|\)</span> for all <span class="process-math">\(i\text{.}\)</span> Let us assume that <span class="process-math">\(A\)</span> is not invertible, that is that there is a vector <span class="process-math">\(\vv \neq \vzero\)</span> such that <span class="process-math">\(A \vv = \vzero\text{.}\)</span> Let <span class="process-math">\(\vv = [v_1 \ v_2 \ \cdots \ v_n]\)</span> and <span class="process-math">\(t\)</span> be between 1 and <span class="process-math">\(n\)</span> so that <span class="process-math">\(|v_t| \geq |v_i|\)</span> for all <span class="process-math">\(i\text{.}\)</span> That is, choose <span class="process-math">\(v_t\)</span> to be the component of <span class="process-math">\(\vv\)</span> with the largest absolute value.</p>
<p id="p-3624">Expanding the product <span class="process-math">\(A\vv\)</span> using the row-column product along the <span class="process-math">\(t\)</span>th row shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{t1}v_1 + a_{t2}v_2 + \cdots a_{tn}v_n = 0\text{.}
\end{equation*}
</div>
<p id="p-3625">Solving for the <span class="process-math">\(a_{tt}\)</span> term gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{tt}v_t = -(a_{t1}v_1 + a_{t2}v_2 + \cdots a_{t(t-1)}v_{t-1}+a_{t(t+1)}v_{t+1} + \cdots + a_{tn}v_n)\text{.}
\end{equation*}
</div>
<p id="p-3626">Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-150">
\begin{align*}
|a_{tt}| |v_t| \amp = |-(a_{t1}v_1 + a_{t2}v_2 + \cdots a_{t(t-1)}v_{t-1}+a_{t(t+1)}v_{t+1} + \cdots + a_{tn}v_n|\\
\amp = |a_{t1}v_1 + a_{t2}v_2 + \cdots a_{t(t-1)}v_{t-1}+a_{t(t+1)}v_{t+1} + \cdots + a_{tn}v_n|\\
\amp \leq |a_{t1}| |v_1| + |a_{t2}| |v_2| + \cdots |a_{t(t-1)}| |v_{t-1}| + |a_{t(t+1)}| |v_{t+1}| + \cdots + |a_{tn}| |v_n|\\
\amp \leq |a_{t1}| |v_t| + |a_{t2}| |v_t| + \cdots |a_{t(t-1)}| |v_{t}| + |a_{t(t+1)}| |v_{t}| + \cdots + |a_{tn}| |v_t|\\
\amp =  (|a_{t1}| + |a_{t2}| + \cdots |a_{t(t-1)}|  + |a_{t(t+1)}| + \cdots + |a_{tn}|) |v_t|\text{.}
\end{align*}
</div>
<p id="p-3627">Since <span class="process-math">\(|v_t| \neq 0\text{,}\)</span> we cancel the <span class="process-math">\(|v_t|\)</span> term to conclude that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|a_{tt}| \leq  |a_{t1}| + |a_{t2}| + \cdots |a_{t(t-1)}|  + |a_{t(t+1)}| + \cdots + |a_{tn}|\text{.}
\end{equation*}
</div>
<p id="p-3628">But this contradicts the condition that <span class="process-math">\(|a_{ii}| &gt; \sum_{j \neq i} |a_{ij}|\)</span> for all <span class="process-math">\(i\text{.}\)</span> We conclude that 0 is not an eigenvalue for <span class="process-math">\(A\)</span> and <span class="process-math">\(A\)</span> is invertible.</p></article><p id="p-3629">Any matrix <span class="process-math">\(A = [a_{ij}]\)</span> satisfying the condition of the Levy-Desplanques Theorem is given a special name.</p>
<article class="definition definition-like" id="definition-45"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">21.6</span><span class="period">.</span>
</h4>
<p id="p-3630">A square matrix <span class="process-math">\(A = [a_{ij}]\)</span> is <dfn class="terminology">strictly diagonally dominant</dfn> if <span class="process-math">\(|a_{ii}| &gt; \sum_{j \neq i} |a_{ij}|\)</span> for all <span class="process-math">\(i\text{.}\)</span></p></article><p id="p-3631">So any strictly diagonally dominant matrix is invertible. A quick glance can show that a matrix is strictly diagonally dominant. For example, since <span class="process-math">\(|3| &gt; |1| + |-1|\text{,}\)</span> <span class="process-math">\(|12| &gt; |5| +|6|\text{,}\)</span> and <span class="process-math">\(|-8| &gt; |-2| + |4|\text{,}\)</span> the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{rcr} 3\amp 1\amp -1 \\ 5\amp 12\amp 6 \\ -2\amp 4\amp -8 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">is strictly diagonally dominant and therefore invertible. However, just because a matrix is not strictly diagonally dominant, it does not follow that the matrix is non-invertible. For example, the matrix <span class="process-math">\(B = \left[ \begin{array}{cc} 1\amp 2 \\ 0\amp 1 \end{array}  \right]\)</span> is invertible, but not strictly diagonally dominant.</p>
<p id="p-3632">Now we can address the Gershgorin Disk Theorem.</p>
<article class="activity project-like" id="act_Gershgorin_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">21.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-349"><p id="p-3633">Let <span class="process-math">\(A\)</span> be an arbitrary <span class="process-math">\(n \times n\)</span> matrix and assume that <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1202"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3634">Explain why the matrix <span class="process-math">\(A - \lambda I\)</span> is singular.</p></article><article class="task exercise-like" id="task-1203"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3635">What does the Levy-Desplanques Theorem tell us about the matrix <span class="process-math">\(A - \lambda I\text{?}\)</span></p></article><article class="task exercise-like" id="task-1204"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3636">Explain how we can conclude the Gershgorin Disk Theorem. <article class="theorem theorem-like" id="thm_Gershgorin"><h6 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">21.7</span><span class="period">.</span><span class="space"> </span><span class="title">Gershgorin Disk Theorem.</span>
</h6>
<p id="p-3637">Let <span class="process-math">\(A=[a_{ij}]\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with complex entries. Then every eigenvalue of <span class="process-math">\(A\)</span> lies in one of the Gershgorin discs</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{z \in \C : |z-a_{ii}| \leq r_i\}\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(r_i = \sum_{j \neq i} |a_{ij}|\text{.}\)</span></p></article> Based on this theorem, we define a Gershgorin disk to be <span class="process-math">\(D(a_{ii}, r_i)\text{,}\)</span> where <span class="process-math">\(r_i =  \sum_{j \neq i} |a_{ij}|\text{.}\)</span></p></article><article class="task exercise-like" id="task-1205"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3638">Use the Gershgorin Disk Theorem to give estimates on the locations of the eigenvalues of the matrix <span class="process-math">\(A = \left[ \begin{array}{rr} -1\amp 2 \\ -3\amp 2 \end{array} \right]\text{.}\)</span></p></article></article><p id="p-3639">The Gershgorin Disk Theorem has a consequence that gives additional information about the eigenvalues if some of the Gershgorin disks do not overlap.</p>
<article class="theorem theorem-like" id="thm_Gersgorin_consequence"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">21.8</span><span class="period">.</span>
</h4>
<p id="p-3640">If <span class="process-math">\(S\)</span> is a union of <span class="process-math">\(m\)</span> Gershgorin disks of a matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(S\)</span> does not intersect any other Gershgorin disk, then <span class="process-math">\(S\)</span> contains exactly <span class="process-math">\(m\)</span> eigenvalues (counting multiplicities) of <span class="process-math">\(A\text{.}\)</span></p></article><article class="proof" id="proof-8"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-3641">Most proofs of this theorem require some results from topology. For that reason, we will not present a completely rigorous proof but rather give the highlights. Let <span class="process-math">\(A = [a_{ij}]\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. Let <span class="process-math">\(D_i\)</span> be a collection of Gershgorin disks of <span class="process-math">\(A\)</span> for <span class="process-math">\(1 \leq i \leq m\)</span> such that <span class="process-math">\(S = \cup_{1 \leq i \leq m} D_i\)</span> does not intersect any other Gershgorin disk of <span class="process-math">\(A\text{,}\)</span> and let <span class="process-math">\(S'\)</span> be the union of the Gershgorin disks of <span class="process-math">\(A\)</span> that are different from the <span class="process-math">\(D_i\text{.}\)</span> Note that <span class="process-math">\(S \cap S' = \emptyset\text{.}\)</span> Let <span class="process-math">\(C\)</span> be the matrix whose <span class="process-math">\(i\)</span>th column is <span class="process-math">\(a_{ii}\ve_i\text{,}\)</span> that is <span class="process-math">\(C\)</span> is the diagonal matrix whose diagonal entries are the corresponding diagonal entries of <span class="process-math">\(A\text{.}\)</span> Note that the eigenvalues of <span class="process-math">\(C\)</span> are <span class="process-math">\(a_{ii}\)</span> and the Gershgorin disks of <span class="process-math">\(C\)</span> are just the points <span class="process-math">\(a_{ii}\text{.}\)</span> So our theorem is true for this matrix <span class="process-math">\(C\text{.}\)</span> To prove the result, we build a continuum of matrices from <span class="process-math">\(C\)</span> to <span class="process-math">\(A\)</span> as follows: let <span class="process-math">\(B = A-C\)</span> (so that <span class="process-math">\(B\)</span> is the matrix whose off-diagonal entries are those of <span class="process-math">\(A\)</span> and whose diagonal entries are 0), and let <span class="process-math">\(A(t) = tB + C\)</span> for <span class="process-math">\(t\)</span> in the interval <span class="process-math">\([0,1]\text{.}\)</span> Note that <span class="process-math">\(A(1) = A\text{.}\)</span> Since the diagonal entries of <span class="process-math">\(A(t)\)</span> are the same as those of <span class="process-math">\(A\text{,}\)</span> the Gershgorin disks of <span class="process-math">\(A(t)\)</span> have the same centers as the corresponding Gershgorin disks of <span class="process-math">\(A\text{,}\)</span> while the radii of the Gershgorin disks of <span class="process-math">\(A(t)\)</span> are those of <span class="process-math">\(A\)</span> but scaled by <span class="process-math">\(t\text{.}\)</span> So the Gershgorin disks of <span class="process-math">\(A(t)\)</span> increase from points (the <span class="process-math">\(a_{ii}\)</span>) to the Gershgorin disks of <span class="process-math">\(A\)</span> as <span class="process-math">\(t\)</span> increases from 0 to 1. While the centers of the disks all remain fixed, it is important to recognize that the eigenvalues of <span class="process-math">\(A(t)\)</span> move as <span class="process-math">\(t\)</span> changes. An illustration of this is shown in <a href="" class="xref" data-knowl="./knowl/F_Gershgorin_2.html" title="Figure 21.9">Figure 21.9</a> with the eigenvalues as the black points and the changing Gershgorin disks dashed in magenta, using the matrix <span class="process-math">\(\left[ \begin{array}{cc} i\amp \frac{1}{2} \\ 1\amp -2+i \end{array} \right]\text{.}\)</span> We can learn about how the eigenvalues move with the characteristic polynomial.</p>
<figure class="figure figure-like" id="F_Gershgorin_2"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/Gershgorin_2.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">21.9<span class="period">.</span></span><span class="space"> </span>How eigenvalues move.</figcaption></figure><p id="p-3642">Let <span class="process-math">\(p(t,x)\)</span> be the characteristic polynomial of <span class="process-math">\(A(t)\text{.}\)</span> Note that these characteristic polynomials are functions of both <span class="process-math">\(t\)</span> and <span class="process-math">\(x\text{.}\)</span> Since polynomials are continuous functions, their roots (the eigenvalues of <span class="process-math">\(A(t)\)</span>) are continuous for <span class="process-math">\(t \in [0,1]\)</span> as well. Let <span class="process-math">\(\lambda(t)\)</span> be an eigenvalue of <span class="process-math">\(A(t)\text{.}\)</span> Note that <span class="process-math">\(\lambda(1)\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> and <span class="process-math">\(\lambda(0)\)</span> is one of the <span class="process-math">\(a_{ii}\)</span> and is therefore in <span class="process-math">\(S\text{.}\)</span> We will argue that <span class="process-math">\(\lambda(t)\)</span> is in <span class="process-math">\(S\)</span> for every value of <span class="process-math">\(t\)</span> in <span class="process-math">\([0,1]\text{.}\)</span> Let <span class="process-math">\(r_i\)</span> be the radius of <span class="process-math">\(D_i\)</span> and let <span class="process-math">\(D(t)_i\)</span> be the Gershgorin disk of <span class="process-math">\(A(t)\)</span> with the same center as <span class="process-math">\(D_i\)</span> and radius <span class="process-math">\(r(t)_i = tr_i\text{.}\)</span> Let <span class="process-math">\(S(t) = \cup_{1 \leq i \leq m} D(s)_i\text{.}\)</span> Since <span class="process-math">\(r(s)_i \leq r_i\text{,}\)</span> it follows that <span class="process-math">\(D(s)_i \subseteq D_i\)</span> and so <span class="process-math">\(S(t) \cap S' = \emptyset\)</span> as well. From topology, we know that since the disks <span class="process-math">\(D_i\)</span> are closed, the union <span class="process-math">\(S\)</span> of these disks is also closed. Similarly, <span class="process-math">\(S(t)\)</span> and <span class="process-math">\(S'\)</span> are closed. Thus, <span class="process-math">\(\lambda(t)\)</span> is continuous in a closed set and so does not leave the set. Thus, <span class="process-math">\(\lambda(t)\)</span> is in <span class="process-math">\(S\)</span> for every value of <span class="process-math">\(t\)</span> in <span class="process-math">\([0,1]\text{.}\)</span></p></article></section></section></div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
