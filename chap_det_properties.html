<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Properties of Determinants</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
},
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{colortbl}\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_complex_eigenvalues.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="part-orthog.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_complex_eigenvalues.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a class="next-button button toolbar-item" href="part-orthog.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="chapter" id="chap_det_properties"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">22</span> <span class="title">Properties of Determinants</span>
</h2>
<section class="introduction" id="introduction-350"><article class="objectives goal-like" id="objectives-22"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-351"><p id="p-3643">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-620"><p id="p-3644">How do elementary row operations change the determinant?</p></li>
<li id="li-621"><p id="p-3645">How can we represent elementary row operations via matrix multiplication?</p></li>
<li id="li-622"><p id="p-3646">How can we use elementary row operations to calculate the determinant more efficiently?</p></li>
<li id="li-623"><p id="p-3647">What is the Cramer's rule for the explicit formula for the inverse of a matrix?</p></li>
<li id="li-624"><p id="p-3648">How can we interpret determinants from a geometric perspective?</p></li>
<li id="li-625"><p id="p-3649">What is an <span class="process-math">\(LU\)</span> factorization of a matrix and why is such a factorization useful?</p></li>
</ul></article></section><section class="section" id="sec_det_prop_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-3650">This section is different than others in that it contains mainly proofs of previously stated results and only a little new material. Consequently, there is no application attached to this section.</p>
<p id="p-3651">We have seen that an important property of the determinant is that it provides an easy criteria for the invertibility of a matrix. As a result, we obtained an algebraic method for finding the eigenvalues of a matrix, using the characteristic equation. In this section, we will investigate other properties of the determinant related to how elementary row operations change the determinant. These properties of the determinant will help us evaluate the determinant in a more efficient way compared to using the cofactor expansion method, which is computationally intensive for large <span class="process-math">\(n\)</span> values due to it being a recursive method. Finally, we will derive a geometrical interpretation of the determinant.</p>
<article class="exploration project-like" id="pa_4_f"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">22.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1206"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-352"><p id="p-3652">We first consider how the determinant changes if we multiply a row of the matrix by a constant.</p></div>
<article class="task exercise-like" id="task-1207"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3653">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 3 \\ 1\amp 4 \end{array} \right]\text{.}\)</span> Pick a few different values for the constant <span class="process-math">\(k\)</span> and compare the determinant of <span class="process-math">\(A\)</span> and that of <span class="process-math">\(\left[ \begin{array}{cc} 2k\amp 3k \\ 1\amp 4 \end{array} \right]\text{.}\)</span> What do you conjecture that the effect of multiplying a row by a constant on the determinant is?</p></article><article class="task exercise-like" id="task-1208"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3654">If we want to make sure our conjecture is valid for any <span class="process-math">\(2\times 2\)</span> matrix, we need to show that for <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp b\\c\amp d \end{array} \right]\text{,}\)</span> the relationship between <span class="process-math">\(\det(A)\)</span> and the determinant of <span class="process-math">\(\left[ \begin{array}{cc} a\cdot k\amp b\cdot k\\c\amp d \end{array} \right]\)</span> follows our conjecture. We should also check that the relationship between <span class="process-math">\(\det(A)\)</span> and the determinant of <span class="process-math">\(\left[ \begin{array}{cc} a\amp b\\c\cdot k\amp d\cdot k \end{array} \right]\)</span> follows our conjecture. Verify this.</p></article><article class="task exercise-like" id="task-1209"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3655">Make a similar conjecture for what happens to the determinant when a row of a <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\)</span> is multiplied by a constant <span class="process-math">\(k\text{,}\)</span> and explain why your conjecture is true using the cofactor expansion definition of the determinant.</p></article></article><article class="task exercise-like" id="task-1210"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-353"><p id="p-3656">The second type of elementary row operation we consider is row swapping.</p></div>
<article class="task exercise-like" id="task-1211"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3657">Take a general <span class="process-math">\(2\times 2\)</span> matrix <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp b\\c\amp d \end{array} \right]\)</span> and determine how row swapping effects the determinant.</p></article><article class="task exercise-like" id="task-1212"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3658">Now choose a few different <span class="process-math">\(3\times 3\)</span> matrices and see how row swapping changes the determinant in these matrices by evaluating the determinant with a calculator or any other appropriate technology.</p></article><article class="task exercise-like" id="task-1213"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3659">Based on your results so far, conjecture how row swapping changes the determinant in general.</p></article></article><article class="task exercise-like" id="task-1214"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3660">The last type of elementary row operation is adding a multiple of a row to another. Determine the effect of this operation on a <span class="process-math">\(2\times 2\)</span> matrix by evaluating the determinant of a general <span class="process-math">\(2\times 2\)</span> matrix after a multiple of one row is added to the other row.</p></article><article class="task exercise-like" id="task-1215"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<div class="introduction" id="introduction-354"><p id="p-3661">All of the elementary row operations we discussed above can be achieved by matrix multiplication with <dfn class="terminology">elementary matrices</dfn>. For each of the following elementary matrices, determine what elementary operation it corresponds to by calculating the product <span class="process-math">\(EA\text{,}\)</span> where <span class="process-math">\(A = \left[ \begin{array}{ccc} a_{11}\amp a_{12}\amp a_{13}\\a_{21}\amp a_{22}\amp a_{23}\\a_{31}\amp a_{32}\amp a_{33} \end{array} \right]\)</span> is a general <span class="process-math">\(3\times 3\)</span> matrix.</p></div>
<article class="task exercise-like" id="task-1216"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3662"><span class="process-math">\(E = \left[ \begin{array}{ccc} 0\amp 1\amp 0\\ 1\amp 0\amp 0 \\ 0\amp 0\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1217"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3663"><span class="process-math">\(E = \left[ \begin{array}{ccc} 1\amp 0\amp 0\\ 0\amp 3\amp 0 \\ 0\amp 0\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1218"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3664"><span class="process-math">\(E = \left[ \begin{array}{ccc} 1\amp 0\amp 0\\ 0\amp 1\amp 2 \\ 0\amp 0\amp 1 \end{array} \right]\)</span></p></article></article></article></section><section class="section" id="sec_det_row_ops"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Elementary Row Operations and Their Effects on the Determinant</span>
</h3>
<p id="p-3665">In <a href="" class="xref" data-knowl="./knowl/pa_4_f.html" title="Preview Activity 22.1">Preview Activity 22.1</a>, we conjectured how elementary row operations affect the determinant of a matrix. In the following activity, we prove how the determinant changes when a row is multiplied by a constant using the cofactor expansion definition of the determinant.</p>
<article class="activity project-like" id="act_4_f_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-355"><p id="p-3666">In this activity, assume that the determinant of <span class="process-math">\(A\)</span> can be determined by a cofactor expansion along any row or column. (We will prove this result independently later in this section.) Consider an arbitrary <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A = [a_{ij}]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1219"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3667">Write the expression for <span class="process-math">\(\det(A)\)</span> using the cofactor expansion along the second row.</p></article><article class="task exercise-like" id="task-1220"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3668">Let <span class="process-math">\(B\)</span> be obtained by multiplying the second row of <span class="process-math">\(A\)</span> by <span class="process-math">\(k\text{.}\)</span> Write the expression for <span class="process-math">\(\det(B)\)</span> if the cofactor expansion along the second row is used.</p></article><article class="task exercise-like" id="task-1221"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3669">Use the expressions you found above, to express <span class="process-math">\(\det(B)\)</span> in terms of <span class="process-math">\(\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1222"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3670">Explain how this method generalizes to prove the relationship between the determinant of a matrix <span class="process-math">\(A\)</span> and that of the matrix obtained by multiplying a row by a constant <span class="process-math">\(k\text{.}\)</span></p></article></article><p id="p-3671">Your work in <a href="" class="xref" data-knowl="./knowl/act_4_f_1.html" title="Activity 22.2">Activity 22.2</a> proves the first part of the following theorem on how elementary row operations change the determinant of a matrix.</p>
<article class="theorem theorem-like" id="thm_4_f_1"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.1</span><span class="period">.</span>
</h4>
<p id="p-3672">Let <span class="process-math">\(A\)</span> be a square matrix.</p>
<ol class="decimal">
<li id="li-626"><p id="p-3673">If <span class="process-math">\(B\)</span> is obtained by multiplying a row of <span class="process-math">\(A\)</span> by a constant <span class="process-math">\(k\text{,}\)</span> then <span class="process-math">\(\det(B)=k\det(A)\text{.}\)</span></p></li>
<li id="li-627"><p id="p-3674">If <span class="process-math">\(B\)</span> is obtained by swapping two rows of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\det(B)=-\det(A)\text{.}\)</span></p></li>
<li id="li-628"><p id="p-3675">If <span class="process-math">\(B\)</span> is obtained by adding a multiple of a row of <span class="process-math">\(A\)</span> to another, then <span class="process-math">\(\det(B)=\det(A)\text{.}\)</span></p></li>
</ol></article><p id="p-3676">In the next section, we will use elementary matrices to prove the last two properties of <a href="" class="xref" data-knowl="./knowl/thm_4_f_1.html" title="Theorem 22.1">Theorem 22.1</a>.</p></section><section class="section" id="sec_mtx_elem"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Elementary Matrices</span>
</h3>
<p id="p-3677">As we saw in <a href="" class="xref" data-knowl="./knowl/pa_4_f.html" title="Preview Activity 22.1">Preview Activity 22.1</a>, elementary row operations can be achieved by multiplication by <dfn class="terminology">elementary matrices</dfn>.</p>
<article class="definition definition-like" id="definition-46"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">22.2</span><span class="period">.</span>
</h4>
<p id="p-3678">An <dfn class="terminology">elementary matrix</dfn> is a matrix obtained by performing a single elementary row operation on an identity matrix.</p></article><p id="p-3679">The following elementary matrices correspond, respectively, to an elementary row operation which swaps rows 2 and 4; an elementary row operation which multiplies the third row by 5; and an elementary row operation which adds four times the third row to the first row on any <span class="process-math">\(4\times 4\)</span> matrix:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_1 = \left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 0\\0\amp 0\amp 0\amp 1\\0\amp 0\amp 1\amp 0\\ 0\amp 1\amp 0\amp 0 \end{array}  \right], \ \ E_2 = \left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 0\\0\amp 1\amp 0\amp 0\\0\amp 0\amp 5\amp 0 \\ 0\amp 0\amp 0\amp 1 \end{array}  \right], \ \ \text{ and }  \ \ E_3 = \left[ \begin{array}{cccc} 1\amp 0\amp 4\amp 0\\0\amp 1\amp 0\amp 0\\0\amp 0\amp 1\amp 0\\0\amp 0\amp 0\amp 1 \end{array}  \right]\,\text{.}
\end{equation*}
</div>
<p id="p-3680">To obtain an elementary matrix corresponding an elementary row operation, we simply perform the elementary row operation on the identity matrix. For example, <span class="process-math">\(E_1\)</span> above is obtained by swapping rows 2 and 4 of the identity matrix.</p>
<p id="p-3681">With the use of elementary matrices, we can now prove the result about how the determinant is affected by elementary row operations. We first rewrite <a href="" class="xref" data-knowl="./knowl/thm_4_f_1.html" title="Theorem 22.1">Theorem 22.1</a> in terms of elementary matrices:</p>
<article class="theorem theorem-like" id="thm_4_f_2"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.3</span><span class="period">.</span>
</h4>
<p id="p-3682">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix. If <span class="process-math">\(E\)</span> is an <span class="process-math">\(n\times n\)</span> elementary matrix, then <span class="process-math">\(\det(EA)=\det(E)\det(A)\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(E) = \left\{ \begin{array}{rl} r \amp  \text{ if \(E\) corresponds to multiplying a row by \(r\) }  \\ -1\amp  \text{ if \(E\) corresponds to swapping two rows }  \\ 1 \amp  \text{ if \(E\) corresponds to adding a multiple of a row to another. } \end{array}  \right.
\end{equation*}
</div></article><section class="paragraphs" id="paragraphs-26"><h4 class="heading"><span class="title">Notes on Theorem 22.3.</span></h4>
<p id="p-3683">An elementary matrix <span class="process-math">\(E\)</span> obtained by multiplying a row by <span class="process-math">\(r\)</span> is a diagonal matrix with one <span class="process-math">\(r\)</span> along the diagonal and the rest 1s, so <span class="process-math">\(\det(E) = r\text{.}\)</span> Similarly, an elementary matrix <span class="process-math">\(E\)</span> obtained by adding a multiple of a row to another is a triangular matrix with 1s along the diagonal, so <span class="process-math">\(\det(E) = 1\text{.}\)</span> The fact that the the determinant of an elementary matrix obtained by swapping two rows is <span class="process-math">\(-1\)</span> is a bit more complicated and is verified independently later in this section. Also, the proof of <a href="" class="xref" data-knowl="./knowl/thm_4_f_2.html" title="Theorem 22.3">Theorem 22.3</a> depends on the fact that the cofactor expansion of a matrix is the same along any two rows. A proof of this can also be found later in this section.</p></section><article class="proof" id="proof-9"><h4 class="heading"><span class="title">Proof of Theorem 22.3.</span></h4>
<p id="p-3684">We will prove the result by induction on <span class="process-math">\(n\text{,}\)</span> the size of the matrix <span class="process-math">\(A\text{.}\)</span> We verified these results in <a href="" class="xref" data-knowl="./knowl/pa_4_f.html" title="Preview Activity 22.1">Preview Activity 22.1</a> for <span class="process-math">\(n=2\)</span> using elementary row operations. The elementary matrix versions follow immediately.</p>
<p id="p-3685">Now assume the theorem is true for <span class="process-math">\(k\times k\)</span> matrices with <span class="process-math">\(k\geq 2\)</span> and consider an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> where <span class="process-math">\(n=k+1\text{.}\)</span> If <span class="process-math">\(E\)</span> is an <span class="process-math">\(n\times n\)</span> elementary matrix, we want to show that <span class="process-math">\(\det(EA)=\det(E)\det(A)\text{.}\)</span> Let <span class="process-math">\(EA=B\text{.}\)</span> (Although it is an abuse of language, we will refer to both the elementary matrix and the elementary row operation corresponding to it by <span class="process-math">\(E\text{.}\)</span>)</p>
<p id="p-3686">When finding <span class="process-math">\(\det(B)=\det(EA)\)</span> we will use a cofactor expansion along a row which is not affected by the elementary row operation <span class="process-math">\(E\text{.}\)</span> Since <span class="process-math">\(E\)</span> affects at most two rows and <span class="process-math">\(A\)</span> has <span class="process-math">\(n\geq 3\)</span> rows, it is possible to find such a row, say row <span class="process-math">\(i\text{.}\)</span> The cofactor expansion along row <span class="process-math">\(i\)</span> of <span class="process-math">\(B\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_f_1">
\begin{equation}
b_{i1} (-1)^{i+1} \det(B_{i1}) + b_{i2} (-1)^{i+2} \det(B_{i2}) + \cdots + b_{in} (-1)^{i+n} \det(B_{in}) \,\text{.}\tag{22.1}
\end{equation}
</div>
<p id="p-3687">Since we chose a row of <span class="process-math">\(A\)</span> which was not affected by the elementary row operation, it follows that <span class="process-math">\(b_{ij}=a_{ij}\)</span> for <span class="process-math">\(1\leq j\leq n\text{.}\)</span> Also, the matrix <span class="process-math">\(B_{ij}\)</span> obtained by removing row <span class="process-math">\(i\)</span> and column <span class="process-math">\(j\)</span> from matrix <span class="process-math">\(B=EA\)</span> can be obtained from <span class="process-math">\(A_{ij}\)</span> by an elementary row operation of the same type as <span class="process-math">\(E\text{.}\)</span> Hence there is an elementary matrix <span class="process-math">\(E_k\)</span> of the same type as <span class="process-math">\(E\)</span> with <span class="process-math">\(B_{ij}=E_k A_{ij}\text{.}\)</span> Therefore, by induction, <span class="process-math">\(\det(B_{ij})=\det(E_k)\det(A_{ij})\)</span> and <span class="process-math">\(\det(E_k)\)</span> is equal to 1, -1 or <span class="process-math">\(r\)</span> depending on the type of elementary row operation. If we substitute this information into equation <a href="" class="xref" data-knowl="./knowl/eq_4_f_1.html" title="Equation 22.1">(22.1)</a>, we obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_4_f_1.html">
\begin{equation*}
\begin{split} \det(B)\amp = a_{i1} (-1)^{i+1} \det(E_k) \det(A_{i1}) + a_{i2} (-1)^{i+2} \det(E_k) \det(A_{i2}) \\ \amp \qquad + \cdots + a_{in} (-1)^{i+n} \det(E_k) \det(A_{in})\\ \amp = \det(E_k) \det(A) \, . \end{split}
\end{equation*}
</div>
<p id="p-3688">This equation proves <span class="process-math">\(\det(EA)=\det(E_k)\det(A)\)</span> for any <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> where <span class="process-math">\(E_k\)</span> is the corresponding elementary row operation on the <span class="process-math">\(k\times k\)</span> matrices obtained in the cofactor expansion.</p>
<p id="p-3689">The proof of the inductive step will be finished if we show that <span class="process-math">\(\det(E_k)=\det(E)\text{.}\)</span> This equality follows if we let <span class="process-math">\(A=I_n\)</span> in <span class="process-math">\(\det(EA)=\det(E_k)\det(A)\text{.}\)</span> Therefore, <span class="process-math">\(\det(E)\)</span> is equal to <span class="process-math">\(r\text{,}\)</span> or 1, or <span class="process-math">\(-1\text{,}\)</span> depending on the type of the elementary row operation <span class="process-math">\(E\)</span> since the same is true of <span class="process-math">\(\det(E_k)\)</span> by inductive hypothesis.</p>
<p id="p-3690">Therefore, by the principle of induction, the claim is true for every <span class="process-math">\(n\geq 2\text{.}\)</span></p></article><p id="p-3691">As a corollary of this theorem, we can prove the multiplicativity of determinants:</p>
<article class="theorem theorem-like" id="thm_determinant_product"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.4</span><span class="period">.</span>
</h4>
<p id="p-3692">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be <span class="process-math">\(n\times n\)</span> matrices. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(AB)=\det(A)\det(B) \,\text{.}
\end{equation*}
</div></article><article class="proof" id="proof-10"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-3693">If <span class="process-math">\(A\)</span> is non-invertible, then <span class="process-math">\(AB\)</span> is also non-invertible and both <span class="process-math">\(\det(A)\)</span> and <span class="process-math">\(\det(AB)\)</span> are 0, proving the equality in this case.</p>
<p id="p-3694">Suppose now that <span class="process-math">\(A\)</span> is invertible. By the Invertible Matrix Theorem, we know that <span class="process-math">\(A\)</span> is row equivalent to <span class="process-math">\(I_n\text{.}\)</span> Expressed in terms of elementary matrices, this means that there are elementary matrices <span class="process-math">\(E_1, E_2, \ldots, E_\ell\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_f_2">
\begin{equation}
A= E_1 E_2 \cdots E_\ell I_n = E_1 E_2 \cdots E_\ell \,\text{.}\tag{22.2}
\end{equation}
</div>
<p id="p-3695">Therefore, repeatedly applying <a href="" class="xref" data-knowl="./knowl/thm_4_f_2.html" title="Theorem 22.3">Theorem 22.3</a>, we find that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/thm_4_f_2.html" id="eq_4_f_3">
\begin{equation}
\det(A) = \det(E_1) \det(E_2) \cdots \det(E_\ell) \,\text{.}\tag{22.3}
\end{equation}
</div>
<p id="p-3696">If we multiply equation <a href="" class="xref" data-knowl="./knowl/eq_4_f_2.html" title="Equation 22.2">(22.2)</a> by <span class="process-math">\(B\)</span> on the right, we obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_4_f_2.html">
\begin{equation*}
AB = E_1 E_2 \cdots E_\ell B \,\text{.}
\end{equation*}
</div>
<p id="p-3697">Again, by repeatedly applying <a href="" class="xref" data-knowl="./knowl/thm_4_f_2.html" title="Theorem 22.3">Theorem 22.3</a> with this product of matrices, we find</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/thm_4_f_2.html">
\begin{equation*}
\det(AB) = \det(E_1 E_2 \cdots E_\ell B ) = \det(E_1) \det(E_2) \cdots \det(E_\ell) \det(B) \,\text{.}
\end{equation*}
</div>
<p id="p-3698">From equation <a href="" class="xref" data-knowl="./knowl/eq_4_f_3.html" title="Equation 22.3">(22.3)</a>, the product of <span class="process-math">\(\det(E_i)\)</span>'s equals <span class="process-math">\(\det(A)\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_4_f_3.html">
\begin{equation*}
\det(AB) = \det(A) \det(B)
\end{equation*}
</div>
<p class="continuation">which finishes the proof of the theorem.</p></article><p id="p-3699">We can use the multiplicative property of the determinant and the determinants of elementary matrices to calculate the determinant of a matrix in a more efficient way than using the cofactor expansion. The next activity provides an example.</p>
<article class="activity project-like" id="act_4_f_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-356"><p id="p-3700">Let <span class="process-math">\(A=\left[ \begin{array}{rcc} 1\amp 1\amp 2\\ 2\amp 2\amp 6\\ -1\amp 2\amp 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1223"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3701">Use elementary row operations to reduce <span class="process-math">\(A\)</span> to a row echelon form. Keep track of the elementary row operation you use.</p></article><article class="task exercise-like" id="task-1224"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3702">Taking into account how elementary row operations affect the determinant, use the row echelon form of <span class="process-math">\(A\)</span> to calculate <span class="process-math">\(\det(A)\text{.}\)</span></p></article></article><p id="p-3703">Your work in <a href="" class="xref" data-knowl="./knowl/act_4_f_2.html" title="Activity 22.3">Activity 22.3</a> provides an efficient method for calculating the determinant. If <span class="process-math">\(A\)</span> is a square matrix, we use row operations given by elementary matrices <span class="process-math">\(E_1\text{,}\)</span> <span class="process-math">\(E_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(E_k\)</span> to row reduce <span class="process-math">\(A\)</span> to row echelon form <span class="process-math">\(R\text{.}\)</span> That is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4_f_2.html">
\begin{equation*}
R = E_kE_{k-1} \cdots E_2E_1A\text{.}
\end{equation*}
</div>
<p id="p-3704">We know <span class="process-math">\(\det(E_i)\)</span> for each <span class="process-math">\(i\text{,}\)</span> and since <span class="process-math">\(R\)</span> is a triangular matrix we can find its determinant. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = \det(E_1)^{-1}\det(E_2)^{-1} \cdots \det(E_2)^{-1}\det(R)\text{.}
\end{equation*}
</div>
<p id="p-3705">In other words, if we keep track of how the row operations affect the determinant, we can calculate the determinant of a matrix <span class="process-math">\(A\)</span> using row operations.</p>
<article class="activity project-like" id="act_4_f_2_b"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-357">
<p id="p-3706"><a href="" class="xref" data-knowl="./knowl/thm_4_f_2.html" title="Theorem 22.3">Theorem 22.3</a> and <a href="" class="xref" data-knowl="./knowl/thm_determinant_product.html" title="Theorem 22.4">Theorem 22.4</a> can be used to prove the following (part c of <a href="" class="xref" data-knowl="./knowl/thm_determinant_properties.html" title="Theorem 17.3">Theorem 17.3</a>) that <span class="process-math">\(A\)</span> is invertible if and only if <span class="process-math">\(\det(A) \neq 0\text{.}\)</span> We see how in this activity. Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. We can row reduce <span class="process-math">\(A\)</span> to its reduced row echelon form <span class="process-math">\(R\)</span> by elementary matrices <span class="process-math">\(E_1\text{,}\)</span> <span class="process-math">\(E_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(E_k\)</span> so that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/thm_4_f_2.html ./knowl/thm_determinant_product.html ./knowl/thm_determinant_properties.html">
\begin{equation*}
R = E_1E_2 \cdots E_kA\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-1225"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3707">Suppose <span class="process-math">\(A\)</span> is invertible. What, then, is <span class="process-math">\(R\text{?}\)</span> What is <span class="process-math">\(\det(R)\text{?}\)</span> Can the determinant of an elementary matrix ever be <span class="process-math">\(0\text{?}\)</span> How do we conclude that <span class="process-math">\(\det(A) \neq 0\text{?}\)</span></p></article><article class="task exercise-like" id="task-1226"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3708">Now suppose that <span class="process-math">\(\det(A) \neq 0\text{.}\)</span> What can we conclude about <span class="process-math">\(\det(R)\text{?}\)</span> What, then, must <span class="process-math">\(R\)</span> be? How do we conclude that <span class="process-math">\(A\)</span> is invertible?</p></article></article><section class="paragraphs" id="paragraphs-27"><h4 class="heading"><span class="title">Summary.</span></h4>
<p id="p-3709">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix. Suppose we swap rows <span class="process-math">\(s\)</span> times and divide rows by constants <span class="process-math">\(k_1, k_2, \ldots,
k_r\)</span> while computing a row echelon form <span class="process-math">\(\text{ REF } (A)\)</span> of <span class="process-math">\(A\text{.}\)</span> Then <span class="process-math">\(\det(A)=(-1)^s k_1 k_2\cdots k_r \det(\text{ REF } (A))\text{.}\)</span></p></section></section><section class="section" id="sec_det_geom"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Geometric Interpretation of the Determinant</span>
</h3>
<p id="p-3710">Determinants have interesting and useful applications from a geometric perspective. To understand the geometric interpretation of the determinant of an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we consider the image of the unit square under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> and see how its area changes based on <span class="process-math">\(A\text{.}\)</span></p>
<article class="activity project-like" id="act_4_f_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.5</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1227"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-358"><p id="p-3711">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 0\\0\amp 3 \end{array} \right]\text{.}\)</span> Start with the unit square in <span class="process-math">\(\R^2\)</span> with corners at the origin and at <span class="process-math">\((1,1)\text{.}\)</span> In other words, the unit square we are considering consists of all vectors <span class="process-math">\(\vv=\left[ \begin{array}{c} x\\y \end{array} \right]\)</span> where <span class="process-math">\(0\leq x\leq 1\)</span> and <span class="process-math">\(0\leq y\leq 1\text{,}\)</span> visualized as points in the plane.</p></div>
<article class="task exercise-like" id="task-1228"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3712">Consider the collection of image vectors <span class="process-math">\(A\vv\)</span> obtained by multiplying <span class="process-math">\(\vv\)</span>'s by <span class="process-math">\(A\text{.}\)</span> Sketch the rectangle formed by these image vectors.</p></article><article class="task exercise-like" id="task-1229"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3713">Explain how the area of this image rectangle and the unit square is related via <span class="process-math">\(\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1230"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3714">Does the relationship you found above generalize to an arbitrary <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp 0\\0\amp b \end{array} \right]\text{?}\)</span> If not, modify the relationship to hold for all diagonal matrices.</p></article></article><article class="task exercise-like" id="task-1231"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-359"><p id="p-3715">Let <span class="process-math">\(A=\left[ \begin{array}{cc} 2\amp 1\\ 0\amp 3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1232"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3716">Sketch the image of the unit square under the transformation <span class="process-math">\(T(\vv)=A\vv\text{.}\)</span> To make the sketching easier, find the images of the vectors <span class="process-math">\([0 \ 0]^{\tr}, [1 \ 0]^{\tr}, [0 \ 1]^{\tr}, [1 \ 1]^{\tr}\)</span> as points first and then connect these images to find the image of the unit square.</p></article><article class="task exercise-like" id="task-1233"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3717">Check that the area of the parallelogram you obtained in the above part is equal to <span class="process-math">\(\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1234"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3718">Does the relationship between the area and <span class="process-math">\(\det(A)\)</span> still hold if <span class="process-math">\(A=\left[ \begin{array}{rc} -2\amp 1\\ 0\amp 3 \end{array} \right]\text{?}\)</span> If not, how will you modify the relationship?</p></article></article></article><p id="p-3719">It can be shown that for all <span class="process-math">\(2\times 2\)</span> matrices a similar relationship holds.</p>
<article class="theorem theorem-like" id="theorem-51"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.5</span><span class="period">.</span>
</h4>
<p id="p-3720">For a <span class="process-math">\(2\times 2\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the area of the image of the unit square under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> is equal to <span class="process-math">\(|\det(A)|\text{.}\)</span> This is equivalent to saying that <span class="process-math">\(|\det(A)|\)</span> is equal to the area of the parallelogram defined by the columns of <span class="process-math">\(A\text{.}\)</span> The area of the parallelogram is also equal to the lengths of the column vectors of <span class="process-math">\(A\)</span> multiplied by <span class="process-math">\(|\sin(\theta)|\)</span> where <span class="process-math">\(\theta\)</span> is the angle between the two column vectors.</p></article><p id="p-3721">There is a similar geometric interpretation of the determinant of a <span class="process-math">\(3\times 3\)</span> matrix in terms of volume.</p>
<article class="theorem theorem-like" id="theorem-52"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.6</span><span class="period">.</span>
</h4>
<p id="p-3722">For a <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the volume of the image of the unit cube under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> is equal to <span class="process-math">\(|\det(A)|\text{.}\)</span> This is equivalent to saying that <span class="process-math">\(|\det(A)|\)</span> is equal to the volume of the parallelepiped defined by the columns of <span class="process-math">\(A\text{.}\)</span></p></article><p id="p-3723">The sign of <span class="process-math">\(\det(A)\)</span> can be interpreted in terms of the orientation of the column vectors of <span class="process-math">\(A\text{.}\)</span> See the project in <a href="chap_determinants.html" class="internal" title="Section 17: The Determinant">Section 17</a> for details.</p></section><section class="section" id="sec_inv_cramers"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">An Explicit Formula for the Inverse and Cramer's Rule</span>
</h3>
<p id="p-3724">In <a href="chap_matrix_inverse.html" class="internal" title="Section 10: The Inverse of a Matrix">Section 10</a> we found the inverse <span class="process-math">\(A^{-1}\)</span> using row reduction of the matrix obtained by augmenting <span class="process-math">\(A\)</span> with <span class="process-math">\(I_n\text{.}\)</span> However, in theoretical applications, having an explicit formula for <span class="process-math">\(A^{-1}\)</span> can be handy. Such an explicit formula provides us with an algebraic expression for <span class="process-math">\(A^{-1}\)</span> in terms of the entries of <span class="process-math">\(A\text{.}\)</span> A consequence of the formula we develop is Cramer's Rule, which can be used to provide formulas that give solutions to certain linear systems.</p>
<p id="p-3725">We begin with an interesting connection between a square matrix and the matrix of its cofactors that we explore in the next activity.</p>
<article class="activity project-like" id="act_4_f_4"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-360"><p id="p-3726">Let <span class="process-math">\(A = \left[ \begin{array}{crc} 2\amp 1\amp 3 \\ 1\amp 4\amp 5 \\ 2\amp -1\amp 2 \end{array}  \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1235"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3727">Calculate the <span class="process-math">\((1,1)\text{,}\)</span> <span class="process-math">\((1,2)\text{,}\)</span> and <span class="process-math">\((1,3)\)</span> cofactors of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1236"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3728">If <span class="process-math">\(C_{ij}\)</span> represents the <span class="process-math">\((i,j)\)</span> cofactor of <span class="process-math">\(A\text{,}\)</span> then the cofactor matrix <span class="process-math">\(C\)</span> is the matrix <span class="process-math">\(C = [C_{ij}]\text{.}\)</span> The <dfn class="terminology">adjugate</dfn> matrix of <span class="process-math">\(A\)</span> is the transpose of the cofactor matrix. In our example, the adjugate matrix of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\adj(A) = \left[ \begin{array}{rrr} 13\amp -5\amp -7 \\ 8\amp -2\amp -7 \\ -9\amp 4\amp 7 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Check the entries of this adjugate matrix with your calculations from part (a). Then calculate the matrix product</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \ \adj(A)\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1237"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3729">What do you notice about the product <span class="process-math">\(A \ \adj(A)\text{?}\)</span> How is this product related to <span class="process-math">\(\det(A)\text{?}\)</span></p></article></article><p id="p-3730">The result of <a href="" class="xref" data-knowl="./knowl/act_4_f_4.html" title="Activity 22.6">Activity 22.6</a> is rather surprising, but it is valid in general. That is, if <span class="process-math">\(A = [a_{ij}]\)</span> is an invertible <span class="process-math">\(n \times n\)</span> matrix and <span class="process-math">\(C_{ij}\)</span> is the <span class="process-math">\((i,j)\)</span> cofactor of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(A \ \adj(A)=\det(A) I_n\text{.}\)</span> In other words, <span class="process-math">\(A \left(\frac{\adj(A)}{\det(A)}\right) = I_n\)</span> and so</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4_f_4.html">
\begin{equation*}
A^{-1} = \frac{1}{\det(A)} \adj(A)\text{.}
\end{equation*}
</div>
<p id="p-3731">This gives us another formulation of the inverse of a matrix. To see why <span class="process-math">\(A \ \adj(A) = \det(A) I_n\text{,}\)</span> we use the row-column version of the matrix product to find the <span class="process-math">\(ij\)</span>th entry of <span class="process-math">\(A \ \adj(A)\)</span> as indicated by the shaded row and column   </p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccc} a_{11}     \amp  a_{12}   \amp  \cdots   \amp  a_{1n} \\ a_{21}     \amp a_{22}    \amp  \cdots  \amp  a_{2n} \\ \vdots     \amp  \vdots      \amp            \amp \vdots  \\ \cellcolor[gray]{.9}  a_{i1}  \amp \cellcolor[gray]{.9} a_{i2}     \amp \cellcolor[gray]{.9} \cdots   \amp \cellcolor[gray]{.9} a_{in} \\ \vdots     \amp  \vdots      \amp            \amp \vdots  \\ a_{n1}     \amp  a_{n2}   \amp  \cdots   \amp a_{nn} \end{array}  \right] \left[ \begin{array}{cccccc} C_{11}   \amp  C_{21} \amp  \cdots    \amp \cellcolor[gray]{.9} C_{j1} \amp \cdots \amp  C_{n1} \\ C_{12}   \amp  C_{22} \amp  \cdots    \amp \cellcolor[gray]{.9} C_{j2} \amp \cdots \amp  C_{n2} \\ \vdots   \amp   \vdots  \amp          \amp     \cellcolor[gray]{.9}       \amp        \amp  \vdots \\ C_{1n}   \amp  C_{2n} \amp  \cdots  \amp \cellcolor[gray]{.9} C_{jn} \amp \cdots \amp  C_{nn} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3732">Thus the <span class="process-math">\(ij\)</span>th entry of <span class="process-math">\(A \ \adj(A)\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_f_4">
\begin{equation}
a_{i1}C_{j1} + a_{i2}C_{j2} + \cdots + a_{in}C_{jn}\text{.}\tag{22.4}
\end{equation}
</div>
<p id="p-3733">Notice that if <span class="process-math">\(i=j\text{,}\)</span> then expression <a href="" class="xref" data-knowl="./knowl/eq_4_f_4.html" title="Equation 22.4">(22.4)</a> is the cofactor expansion of <span class="process-math">\(A\)</span> along the <span class="process-math">\(i\)</span>th row. So the <span class="process-math">\(ii\)</span>th entry of <span class="process-math">\(A \ \adj(A)\)</span> is <span class="process-math">\(\det(A)\text{.}\)</span> It remains to show that the <span class="process-math">\(ij\)</span>th entry of <span class="process-math">\(A \ \adj(A)\)</span> is 0 when <span class="process-math">\(i \neq j\text{.}\)</span></p>
<p id="p-3734">When <span class="process-math">\(i \neq j\text{,}\)</span> the expression <a href="" class="xref" data-knowl="./knowl/eq_4_f_4.html" title="Equation 22.4">(22.4)</a> is the cofactor expansion of the matrix   </p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_4_f_4.html ./knowl/eq_4_f_4.html">
\begin{equation*}
\left[ \begin{array}{cccc} a_{11}     \amp  a_{12}   \amp  \cdots   \amp  a_{1n} \\ a_{21}     \amp a_{22}    \amp  \cdots  \amp  a_{2n} \\ \vdots     \amp  \vdots      \amp            \amp \vdots  \\ a_{i1}      \amp a_{i2}     \amp  \cdots   \amp  a_{in} \\ \vdots     \amp  \vdots      \amp            \amp \vdots  \\ a_{j-11}      \amp a_{j-12}     \amp  \cdots   \amp  a_{j-1n} \\ \cellcolor[gray]{.9} a_{i1} \amp \cellcolor[gray]{.9}  a_{i2} \amp \cellcolor[gray]{.9} \cdots   \amp \cellcolor[gray]{.9} a_{in} \\ a_{j+11}      \amp a_{i+12}     \amp  \cdots   \amp  a_{j+1n} \\ \vdots     \amp  \vdots      \amp            \amp \vdots  \\ a_{n1}     \amp  a_{n2}   \amp  \cdots   \amp a_{nn} \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">along the <span class="process-math">\(j\)</span>th row. This matrix is the one obtained by replacing the <span class="process-math">\(j\)</span>th row of <span class="process-math">\(A\)</span> with the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(A\text{.}\)</span> Since this matrix has two identical rows, it is not row equivalent to the identity matrix and is therefore not invertible. Thus, when <span class="process-math">\(i \neq j\)</span> expression <a href="" class="xref" data-knowl="./knowl/eq_4_f_4.html" title="Equation 22.4">(22.4)</a> is 0. This makes <span class="process-math">\(A \ \adj(A) = \det(A) I_n\text{.}\)</span></p>
<p id="p-3735">One consequence of the formula <span class="process-math">\(A^{-1} = \frac{1}{\det(A)} \adj(A)\)</span> is Cramer's rule, which describes the solution to the equation <span class="process-math">\(A \vx = \vb\text{.}\)</span></p>
<article class="activity project-like" id="act_4_f_5"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">22.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-361"><p id="p-3736">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 3\amp 1 \\ 4\amp 2 \end{array} \right]\text{,}\)</span> and let <span class="process-math">\(\vb = \left[ \begin{array}{c}2\\6 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1238"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3737">Solve the equation <span class="process-math">\(A \vx = \vb\)</span> using the inverse of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1239"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3738">Let <span class="process-math">\(A_1 = \left[ \begin{array}{cc} 2\amp 1 \\ 6\amp 2 \end{array} \right]\text{,}\)</span> the matrix obtained by replacing the first column of <span class="process-math">\(A\)</span> with <span class="process-math">\(\vb\text{.}\)</span> Calculate <span class="process-math">\(\frac{\det(A_1)}{\det(A)}\)</span> and compare to your solution from part (a). What do you notice?</p></article><article class="task exercise-like" id="task-1240"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3739">Now let <span class="process-math">\(A_2 = \left[ \begin{array}{cc} 3\amp 2 \\ 4\amp 6 \end{array} \right]\text{,}\)</span> the matrix obtained by replacing the second column of <span class="process-math">\(A\)</span> with <span class="process-math">\(\vb\text{.}\)</span> Calculate <span class="process-math">\(\frac{\det(A_2)}{\det(A)}\)</span> and compare to your solution from part (a). What do you notice?</p></article></article><p id="p-3740">The result from <a href="" class="xref" data-knowl="./knowl/act_4_f_5.html" title="Activity 22.7">Activity 22.7</a> may seem a bit strange, but turns out to be true in general. The result is called <em class="emphasis">Cramer's Rule</em>.</p>
<article class="theorem theorem-like" id="theorem-53"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">22.7</span><span class="period">.</span><span class="space"> </span><span class="title">Cramer's Rule.</span>
</h4>
<p id="p-3741">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> invertible matrix. For any <span class="process-math">\(\vb\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> the solution <span class="process-math">\(\vx\)</span> of <span class="process-math">\(A\vx=\vb\)</span> has entries</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_i =\frac{\det(A_i)}{\det(A)}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(A_i\)</span> represents the matrix formed by replacing <span class="process-math">\(i\)</span>th column of <span class="process-math">\(A\)</span> with <span class="process-math">\(\vb\text{.}\)</span> </p></article><p id="p-3742">To see why Cramer's Rule works in general, let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> invertible matrix and <span class="process-math">\(\vb = [b_1 \ b_2 \ \cdots \ b_n]^{\tr}\text{.}\)</span> The solution to <span class="process-math">\(A \vx = \vb\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = A^{-1} \vb = \frac{1}{\det(A)} \adj(A) \vb = \frac{1}{\det(A)}\left[ \begin{array}{cccc} C_{11}   \amp  C_{21} \amp \cdots \amp  C_{n1} \\ C_{12}   \amp  C_{22} \amp \cdots \amp  C_{n2} \\ \vdots   \amp   \vdots  \amp        \amp  \vdots \\ C_{1n}   \amp  C_{2n} \amp \cdots \amp  C_{nn} \end{array}  \right] \left[ \begin{array}{c} b_1 \\ b_2 \\ \vdots \\ b_n \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3743">Expanding the product gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = \frac{1}{\det(A)}\left[ \begin{array}{c} b_1C_{11} + b_2C_{21} + \cdots + b_nC_{n1}  \\ b_1C_{12} + b_2C_{22} + \cdots + b_nC_{n2}   \\ \vdots \\ b_1C_{1n} + b_2C_{2n} + \cdots + b_nC_{nn} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3744">The expression</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
b_1C_{1j} + b_2C_{2j} + \cdots + b_nC_{nj}
\end{equation*}
</div>
<p class="continuation">is the cofactor expansion of the matrix   </p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A_j = \left[ \begin{array}{cccccccc} a_{11}   \amp  a_{12} \amp  \cdots    \amp a_{1j-1} \amp \cellcolor[gray]{.9} b_1  \amp a_{1j+1}    \amp \cdots   \amp  a_{1n} \\ a_{21}   \amp  a_{22} \amp  \cdots    \amp a_{2j-1} \amp \cellcolor[gray]{.9} b_2   \amp a_{2j+1}  \amp \cdots  \amp  a_{2n} \\ \vdots   \amp   \vdots  \amp          \amp              \amp  \cellcolor[gray]{.9}  \amp         \amp        \amp  \vdots \\ a_{n1}   \amp  a_{n2} \amp  \cdots    \amp a_{nj-1} \amp \cellcolor[gray]{.9} b_n   \amp a_{nj+1}  \amp \cdots  \amp  a_{nn} \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">along the <span class="process-math">\(j\)</span>th column, giving us the formula in Cramer's Rule.</p>
<p id="p-3745">Cramer's Rule is not a computationally efficient method. To find a solution to a linear system of <span class="process-math">\(n\)</span> equations in <span class="process-math">\(n\)</span> unknowns using Cramer's Rule requires calculating <span class="process-math">\(n+1\)</span> determinants of <span class="process-math">\(n \times n\)</span> matrices — quite inefficient when <span class="process-math">\(n\)</span> is 3 or greater. Our standard method of solving systems using Gaussian elimination is much more efficient. However, Cramer's Rule does provide a formula for the solution to <span class="process-math">\(A \vx = \vb\)</span> as long as <span class="process-math">\(A\)</span> is invertible.</p></section><section class="section" id="sec_det_transpose"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Determinant of the Transpose</span>
</h3>
<p id="p-3746">In this section we establish the fact that the determinant of a square matrix is the same as the determinant of its transpose.</p>
<p id="p-3747">The result is easily verified for <span class="process-math">\(2 \times 2\)</span> matrices, so we will proceed by induction and assume that the determinant of the transpose of any <span class="process-math">\((n-1) \times (n-1)\)</span> matrix is the same as the determinant of its transpose. Suppose <span class="process-math">\(A = [a_{ij}]\)</span> is an <span class="process-math">\(n \times n\)</span> matrix. By definition,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13} + \cdots + a_{1n}C_{1n}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A^{\tr}) = a_{11}C_{11} + a_{21}C_{21} + a_{31}C_{31} + \cdots + a_{n1}C_{n1}\text{.}
\end{equation*}
</div>
<p id="p-3748">Note that the only terms in either determinant that contains <span class="process-math">\(a_{11}\)</span> is <span class="process-math">\(a_{11}C_{11}\text{.}\)</span> This term is the same in both determinants, so we proceed to examine other elements. Let us consider all terms in the cofactor expansion for <span class="process-math">\(\det(A^{\tr})\)</span> that contain <span class="process-math">\(a_{i1}a_{1j}\text{.}\)</span> The only summand that contains <span class="process-math">\(a_{i1}\)</span> is <span class="process-math">\(a_{i1}C_{i1}\text{.}\)</span> Letting <span class="process-math">\(A_{ij}\)</span> be the sub-matrix of <span class="process-math">\(A\)</span> obtained by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column, we see that <span class="process-math">\(a_{i1}C_{i1} = (-1)^{i+1}a_{i1}\det(A_{i1})\text{.}\)</span> Now let's examine the sub-matrix <span class="process-math">\(A_{i1}\text{:}\)</span>   </p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccccccc} \cellcolor[gray]{.9} a_{12} \amp \cellcolor[gray]{.9} a_{13} \amp  \cellcolor[gray]{.9} \cdots    \amp \cellcolor[gray]{.9} a_{1j} \amp \cellcolor[gray]{.9} \cdots \amp \cellcolor[gray]{.9} a_{1n-1} \amp \cellcolor[gray]{.9} a_{1n} \\ a_{22} \amp  a_{23} \amp  \cdots    \amp \cellcolor[gray]{.9} a_{2j} \amp \cdots \amp  a_{2n-1} \amp  a_{2n} \\ \vdots \amp        \amp  \ddots    \amp \cellcolor[gray]{.9} \vdots          \amp \ddots \amp  \amp  \\ a_{i-12} \amp  a_{i-13} \amp  \cdots   \amp  \cellcolor[gray]{.9} a_{i-1j} \amp \cdots \amp  a_{i-1n-1} \amp  a_{i-1n} \\ a_{i+12} \amp  a_{i+13} \amp  \cdots    \amp \cellcolor[gray]{.9} a_{i+1j} \amp \cdots \amp  a_{i+1n-1} \amp  a_{i+1n} \\ a_{n2} \amp  a_{n3} \amp  \cdots    \amp \cellcolor[gray]{.9} a_{nj} \amp \cdots \amp  a_{nn-1} \amp  a_{nn} \end{array}  \right]
\end{equation*}
</div>
<p id="p-3749">When we expand along the first row to calculate <span class="process-math">\(\det(A_{i1})\text{,}\)</span> the only term that will involve <span class="process-math">\(a_{1j}\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(-1)^{j-1+1}a_{1j}\det(A_{i1, 1j})\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(A_{ik,jm}\)</span> denotes the sub-matrix of <span class="process-math">\(A\)</span> obtained by deleting rows <span class="process-math">\(i\)</span> and <span class="process-math">\(k\)</span> and columns <span class="process-math">\(j\)</span> and <span class="process-math">\(m\)</span> from <span class="process-math">\(A\text{.}\)</span> So the term that contains <span class="process-math">\(a_{i1}a_{1j}\)</span> in the cofactor expansion for <span class="process-math">\(\det(A^{\tr})\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_det_transpose_1">
\begin{equation}
(-1){i+1}a_{i1}(-1)^{j}a_{1j}\det(A_{i1_{1j}}) = (-1)^{i+j+1} a_{i1}a_{1j}\det(A_{i1, 1j})\text{.}\tag{22.5}
\end{equation}
</div>
<p id="p-3750">Now we examine the cofactor expansion for <span class="process-math">\(\det(A)\)</span> to find the terms that contain <span class="process-math">\(a_{i1}a_{1j}\text{.}\)</span> The quantity <span class="process-math">\(a_{1j}\)</span> only appears in the cofactor expansion as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{1j}C_{1j} = (-1)^{1+j}a_{1j}\det(A_{1j})\text{.}
\end{equation*}
</div>
<p id="p-3751">Now let's examine the sub-matrix <span class="process-math">\(A_{1j}\text{:}\)</span>   </p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccccccc} \cellcolor[gray]{.9} a_{21}   \amp  a_{22}   \amp  \cdots    \amp a_{2j-1} \amp a_{2j+1} \amp \cdots \amp  a_{2n} \\ \cellcolor[gray]{.9} a_{31}   \amp  a_{32}   \amp  \cdots    \amp a_{3j-1} \amp a_{3j+1} \amp \cdots \amp  a_{3n} \\ \cellcolor[gray]{.9} \vdots   \amp            \amp  \ddots    \amp  \vdots   \amp \ddots    \amp       \amp  \\  \cellcolor[gray]{.9} a_{i1}   \amp \cellcolor[gray]{.9} a_{i2}   \amp \cellcolor[gray]{.9} \cdots     \amp \cellcolor[gray]{.9} a_{ij-1} \amp \cellcolor[gray]{.9} a_{ij+1}   \amp \cellcolor[gray]{.9} \cdots \amp \cellcolor[gray]{.9} a_{in} \\ \cellcolor[gray]{.9} \vdots   \amp            \amp             \amp  \vdots   \amp          \amp \vdots \amp \\ \cellcolor[gray]{.9} a_{n1}   \amp  a_{n2}   \amp  \cdots    \amp a_{nj-1} \amp a_{nj+1}  \amp \cdots \amp  a_{nn} \end{array}  \right]
\end{equation*}
</div>
<p id="p-3752">Here is where we use the induction hypothesis. Since <span class="process-math">\(A_{1j}\)</span> is an <span class="process-math">\((n-1) \times (n-1)\)</span> matrix, its determinant can be found with a cofactor expansion down the first column. The only term in this cofactor expansion that will involve <span class="process-math">\(a_{i1}\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(-1)^{i-1+1}a_{i1} \det(A_{1i, j1})\text{.}
\end{equation*}
</div>
<p id="p-3753">So the term that contains <span class="process-math">\(a_{i1}a_{1j}\)</span> in the cofactor expansion for <span class="process-math">\(\det(A)\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_det_transpose_2">
\begin{equation}
(-1)^{1+j}a_{1j}(-1)^{i-1+1}a_{i1} \det(A_{1j_{i1}}) = (-1)^{i+j+1} a_{i1}a_{1j}\det(A_{1i, j1})\text{.}\tag{22.6}
\end{equation}
</div>
<p id="p-3754">Since the quantities in <a href="" class="xref" data-knowl="./knowl/eq_det_transpose_1.html" title="Equation 22.5">(22.5)</a> and <a href="" class="xref" data-knowl="./knowl/eq_det_transpose_2.html" title="Equation 22.6">(22.6)</a> are equal, we conclude that the terms in the two cofactor expansions are the same and</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_det_transpose_1.html ./knowl/eq_det_transpose_2.html">
\begin{equation*}
\det(A^{\tr}) = \det(A)\text{.}
\end{equation*}
</div></section><section class="section" id="sec_det_row_swap"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Row Swaps and Determinants</span>
</h3>
<p id="p-3755">In this section we determine the effect of row swaps to the determinant. Let <span class="process-math">\(E_{rs}\)</span> be the elementary matrix that swaps rows <span class="process-math">\(r\)</span> and <span class="process-math">\(s\)</span> in the <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A=[a_{ij}]\text{.}\)</span> Applying <span class="process-math">\(E_{12}\)</span> to a <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(A = \left[ \begin{array}{cc} a \amp  b \\ c \amp  d \end{array}  \right]\text{,}\)</span> we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = ad - bc = -(ad-bc) = \det\left(\left[ \begin{array}{cc} c \amp  d \\ a \amp  b \end{array}  \right]\right) = \det(E_{12}A)\text{.}
\end{equation*}
</div>
<p id="p-3756">So swapping rows in a <span class="process-math">\(2 \times 2\)</span> matrix multiplies the determinant by <span class="process-math">\(-1\text{.}\)</span> Suppose that row swapping on any <span class="process-math">\((n-1) \times (n-1)\)</span> matrix multiplies the determinant by <span class="process-math">\(-1\)</span> (in other words, we are proving our statement by mathematical induction). Now suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix and let <span class="process-math">\(B = [b_{ij}] = E_{rs}A\text{.}\)</span> We first consider the case that <span class="process-math">\(s = r+1\)</span> — that we swap adjacent rows. We consider two cases, <span class="process-math">\(r &gt; 1\)</span> and <span class="process-math">\(r = 1\text{.}\)</span> First let us suppose that <span class="process-math">\(r &gt; 1\text{.}\)</span> Let <span class="process-math">\(C_{ij}\)</span> be the <span class="process-math">\((i,j)\)</span> cofactor of <span class="process-math">\(A\)</span> and <span class="process-math">\(C'_{ij}\)</span> the <span class="process-math">\((i,j)\)</span> cofactor of <span class="process-math">\(B\text{.}\)</span> We have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{12}C_{12} + \cdots + a_{1n}C_{1n}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(B) = b_{11}C'_{11} + b_{12}C'_{12} + \cdots + b_{1n}C'_{1n}\text{.}
\end{equation*}
</div>
<p id="p-3757">Since <span class="process-math">\(r &gt; 1\text{,}\)</span>it follows that <span class="process-math">\(a_{1j} = b_{1j}\)</span> for every <span class="process-math">\(j\text{.}\)</span> For each <span class="process-math">\(j\)</span> the sub-matrix <span class="process-math">\(B_{1j}\)</span> obtained from <span class="process-math">\(B\)</span> by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column is the same matrix as obtained from <span class="process-math">\(A_{ij}\)</span> by swapping rows <span class="process-math">\(r\)</span> and <span class="process-math">\(s\text{.}\)</span> So by our induction hypothesis, we have <span class="process-math">\(C'_{1j} = -C_{1j}\)</span> for each <span class="process-math">\(j\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-151">
\begin{align*}
\det(B) \amp = b_{11}C'_{11} + b_{12}C'_{12} + \cdots + b_{1n}C'_{1n}\\
\amp = a_{11}(-C_{11}) + a_{12}(-C_{12}) + \cdots + a_{1n}(-C_{1n})\\
\amp = -(a_{11}C_{11} + a_{12}C_{12} + \cdots + a_{1n}C_{1n})\\
\amp = -\det(A)\text{.}
\end{align*}
</div>
<p id="p-3758">Now we consider the case where <span class="process-math">\(r=1\text{,}\)</span> where <span class="process-math">\(B\)</span> is the matrix obtained from <span class="process-math">\(A\)</span> by swapping the first and second rows. Here we will use the fact that <span class="process-math">\(\det(A) = \det(A^{\tr})\)</span> which allows us to calculate <span class="process-math">\(\det(A)\)</span> and <span class="process-math">\(\det(B)\)</span> with the cofactor expansions down the first column. In this case we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{21}C_{21} + \cdots + a_{n1}C_{n1}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-152">
\begin{align*}
\det(B) \amp = b_{11}C'_{11} + b_{21}C'_{21} + \cdots + b_{n1}C'_{n1}\\
\amp = a_{21}C'_{11} + a_{11}C'_{21} + a_{31}C'_{31} + \cdots + a_{n1}C'_{n1}\text{.}
\end{align*}
</div>
<p id="p-3759">For each <span class="process-math">\(i \geq 3\text{,}\)</span> the sub-matrix <span class="process-math">\(B_{i1}\)</span> is just <span class="process-math">\(A_{i1}\)</span> with rows 1 and 2 swapped. So we have <span class="process-math">\(C'_{i1} = -C_{i1}\)</span> by our induction hypothesis. Since we swapped rows 1 and 2, we have <span class="process-math">\(B_{21} = A_{11}\)</span> and <span class="process-math">\(B_{11} = A_{21}\text{.}\)</span> Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
b_{11}C'_{11} = (-1)^{1+1}b_{11}\det(A_{21}) = a_{21}\det(A_{21}) = -a_{21}C_{21}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
b_{21}C'_{21} = (-1)^{2+1}a_{11}\det(A_{11}) = -a_{11}\det(A_{11}) = -a_{11}C_{11}\text{.}
\end{equation*}
</div>
<p id="p-3760">Putting this all together gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-153">
\begin{align*}
\det(B) \amp = b_{11}C'_{11} + b_{21}C'_{21} + \cdots + b_{n1}C'_{n1}\\
\amp = -a_{21}C_{21} - a_{11}C_{11} + a_{31}(-C_{31}) + \cdots + a_{n1}(-C_{n1})\\
\amp = -\left(a_{11}C_{11} + a_{21}C_{21} + \cdots + a_{n1}C_{n1}\right)\\
\amp = - \det(A)\text{.}
\end{align*}
</div>
<p id="p-3761">So we have shown that if <span class="process-math">\(B\)</span> is obtained from <span class="process-math">\(A\)</span> by interchanging two adjacent rows, then <span class="process-math">\(\det(B) = -\det(A)\text{.}\)</span> Now we consider the general case. Suppose <span class="process-math">\(B\)</span> is obtained from <span class="process-math">\(A\)</span> by interchanging rows <span class="process-math">\(r\)</span> and <span class="process-math">\(s\text{,}\)</span> with <span class="process-math">\(r \lt  s\text{.}\)</span> We can perform this single row interchange through a sequence of adjacent row interchanges. First we swap rows <span class="process-math">\(r\)</span> and <span class="process-math">\(r+1\text{,}\)</span> then rows <span class="process-math">\(r+1\)</span> and <span class="process-math">\(r+2\text{,}\)</span> and continue until we swap rows <span class="process-math">\(s-1\)</span> and <span class="process-math">\(s\text{.}\)</span> This places the original row <span class="process-math">\(r\)</span> into the row <span class="process-math">\(s\)</span> position, and the process involved <span class="process-math">\(s-r\)</span> adjacent row interchanges. Each of these interchanges multiplies the determinant by a factor of <span class="process-math">\(-1\text{.}\)</span> At the end of this sequence of row swaps, the original row <span class="process-math">\(s\)</span> is now row <span class="process-math">\(s-1\text{.}\)</span> So it will take one fewer adjacent row interchanges to move this row to be row <span class="process-math">\(r\text{.}\)</span> This sequence of <span class="process-math">\((s-r)+(s-r-1) = 2(s-r-1)-1\)</span> row interchanges produces the matrix <span class="process-math">\(B\text{.}\)</span> Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(B) = (-1)^{2(s-r)-1}\det(A) = -\det(A)\text{,}
\end{equation*}
</div>
<p class="continuation">and interchanging any two rows multiplies the determinant by <span class="process-math">\(-1\text{.}\)</span></p></section><section class="section" id="sec_cofactor_expand"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Cofactor Expansions</span>
</h3>
<p id="p-3762">We have stated that the determinant of a matrix can be calculated by using a cofactor expansion along any row or column. We use the result that swapping rows introduces a factor of <span class="process-math">\(-1\)</span> in the determinant to verify that result in this section. Note that in proving that <span class="process-math">\(\det(A^{\tr}) = \det(A)\text{,}\)</span> we have already shown that the cofactor expansion along the first column is the same as the cofactor expansion along the first row. If we can prove that the cofactor expansion along any row is the same, then the fact that <span class="process-math">\(\det(A^{\tr}) = \det(A)\)</span> will imply that the cofactor expansion along any column is the same as well.</p>
<p id="p-3763">Now we demonstrate that the cofactor expansions along the first row and the <span class="process-math">\(i\)</span>th row are the same. Let <span class="process-math">\(A = [a_{ij}]\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. The cofactor expansion of <span class="process-math">\(A\)</span> along the first row is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{11}C_{11} + a_{12}C_{12} + \cdots + a_{1n}C_{1n}
\end{equation*}
</div>
<p class="continuation">and the cofactor expansion along the <span class="process-math">\(i\)</span>th row is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{i1}C_{i1} + a_{i2}C_{i2} + \cdots + a_{in}C_{in}\text{.}
\end{equation*}
</div>
<p id="p-3764">Let <span class="process-math">\(B\)</span> be the matrix obtained by swapping row <span class="process-math">\(i\)</span> with previous rows so that row <span class="process-math">\(i\)</span> becomes the first row and the order of the remaining rows is preserved.   </p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B = \left[ \begin{array}{cccccc} \cellcolor[gray]{.9} a_{i1}    \amp \cellcolor[gray]{.9} a_{i2}   \amp \cellcolor[gray]{.9} \cdots  \amp \cellcolor[gray]{.9} a_{ij}   \amp \cellcolor[gray]{.9} \cdots \amp \cellcolor[gray]{.9} a_{in} \\ \cellcolor[gray]{.9} a_{11}     \amp  a_{12}   \amp  \cdots    \amp a_{1j}   \amp \cdots \amp  a_{1n} \\ \cellcolor[gray]{.9} a_{21}     \amp  a_{22}   \amp  \cdots    \amp a_{2j}   \amp \cdots \amp  a_{2n} \\ \cellcolor[gray]{.9} a_{i-11}   \amp  a_{i-12}   \amp  \cdots    \amp a_{i-1j}   \amp \cdots \amp  a_{i-1n} \\ \cellcolor[gray]{.9} a_{i+11}   \amp  a_{i+12}   \amp  \cdots    \amp a_{i+1j}   \amp \cdots \amp  a_{i+1n} \\ \cellcolor[gray]{.9} \vdots     \amp  \ddots    \amp  \vdots     \amp \ddots    \amp       \amp  \\ \cellcolor[gray]{.9} a_{n1}     \amp  a_{n2}   \amp  \cdots    \amp a_{nj}    \amp \cdots \amp  a_{nn} \end{array}  \right]
\end{equation*}
</div>
<p id="p-3765">Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(B) = (-1)^{i-1} \det(A)\text{.}
\end{equation*}
</div>
<p id="p-3766">So, letting <span class="process-math">\(C'_{ij}\)</span> be the <span class="process-math">\((i,j)\)</span> cofactor of <span class="process-math">\(B\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = (-1)^{i-1} \det(B) = (-1)^{i-1}\left(a_{i1}C'_{11} + a_{i2}C'_{12} + \cdots + a_{in}C'_{1n}\right)\text{.}
\end{equation*}
</div>
<p id="p-3767">Notice that for each <span class="process-math">\(j\)</span> we have <span class="process-math">\(B_{1j} = A_{ij}\text{.}\)</span> So</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-154">
\begin{align*}
\det(A) \amp = (-1)^{i-1}\big(a_{i1}C'_{11} + a_{i2}C'_{12} + \cdots + a_{in}C'_{1n}\big)\\
\amp = (-1)^{i-1}\Big(a_{i1}(-1)^(1+1)\det(B_{11}) + a_{i2}(-1)^{1+2}\det(B_{12})\\
\amp \qquad + \cdots + a_{in}(-1)^{1+n}\det(B_{1n})\Big)\\
\amp = (-1)^{i-1}\Big(a_{i1}(-1)^(1+1)\det(A_{i1}) + a_{i2}(-1)^{1+2}\det(A_{i2})\\
\amp \qquad + \cdots + a_{in}(-1)^{1+n}\det(A_{in})\Big)\\
\amp = a_{i1}(-1)^(i+1)\det(A_{i1}) + a_{i2}(-1)^{i+2}\det(A_{i2})\\
\amp \qquad + \cdots + a_{in}(-1)^{i+n}\det(A_{in})\\
\amp = a_{i1}C_{i1} + a_{i2}C_{i2} + \cdots + a_{in}C_{in}\text{.}
\end{align*}
</div></section><section class="section" id="sec_mtx_lu_factor"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The LU Factorization of a Matrix</span>
</h3>
<p id="p-3768">There are many instances where we have a number of systems to solve of the form <span class="process-math">\(A \vx = \vb\text{,}\)</span> all with the same coefficient matrix. The system may evolve over time so that we do not know the constant vectors <span class="process-math">\(\vb\)</span> in the system all at once, but only determine them as time progresses. Each time we obtain a new vector <span class="process-math">\(\vb\text{,}\)</span> we have to apply the same row operations to reduce the coefficient matrix to solve the new system. This is time repetitive and time consuming. Instead, we can keep track of the row operations in one row reduction and save ourselves a significant amount of time. One way of doing this is the <span class="process-math">\(LU\)</span>-factorization (or decomposition).</p>
<p id="p-3769">To illustrate, suppose we can write the matrix <span class="process-math">\(A\)</span> as a product <span class="process-math">\(A = LU\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
L = \left[ \begin{array}{rccc} 1\amp 0\amp 0\amp 0\\-1\amp 1\amp 0\amp 0 \\0\amp 1\amp 1\amp 0\\1\amp 0\amp 0\amp 1 \end{array}   \right] \ \ \text{ and }  \ \ U = \left[ \begin{array}{ccrr} 1\amp 0\amp 1\amp 0\\0\amp 1\amp 3\amp -2 \\0\amp 0\amp 0\amp 3\\0\amp 0\amp 0\amp 0 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3770">Let <span class="process-math">\(\vb = [3 \ 1 \ 1 \ 3]^{\tr}\)</span> and <span class="process-math">\(\vx = [x_1 \ x_2 \ x_3 \ x_4]^{\tr}\text{,}\)</span> and consider the linear system <span class="process-math">\(A \vx = \vb\text{.}\)</span> If <span class="process-math">\(A \vx = \vb\text{,}\)</span> then <span class="process-math">\(LU \vx = \vb\text{.}\)</span> We can solve this system without applying row operations as follows. Let <span class="process-math">\(U\vx = \vz\text{,}\)</span> where <span class="process-math">\(\vz = [z_1 \ z_2 \ z_3 \ z_4]^{\tr}\text{.}\)</span> We can solve <span class="process-math">\(L\vz = \vb\)</span> by using forward substitution.</p>
<p id="p-3771">The equation <span class="process-math">\(L \vz = \vb\)</span> is equivalent to the system</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-155">
\begin{align*}
{}z_1   \  \amp {}  \  \amp {}      \  \amp {} \  \amp {}     \  \amp {} \   \amp {}       \amp = 3\\
{-}z_1  \  \amp {+} \  \amp {}z_2   \  \amp {} \   \amp {}     \  \amp {}  \   \amp {}       \amp = 1\\
{}      \  \amp {}  \  \amp {}z_2   \  \amp {+} \   \amp {}z_3  \   \amp {}  \   \amp {}       \amp = 1\\
{}      \  \amp {}  \  \amp {}      \  \amp {}  \   \amp {}     \   \amp {}  \   \amp {}z_4    \amp = 3\text{.}
\end{align*}
</div>
<p id="p-3772">The first equation shows that <span class="process-math">\(z_1=3\text{.}\)</span> Substituting into the second equation gives us <span class="process-math">\(z_2 = 4\text{.}\)</span> Using this information in the third equation yields <span class="process-math">\(z_3 = -3\text{,}\)</span> and then the fourth equation shows that <span class="process-math">\(z_4 = 0\text{.}\)</span> To return to the original system, since <span class="process-math">\(U\vx = \vz\text{,}\)</span> we now solve this system to find the solution vector <span class="process-math">\(\vx\text{.}\)</span> In this case, since <span class="process-math">\(U\)</span> is upper triangular, we use back substitution. The equation <span class="process-math">\(U\vx = \vz\)</span> is equivalent to the system</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-156">
\begin{align*}
{}x_1   \  \amp {}  \  \amp {}      \  \amp {+} \  \amp {}x_3   \  \amp {}    \   \amp {}       \amp = \amp {}\amp 3\\
{}      \  \amp {} \  \amp {}x_2   \  \amp {+} \   \amp {3}x_3  \  \amp {-}  \  \amp {2}x_4   \amp = \amp {}\amp 4\\
{}      \  \amp {}  \  \amp {}      \  \amp {}  \   \amp {}      \   \amp {}  \  \amp {3}x_4   \amp = \amp {-}\amp 3\text{.}
\end{align*}
</div>
<p id="p-3773"> Note that the third column of <span class="process-math">\(U\)</span> is not a pivot column, so <span class="process-math">\(x_3\)</span> is a free variable. The last equation shows that <span class="process-math">\(x_4=-1\text{.}\)</span> Substituting into the second equation and solving for <span class="process-math">\(x_2\)</span> yields <span class="process-math">\(x_2 = 2-3x_3\text{.}\)</span> The first equation then gives us <span class="process-math">\(x_1 = 3-x_3\text{.}\)</span> So the general solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = \left[ \begin{array}{r} 3\\2\\0\\-1 \end{array}  \right] +  \left[ \begin{array}{r} -1\\-3\\1\\0 \end{array}  \right]x_3
\end{equation*}
</div>
<p class="continuation">to <span class="process-math">\(A \vx = \vb\)</span> can be found through <span class="process-math">\(L\)</span> and <span class="process-math">\(U\)</span> via forward and backward substitution. If we can find a factorization of a matrix <span class="process-math">\(A\)</span> into a lower triangular matrix <span class="process-math">\(L\)</span> and an upper triangular matrix <span class="process-math">\(U\text{,}\)</span> then <span class="process-math">\(A= LU\)</span> is called an <dfn class="terminology"><span class="process-math">\(LU\)</span>-factorization</dfn> or <dfn class="terminology"><span class="process-math">\(LU\)</span>-decomposition</dfn>.</p>
<p id="p-3774">We can use elementary matrices to obtain a factorization of certain matrices into products of lower triangular (the “L” in LU) and upper triangular (the “U” in LU) matrices. We illustrate with an example. Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{rccr} 1\amp 0\amp 1\amp 0\\-1\amp 1\amp 2\amp -2 \\0\amp 1\amp 3\amp 1\\1\amp 0\amp 1\amp 0 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3775">Our goal is to find an upper triangular matrix <span class="process-math">\(U\)</span> and a lower triangular matrix <span class="process-math">\(L\)</span> so that <span class="process-math">\(A = LU\text{.}\)</span> We begin by row reducing <span class="process-math">\(A\)</span> to an upper triangular matrix, keeping track of the elementary matrices used to perform the row operations. We start by replacing the entries below the <span class="process-math">\((1,1)\)</span> entry in <span class="process-math">\(A\)</span> with zeros. The elementary matrices that perform these operations are</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_1 = \left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 0\\1\amp 1\amp 0\amp 0 \\0\amp 0\amp 1\amp 0\\0\amp 0\amp 0\amp 1 \end{array}   \right] \ \ \text{ and }  \ \ E_2 = \left[ \begin{array}{rccc} 1\amp 0\amp 0\amp 0\\0\amp 1\amp 0\amp 0 \\0\amp 0\amp 1\amp 0\\-1\amp 0\amp 0\amp 1 \end{array}   \right]\text{,}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_2E_1A = \left[ \begin{array}{ccrr} 1\amp 0\amp 1\amp 0\\0\amp 1\amp 3\amp -2 \\0\amp 1\amp 3\amp 1\\0\amp 0\amp 0\amp 0 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3776">We next zero out the entries below the <span class="process-math">\((2,2)\)</span> entry as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_3E_2E_1A = \left[ \begin{array}{ccrr} 1\amp 0\amp 1\amp 0\\0\amp 1\amp 3\amp -2 \\0\amp 0\amp 0\amp 3\\0\amp 0\amp 0\amp 0 \end{array}   \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_3 = \left[ \begin{array}{crcc} 1\amp 0\amp 0\amp 0\\0\amp 1\amp 0\amp 0 \\0\amp -1\amp 1\amp 0\\0\amp 0\amp 0\amp 1 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3777">The product <span class="process-math">\(E_3E_2E_1A\)</span> is an upper triangular matrix <span class="process-math">\(U\text{.}\)</span> So we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_3E_2E_1A = U
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = E_1^{-1}E_2^{-1}E_3^{-1}U\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_1^{-1}E_2^{-1}E_3^{-1} = \left[ \begin{array}{rccc} 1\amp 0\amp 0\amp 0\\-1\amp 1\amp 0\amp 0 \\0\amp 1\amp 1\amp 0\\1\amp 0\amp 0\amp 1 \end{array}   \right]
\end{equation*}
</div>
<p class="continuation">is a lower triangular matrix <span class="process-math">\(L\text{.}\)</span> So we have decomposed the matrix <span class="process-math">\(A\)</span> into a product <span class="process-math">\(A = LU\text{,}\)</span> where <span class="process-math">\(L\)</span> is lower triangular and <span class="process-math">\(U\)</span> is upper triangular. Since every matrix is row equivalent to a matrix in row echelon form, we can always find an upper triangular matrix <span class="process-math">\(U\)</span> in this way. However, we may not always obtain a corresponding lower triangular matrix, as the next example illustrates.</p>
<p id="p-3778">Suppose we change the problem slightly and consider the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B = \left[ \begin{array}{rccr} 1\amp 0\amp 1\amp 0\\-1\amp 1\amp 2\amp -2 \\0\amp 1\amp 3\amp 1\\1\amp 0\amp 0\amp 1 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3779">Using the same elementary matrices <span class="process-math">\(E_1\text{,}\)</span> <span class="process-math">\(E_2\text{,}\)</span> and <span class="process-math">\(E_3\)</span> as earlier, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_3E_2E_1B = \left[ \begin{array}{ccrr} 1\amp 0\amp 1\amp 0\\0\amp 1\amp 3\amp -2 \\0\amp 0\amp 0\amp 3\\0\amp 0\amp -1\amp 1 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3780">To reduce <span class="process-math">\(B\)</span> to row-echelon form now requires a row interchange. Letting</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_4 = \left[ \begin{array}{crcc} 1\amp 0\amp 0\amp 0\\0\amp 1\amp 0\amp 0 \\0\amp 0\amp 0\amp 1\\0\amp 0\amp 1\amp 0 \end{array}   \right]
\end{equation*}
</div>
<p class="continuation">brings us to</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_4E_3E_2E_1B = \left[ \begin{array}{ccrr} 1\amp 0\amp 1\amp 0\\0\amp 1\amp 3\amp -2 \\0\amp 0\amp -1\amp 1\\0\amp 0\amp 0\amp 3 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-3781">So in this case we have <span class="process-math">\(U = E_4E_3E_2E_1B\text{,}\)</span> but</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_1^{-1}E_2^{-1}E_3^{-1}E_4^{-1} = \left[ \begin{array}{rccc} 1\amp 0\amp 0\amp 0\\-1\amp 1\amp 0\amp 0 \\0\amp 1\amp 0\amp 1\\1\amp 0\amp 1\amp 0 \end{array}   \right]
\end{equation*}
</div>
<p class="continuation">is not lower triangular. The difference in this latter example is that we needed a row swap to obtain the upper triangular form.</p></section><section class="section" id="sec_det_prop_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-3782">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-44"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">22.8</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1241"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-362"><p id="p-3783">If <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(B\)</span> are <span class="process-math">\(n\times n\)</span> matrices with <span class="process-math">\(\det(A)=3\)</span> and <span class="process-math">\(\det(B)=2\text{,}\)</span> evaluate the following determinant values. Briefly justify.</p></div>
<article class="task exercise-like" id="task-1242"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3784"><span class="process-math">\(\det(A^{-1})\)</span></p>
<div class="solution solution-like" id="solution-130">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3785">Assume that <span class="process-math">\(\det(A)=3\)</span> and <span class="process-math">\(\det(B)=2\text{.}\)</span></p>
<p id="p-3786">Since <span class="process-math">\(\det(A) \neq 0\text{,}\)</span> we know that <span class="process-math">\(A\)</span> is invertible. Since <span class="process-math">\(1 = \det(I_n) = \det(AA^{-1}) = \det(A) \det(A^{-1})\text{,}\)</span> it follows that <span class="process-math">\(\det(A^{-1}) = \frac{1}{\det(A)} = \frac{1}{3}\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1243"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3787"><span class="process-math">\(\det(ABA^{\mathsf{T}})\)</span></p>
<div class="solution solution-like" id="solution-131">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3788">Assume that <span class="process-math">\(\det(A)=3\)</span> and <span class="process-math">\(\det(B)=2\text{.}\)</span></p>
<p id="p-3789">We know that <span class="process-math">\(\det(A^{\tr}) = \det(A)\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-157">
\begin{align*}
\det(ABA^\tr) \amp = \det(A) \det(B) \det(A^{\tr})\\
\amp = \det(A) \det(B) \det(A)\\
\amp = (3)(2)(3)\\
\amp = 18\text{.}
\end{align*}
</div>
</div></article><article class="task exercise-like" id="task-1244"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3790"><span class="process-math">\(\det(A^3(BA)^{-1}(AB)^2)\)</span></p>
<div class="solution solution-like" id="solution-132">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3791">Assume that <span class="process-math">\(\det(A)=3\)</span> and <span class="process-math">\(\det(B)=2\text{.}\)</span></p>
<p id="p-3792">Using properties of determinants gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-158">
\begin{align*}
\det(A^3(BA)^{-1}(AB)^2) \amp = \det(A^3)\det((BA)^{-1}) \det((AB)^2)\\
\amp = (\det(A))^3 \left(\frac{1}{\det(AB)}\right) (\det(AB))^2\\
\amp = 27 \left(\frac{1}{\det(A) \det(B)} \right) (\det(A)\det(B))^2\\
\amp = \frac{(27)(6^2)}{6}\\
\amp = 162\text{.}
\end{align*}
</div>
</div></article></article><article class="task exercise-like" id="task-1245"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-363"><p id="p-3793">If the determinant of <span class="process-math">\(\left[ \begin{array}{ccc} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{array} \right]\)</span> is <span class="process-math">\(m\text{,}\)</span> find the determinant of each of the following matrices.</p></div>
<article class="task exercise-like" id="task-1246"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3794"><span class="process-math">\(\left[ \begin{array}{ccc} a\amp b\amp c\\2d\amp 2e\amp 2f\\g\amp h\amp i \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-133">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3795">Assume that <span class="process-math">\(\det\left(\left[ \begin{array}{ccc} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{array}  \right] \right) = m\text{.}\)</span></p>
<p id="p-3796">Multiplying a row by a scalar multiples the determinant by that scalar, so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det\left( \left[ \begin{array}{ccc} a\amp b\amp c\\2d\amp 2e\amp 2f\\g\amp h\amp i \end{array}  \right] \right) = 2m\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1247"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3797"><span class="process-math">\(\left[ \begin{array}{ccc} d\amp e\amp f\\g\amp h\amp i\\a\amp b\amp c \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-134">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3798">Assume that <span class="process-math">\(\det\left(\left[ \begin{array}{ccc} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{array}  \right] \right) = m\text{.}\)</span></p>
<p id="p-3799">Interchanging two rows multiples the determinant by <span class="process-math">\(-1\text{.}\)</span> It takes two row swaps in the original matrix to obtain this one, so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det\left( \left[ \begin{array}{ccc} d\amp e\amp f\\g\amp h\amp i\\a\amp b\amp c \end{array}  \right] \right) = (-1)^2m = m\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1248"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3800"><span class="process-math">\(\left[ \begin{array}{ccc} a\amp b\amp c\\g-2d\amp h-2e\amp i-2f\\a+d\amp b+e\amp c+f \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-135">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-3801">Assume that <span class="process-math">\(\det\left(\left[ \begin{array}{ccc} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{array}  \right] \right) = m\text{.}\)</span></p>
<p id="p-3802">Adding a multiple of a row to another does not change the determinant of the matrix. Since there is a row swap needed to get this matrix from the original we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det\left(\left[ \begin{array}{ccc} a\amp b\amp c\\g-2d\amp h-2e\amp i-2f\\a+d\amp b+e\amp c+f \end{array}  \right]\right) = -m\text{.}
\end{equation*}
</div>
</div></article></article></article><article class="example example-like" id="example-45"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">22.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-364"><p id="p-3803">Let <span class="process-math">\(A = \left[ \begin{array}{ccr} 2\amp 8\amp 0\\2\amp 2\amp -3\\1\amp 2\amp 7 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1249"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3804">Find an LU factorization for <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-136">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3805">We row reduce <span class="process-math">\(A\)</span> to an upper triangular matrix by applying elementary matrices. First notice that if <span class="process-math">\(E_1 = \left[ \begin{array}{rcc} 1\amp 0\amp 0 \\-1\amp 1\amp 0 \\ 0\amp 0\amp 1 \end{array}  \right]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_1 A = \left[ \begin{array}{crr} 2\amp 8\amp 0 \\ 0\amp -6\amp -3 \\ 1\amp 2\amp 7 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Letting <span class="process-math">\(E_2 =  \left[ \begin{array}{rcc} 1\amp 0\amp 0 \\0\amp 1\amp 0 \\ -\frac{1}{2}\amp 0\amp 1 \end{array}  \right]\)</span> gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_2E_1A = \left[ \begin{array}{crr} 2\amp 8\amp 0 \\ 0\amp -6\amp -3 \\ 0\amp -2\amp 7 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Finally, when <span class="process-math">\(E_3 = \left[ \begin{array}{crc} 1\amp 0\amp 0 \\0\amp 1\amp 0 \\ 0\amp -\frac{1}{3}\amp 1 \end{array}  \right]\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U=E_3E_2E_1A = \left[ \begin{array}{crr} 2\amp 8\amp 0 \\ 0\amp -6\amp -3 \\ 0\amp 0\amp 8 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">This gives us <span class="process-math">\(E_3E_2E_1A = U\text{,}\)</span> so we can take</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
L = E_1^{-1}E_2^{-1}E_3^{-1} =  \left[ \begin{array}{ccc} 1\amp 0\amp 0 \\1\amp 1\amp 0 \\ \frac{1}{2}\amp \frac{1}{3}\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1250"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3806">Use the LU factorization with forward substitution and back substitution to solve the system <span class="process-math">\(A \vx = [18 \ 3 \ 12]^{\tr}\text{.}\)</span></p>
<div class="solution solution-like" id="solution-137">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3807">To solve the system <span class="process-math">\(A \vx = \vb\text{,}\)</span> where <span class="process-math">\(\vb = [18 \ 3 \ 12]^{\tr}\text{,}\)</span> we use the LU factorization of <span class="process-math">\(A\)</span> and solve <span class="process-math">\(LU \vx = \vb\text{.}\)</span> Let <span class="process-math">\(\vx = [x_1 \ x_2 \ x_3]^{\tr}\)</span> and let <span class="process-math">\(\vz = [z_1 \ z_2 \ z_3]^{\tr}\)</span> with <span class="process-math">\(U \vx = \vz\)</span> so that <span class="process-math">\(L \vz = L(U\vx) = A\vx = \vb\text{.}\)</span> First we solve <span class="process-math">\(L \vz = [18 \ 3 \ 12]^{\tr}\)</span> to find <span class="process-math">\(\vz\)</span> using forward substitution. The first row of <span class="process-math">\(L\)</span> shows that <span class="process-math">\(z_1 = 18\)</span> and the second row that <span class="process-math">\(z_1 + z_2 = 3\text{.}\)</span> So <span class="process-math">\(z_2 = -15\text{.}\)</span> The third row of <span class="process-math">\(L\)</span> gives us <span class="process-math">\(\frac{1}{2}z_1 + \frac{1}{3}z_2 + z_3 = 12\text{,}\)</span> so <span class="process-math">\(z_3 = 12 - 9 + 5 = 8\text{.}\)</span> Now to find <span class="process-math">\(\vx\)</span> we solve <span class="process-math">\(U \vx = \vz\)</span> using back substitution. The third row of <span class="process-math">\(U\)</span> tells us that <span class="process-math">\(8x_3 = 8\)</span> or that <span class="process-math">\(x_3 = 1\text{.}\)</span> The second row of <span class="process-math">\(U\)</span> shows that <span class="process-math">\(-6x_2-3x_3 = -15\)</span> or <span class="process-math">\(x_2 =2\text{.}\)</span> Finally, the first row of <span class="process-math">\(U\)</span> gives us <span class="process-math">\(2x_1+8x_2 = 18\text{,}\)</span> or <span class="process-math">\(x_1 = 1\text{.}\)</span> So the solution to <span class="process-math">\(A \vx = \vb\)</span> is <span class="process-math">\(\vx = [1 \ 2 \ 1]^{\tr}\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_det_prop_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-629">
<p id="p-3808">The elementary row operations have the following effects on the determinant:</p>
<ul class="circle">
<li id="li-630"><p id="p-3809">If we multiply a row of a matrix by a constant <span class="process-math">\(k\text{,}\)</span> then the determinant is multiplied by <span class="process-math">\(k\text{.}\)</span></p></li>
<li id="li-631"><p id="p-3810">If we swap two rows of a matrix, then the determinant changes sign.</p></li>
<li id="li-632"><p id="p-3811">If we add a multiple of a row of a matrix to another, the determinant does not change.</p></li>
</ul>
</li>
<li id="li-633"><p id="p-3812">Each of the elementary row operations can be achieved by multiplication by elementary matrices. To obtain the elementary matrix corresponding to an elementary row operation, we perform the operation on the identity matrix.</p></li>
<li id="li-634">
<p id="p-3813">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> invertible matrix. For any <span class="process-math">\(\vb\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> the solution <span class="process-math">\(\vx\)</span> of <span class="process-math">\(A\vx=\vb\)</span> has entries</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_i =\frac{\det(A_i(\vb))}{\det(A)}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(A_i(\vb)\)</span> represents the matrix formed by replacing <span class="process-math">\(i\)</span>th column of <span class="process-math">\(A\)</span> with <span class="process-math">\(\vb\text{.}\)</span></p>
</li>
<li id="li-635">
<p id="p-3814">Let <span class="process-math">\(A\)</span> be an invertible <span class="process-math">\(n\times n\)</span> matrix. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A^{-1} = \frac{1}{\det(A)} \text{ adj }  A
\end{equation*}
</div>
<p class="continuation">where the <span class="process-math">\(\text{ adj }  A\)</span> matrix, the <dfn class="terminology">adjugate of <span class="process-math">\(A\)</span></dfn>, is defined as the matrix whose <span class="process-math">\(ij\)</span>-th entry is <span class="process-math">\(C_{ji}\text{,}\)</span> the <span class="process-math">\(ji\)</span>-th cofactor of <span class="process-math">\(A\text{.}\)</span></p>
</li>
<li id="li-636"><p id="p-3815">For a <span class="process-math">\(2\times 2\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the area of the image of the unit square under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> is equal to <span class="process-math">\(|\det(A)|\text{,}\)</span> which is also equal to the area of the parallelogram defined by the columns of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-637"><p id="p-3816">For a <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the volume of the image of the unit cube under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> is equal to <span class="process-math">\(|\det(A)|\text{,}\)</span> which is also equal to the volume of the parallelepiped defined by the columns of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-638"><p id="p-3817">An <span class="process-math">\(LU\)</span> factorization of a square matrix <span class="process-math">\(A\)</span> consists of a lower triangular matrix <span class="process-math">\(L\)</span> and an upper triangular matrix <span class="process-math">\(U\)</span> so that <span class="process-math">\(A = LU\text{.}\)</span></p></li>
<li id="li-639"><p id="p-3818">A square matrix <span class="process-math">\(A\)</span> has an <span class="process-math">\(LU\)</span> factorization if we can use row operations without row interchanges to row reduce <span class="process-math">\(A\)</span> to an upper triangular matrix <span class="process-math">\(U\text{.}\)</span> In this situation the elementary matrices that perform the row operations produce a lower triangular matrix <span class="process-math">\(L\)</span> so that <span class="process-math">\(A = LU\text{.}\)</span> If <span class="process-math">\(A\)</span> cannot be reduced to an upper triangular matrix <span class="process-math">\(U\)</span> without row interchanges, then we can factor <span class="process-math">\(A\)</span> in the form <span class="process-math">\(PLU\text{,}\)</span> where <span class="process-math">\(L\)</span> is a lower triangular matrix, <span class="process-math">\(U\)</span> is an upper triangular matrix, and <span class="process-math">\(P\)</span> is obtained from the identity matrix by appropriate row interchanges.</p></li>
<li id="li-640"><p id="p-3819">There are many instances where we have a number of systems to solve of the form <span class="process-math">\(A \vx = \vb\text{,}\)</span> all with the same coefficient matrix but where the vectors <span class="process-math">\(\vb\)</span> can change. With an <span class="process-math">\(LU\)</span> factorization, we can keep track of the row operations in one row reduction and save ourselves a significant amount of time when solving these systems.</p></li>
</ul></section><section class="exercises" id="sec_det_prop_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="ex_4_f_det_multiple"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<p id="p-3820">Find a formula for <span class="process-math">\(\det(rA)\)</span> in terms of <span class="process-math">\(r\)</span> and <span class="process-math">\(\det(A)\text{,}\)</span> where <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> matrix and <span class="process-math">\(r\)</span> is a scalar. Explain why your formula is valid.</p></article><article class="exercise exercise-like" id="exercise-209"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-3822">Find <span class="process-math">\(\det(A)\)</span> by hand using elementary row operations where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A= \left[ \begin{array}{rrrr} 1\amp 2\amp -1\amp 3\\ -1\amp -2\amp 3\amp -1\\ -2\amp -1\amp 2\amp -3\\ 1\amp 8\amp -3\amp 8 \end{array}  \right] \,\text{.}
\end{equation*}
</div></article><article class="exercise exercise-like" id="exercise-210"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-365"><p id="p-3823">Consider the matrix <span class="process-math">\(A= \left[ \begin{array}{rrrr} 4\amp -1\amp -1\amp -1 \\ -1\amp 4\amp -1\amp -1\\ -1\amp -1\amp 4\amp -1\\ -1\amp -1\amp -1\amp 4 \end{array}  \right]\text{.}\)</span> We will find <span class="process-math">\(\det(A)\)</span> using elementary row operations. (This matrix arises in graph theory, and its determinant gives the number of spanning trees in the complete graph with 5 vertices. This number is also equal to the number of labeled trees with 5 vertices.)</p></div>
<article class="task exercise-like" id="task-1251"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3824">Add rows <span class="process-math">\(R_2\text{,}\)</span> <span class="process-math">\(R_3\)</span> and <span class="process-math">\(R_4\)</span> to the first row in that order.</p></article><article class="task exercise-like" id="task-1252"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3826">Then add the new <span class="process-math">\(R_1\)</span> to rows <span class="process-math">\(R_2\text{,}\)</span> <span class="process-math">\(R_3\)</span> and <span class="process-math">\(R_4\)</span> to get a triangular matrix <span class="process-math">\(B\text{.}\)</span></p></article><article class="task exercise-like" id="task-1253"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3828">Find the determinant of <span class="process-math">\(B\text{.}\)</span> Then use <span class="process-math">\(\det(B)\)</span> and properties of how elementary row operations affect determinants to find <span class="process-math">\(\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1254"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3830">Generalize your work to find the determinant of the <span class="process-math">\(n\times n\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A= \left[ \begin{array}{rrrrrr} n\amp -1\amp -1\amp \cdots \amp -1\amp -1 \\ -1\amp n\amp -1\amp \cdots \amp -1\amp -1\\ \vdots \amp \vdots \amp \vdots \amp \cdots \amp  \vdots \amp  \vdots\\ -1\amp -1\amp -1\amp  \cdots\amp -1\amp n \end{array}  \right] \,\text{.}
\end{equation*}
</div></article></article><article class="exercise exercise-like" id="exercise-211"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-3832">For which matrices <span class="process-math">\(A\text{,}\)</span> if any, is <span class="process-math">\(\det(A)=-\det(-A)\text{?}\)</span> Justify your answer.</p></article><article class="exercise exercise-like" id="exercise-212"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-3833">Find the inverse <span class="process-math">\(A^{-1}\)</span> of <span class="process-math">\(A=\left[ \begin{array}{ccc} 1\amp 0\amp 1 \\ 0\amp 1\amp 0\\2\amp 0\amp 1 \end{array} \right]\)</span> using the adjugate matrix.</p></article><article class="exercise exercise-like" id="exercise-213"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-3835">For an invertible <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> what is the relationship between <span class="process-math">\(\det(A)\)</span> and <span class="process-math">\(\det(\text{ adj } A)\text{?}\)</span> Justify your result.</p></article><article class="exercise exercise-like" id="exercise-214"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-366"><p id="p-3836">Let <span class="process-math">\(A = \left[ \begin{array}{ccc} a\amp b\amp 1\\c\amp d\amp 2\\e\amp f\amp 3 \end{array} \right]\text{,}\)</span> and assume that <span class="process-math">\(\det(A) = 2\text{.}\)</span> Determine the determinants of each of the following.</p></div>
<article class="task exercise-like" id="task-1255"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3837"><span class="process-math">\(B= \left[ \begin{array}{ccc} a\amp b\amp 1\\3c\amp 3d\amp 6\\e+a\amp f+b\amp 4 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1256"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3839"><span class="process-math">\(C = \left[ \begin{array}{ccr} 2e\amp 2f\amp 6 \\2c-2e\amp 2d-2f\amp -2\\2a\amp 2b\amp 2 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-215"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<p id="p-3841">Find the area of the parallelogram with one vertex at the origin and adjacent vertices at <span class="process-math">\((1,2)\)</span> and <span class="process-math">\((a,b)\text{.}\)</span> For which <span class="process-math">\((a,b)\)</span> is the area 0? When does this happen geometrically?</p></article><article class="exercise exercise-like" id="exercise-216"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-3842">Find the volume of the parallelepiped with one vertex at the origin and three adjacent vertices at <span class="process-math">\((3,2,0)\text{,}\)</span> <span class="process-math">\((1,1,1)\)</span> and <span class="process-math">\((1,3,c)\)</span> where <span class="process-math">\(c\)</span> is unknown. For which <span class="process-math">\(c\text{,}\)</span> is the volume 0? When does this happen geometrically?</p></article><article class="exercise exercise-like" id="exercise-217"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-367"><p id="p-3844">Find an <span class="process-math">\(LU\)</span> factorization of each of the following matrices <span class="process-math">\(A\text{.}\)</span> Use the <span class="process-math">\(LU\)</span> factorization to solve the system <span class="process-math">\(A \vx = \vb\)</span> for the given vector <span class="process-math">\(\vb\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1257"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3845"><span class="process-math">\(A = \left[ \begin{array}{rcc} 2\amp 1\amp 3 \\ -1\amp 0\amp 1 \\ 2\amp 1\amp 5 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vb = \left[ \begin{array}{c} 1 \\ 2 \\ 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1258"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3846"><span class="process-math">\(A = \left[ \begin{array}{rcc} 1\amp 1\amp 0 \\ -1\amp 1\amp 1 \\ 0\amp 2\amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vb = \left[ \begin{array}{c} 1 \\ 2 \\ 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1259"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3847"><span class="process-math">\(A = \left[ \begin{array}{rcrc} 1\amp 1\amp 1\amp 0 \\ 1\amp 0\amp 1\amp 1 \\ -1\amp 1\amp 0\amp 0 \\ 0\amp 1\amp -1\amp 0 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vb = \left[ \begin{array}{c} 3 \\ 0 \\ 2 \\ 0 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-218"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-368"><p id="p-3848">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2\\2\amp 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1260"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3849">Find an <span class="process-math">\(LU\)</span> decomposition of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1261"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3850">Find a different factorization of <span class="process-math">\(A\)</span> into a product <span class="process-math">\(L'U'\)</span> where <span class="process-math">\(L'\)</span> is a lower triangular matrix different from <span class="process-math">\(L\)</span> and <span class="process-math">\(U'\)</span> is an upper triangular matrix different from <span class="process-math">\(U\text{.}\)</span> Conclude that the <span class="process-math">\(LU\)</span> decomposition of a matrix is not unique.</p></article></article><article class="exercise exercise-like" id="exercise-219"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-369"><p id="p-3851">Let <span class="process-math">\(A = \left[ \begin{array}{rcc} 1\amp 2\amp 3\\-1\amp 2\amp 0 \\ 2\amp 0\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1262"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3852">Find an <span class="process-math">\(LU\)</span> decomposition of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1263"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3853">Find an <span class="process-math">\(LU\)</span> decomposition of <span class="process-math">\(A\)</span> in which the diagonal entries of <span class="process-math">\(D\)</span> are all 1.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-28" id="hint-28"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-28"><div class="hint solution-like"><p id="p-3854">Continue row reducing.</p></div></div>
</div></article><article class="task exercise-like" id="task-1264"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3855">Find an upper triangular matrix <span class="process-math">\(L\)</span> whose diagonal entries are all 1, a lower triangular matrix <span class="process-math">\(U\)</span> whose diagonal entries are all 1, and a diagonal matrix <span class="process-math">\(D\)</span> such that <span class="process-math">\(A = LDU\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-220"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-370"><p id="p-3856">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1265"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3857">If two rows are equal in <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\det(A)=0\text{.}\)</span></p></article><article class="task exercise-like" id="task-1266"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3859">If <span class="process-math">\(A\)</span> is a square matrix and <span class="process-math">\(R\)</span> is a row echelon form of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\det(A) = \det(R)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1267"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3860">If a matrix <span class="process-math">\(A\)</span> is invertible, then 0 is not an eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1268"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3862">If <span class="process-math">\(A\)</span> is a <span class="process-math">\(2\times 2\)</span> matrix for which the image of the unit square under the transformation <span class="process-math">\(T(\vx)=A\vx\)</span> has zero area, then <span class="process-math">\(A\)</span> is non-invertible.</p></article><article class="task exercise-like" id="task-1269"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3863">Row operations do not change the determinant of a square matrix.</p></article><article class="task exercise-like" id="task-1270"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3865">If <span class="process-math">\(A_{ij}\)</span> is the matrix obtained from a square matrix <span class="process-math">\(A = [a_{ij}]\)</span> by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(jth\)</span> column of <span class="process-math">\(A\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-160">
\begin{align*}
a_{i1}(-1)^{i+1}\amp \det(A_{i1}) + a_{i2}(-1)^{i+2}\det(A_{i2}) + \cdots\\
\amp \qquad + a_{in}(-1)^{i+n}\det(A_{in})\\
\amp =  a_{1j}(-1)^{j+1}\det(A_{1j}) + a_{2i}(-1)^{j+2}\det(A_{2i}) + \cdots\\
\amp \qquad + a_{nj}(-1)^{j+n}\det(A_{nj})
\end{align*}
</div>
<p class="continuation">for any <span class="process-math">\(i\)</span> and <span class="process-math">\(j\)</span> between <span class="process-math">\(1\)</span> and <span class="process-math">\(n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1271"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3866">If <span class="process-math">\(A\)</span> is an invertible matrix, then <span class="process-math">\(\det\left(A^{\tr}A\right) &gt; 0\text{.}\)</span></p></article></article></section></section></div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
