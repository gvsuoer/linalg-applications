<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The Dot Product in \R^n</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
},
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{colortbl}\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="part-orthog.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-orthog.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_orthogonal_basis.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="part-orthog.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-orthog.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_orthogonal_basis.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link active">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_dot_product"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span>
</h2>
<section class="introduction" id="introduction-371"><article class="objectives goal-like" id="objectives-23"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-372"><p id="p-3868">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-641"><p id="p-3869">What is the dot product of two vectors? Under what conditions is the dot product defined?</p></li>
<li id="li-642"><p id="p-3870">How do we find the angle between two nonzero vectors in <span class="process-math">\(\R^n\text{?}\)</span></p></li>
<li id="li-643"><p id="p-3871">How does the dot product tell us if two vectors are orthogonal?</p></li>
<li id="li-644"><p id="p-3872">How do we define the length of a vector in any dimension and how can the dot product be used to calculate the length?</p></li>
<li id="li-645"><p id="p-3873">How do we define the distance between two vectors?</p></li>
<li id="li-646"><p id="p-3874">What is the orthogonal projection of a vector <span class="process-math">\(\vu\)</span> in the direction of the vector <span class="process-math">\(\vv\)</span> and how do we find it?</p></li>
<li id="li-647"><p id="p-3875">What is the orthogonal complement of a subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\text{?}\)</span></p></li>
</ul></article></section><section class="section" id="sec_appl_figs_computer"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: Hidden Figures in Computer Graphics</span>
</h3>
<p id="p-3876">In video games, the speed at which a computer can render changing graphics views is vitally important. To increase a computer's ability to render a scene, programs often try to identify those parts of the images a viewer could see and those parts the viewer could not see. For example, in a scene involving buildings, the viewer could not see any images blocked by a solid building. In the mathematical world, this can be visualized by graphing surfaces. In <a href="" class="xref" data-knowl="./knowl/F_House.html" title="Figure 23.1">Figure 23.1</a> we see a crude image of a house made up of small polygons (this is how programs generally represent surfaces). On the left in <a href="" class="xref" data-knowl="./knowl/F_House.html" title="Figure 23.1">Figure 23.1</a> we see all of the polygons that are needed to construct the entire surface, even those polygons that lie behind others which we could not see if the surface was solid. On the right in <a href="" class="xref" data-knowl="./knowl/F_House.html" title="Figure 23.1">Figure 23.1</a> we have hidden the parts of the polygons that we cannot see from our view.</p>
<figure class="figure figure-like" id="F_House"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/6_a_House.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.1<span class="period">.</span></span><span class="space"> </span>Images of a house.</figcaption></figure><p id="p-3877">We also see this idea in mathematics when we graph surfaces. <a href="" class="xref" data-knowl="./knowl/F_Surface.html" title="Figure 23.2">Figure 23.2</a> shows the graph of the surface defined by <span class="process-math">\(f(x,y) = \sqrt{4-x^2}\)</span> that is made up of polygons. At left we see all of the polygons and at right only those parts that would be visible from our viewing perspective.</p>
<figure class="figure figure-like" id="F_Surface"><div class="sidebyside"><div class="sbsrow" style="margin-left:10%;margin-right:10%;">
<div class="sbspanel top" style="width:37.5%;"><img src="external/6_a_Surface_1.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:37.5%;"><img src="external/6_a_Surface_2.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.2<span class="period">.</span></span><span class="space"> </span>Graphs of <span class="process-math">\(f(x,y) = \sqrt{4-x^2}\text{.}\)</span></figcaption></figure><p id="p-3878">By eliminating the parts of the polygons we cannot see from our viewing perspective, the computer program can more quickly render the viewing image. Later in this section we will explore one method for how programs remove the hidden portions of images. This process involves the dot product of vectors.</p></section><section class="section" id="sec_dot_prod_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-3879">Orthogonality, a concept which generalizes the idea of perpendicularity, is an important concept in linear algebra. We use the dot product to define orthogonality and more generally angles between vectors in <span class="process-math">\(\R^n\)</span> for any dimension <span class="process-math">\(n\text{.}\)</span> The dot product has many applications, e.g., finding components of forces acting in different directions in physics and engineering. The dot product is also an example of a larger concept, <dfn class="terminology">inner products</dfn>, that we will discuss later. We introduce and investigate dot products in this section.</p>
<p id="p-3880">We will illustrate the dot product in <span class="process-math">\(\R^2\text{,}\)</span> but the process we go through will translate to any dimension. Recall that we can represent the vector <span class="process-math">\(\vv = \left[ \begin{array}{c} v_1 \\ v_2 \end{array}  \right]\)</span> as the directed line segment (or arrow) from the origin to the point <span class="process-math">\((v_1, v_2)\)</span> in <span class="process-math">\(\R^2\text{,}\)</span> as illustrated in <a href="" class="xref" data-knowl="./knowl/F_6_a_Vector_norm.html" title="Figure 23.3">Figure 23.3</a>. Using the Pythagorean Theorem we can then define the length (or magnitude or norm) of the vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^2\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_6_a_Vector_norm.html">
\begin{equation*}
|| \vv || = \sqrt{v_1^2 + v_2^2}\text{.}
\end{equation*}
</div>
<p id="p-3881">We can also write this norm as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\sqrt{v_1v_1 + v_2v_2}\text{.}
\end{equation*}
</div>
<p id="p-3882">The expression under the square root is an important one and we extend it and give it a special name.</p>
<figure class="figure figure-like" id="F_6_a_Vector_norm"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_Vector_norm.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.3<span class="period">.</span></span><span class="space"> </span>A vector in <span class="process-math">\(\R^2\)</span> from the origin to a point.</figcaption></figure><p id="p-3883">If <span class="process-math">\(\vu = [ u_1 \ u_2 ]^{\tr}\)</span> and <span class="process-math">\(\vv = [ v_1 \ v_2]^{\tr}\)</span> are vectors in <span class="process-math">\(\R^2\text{,}\)</span> then we call the expression <span class="process-math">\(u_1v_1+u_2v_2\)</span> the <dfn class="terminology">dot product</dfn> of <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> and denote it as <span class="process-math">\(\vu \cdot \vv\text{.}\)</span> With this idea in mind, we can rewrite the norm of the vector <span class="process-math">\(\vv\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|| \vv || = \sqrt{\vv \cdot \vv}\text{.}
\end{equation*}
</div>
<p id="p-3884">The definition of the dot product translates naturally to <span class="process-math">\(\R^n\)</span> (see <a href="" class="xref" data-knowl="./knowl/ex_1_e_scalar_product.html" title="Exercise 5">Exercise 5</a> in <a href="chap_matrix_vector.html" class="internal" title="Section 5: The Matrix-Vector Form of a Linear System">Section 5</a>).</p>
<article class="definition definition-like" id="def_6_a_dot_product"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.4</span><span class="period">.</span>
</h4>
<p id="p-3885">Let <span class="process-math">\(\vu = [u_1 \ u_2 \ \cdots \ u_n]\)</span> and <span class="process-math">\(\vv = [ v_1 \ v_2 \ \cdots \ v_n ]\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span> The <dfn class="terminology">dot product</dfn> (or <dfn class="terminology">scalar product</dfn> ) of <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> is the scalar</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu \cdot \vv = u_1v_1 + u_2v_2 + \cdots + u_nv_n = \displaystyle \sum_{i=1}^n u_iv_i\text{.}
\end{equation*}
</div></article><p id="p-3886">The dot product then allows us to define the norm (or magnitude or length) of any vector in <span class="process-math">\(\R^n\text{.}\)</span></p>
<article class="definition definition-like" id="def_6_a_length_Rn"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.5</span><span class="period">.</span>
</h4>
<p id="p-3887">The <dfn class="terminology">norm</dfn> <span class="process-math">\(||\vv||\)</span> of the vector <span class="process-math">\(\vv \in \R^n\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||\vv|| = \sqrt{\vv \cdot \vv}\text{.}
\end{equation*}
</div></article><p id="p-3888"> We also use the words <dfn class="terminology">magnitude</dfn> or <dfn class="terminology">length</dfn> as alternatives for the word norm. We can equivalently write the norm of the vector <span class="process-math">\(\vv = [ v_1 \ v_2 \ \cdots \ v_n ]^{\tr}\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||\vv|| = \sqrt{v_1^2 + v_2^2 + \cdots + v_n^2}\text{.}
\end{equation*}
</div>
<p id="p-3889">We can also realize the dot product as a matrix product. If <span class="process-math">\(\vu = [ u_1 \ u_2 \ \cdots \ u_n ]^{\tr}\)</span> and <span class="process-math">\(\vv = [  v_1 \ v_2 \ \cdots \ v_n ]^{\tr}\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu \cdot \vv = \vu^{\tr}\vv
\end{equation*}
</div>
<p class="continuation"><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-39" id="fn-39"><sup> 39 </sup></a>.</p>
<section class="paragraphs" id="paragraphs-28"><h4 class="heading"><span class="title">IMPORTANT NOTE.</span></h4>
<p id="p-3890">The dot product is only defined between two vectors with the <em class="emphasis">same number of components</em>.</p></section><article class="exploration project-like" id="pa_6_a"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">23.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1272"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3891">Find <span class="process-math">\(\vu \cdot \vv\)</span> if <span class="process-math">\(\vu = [2 \ 3 \ -1 \ 4]^{\tr}\)</span> and <span class="process-math">\(\vv = [4 \ 6 \ 7 \ -5]^{\tr}\)</span> in <span class="process-math">\(\R^4\text{.}\)</span></p></article><article class="task exercise-like" id="task-1273"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-373">
<p id="p-3892">The dot product satisfies some useful properties as given in the next theorem.</p>
<article class="theorem theorem-like" id="thm_6_a_dot_product"><h6 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">23.6</span><span class="period">.</span>
</h6>
<p id="p-3893">Let <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\text{,}\)</span> and <span class="process-math">\(\vw\)</span> be vectors in <span class="process-math">\(\R^n\text{,}\)</span> and let <span class="process-math">\(c\)</span> be a scalar. Then</p>
<ul class="disc">
<li id="li-648"><p id="p-3894"><span class="process-math">\(\vu \cdot \vv = \vv \cdot \vu\)</span> (the dot product is <dfn class="terminology">commutative</dfn>),</p></li>
<li id="li-649"><p id="p-3895"><span class="process-math">\((\vu + \vv) \cdot \vw = (\vu \cdot \vw) + (\vv \cdot \vw)\)</span> (the dot product <dfn class="terminology">distributes over vector addition</dfn>),</p></li>
<li id="li-650"><p id="p-3896"><span class="process-math">\((c\vu) \cdot \vv = \vu \cdot (c\vv) = c(\vu \cdot \vv)\text{,}\)</span></p></li>
<li id="li-651"><p id="p-3897"><span class="process-math">\(\vu \cdot \vu \geq 0\)</span> with equality if and only if <span class="process-math">\(\vu = \vzero\text{,}\)</span></p></li>
<li id="li-652"><p id="p-3898"><span class="process-math">\(||c \vu || = |c| ||\vu||\text{.}\)</span></p></li>
</ul></article><p id="p-3899">Verification of some of these properties is left to the exercises. Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^5\)</span> with <span class="process-math">\(\vu \cdot \vv = -1\text{,}\)</span> <span class="process-math">\(|| \vu || = 2\)</span> and <span class="process-math">\(|| \vv || = 3\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-1274"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3900">Use property (c) of <a href="" class="xref" data-knowl="./knowl/thm_6_a_dot_product.html" title="Theorem 23.6">Theorem 23.6</a> to determine the value of <span class="process-math">\(\vu \cdot 2\vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-1275"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3901">Use property (b) of <a href="" class="xref" data-knowl="./knowl/thm_6_a_dot_product.html" title="Theorem 23.6">Theorem 23.6</a> to determine the value of <span class="process-math">\((\vu + \vv) \cdot \vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-1276"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3902">Use whatever properties of <a href="" class="xref" data-knowl="./knowl/thm_6_a_dot_product.html" title="Theorem 23.6">Theorem 23.6</a> that are needed to determine the value of <span class="process-math">\((2\vu+4\vv) \cdot (\vu - 7\vv)\text{.}\)</span></p></article></article><article class="task exercise-like" id="task-1277"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-374"><p id="p-3903">At times we will want to find vectors in the direction of a given vector that have a certain magnitude. Let <span class="process-math">\(\vu = [2 \ 2 \ 1]^{\tr}\)</span> in <span class="process-math">\(\R^3\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1278"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3904">What is <span class="process-math">\(|| \vu ||\text{?}\)</span></p></article><article class="task exercise-like" id="task-1279"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3905">Show that <span class="process-math">\(\left| \left| \frac{1}{||\vu||} \vu \right| \right| = 1\text{.}\)</span></p></article><article class="task exercise-like" id="task-1280"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3906">Vectors with magnitude 1 are important and are given a special name. <article class="definition definition-like" id="def_6_a_unit_vector"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.7</span><span class="period">.</span>
</h6>
<p id="p-3907">A vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> is a <dfn class="terminology">unit vector</dfn> if <span class="process-math">\(|| \vv || = 1\text{.}\)</span></p></article></p>
<p id="p-3908">We can use unit vectors to find vectors of a given length in the direction of a given vector. Let <span class="process-math">\(c\)</span> be a positive scalar and <span class="process-math">\(\vv\)</span> a vector in <span class="process-math">\(\R^n\text{.}\)</span> Use properties from <a href="" class="xref" data-knowl="./knowl/thm_6_a_dot_product.html" title="Theorem 23.6">Theorem 23.6</a> to show that the magnitude of the vector <span class="process-math">\(c \frac{\vv}{||\vv||}\)</span> is <span class="process-math">\(c\text{.}\)</span></p></article></article></article></section><section class="section" id="sec_dist_vec"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Distance Between Vectors</span>
</h3>
<p id="p-3909">Finding optimal solutions to systems is an important problem in applied mathematics. It is often the case that we cannot find an exact solution that satisfies certain constraints, so we look instead for the “best” solution that satisfies the constraints. An example of this is fitting a least squares line to a set of data. As we will see, the dot product will allow us to find “best” solutions to certain types of problems, where we measure accuracy using the notion of a distance between vectors. Geometrically, we can represent a vector <span class="process-math">\(\vu\)</span> as a directed line segment from the origin to the point defined by <span class="process-math">\(\vu\text{.}\)</span> If we have two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> we can think of the length of the difference <span class="process-math">\(\vu - \vv\)</span> as a measure of how far apart the two vectors are from each other. It is natural, then to define the distance between vectors as follows.</p>
<article class="definition definition-like" id="def_6_a_distance"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.8</span><span class="period">.</span>
</h4>
<p id="p-3910">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span> The <dfn class="terminology">distance</dfn> between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> is the length of the difference <span class="process-math">\(\vu - \vv\)</span> or</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|| \vu - \vv ||\text{.}
\end{equation*}
</div></article><p id="p-3911">As <a href="" class="xref" data-knowl="./knowl/F_6_a_vector_difference.html" title="Figure 23.9">Figure 23.9</a> illustrates, if vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> emanate from the same initial point, and <span class="process-math">\(P\)</span> and <span class="process-math">\(Q\)</span> are the terminal points of <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> respectively, then the difference <span class="process-math">\(|| \vu - \vv||\)</span> is the standard Euclidean distance between the points <span class="process-math">\(P\)</span> and <span class="process-math">\(Q\text{.}\)</span></p>
<figure class="figure figure-like" id="F_6_a_vector_difference"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_vector_difference.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.9<span class="period">.</span></span><span class="space"> </span><span class="process-math">\(|| \vu - \vv||\text{.}\)</span></figcaption></figure></section><section class="section" id="sec_angle_vec"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Angle Between Two Vectors</span>
</h3>
<p id="p-3912">Determining a “best” solution to a problem often involves finding a solution that minimizes a distance. We generally accomplish a minimization through orthogonality — which depends on the angle between vectors. Given two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> we position the vectors so that they emanate from the same initial point. If the vectors are nonzero, then they determine a plane in <span class="process-math">\(\R^n\text{.}\)</span> In that plane there are two angles that these vectors create. We will define the angle between the vectors to be the smaller of these two angles. The dot product will tell us how to find the angle between vectors. Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\)</span> and <span class="process-math">\(\theta\)</span> the angle between them as illustrated in <a href="" class="xref" data-knowl="./knowl/F_Angle.html" title="Figure 23.10">Figure 23.10</a>.</p>
<figure class="figure figure-like" id="F_Angle"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_Angle.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.10<span class="period">.</span></span><span class="space"> </span>The angle between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span></figcaption></figure><p id="p-3913">Using the Law of Cosines, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||\vu-\vv||^2=||\vu||^2+||\vv||^2 - 2||\vu|| \ ||\vv|| \ \cos(\theta) \,\text{.}
\end{equation*}
</div>
<p id="p-3914">Rearranging, we obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-161">
\begin{align*}
||\vu|| \ ||\vv|| \ \cos(\theta) \amp = \frac{1}{2} \left( ||\vu||^2+||\vv||^2 - ||\vu-\vv||^2 \right)\\
\amp = \frac{1}{2} (||\vu||^2+||\vv||^2 - (\vu-\vv)\cdot (\vu-\vv) )\\
\amp = \frac{1}{2} (||\vu||^2+||\vv||^2 - \vu\cdot \vu +2\vu \cdot \vv - \vv\cdot \vv )\\
\amp = \vu \cdot \vv  \, \text{.}
\end{align*}
</div>
<p id="p-3915"> So the angle <span class="process-math">\(\theta\)</span> between two nonzero vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> satisfies the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_6_a_angle_between">
\begin{equation}
\cos(\theta) = \frac{\vu \cdot \vv}{||\vu|| \ ||\vv||}\text{.}\tag{23.1}
\end{equation}
</div>
<p id="p-3916">Of particular interest to us will be the situation where vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are <dfn class="terminology">orthogonal</dfn> (perpendicular).<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-40" id="fn-40"><sup> 40 </sup></a> Intuitively, we think of two vectors as orthogonal if the angle between them is <span class="process-math">\(90^{\circ}\text{.}\)</span></p>
<article class="activity project-like" id="act_6_a_orthogonality"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.2</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1281"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3917">The vectors <span class="process-math">\(\ve_1 = [ 1 \ 0]^{\tr}\)</span> and <span class="process-math">\(\ve_2 = [0 \ 1]^{\tr}\)</span> are perpendicular in <span class="process-math">\(\R^2\text{.}\)</span> What is <span class="process-math">\(\ve_1 \cdot \ve_2\text{?}\)</span></p></article><article class="task exercise-like" id="task-1282"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-375"><p id="p-3918">Now let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be any vectors in <span class="process-math">\(\R^n\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1283"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3919">Suppose the angle between nonzero vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> is <span class="process-math">\(90^{\circ}\text{.}\)</span> What does Equation <a href="" class="xref" data-knowl="./knowl/eq_6_a_angle_between.html" title="Equation 23.1">(23.1)</a> tell us about <span class="process-math">\(\vu \cdot \vv\text{?}\)</span></p></article><article class="task exercise-like" id="task-1284"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3920">Now suppose that <span class="process-math">\(\vu \cdot \vv = 0\text{.}\)</span> What does Equation <a href="" class="xref" data-knowl="./knowl/eq_6_a_angle_between.html" title="Equation 23.1">(23.1)</a> tell us about the angle between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{?}\)</span> Why?</p></article><article class="task exercise-like" id="task-1285"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3921">Explain why the following definition makes sense. <article class="definition definition-like" id="def_6_a_orthogonal_dot_product"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.11</span><span class="period">.</span>
</h6>
<p id="p-3922">Two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> are <dfn class="terminology">orthogonal</dfn> if <span class="process-math">\(\vu \cdot \vv = 0\text{.}\)</span></p></article></p></article><article class="task exercise-like" id="task-1286"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-3923">According to <a href="" class="xref" data-knowl="./knowl/def_6_a_orthogonal_dot_product.html" title="Definition 23.11">Definition 23.11</a>, to which vectors is <span class="process-math">\(\vzero\)</span> orthogonal? Does this make sense to you intuitively? Explain.</p></article></article></article><article class="activity project-like" id="activity-86"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.3</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1287"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3924">Find the angle between the two vectors <span class="process-math">\(\vu = [1 \ 3 \ -2 \ 5]^{\tr}\)</span> and <span class="process-math">\(\vv = [5 \ 2 \ 3 \ -1]^{\tr}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1288"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3925">Find, if possible, two non-parallel vectors orthogonal to <span class="process-math">\(\vu = \left[ \begin{array}{r} 0\\3\\-2\\1 \end{array} \right]\text{.}\)</span></p></article></article></section><section class="section" id="sec_orthog_proj"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Orthogonal Projections</span>
</h3>
<p id="p-3926">When running a sprint, the racers may be aided or slowed by the wind. The wind assistance is a measure of the wind speed that is helping push the runners down the track. It is much easier to run a very fast race if the wind is blowing hard in the direction of the race. So that world records aren't dependent on the weather conditions, times are only recorded as record times if the wind aiding the runners is less than or equal to 2 meters per second. Wind speed for a race is recorded by a wind gauge that is set up close to the track. It is important to note, however, that weather is not always as cooperative as we might like. The wind does not always blow exactly in the direction of the track, so the gauge must account for the angle the wind makes with the track. If the wind is blowing in the direction of the vector <span class="process-math">\(\vu\)</span> in <a href="" class="xref" data-knowl="./knowl/F_Projection.html" title="Figure 23.12">Figure 23.12</a> and the track is in the direction of the vector <span class="process-math">\(\vv\)</span> in <a href="" class="xref" data-knowl="./knowl/F_Projection.html" title="Figure 23.12">Figure 23.12</a>, then only part of the total wind vector is actually working to help the runners. This part is called the orthogonal projection of the vector <span class="process-math">\(\vu\)</span> onto the vector <span class="process-math">\(\vv\)</span> and is denoted <span class="process-math">\(\proj_{\vv} \vu\text{.}\)</span> The next activity shows how to find this projection.</p>
<figure class="figure figure-like" id="F_Projection"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_Projection.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.12<span class="period">.</span></span><span class="space"> </span>The orthogonal projection of <span class="process-math">\(\vu\)</span> onto <span class="process-math">\(\vv\text{.}\)</span></figcaption></figure><article class="activity project-like" id="activity-87"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-376"><p id="p-3927">Since the orthogonal projection <span class="process-math">\(\proj_{\vv} \vu\)</span> is in the direction of <span class="process-math">\(\vv\text{,}\)</span> there exists a constant <span class="process-math">\(c\)</span> such that <span class="process-math">\(\proj_{\vv} \vu = c \vv\text{.}\)</span> If we determine the value of <span class="process-math">\(c\text{,}\)</span> we can find <span class="process-math">\(\proj_{\vv} \vu\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1289"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3928">The wind component that acts perpendicular to the direction of <span class="process-math">\(\vv\)</span> is called the projection of <span class="process-math">\(\vu\)</span> orthogonal to <span class="process-math">\(\vv\)</span> and is denoted <span class="process-math">\(\proj_{\perp \vv} \vu\)</span> as shown in <a href="" class="xref" data-knowl="./knowl/F_Projection.html" title="Figure 23.12">Figure 23.12</a>. Write an equation that involves <span class="process-math">\(\proj_{\vv} \vu\text{,}\)</span> <span class="process-math">\(\proj_{\perp \vv} \vu\text{,}\)</span> and <span class="process-math">\(\vu\text{.}\)</span> Then solve that equation for <span class="process-math">\(\proj_{\perp \vv} \vu\text{.}\)</span></p></article><article class="task exercise-like" id="task-1290"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3929">Given that <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\proj_{\perp \vv} \vu\)</span> are orthogonal, what does that tell us about <span class="process-math">\(\vv \cdot \proj_{\perp \vv} \vu\text{?}\)</span> Combine this fact with the result of part (a) and that <span class="process-math">\(\proj_{\vv} \vu = c \vv\)</span> to obtain an equation involving <span class="process-math">\(\vv\text{,}\)</span> <span class="process-math">\(\vu\text{,}\)</span> and <span class="process-math">\(c\text{.}\)</span></p></article><article class="task exercise-like" id="task-1291"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3930">Solve for <span class="process-math">\(c\)</span> using the equation you found in the previous step.</p></article><article class="task exercise-like" id="task-1292"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3931">Use your value of <span class="process-math">\(c\)</span> to identify <span class="process-math">\(\proj_{\vv} \vu\text{.}\)</span></p></article></article><p id="p-3932">To summarize:</p>
<article class="definition definition-like" id="definition-52"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.13</span><span class="period">.</span>
</h4>
<p id="p-3933">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\)</span> with <span class="process-math">\(\vv \neq \vzero\text{.}\)</span></p>
<ol class="decimal">
<li id="li-653">
<p id="p-3934">The <dfn class="terminology">orthogonal projection</dfn> of <span class="process-math">\(\vu\)</span> onto <span class="process-math">\(\vv\)</span> is the vector</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_6_a_projection">
\begin{equation}
\proj_{\vv} \vu = \frac{\vu \cdot \vv}{||\vv||^2} \vv\text{.}\tag{23.2}
\end{equation}
</div>
</li>
<li id="li-654">
<p id="p-3935">The <dfn class="terminology">projection</dfn> of <span class="process-math">\(\vu\)</span> orthogonal to <span class="process-math">\(\vv\)</span> is the vector</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\proj_{\perp \vv} \vu = \vu - \proj_{\vv} \vu\text{.}
\end{equation*}
</div>
</li>
</ol></article><article class="activity project-like" id="activity-88"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.5</span><span class="period">.</span>
</h4>
<p id="p-3936">Let <span class="process-math">\(\vu = \left[ \begin{array}{c} 5\\8 \end{array} \right]\)</span> and <span class="process-math">\(\vv = \left[ \begin{array}{r} 6\\-10 \end{array} \right]\text{.}\)</span> Find <span class="process-math">\(\proj_{\vv} \vu\)</span> and <span class="process-math">\(\proj_{\perp \vv} \vu\)</span> and draw a picture to illustrate.</p></article><p id="p-3937">The orthogonal projection of a vector <span class="process-math">\(\vu\)</span> onto a vector <span class="process-math">\(\vv\)</span> is really a projection of the vector <span class="process-math">\(\vu\)</span> onto the space <span class="process-math">\(\Span\{\vv\}\text{.}\)</span> The vector <span class="process-math">\(\proj_{\vv} \vu\)</span> is the best approximation to <span class="process-math">\(\vu\)</span> of all the vectors in <span class="process-math">\(\Span\{\vv\}\)</span> in the sense that <span class="process-math">\(\proj_{\vv} \vu\)</span> is the closest to <span class="process-math">\(\vu\)</span> among all vectors in <span class="process-math">\(\Span\{\vv\}\text{,}\)</span> as we will prove later.</p></section><section class="section" id="sec_orthog_comp"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Orthogonal Complements</span>
</h3>
<p id="p-3938"> In <a href="" class="xref" data-knowl="./knowl/act_6_a_orthogonality.html" title="Activity 23.2">Activity 23.2</a> we defined two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> to be orthogonal (or perpendicular) if <span class="process-math">\(\vu \cdot \vv = 0\text{.}\)</span> A use of orthogonality in geometry is to define a plane. A plane through the origin in <span class="process-math">\(\R^3\)</span> is a two dimensional subspace of <span class="process-math">\(\R^3\text{,}\)</span> and a plane is defined to be the set of all vectors in <span class="process-math">\(\R^3\)</span> that are orthogonal to a given vector (called a <dfn class="terminology">normal</dfn> vector). For example, to find the equation of the plane through the origin in <span class="process-math">\(\R^3\)</span> orthogonal to the normal vector <span class="process-math">\(\vn = [1 \ 2 \ -1]^{\tr}\text{,}\)</span> we seek all the vectors <span class="process-math">\(\vv = [x \  y \ z]^{\tr}\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_6_a_orthogonality.html">
\begin{equation*}
\vv \cdot \vn = \vzero\text{.}
\end{equation*}
</div>
<p id="p-3939">This gives us the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x+2y-z = 0
\end{equation*}
</div>
<p class="continuation">as the equation of this plane. The collection of all vectors that are orthogonal to a given subspace of vectors is called the <dfn class="terminology">orthogonal complement</dfn> of that subspace in <span class="process-math">\(\R^n\text{.}\)</span></p>
<article class="definition definition-like" id="def_6_a_orth_complement"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">23.14</span><span class="period">.</span>
</h4>
<p id="p-3940">Let <span class="process-math">\(W\)</span> be a subspace of <span class="process-math">\(\R^n\)</span> for some <span class="process-math">\(n \geq 1\text{.}\)</span> The <dfn class="terminology">orthogonal complement</dfn> of <span class="process-math">\(W\)</span> is the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
W^{\perp} = \{\vx \in \R^n : \vx \cdot \vw = 0 \text{ for all }  \vw \in W\}\text{.}
\end{equation*}
</div></article><article class="exploration project-like" id="pa_6_a_2"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">23.6</span><span class="period">.</span>
</h4>
<p id="p-3941">Let <span class="process-math">\(W = \Span\{[1 \ -1]^{\tr}\}\)</span> in <span class="process-math">\(\R^2\text{.}\)</span> Completely describe all vectors in <span class="process-math">\(W^{\perp}\)</span> both algebraically and geometrically.</p></article><p id="p-3942">There is a more general idea here as defined in <a href="" class="xref" data-knowl="./knowl/pa_6_a_2.html" title="Preview Activity 23.6">Preview Activity 23.6</a>. If we have a set <span class="process-math">\(S\)</span> of vectors in <span class="process-math">\(\R^n\text{,}\)</span> we let <span class="process-math">\(S^{\perp}\)</span> (read as “<span class="process-math">\(S\)</span> perp”, called the <dfn class="terminology">orthogonal complement</dfn> of <span class="process-math">\(S\)</span>) be the set of all vectors in <span class="process-math">\(\R^n\)</span> that are orthogonal to every vector in <span class="process-math">\(S\text{.}\)</span> In our plane example, the set <span class="process-math">\(S\)</span> is <span class="process-math">\(\{\vn\}\)</span> and <span class="process-math">\(S^{\perp}\)</span> is the plane with equation <span class="process-math">\(x+2y-z=0\text{.}\)</span></p>
<article class="activity project-like" id="activity-89"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-377"><p id="p-3943">We have seen another example of orthogonal complements. Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix with rows <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\)</span> , <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vr_m\)</span> in order. Consider the three spaces <span class="process-math">\(\Nul A\text{,}\)</span> <span class="process-math">\(\Row A\text{,}\)</span> and <span class="process-math">\(\Col A\)</span> related to <span class="process-math">\(A\text{,}\)</span> where <span class="process-math">\(\Row A = \Span\{\vr_1, \vr_2, \ldots, \vr_m\}\)</span> (that is, <span class="process-math">\(\Row A\)</span> is the span of the rows of <span class="process-math">\(A\)</span>). Let <span class="process-math">\(\vx\)</span> be a vector in <span class="process-math">\(\Row A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1293"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3944">What does it mean for <span class="process-math">\(\vx\)</span> to be in <span class="process-math">\(\Row A\text{?}\)</span></p></article><article class="task exercise-like" id="task-1294"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3945">Now let <span class="process-math">\(\vy\)</span> be a vector in <span class="process-math">\(\Nul A\text{.}\)</span> Use the result of part (a) and the fact that <span class="process-math">\(A \vy = \vzero\)</span> to explain why <span class="process-math">\(\vx \cdot \vy = 0\text{.}\)</span> Explain how this verifies <span class="process-math">\((\Row A)^{\perp} = \Nul A\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-29" id="hint-29"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-29"><div class="hint solution-like"><p id="p-3946">Calculate <span class="process-math">\(A \vy\)</span> using scalar products of rows of <span class="process-math">\(A\)</span> with <span class="process-math">\(\vy\text{.}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-1295"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3947">Use <span class="process-math">\(A^\tr\)</span> in place of <span class="process-math">\(A\)</span> in the result of the previous part to show <span class="process-math">\((\Col A)^{\perp} = \Nul A^{\tr}\text{.}\)</span></p></article></article><p id="p-3948">The activity proves the following theorem:</p>
<article class="theorem theorem-like" id="thm_6_a_orthogonal_subspaces"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">23.15</span><span class="period">.</span>
</h4>
<p id="p-3949">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(\Row A)^{\perp} = \Nul A \text{ and }  (\Col A)^{\perp} = \Nul A^{\tr}\text{.}
\end{equation*}
</div></article><p id="p-3950">To show that a vector is in the orthogonal complement of a subspace, it is not necessary to demonstrate that the vector is orthogonal to every vector in the subspace. If we have a basis for the subspace, it suffices to show that the vector is orthogonal to every vector in that basis for the subspace, as the next theorem demonstrates.</p>
<article class="theorem theorem-like" id="thm_6_a_dot_pd_orth_complement_basis"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">23.16</span><span class="period">.</span>
</h4>
<p id="p-3951">Let <span class="process-math">\(\CB = \{\vw_1, \vw_2, \ldots, \vw_m\}\)</span> be a basis for a subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\text{.}\)</span> A vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> is orthogonal to every vector in <span class="process-math">\(W\)</span> if and only if <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(\CB\text{.}\)</span></p></article><article class="proof" id="proof-11"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-3952">Let <span class="process-math">\(\CB = \{\vw_1, \vw_2, \ldots, \vw_m\}\)</span> be a basis for a subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\)</span> and let <span class="process-math">\(\vv\)</span> be a vector in <span class="process-math">\(\R^n\text{.}\)</span> Our theorem is a biconditional, so we need to prove both implications. Since <span class="process-math">\(\CB \subset W\text{,}\)</span> it follows that if <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(W\text{,}\)</span> then <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(\CB\text{.}\)</span> This proves the forward implication. Now we assume that <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(\CB\)</span> and show that <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(W\text{.}\)</span> Let <span class="process-math">\(\vx\)</span> be a vector in <span class="process-math">\(W\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = x_1\vw_1 + x_2\vw_2 + \cdots + x_m\vw_m
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_m\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-162">
\begin{align*}
\vv \cdot \vx \amp = \vv \cdot (x_1\vw_1 + x_2\vw_2 + \cdots + x_m\vw_m)\\
\amp = x_1(\vv \cdot \vw_1) + x_2(\vv \cdot \vw_2) + \cdots + x_m(\vv \cdot \vw_m)\\
\amp = 0\text{.}
\end{align*}
</div>
<p id="p-3953">Thus, <span class="process-math">\(\vv\)</span> is orthogonal to <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vv\)</span> is orthogonal to every vector in <span class="process-math">\(W\text{.}\)</span></p></article><article class="activity project-like" id="activity-90"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">23.8</span><span class="period">.</span>
</h4>
<p id="p-3954">Let <span class="process-math">\(W = \Span\left\{ \left[ \begin{array}{c} 1 \\ 1 \\ 0 \end{array} \right], \left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array} \right] \right\}\text{.}\)</span> Find all vectors in <span class="process-math">\(W^{\perp}\text{.}\)</span></p></article><p id="p-3955">We will work more closely with projections and orthogonal complements in later sections.</p></section><section class="section" id="sec_dot_prod_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-3956">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-46"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">23.17</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-378"><p id="p-3957">Let <span class="process-math">\(\ell\)</span> be the line defined by the equation <span class="process-math">\(ax+by+c=0\)</span> with in <span class="process-math">\(\R^2\)</span> and let <span class="process-math">\(P = (x_0,y_0)\)</span> be a point in the plane. In this example we will learn how to find the distance from <span class="process-math">\(P\)</span> to <span class="process-math">\(\ell\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1296"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3958">Show that <span class="process-math">\(\vn = [a \ b]^{\tr}\)</span> is orthogonal to the line <span class="process-math">\(\ell\text{.}\)</span> That is, <span class="process-math">\(\vn\)</span> is orthogonal to any vector on the line <span class="process-math">\(\ell\text{.}\)</span></p>
<div class="solution solution-like" id="solution-138">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3959">Any vector on the line <span class="process-math">\(\ell\)</span> is a  vector between two points on the line. Let <span class="process-math">\(Q = (x_1,y_1)\)</span> and <span class="process-math">\(R = (x_2,y_2)\)</span> be points on the line <span class="process-math">\(\ell\text{.}\)</span> Then <span class="process-math">\(\vu = \overrightarrow{QR} = [x_2-x_1 \ y_2-y_1]^{\tr}\)</span> is a vector on line <span class="process-math">\(\ell\text{.}\)</span> Since <span class="process-math">\(Q\)</span> and <span class="process-math">\(R\)</span> are on the line, we know that <span class="process-math">\(ax_1+by_1+c=0\)</span> and <span class="process-math">\(ax_2+by_2+c = 0\text{.}\)</span> So <span class="process-math">\(-c = ax_1+by_1 = ax_2+by_2\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
0 = a(x_2-x_1) + b(y_2-y_1) = [a \ b]^{\tr} \vu\text{.}
\end{equation*}
</div>
<p class="continuation">Thus, <span class="process-math">\(\vn = [a \ b]^{\tr}\)</span> is orthogonal to every vector on the line <span class="process-math">\(\ell\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1297"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3960">Let <span class="process-math">\(Q = (x_1, y_1)\)</span> be any point on line <span class="process-math">\(\ell\text{.}\)</span> Draw a representative picture of <span class="process-math">\(P\text{,}\)</span> <span class="process-math">\(\vn\)</span> with its initial point at <span class="process-math">\(P\text{,}\)</span> along with <span class="process-math">\(Q\)</span> and <span class="process-math">\(\ell\text{.}\)</span> Explain how to use a projection to determine the distance from <span class="process-math">\(P\)</span> to <span class="process-math">\(\ell\text{.}\)</span></p>
<div class="solution solution-like" id="solution-139">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3961">A picture of the situation is shown in <a href="" class="xref" data-knowl="./knowl/F_dist_point_line.html" title="Figure 23.18">Figure 23.18</a>. If <span class="process-math">\(\vv = \overrightarrow{PQ}\text{,}\)</span> then the distance from point <span class="process-math">\(P\)</span> to line <span class="process-math">\(\ell\)</span> is given by <span class="process-math">\(||\proj_{\vn} \vv||\text{.}\)</span> <figure class="figure figure-like" id="F_dist_point_line"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_distance_line.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.18<span class="period">.</span></span><span class="space"> </span>Distance from a point to a line.</figcaption></figure></p>
</div></article><article class="task exercise-like" id="task-1298"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3962">Use the idea from part (b) to show that the distance <span class="process-math">\(d\)</span> from <span class="process-math">\(P\)</span> to <span class="process-math">\(\ell\)</span> satisfies</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_dist_point_line">
\begin{equation}
d = \frac{|ax_0+by_0+c|}{\sqrt{a^2+b^2}}\text{.}\tag{23.3}
\end{equation}
</div>
<div class="solution solution-like" id="solution-140">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3963">Recall that <span class="process-math">\(\vn = [a \ b]^{\tr}\)</span> and <span class="process-math">\(\vv = \overrightarrow{PQ} = [x_1-x_0 \ y_1-y_0]^{\tr}\text{.}\)</span> Since <span class="process-math">\(ax_1+by_1+c = 0\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-163">
\begin{align*}
\proj_{\vn} \vv \amp = \frac{\vv \cdot \vv}{||\vn||^2} \vn\\
\amp = \frac{a(x_1-x_0)+ b(y_1-y_0)}{a^2+b^2} [a \ b]^{\tr}\\
\amp = \frac{ax_1+by_1-ax_0-by_0}{a^2+b^2} [a \ b]^{\tr}\\
\amp = \frac{-c-ax_0-by_0}{a^2+b^2} [a \ b]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">So</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||\proj_{\vn} \vv|| = \frac{|ax_0+by_0+c|}{a^2+b^2} \sqrt{a^2+b^2} = \frac{|ax_0+by_0+c|}{\sqrt{a^2+b^2}}\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1299"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3964">Use Equation <a href="" class="xref" data-knowl="./knowl/eq_dist_point_line.html" title="Equation 23.3">(23.3)</a> to find the distance from the point <span class="process-math">\((3,4)\)</span> to the line <span class="process-math">\(y = 2x+1\text{.}\)</span></p>
<div class="solution solution-like" id="solution-141">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3965">Here we have <span class="process-math">\(P = (3,4)\text{,}\)</span> and the equation of our line is <span class="process-math">\(2x-y+1=0\text{.}\)</span> So <span class="process-math">\(a=2\text{,}\)</span> <span class="process-math">\(b=-1\text{,}\)</span> and <span class="process-math">\(c=-1\text{.}\)</span> Thus, the distance from <span class="process-math">\(P\)</span> to the line is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{|ax_0+by_0+c|}{\sqrt{a^2+b^2}} = \frac{|2(3)-(4)+1|}{\sqrt{4+1}} = \frac{3}{\sqrt{5}}\text{.}
\end{equation*}
</div>
</div></article></article><article class="example example-like" id="example-47"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">23.19</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-379">
<p id="p-3966">Let <span class="process-math">\(a\text{,}\)</span> <span class="process-math">\(b\text{,}\)</span> and <span class="process-math">\(c\)</span> be scalars with <span class="process-math">\(a \neq 0\text{,}\)</span> and let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
W = \{ax+by+cz=0 : x,y,z \in \R\} \,\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-1300"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3967">Find two vectors that span <span class="process-math">\(W\text{,}\)</span> showing that <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(\R^3\text{.}\)</span> (In fact, <span class="process-math">\(W\)</span> is a plane through the origin in <span class="process-math">\(\R^3\text{.}\)</span>)</p>
<div class="solution solution-like" id="solution-142">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3968">The coefficient matrix for the system <span class="process-math">\(ax+by+cz = 0\)</span> is <span class="process-math">\([a \ b \ c]^{\tr}\text{.}\)</span> The first column is a pivot column and the others are not. So <span class="process-math">\(y\)</span> and <span class="process-math">\(z\)</span> are free variables and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[x \ y \ z]^{\tr} = \left[-\frac{b}{a}y - \frac{c}{a}z, y, z\right]^{\tr} = y\left[ -\frac{b}{a} \ 1 \ 0\right]^{\tr} + z\left[ -\frac{c}{a} \ 0 \ 1\right]^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">So <span class="process-math">\(W = \Span\left\{\left[ -\frac{b}{a} \ 1 \ 0\right]^{\tr}, \left[ -\frac{c}{a} \ 0 \ 1\right]^{\tr}\right\}\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1301"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3969">Find a vector <span class="process-math">\(\vn\)</span> that is orthogonal to the two vectors you found in part (a).</p>
<div class="solution solution-like" id="solution-143">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3970">If we let <span class="process-math">\(\vn = [a \ b \ c]^{\tr}\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-164">
\begin{align*}
\vn \cdot \left[ -\frac{b}{a} \ 1 \ 0\right]^{\tr} \amp = -b+b = 0\\
\vn \cdot \left[ -\frac{c}{a} \ 0 \ 1\right]^{\tr}\ \amp = -c+c = 0\text{.}
\end{align*}
</div>
<p class="continuation">Thus, <span class="process-math">\([a \ b \ c]^{\tr}\)</span> is orthogonal to both <span class="process-math">\(\left[ -\frac{b}{a} \ 1 \ 0\right]^{\tr}\)</span> and <span class="process-math">\(\left[ -\frac{c}{a} \ 0 \ 1\right]^{\tr}\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1302"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3971">Explain why <span class="process-math">\(\{\vn\}\)</span> is a basis for <span class="process-math">\(W^{\perp}\text{.}\)</span></p>
<div class="solution solution-like" id="solution-144">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3972">Let <span class="process-math">\(\vu = \left[ -\frac{b}{a} \ 1 \ 0\right]^{\tr}\)</span> and <span class="process-math">\(\vv = \left[ -\frac{c}{a} \ 0 \ 1\right]^{\tr}\text{.}\)</span> Every vector in <span class="process-math">\(W\)</span> has the form <span class="process-math">\(x\vu + y\vv\)</span> for some scalars <span class="process-math">\(x\)</span> and <span class="process-math">\(y\text{,}\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vn \cdot (x\vu + y\vv) = x(\vn \cdot \vu) + y (\vn \cdot \vv) = 0\text{.}
\end{equation*}
</div>
<p class="continuation">So <span class="process-math">\(\vn \in W^{\perp}\text{.}\)</span> Now we need to verify that <span class="process-math">\(\{\vn\}\)</span> spans <span class="process-math">\(W^{\perp}\text{.}\)</span> Let <span class="process-math">\(\vw = [w_1 \ w_2 \ w_3]^{\tr}\)</span> be in <span class="process-math">\(W^{\perp}\text{.}\)</span> Then <span class="process-math">\(\vw \cdot \vz = 0\)</span> for every <span class="process-math">\(\vz \in W\text{.}\)</span> In particular, <span class="process-math">\(\vw \cdot \vu = 0\)</span> or <span class="process-math">\(-\frac{b}{a}w_1 + w_2 = 0\text{,}\)</span> and <span class="process-math">\(\vw \cdot \vv = 0\)</span> or <span class="process-math">\(-\frac{c}{a}w_1 + w_3 = 0\text{.}\)</span> Equivalently, we have <span class="process-math">\(w_2 = \frac{b}{a}w_1\)</span> and <span class="process-math">\(w_3 = \frac{c}{a}w_1\text{.}\)</span> So</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-165">
\begin{align*}
\vw \amp =  [w_1 \ w_2 \ w_3]^{\tr}\\
\amp = \left[ w_1 \ \frac{b}{a}w_1 \ \frac{c}{a}w_1\right]^{\tr}\\
\amp = \frac{1}{a}[a \ b \ c]^{\tr}w_1\\
\amp = \frac{w_1}{a} \vn\text{.}
\end{align*}
</div>
<p class="continuation">So every vector in <span class="process-math">\(W^{\perp}\)</span> is a multiple of <span class="process-math">\(\vn\text{,}\)</span> and <span class="process-math">\(\{\vn\}\)</span> spans <span class="process-math">\(W^{\perp}\text{.}\)</span> We conclude that <span class="process-math">\(\{\vn\}\)</span> is a basis for <span class="process-math">\(W^{\perp}\text{.}\)</span> Thus, the vector <span class="process-math">\([a \ b \ c]^{\tr}\)</span> is a normal vector to the plane <span class="process-math">\(ax+by+cz=0\)</span> if <span class="process-math">\(a \neq 0\text{.}\)</span> The same reasoning works if at least one of <span class="process-math">\(a\text{,}\)</span> <span class="process-math">\(b\text{,}\)</span>or <span class="process-math">\(c\)</span> is nonzero, so we can say in every case that <span class="process-math">\([a \ b \ c]^{\tr}\)</span> is a normal vector to the plane <span class="process-math">\(ax+by+cz=0\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_dot_prod_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-655">
<p id="p-3973">The dot product of vectors <span class="process-math">\(\vu = [u_1 \ u_2 \  \cdots  \ u_n ]^{\tr}\)</span> and <span class="process-math">\(\vv = [ v_1 \ v_2 \ \cdots \ v_n ]^{\tr}\)</span> in <span class="process-math">\(\R^n\)</span> is the scalar</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu \cdot \vv = u_1v_1 + u_2v_2 + \cdots + u_nv_n = \displaystyle \sum_{i=1}^n u_iv_i\text{.}
\end{equation*}
</div>
</li>
<li id="li-656">
<p id="p-3974">The angle <span class="process-math">\(\theta\)</span> between two nonzero vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> satisfies the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\cos(\theta) = \frac{\vu \cdot \vv}{||\vu|| \ ||\vv||}
\end{equation*}
</div>
<p class="continuation">and <span class="process-math">\(0\leq \theta \leq 180\text{.}\)</span></p>
</li>
<li id="li-657"><p id="p-3975">Two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are orthogonal if <span class="process-math">\(\vu \cdot \vv = 0\text{.}\)</span></p></li>
<li id="li-658"><p id="p-3976">The length, or norm, of the vector <span class="process-math">\(\vu\)</span> can be found as <span class="process-math">\(\ds || \vu || = \sqrt{\vu \cdot \vu}\text{.}\)</span></p></li>
<li id="li-659"><p id="p-3977">The distance between the vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\)</span> is <span class="process-math">\(||\vu - \vv ||\text{,}\)</span> which is the length of the difference <span class="process-math">\(\vu - \vv\text{.}\)</span></p></li>
<li id="li-660">
<p id="p-3978">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span></p>
<ul class="circle">
<li id="li-661">
<p id="p-3979">The orthogonal projection of <span class="process-math">\(\vu\)</span> onto <span class="process-math">\(\vv\)</span> is the vector</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\proj_{\vv} \vu = \frac{\vu \cdot \vv}{||\vv||^2} \vv\text{.}
\end{equation*}
</div>
</li>
<li id="li-662">
<p id="p-3980">The projection of <span class="process-math">\(\vu\)</span> perpendicular to <span class="process-math">\(\vv\)</span> is the vector</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\proj_{\perp \vv} \vu = \vu - \proj_{\vv} \vu\text{.}
\end{equation*}
</div>
</li>
</ul>
</li>
<li id="li-663">
<p id="p-3981">The orthogonal complement of the subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\)</span> is the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
W^{\perp} = \{\vx \in \R^n : \vx \cdot \vw = 0 \text{ for all }  \vw \in W\}\text{.}
\end{equation*}
</div>
</li>
</ul></section><section class="exercises" id="sec_dot_prod_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-221"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-380"><p id="p-3982">For each of the following pairs of vectors, find <span class="process-math">\(\vu \cdot \vv\text{,}\)</span> calculate the angle between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> determine if <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are orthogonal, find <span class="process-math">\(||\vu||\)</span> and <span class="process-math">\(||\vv||\text{,}\)</span> calculate the distance between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> and determine the orthogonal projection of <span class="process-math">\(\vu\)</span> onto <span class="process-math">\(\vv\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1303"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3983"><span class="process-math">\(\vu = [1 \ 2]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [-2 \ 1]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1304"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3985"><span class="process-math">\(\vu = [2 \ -2]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [1 \ -1]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1305"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3987"><span class="process-math">\(\vu = [2 \ -1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [1 \ 3]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1306"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3989"><span class="process-math">\(\vu = [1 \ 2 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [-2 \ 1 \ 1]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1307"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-3991"><span class="process-math">\(\vu = [0 \ 0 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [1 \ 1 \ 1]^{\tr}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-222"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-3993">Given <span class="process-math">\(\vu=[2 \ 1\ 2]^\tr\text{,}\)</span> find a vector <span class="process-math">\(\vv\)</span> so that the angle between <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> is <span class="process-math">\(60^\circ\)</span> and the orthogonal projection of <span class="process-math">\(\vv\)</span> onto <span class="process-math">\(\vu\)</span> has length 2.</p></article><article class="exercise exercise-like" id="exercise-223"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-3994">For which value(s) of <span class="process-math">\(h\)</span> is the angle between <span class="process-math">\([1\ 1\ h]^\tr\)</span> and <span class="process-math">\([1\ 2\ 1]^\tr\)</span> equal to <span class="process-math">\(60^\circ\text{?}\)</span></p></article><article class="exercise exercise-like" id="exercise-224"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-3996">Let <span class="process-math">\(A = [a_{ij}]\)</span> be a <span class="process-math">\(k \times m\)</span> matrix with rows <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vr_k\text{,}\)</span> and let <span class="process-math">\(B = [\vb_1 \ \vb_2 \ \cdots \ \vb_n]\)</span> be an <span class="process-math">\(m \times n\)</span> matrix with columns <span class="process-math">\(\vb_1\text{,}\)</span> <span class="process-math">\(\vb_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vb_n\text{.}\)</span> Show that we can write the matrix product <span class="process-math">\(AB\)</span> in a shorthand way as <span class="process-math">\(AB = [\vr_i \cdot \vb_j]\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-225"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-3997">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\text{,}\)</span> <span class="process-math">\(\vu\)</span> a vector in <span class="process-math">\(\R^n\)</span> and <span class="process-math">\(\vv\)</span> a vector in <span class="process-math">\(\R^m\text{.}\)</span> Show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A\vu \cdot \vv = \vu \cdot A^{\tr} \vv\text{.}
\end{equation*}
</div></article><article class="exercise exercise-like" id="exercise-226"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-381"><p id="p-3999">Let <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\text{,}\)</span> and <span class="process-math">\(\vw\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span> Show that</p></div>
<article class="task exercise-like" id="task-1308"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4000"><span class="process-math">\((\vu + \vv) \cdot \vw = (\vu \cdot \vw) + (\vv \cdot \vw)\)</span> (the dot product <dfn class="terminology">distributes over vector addition</dfn>)</p></article><article class="task exercise-like" id="task-1309"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4001">If <span class="process-math">\(c\)</span> is an arbitrary constant, then <span class="process-math">\((c\vu) \cdot \vv = \vu \cdot (c\vv) = c(\vu \cdot \vv)\)</span></p></article></article><article class="exercise exercise-like" id="ex_Pyth_Thm"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-382">
<p id="p-4002">The Pythagorean Theorem states that if <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> are the lengths of the legs of a right triangle whose hypotenuse has length <span class="process-math">\(c\text{,}\)</span> then <span class="process-math">\(a^2+b^2=c^2\text{.}\)</span> If we think of the legs as defining vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> then the hypotenuse is the vector <span class="process-math">\(\vu+\vv\)</span> and we can restate the Pythagorean Theorem as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||\vu+\vv||^2 = ||\vu||^2+||\vv||^2\text{.}
\end{equation*}
</div>
<p class="continuation">In this exercise we show that this result holds in any dimension.</p>
</div>
<article class="task exercise-like" id="task-1310"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4003">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be orthogonal vectors in <span class="process-math">\(\R^n\text{.}\)</span> Show that <span class="process-math">\(||\vu+\vv||^2 = ||\vu||^2+||\vv||^2\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-30" id="hint-30"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-30"><div class="hint solution-like"><p id="p-4004">Rewrite <span class="process-math">\(||\vu+\vv||^2\)</span> using the dot product.</p></div></div>
</div></article><article class="task exercise-like" id="task-1311"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4005">Must it be true that if <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors in <span class="process-math">\(\R^n\)</span> with <span class="process-math">\(||\vu+\vv||^2 = ||\vu||^2+||\vv||^2\text{,}\)</span> then <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are orthogonal? If not, provide a counterexample. If true, verify the statement.</p></article></article><article class="exercise exercise-like" id="ex_Cauchy_Schwarz"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-383">
<p id="p-4007">The Cauchy-Schwarz inequality,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_6_a_Cauchy_Schwartz">
\begin{equation}
|\vu \cdot \vv| \leq ||\vu|| \ \||\vv||\tag{23.4}
\end{equation}
</div>
<p class="continuation">for any vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> is considered one of the most important inequalities in mathematics. We verify the Cauchy-Schwarz inequality in this exercise. Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-1312"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4008">Explain why the inequality <a href="" class="xref" data-knowl="./knowl/eq_6_a_Cauchy_Schwartz.html" title="Equation 23.4">(23.4)</a> is true if either <span class="process-math">\(\vu\)</span> or <span class="process-math">\(\vv\)</span> is the zero vector. As a consequence, we assume that <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are nonzero vectors for the remainder of this exercise.</p></article><article class="task exercise-like" id="task-1313"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4009">Let <span class="process-math">\(\vw = \proj_{\vv} \vu = \frac{\vu \cdot \vv}{||\vv||^2} \vv\)</span> and let <span class="process-math">\(\vz = \vu - \vw\text{.}\)</span> We know that <span class="process-math">\(\vw \cdot \vz = 0\text{.}\)</span> Use <a href="" class="xref" data-knowl="./knowl/ex_Pyth_Thm.html" title="Exercise 7">Exercise 7</a> of this section to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_Pyth_Thm.html">
\begin{equation*}
||\vu||^2 \geq ||\vw||^2\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1314"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4010">Now show that <span class="process-math">\(||\vw||^2 = \frac{|\vu \cdot \vv|^2}{||\vv||^2}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1315"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4011">Combine parts (b) and (c) to explain why equation <a href="" class="xref" data-knowl="./knowl/eq_6_a_Cauchy_Schwartz.html" title="Equation 23.4">(23.4)</a> is true.</p></article></article><article class="exercise exercise-like" id="exercise-229"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-4012">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span> Then <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\vu+\vv\)</span> form a triangle. We should then expect that the length of any one side of the triangle is smaller than the sum of the lengths of the other sides (since the straight line distance is the shortest distance between two points). In other words, we expect that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_6_a_triangle_inequality.html ./knowl/ex_Cauchy_Schwarz.html" id="eq_6_a_triangle_inequality">
\begin{equation}
||\vu + \vv|| \leq ||\vu|| + ||\vv||\text{.}\tag{23.5}
\end{equation}
</div>
<p class="continuation">Equation <a href="" class="xref" data-knowl="./knowl/eq_6_a_triangle_inequality.html" title="Equation 23.5">(23.5)</a> is called the <dfn class="terminology">Triangle Inequality</dfn>. Use the Cauchy-Schwarz inequality (<a href="" class="xref" data-knowl="./knowl/ex_Cauchy_Schwarz.html" title="Exercise 8">Exercise 8</a>) to prove the triangle inequality.</p></article><article class="exercise exercise-like" id="exercise-230"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-4014">Let <span class="process-math">\(W\)</span> be a subspace of <span class="process-math">\(\R^n\)</span> for some <span class="process-math">\(n\text{.}\)</span> Show that <span class="process-math">\(W^{\perp}\)</span> is also a subspace of <span class="process-math">\(\R^n\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-231"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<p id="p-4015">Let <span class="process-math">\(W\)</span> be a subspace of <span class="process-math">\(\R^n\text{.}\)</span> Show that <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\((W^\perp)^\perp\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-232"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<p id="p-4017">If <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(\R^n\)</span> for some <span class="process-math">\(n\text{,}\)</span> what is <span class="process-math">\(W \cap W^{\perp}\text{?}\)</span> Verify your answer.</p></article><article class="exercise exercise-like" id="exercise-233"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<p id="p-4018">Suppose <span class="process-math">\(W_1\subseteq W_2\)</span> are two subspaces of <span class="process-math">\(\R^n\text{.}\)</span> Show that <span class="process-math">\(W_2^\perp \subseteq W_1^\perp\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-234"><h4 class="heading"><span class="codenumber">14<span class="period">.</span></span></h4>
<p id="p-4020">What are <span class="process-math">\(\left(\R^n\right)^{\perp}\)</span> and <span class="process-math">\(\{\vzero\}^{\perp}\)</span> in <span class="process-math">\(\R^n\text{?}\)</span> Justify your answers.</p></article><article class="exercise exercise-like" id="exercise-235"><h4 class="heading"><span class="codenumber">15<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-384"><p id="p-4021">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1316"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4022">The dot product is defined between any two vectors.</p></article><article class="task exercise-like" id="task-1317"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4024">If <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(\vu \cdot \vv\)</span> is another vector in <span class="process-math">\(\R^n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1318"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4025">If <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(\vu \cdot \vv\)</span> is always non-negative.</p></article><article class="task exercise-like" id="task-1319"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4027">If <span class="process-math">\(\vv\)</span> is a vector in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(\vv \cdot \vv\)</span> is never negative.</p></article><article class="task exercise-like" id="task-1320"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4028">If <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors in <span class="process-math">\(\R^n\)</span> and <span class="process-math">\(\vu \cdot \vv = 0\text{,}\)</span> then <span class="process-math">\(\vu = \vv = \vzero\text{.}\)</span></p></article><article class="task exercise-like" id="task-1321"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4030">If <span class="process-math">\(\vv\)</span> is a vector in <span class="process-math">\(\R^n\)</span> and <span class="process-math">\(\vv \cdot \vv = 0\text{,}\)</span> then <span class="process-math">\(\vv = \vzero\text{.}\)</span></p></article><article class="task exercise-like" id="task-1322"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4031">The norm of the sum of vectors is the sum of the norms of the vectors.</p></article><article class="task exercise-like" id="task-1323"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4033">If <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(\proj_{\vv} \vu\)</span> is a vector in the same direction as <span class="process-math">\(\vu\text{.}\)</span></p></article><article class="task exercise-like" id="task-1324"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4034">The only subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\)</span> for which <span class="process-math">\(W^\perp=\{\vzero\}\)</span> is <span class="process-math">\(W=\R^n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1325"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4036">If a vector <span class="process-math">\(\vu\)</span> is orthogonal to <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{,}\)</span> then <span class="process-math">\(\vu\)</span> is also orthogonal to <span class="process-math">\(\vv_1+\vv_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-1326"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4037">If a vector <span class="process-math">\(\vu\)</span> is orthogonal to <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{,}\)</span> then <span class="process-math">\(\vu\)</span> is also orthogonal to all linear combinations of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-1327"><h5 class="heading">
<span class="codenumber">(l)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4039">If <span class="process-math">\(\vu\neq \vzero\)</span> and <span class="process-math">\(\vv\)</span> are parallel, then the orthogonal projection of <span class="process-math">\(\vv\)</span> onto <span class="process-math">\(\vu\)</span> equals <span class="process-math">\(\vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-1328"><h5 class="heading">
<span class="codenumber">(m)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4040">If <span class="process-math">\(\vu\neq \vzero\)</span> and <span class="process-math">\(\vv\)</span> are orthogonal, then the orthogonal projection of <span class="process-math">\(\vv\)</span> onto <span class="process-math">\(\vu\)</span> equals <span class="process-math">\(\vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-1329"><h5 class="heading">
<span class="codenumber">(n)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4042">For any vector <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\vu\neq \vzero\text{,}\)</span> <span class="process-math">\(||\proj_\vu \vv|| \leq ||\vv||\text{.}\)</span></p></article><article class="task exercise-like" id="task-1330"><h5 class="heading">
<span class="codenumber">(o)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4043">Given an <span class="process-math">\(m\times n\)</span> matrix, <span class="process-math">\(\dim(\Row A)+\dim(\Row A)^\perp = n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1331"><h5 class="heading">
<span class="codenumber">(p)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4045">If <span class="process-math">\(A\)</span> is a square matrix, then the columns of <span class="process-math">\(A\)</span> are orthogonal to the vectors in <span class="process-math">\(\Nul A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1332"><h5 class="heading">
<span class="codenumber">(q)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4046">The vectors in the null space of an <span class="process-math">\(m \times n\)</span> matrix are orthogonal to vectors in the row space of <span class="process-math">\(A\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_back_face"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Back-Face Culling</span>
</h3>
<p id="p-4048">To identify hidden polygons in a surface, we will utilize a technique called <dfn class="terminology">back face culling</dfn>. This involves identifying which polygons are back facing and which are front facing relative to the viewer's perspective. The first step is to assign a direction to each polygon in a surface.</p>
<article class="project project-like" id="act_bf_normal"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">23.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-385">
<p id="p-4049">Consider the polygon <span class="process-math">\(ABCD\)</span> in <a href="" class="xref" data-knowl="./knowl/F_Normal_vector.html" title="Figure 23.20">Figure 23.20</a>. Since a polygon is flat, every vector in the polygon is perpendicular to a fixed vector (which we call a <dfn class="terminology">normal vector</dfn> to the polygon). A normal vector <span class="process-math">\(\vn\)</span> for the polygon <span class="process-math">\(ABCD\)</span> in <a href="" class="xref" data-knowl="./knowl/F_Normal_vector.html" title="Figure 23.20">Figure 23.20</a> is shown. In this activity we learn how to find a normal vector to a polygon.</p>
<p id="p-4050">Let <span class="process-math">\(\vx = [x_1 \ x_2 \ x_3]^{\tr}\)</span> and <span class="process-math">\(\vy = [y_1 \ y_2 \ y_3]^{\tr}\)</span> be two vectors in <span class="process-math">\(\R^3\text{.}\)</span> If <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\)</span> are linearly independent, then <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\)</span> determine a polygon as shown in <a href="" class="xref" data-knowl="./knowl/F_Normal_vector.html" title="Figure 23.20">Figure 23.20</a>. Our goal is to find a vector <span class="process-math">\(\vn\)</span> that is orthogonal to both <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\text{.}\)</span> Let <span class="process-math">\(\vw = [w_1 \ w_2 \ w_3]^{\tr}\)</span> be another vector in <span class="process-math">\(\R^3\)</span> and let <span class="process-math">\(C = \left[ \begin{array}{c} \vw^{\tr} \\ \vx^{\tr} \\ \vy^{\tr} \end{array}  \right]\)</span> be the matrix whose rows are <span class="process-math">\(\vw\text{,}\)</span> <span class="process-math">\(\vx\text{,}\)</span> and <span class="process-math">\(\vy\text{.}\)</span> Let <span class="process-math">\(C_{ij}\)</span> be the <span class="process-math">\(ij\)</span>th cofactor of <span class="process-math">\(C\text{,}\)</span> that is <span class="process-math">\(C_{ij}\)</span> is <span class="process-math">\((-1)^{i+j}\)</span> times the determinant of the submatrix of <span class="process-math">\(C\)</span> obtained by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of <span class="process-math">\(C\text{.}\)</span> Now define the vector <span class="process-math">\(\vx \times \vy\)</span> as follows:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_Normal_vector.html">
\begin{equation*}
\vx \times \vy = C_{11}\ve_1 + C_{12}\ve_2 + C_{13} \ve_3\text{.}
\end{equation*}
</div>
<p id="p-4051">The vector <span class="process-math">\(\vx \times \vy\)</span> is called the <dfn class="terminology">cross product</dfn> of the vectors <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\text{.}\)</span> (Note that the cross product is only defined for vectors in <span class="process-math">\(\R^3\text{.}\)</span>) We will show that <span class="process-math">\(\vx \times \vy\)</span> is orthogonal to both <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\text{,}\)</span> making <span class="process-math">\(\vx \times \vy\)</span> a normal vector to the polygon defined by <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\text{.}\)</span></p>
<figure class="figure figure-like" id="F_Normal_vector"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/6_a_normal.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.20<span class="period">.</span></span><span class="space"> </span>Normal vector to a polygon.</figcaption></figure>
</div>
<article class="task exercise-like" id="task-1333"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4052">Show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx \times \vy = \left[ \begin{array}{c} x_2y_3-x_3y_2 \\ x_3y_1-x_1y_3 \\ x_1y_2-x_2y_1 \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1334"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4053">Use a cofactor expansion of <span class="process-math">\(C\)</span> along the first row and properties of the dot product to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(C) = \vw \cdot (\vx \times \vy)\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1335"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4054">Use the result of part (b) and properties of the determinant to calculate <span class="process-math">\(\vx \cdot (\vx \times \vy)\)</span> and <span class="process-math">\(\vy \cdot (\vx \times \vy)\text{.}\)</span> Explain why <span class="process-math">\(\vx \times \vy\)</span> is orthogonal to both <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\)</span> and is therefore a normal vector to the polygon determined by <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\text{.}\)</span></p></article></article><p id="p-4055"><a href="" class="xref" data-knowl="./knowl/act_bf_normal.html" title="Project Activity 23.9">Project Activity 23.9</a> shows how we can find a normal vector to a parallelogram — take two vectors <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\)</span> between the vertices of the parallelogram and calculate their cross products. Such a normal vector can define a direction for the parallelogram. There is still a problem, however.</p>
<article class="project project-like" id="act_bf_normal_2"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">23.10</span><span class="period">.</span>
</h4>
<p id="p-4056">Let <span class="process-math">\(\vx = [x_1 \ x_2 \ x_3]^{\tr}\)</span> and <span class="process-math">\(\vy = [y_1 \ y_2 \ y_3]^{\tr}\)</span> be any vectors in <span class="process-math">\(\R^3\text{.}\)</span> There is a relationship between <span class="process-math">\(\vx \times \vy\)</span> and <span class="process-math">\(\vy \times \vx\text{.}\)</span> Find and verify this relationship.</p></article><p id="p-4057"><a href="" class="xref" data-knowl="./knowl/act_bf_normal_2.html" title="Project Activity 23.10">Project Activity 23.10</a> shows that the cross product is anticommutative, so we get different directions if we switch the order in which we calculate the cross product. To fix a direction, we establish the convention that we always label the vertices of our parallelogram in the counterclockwise direction as shown in <a href="" class="xref" data-knowl="./knowl/F_Normal_vector.html" title="Figure 23.20">Figure 23.20</a>. This way we always use <span class="process-math">\(\vx\)</span> as the vector from vertex <span class="process-math">\(A\)</span> to vertex <span class="process-math">\(B\)</span> rather than the reverse. With this convention established, we can now define the direction of a parallelogram as the direction of its normal vector.</p>
<p id="p-4058">Once we have a normal vector established for each polygon, we can now determine which polygons are back-face and which are front-face. <a href="" class="xref" data-knowl="./knowl/F_Hidden.html" title="Figure 23.21">Figure 23.21</a> at left provides the gist of the idea, where we represent the polygons with line segments to illustrate. If the viewer's eye is at point <span class="process-math">\(P\)</span> and views the figures, the normal vectors of the visible polygons point in a direction toward the viewer (front-face) and the normal vectors of the polygons hidden from the viewer point away from the viewer (back-face). What remains is to determine an effective computational way to identify the front and back facing polygons.</p>
<figure class="figure figure-like" id="F_Hidden"><div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/6_a_hidden.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/6_a_cull.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">23.21<span class="period">.</span></span><span class="space"> </span>Left: Hidden faces. Right: Back face culling.</figcaption></figure><article class="project project-like" id="act_bf_dot_product"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">23.11</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-386"><p id="p-4059">Consider the situation as depicted at right in <a href="" class="xref" data-knowl="./knowl/F_Hidden.html" title="Figure 23.21">Figure 23.21</a>. Assume that <span class="process-math">\(AB\)</span> and <span class="process-math">\(RS\)</span> are polygons (rendered one dimensionally here) with normal vectors <span class="process-math">\(\vn\)</span> at their centers as shown. The viewer's eye is at point <span class="process-math">\(P\)</span> and the viewer's line of vision to the centers <span class="process-math">\(C_{AB}\)</span> and <span class="process-math">\(C_{RS}\)</span> are indicated by the vectors <span class="process-math">\(\vv\text{.}\)</span> Each vector <span class="process-math">\(\vv\)</span> makes an angle <span class="process-math">\(\theta\)</span> with the normal to the polygon.</p></div>
<article class="task exercise-like" id="task-1336"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4060">What can be said about the angle <span class="process-math">\(\theta\)</span> for a front-facing polygon? What must be true about <span class="process-math">\(\vv \cdot \vn\)</span> for a front-facing polygon? Why?</p></article><article class="task exercise-like" id="task-1337"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4061">What can be said about the angle <span class="process-math">\(\theta\)</span> for a back-facing polygon? What must be true about <span class="process-math">\(\vv \cdot \vn\)</span> for a back-facing polygon? Why?</p></article><article class="task exercise-like" id="task-1338"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4062">The dot product then provides us with a simple computational tool for identifying back-facing polygons (assuming we have already calculated all of the normal vectors). We can then create an algorithm to cull the back-facing polygons. Assuming that we the viewpoint <span class="process-math">\(P\)</span> and the coordinates of the polygons of the surface, complete the pseudo-code for a back-face culling algorithm:</p>
<div class="code-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><pre class="program"><code class="language-none">for all polygons on the surface do
  calculate the normal vector n using the ______ product for the current polygon
  calculate the center C of the current polygon
  calculate the viewing vector ______
    if ______ then
      render the current polygon
  end if
end for
</code></pre></div></article></article><p id="p-4063">As a final comment, back-face culling generally reduces the number of polygons to be rendered by half. This algorithm is not perfect and does not always do what we want it to do (e.g., it may not remove all parts of a polygon that we don't see), so there are other algorithms to use in concert with back-face culling to correctly render objects.</p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-39"><div class="fn">Technically, <span class="process-math">\(\vu^{\tr}\vv\)</span> is a <span class="process-math">\(1 \times 1\)</span> matrix and not a scalar, but we usually think of <span class="process-math">\(1 \times 1\)</span> matrices as scalars.</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-40"><div class="fn">We use the term orthogonal instead of perpendicular because we will be able to extend this idea to situations where we normally don't think of objects as being perpendicular.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
