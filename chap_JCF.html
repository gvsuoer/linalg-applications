<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-23T15:00:58-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The Jordan Canonical Form</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_transformations_eigenvalues.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-lin-trans.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="backmatter-1.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_transformations_eigenvalues.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-lin-trans.html" title="Up">Up</a><a class="next-button button toolbar-item" href="backmatter-1.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_JCF"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span>
</h2>
<section class="introduction" id="introduction-697"><article class="objectives goal-like" id="objectives-40"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-698"><p id="p-6937">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-975"><p id="p-6938">What is the Jordan canonical form of a square matrix?</p></li>
<li id="li-976"><p id="p-6939">What is a generalized eigenvector of a matrix and how are generalized eigenvectors related to the Jordan canonical form of a matrix?</p></li>
<li id="li-977"><p id="p-6940">What does it mean for a vector space <span class="process-math">\(V\)</span> to be a direct sum of subspaces <span class="process-math">\(V_1\text{,}\)</span> <span class="process-math">\(V_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(V_m\text{?}\)</span></p></li>
<li id="li-978"><p id="p-6941">What is a nilpotent matrix? How do nilpotent matrices play a role in the Jordan canonical form?</p></li>
<li id="li-979"><p id="p-6942">What does it mean for a subspace <span class="process-math">\(W\)</span> of a vector space <span class="process-math">\(V\)</span> to be invariant under a linear transformation <span class="process-math">\(T: V \to V\text{?}\)</span></p></li>
</ul></article></section><section class="section" id="sec_appl_epidemic"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: The Bailey Model of an Epidemic</span>
</h3>
<p id="p-6943">The COVID-19 epidemic has generated many mathematical and statistical models to try to understand the spread of the virus. In 1950 Norman Bailey proposed a simple stochastic model of the spread of an epidemic. The solution to the model involves matrix exponentials and the Jordan canonical form is a useful tool for calculating matrix exponentials.</p></section><section class="section" id="sec_jordan_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-6944">We have seen several different matrix factorizations so far, eigenvalue decomposition (<a href="chap_diagonalization.html" class="internal" title="Section 19: Diagonalization">Section 19</a>), singular value decomposition (<a href="chap_SVD.html" class="internal" title="Section 29: The Singular Value Decomposition">Section 29</a>), QR factorization (<a href="chap_gram_schmidt.html" class="internal" title="Section 25: Projections onto Subspaces and the Gram-Schmidt Process in \R^n">Section 25</a>), and LU factorization (<a href="chap_det_properties.html" class="internal" title="Section 22: Properties of Determinants">Section 22</a>). In this section, we investigate the Jordan canonical form, which in a way generalizes the eigenvalue decomposition. For matrices with an eigenvalue decomposition, the geometric multiplicity of each eigenvalue (the dimension of the corresponding eigenspace) must equal its algebraic multiplicity (the number of times the eigenvalue occurs as a root of the characteristic polynomial of the matrix). We know that not every matrix has an eigenvalue decomposition. However, every square matrix has a Jordan canonical form, in which we use generalized eigenvectors and block diagonal form to approximate the eigenvalue decomposition behavior. At the end of the section we provide a complete proof of the existence of the Jordan canonical form.</p></section><section class="section" id="sec_eigen_dne"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">When an Eigenvalue Decomposition Does Not Exist</span>
</h3>
<p id="p-6945">Recall that an eigenvalue decomposition of a matrix exists if and only if the algebraic multiplicity equals the geometric multiplicity for each eigenvalue. In this case, the whole space <span class="process-math">\(\R^n\)</span> decomposes into eigenspaces corresponding to the eigenvalues and the matrix acts as scalar multiplication in each eigenspace. We consider some cases where such a decomposition exists and some where it does not to notice some differences between the two cases and think of ways to improvise the situation.</p>
<article class="exploration project-like" id="pa_JCF"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">40.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-2367"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-699"><p id="p-6946">All of the matrices below have only one eigenvalue, <span class="process-math">\(\lambda = 2\)</span> and characteristic polynomial <span class="process-math">\((\lambda-2)^n\)</span> where <span class="process-math">\(n\)</span> is the matrix size. Therefore, for each case, the algebraic multiplicity of this eigenvalue is the size of the matrix. Find the geometric multiplicity of this eigenvalue (i.e. the dimension of <span class="process-math">\(\Nul(A-\lambda I)\)</span>) in each case below to see how the behavior is different in each case.</p></div>
<article class="task exercise-like" id="task-2368"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-6947"><span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 0 \\ 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2369"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-6948"><span class="process-math">\(B = \left[ \begin{array}{cc} 2\amp 1 \\ 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2370"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-6949"><span class="process-math">\(C = \left[ \begin{array}{ccc} 2\amp 1\amp 0 \\ 0\amp 2\amp 1 \\ 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2371"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-6950"><span class="process-math">\(D = \left[ \begin{array}{ccc} 2\amp 1\amp 0 \\ 0\amp 2\amp 0 \\ 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2372"><h6 class="heading"><span class="codenumber">(v)</span></h6>
<p id="p-6951"><span class="process-math">\(E = \left[ \begin{array}{ccc} 2\amp 0\amp 0 \\ 0\amp 2\amp 0 \\ 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2373"><h6 class="heading"><span class="codenumber">(vi)</span></h6>
<p id="p-6952"><span class="process-math">\(F = \left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 0\amp 0 \\ 0\amp 0\amp 2\amp 1\\ 0\amp 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2374"><h6 class="heading"><span class="codenumber">(vii)</span></h6>
<p id="p-6953"><span class="process-math">\(G = \left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 1\amp 0 \\ 0\amp 0\amp 2\amp 1\\ 0\amp 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2375"><h6 class="heading"><span class="codenumber">(viii)</span></h6>
<p id="p-6954"><span class="process-math">\(H = \left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 0\amp 0 \\ 0\amp 0\amp 2\amp 0\\ 0\amp 0\amp 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2376"><h6 class="heading"><span class="codenumber">(ix)</span></h6>
<p id="p-6955"><span class="process-math">\(J = \left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 1\amp 0 \\ 0\amp 0\amp 2\amp 0\\ 0\amp 0\amp 0\amp 2 \end{array} \right]\)</span></p></article></article><article class="task exercise-like" id="task-2377"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-6956">In the examples above, the only matrices where the algebraic and geometric multiplicities of the eigenvalue 2 are equal are the diagonal matrices, which obviously have eigenvalue decompositions. The existence of ones above the diagonal destroys this property. However, the positioning of the ones is also strategical. By letting ones above the diagonal determine how to split the matrix into diagonal blocks, we can categorize the matrices. For example, the matrix in part (c) has one big <span class="process-math">\(3\times 3\)</span> block with twos on the diagonal and ones above, while the matrix in part (d) as a <span class="process-math">\(2\times 2\)</span> block at the top left and another <span class="process-math">\(1\times 1\)</span> block at the bottom right. Determine the blocks for all matrices above, and identify the relationship between the number of blocks and the geometric multiplicity.</p></article><article class="task exercise-like" id="task-2378"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-6957">For this last problem, we will focus on the matrix <span class="process-math">\(B\)</span> above. We know that <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 1 \\ 0 \end{array} \right]\)</span> is an eigenvector. We do not have a second linearly independent eigenvector, i.e. a solution to <span class="process-math">\((B-2I_2)\vx=\vzero\text{.}\)</span> However, since <span class="process-math">\((B-2I_2)^2=0\text{,}\)</span> we know that <span class="process-math">\((B-2I_2)(B-2I_2)\vx = \vzero\)</span> for any <span class="process-math">\(\vx\text{,}\)</span> which implies that <span class="process-math">\((B-2I_2)\vx\)</span> always lies inside the eigenspace corresponding to <span class="process-math">\(\lambda=2\text{.}\)</span> Find <span class="process-math">\((B-2I_2)\left[ \begin{array}{c} 0 \\ 1 \end{array} \right]\)</span> to verify this works in this particular case.</p></article></article></section><section class="section" id="sec_gen_eigen_jordan"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Generalized Eigenvectors and the Jordan Canonical Form</span>
</h3>
<p id="p-6958">If an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors, then <span class="process-math">\(A\)</span> is similar to a diagonal matrix with the eigenvalues along the diagonal. You discovered in <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a> a matrix without enough linearly independent eigenvectors can look close enough to a diagonal matrix. We now investigate whether this generalized representation can be achieved for all matrices.</p>
<article class="activity project-like" id="act_JC_intro"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-700"><p id="p-6959">Let <span class="process-math">\(M = \left[ \begin{array}{crc} 3 \amp -1 \amp 0 \\ 4 \amp 7 \amp 0 \\ 0\amp 0\amp 1 \end{array} \right]\text{.}\)</span> The characteristic polynomial of <span class="process-math">\(M\)</span> is <span class="process-math">\((\lambda-1)(\lambda - 5)^2\text{,}\)</span> so the eigenvalues of <span class="process-math">\(M\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(5\text{.}\)</span> For <span class="process-math">\(\lambda=1\text{,}\)</span> the eigenspace is also one dimensional and the vector <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array} \right]\)</span> is an eigenvector. For <span class="process-math">\(\lambda=5\text{,}\)</span> although the algebraic multiplicity is 2, the corresponding eigenspace is only one dimensional and <span class="process-math">\(\vv_0 = \left[ \begin{array}{r} -1\\2\\0 \end{array} \right]\)</span> is an eigenvector. We cannot diagonalize matrix <span class="process-math">\(M\)</span> because we do not have a second linearly independent eigenvector for the eigenvalue 5, which would give us the three linearly independent eigenvectors we need. Using the idea as in the last problem of <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a>, we can find another linearly independent vector to give us a matrix close to a diagonal matrix.</p></div>
<article class="task exercise-like" id="task-2379"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-6960">Find a vector <span class="process-math">\(\vv_3\)</span> that is in <span class="process-math">\(\Nul (M-5I_3)^2\)</span> but not in <span class="process-math">\(\Nul (M-5I_3)\text{.}\)</span> Then calculate <span class="process-math">\((M-5I_3)\vv_3\text{.}\)</span> How is <span class="process-math">\(\vv_2 = (M-5I_3)\vv_3\)</span> related to <span class="process-math">\(\vv_0\text{?}\)</span></p></article><article class="task exercise-like" id="task-2380"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-6961">Let <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \vv_3]\)</span> and calculate the product <span class="process-math">\(C^{-1}MC\)</span> for our example matrix <span class="process-math">\(M\text{.}\)</span></p></article><article class="task exercise-like" id="task-2381"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-6962">Describe the effect of <span class="process-math">\((M-I_3)\)</span> and <span class="process-math">\((M-5I_3)^2\)</span> on each of the column vectors of <span class="process-math">\(C\)</span> and explain why this justifies that <span class="process-math">\((M-I_3)(M-5I_3)^2\)</span> is the 0 matrix.</p></article></article><p id="p-6963"> <a href="" class="xref" data-knowl="./knowl/act_JC_intro.html" title="Activity 40.2">Activity 40.2</a> shows that even if a matrix does not have a full complement of linearly independent eigenvectors, we can still almost diagonalize the matrix. If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix that does not have <span class="process-math">\(n\)</span> linearly independent eigenvectors (such matrices area called <dfn class="terminology">defective</dfn>), the matrix <span class="process-math">\(A\)</span> is still similar to a matrix that is “close” to diagonal. <a href="" class="xref" data-knowl="./knowl/act_JC_intro.html" title="Activity 40.2">Activity 40.2</a> shows this for the case of a <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(M\)</span> with two eigenvalues, <span class="process-math">\(\lambda_1, \lambda_2\)</span> with <span class="process-math">\(\lambda_2\)</span> having algebraic multiplicity two, and each eigenvalue with one-dimensional eigenspace. Let <span class="process-math">\(\vv_1\)</span> be an eigenvector corresponding to <span class="process-math">\(\lambda_1\text{.}\)</span> Because <span class="process-math">\(\lambda_2\)</span> also has a one-dimensional eigenspace, the matrix <span class="process-math">\(M\)</span> has only two linearly independent eigenvectors. Nevertheless, as you saw in <a href="" class="xref" data-knowl="./knowl/act_JC_intro.html" title="Activity 40.2">Activity 40.2</a>, we can find a vector <span class="process-math">\(\vv_3\)</span> that is in <span class="process-math">\(\Nul (M - \lambda_2 I)^2\)</span> but not in <span class="process-math">\(\Nul (M-\lambda_2 I)\text{.}\)</span> From this, it follows that the vector <span class="process-math">\(\vv_2 = (M - \lambda_2 I) \vv_3\)</span> is an eigenvector of <span class="process-math">\(M\)</span> with eigenvalue <span class="process-math">\(\lambda_2\text{.}\)</span> In this case we have <span class="process-math">\(M \vv_3 = \lambda_2 \vv_3 + \vv_2\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JC_intro.html ./knowl/act_JC_intro.html ./knowl/act_JC_intro.html" id="md-260">
\begin{align*}
M [\vv_1 \ \vv_2 \ \vv_3] \amp = [M\vv_1 \ M\vv_2 \ M\vv_3]\\
\amp = [\lambda_1 \vv_1 \, \ \, \lambda_2 \vv_2 \, \ \, \lambda_2 \vv_3+\vv_2 ]\\
\amp = [\vv_1  \  \vv_2 \ \vv_3]  \left[ \begin{array}{ccc} \lambda_1 \amp 0 \amp  0\\
0 \amp  \lambda_2 \amp  1\\
0 \amp  0 \amp  \lambda_2 \end{array} \right]\text{.}
\end{align*}
</div>
<p id="p-6964">The lack of two linearly independent eigenvectors for this eigenvalue of algebraic multiplicity two will ensure that <span class="process-math">\(M\)</span> is not similar to a diagonal matrix, but <span class="process-math">\(M\)</span> is similar to a matrix with a diagonal block of the form <span class="process-math">\(\left[ \begin{array}{cc} \lambda \amp 1 \\ 0 \amp \lambda \end{array} \right]\text{.}\)</span> So even though the matrix <span class="process-math">\(M\)</span> is not diagonalizable, we can find an invertible matrix <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \vv_3]\)</span> so that <span class="process-math">\(C^{-1}AC\)</span> is almost diagonalizable.</p>
<p id="p-6965">In general, suppose we have an eigenvalue <span class="process-math">\(\lambda\)</span> of a matrix <span class="process-math">\(A\)</span> with algebraic multiplicity two but with a one-dimensional eigenspace. Then the eigenvalue <span class="process-math">\(\lambda\)</span> is deficient — that is <span class="process-math">\(\dim(E_{\lambda})\)</span> is strictly less than the algebraic multiplicity of <span class="process-math">\(\lambda\text{,}\)</span> i.e. <span class="process-math">\(E_{\lambda}\)</span> does not contain enough linearly independent eigenvectors for <span class="process-math">\(\lambda\text{.}\)</span> But as we saw above, we may be able to find a vector <span class="process-math">\(\vv_2\)</span> that is in <span class="process-math">\(\Nul (A - \lambda I)^2\)</span> but not in <span class="process-math">\(\Nul (A - \lambda I)\text{.}\)</span> When we let <span class="process-math">\(\vv_1 = (A-\lambda I) \vv_2\text{,}\)</span> we then also have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_JCF.html ./knowl/eq_JCF_gen_eigenvector.html" id="eq_JCF_gen_eigenvector">
\begin{equation}
\vzero = (A-\lambda I)^2\vv_2 = (A-\lambda I)\vv_1\tag{40.1}
\end{equation}
</div>
<p class="continuation">as we argued in <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a>, and so <span class="process-math">\(\vv_1\)</span> is an eigenvector for <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> It is vectors that satisfy an equation like <a href="" class="xref" data-knowl="./knowl/eq_JCF_gen_eigenvector.html" title="Equation 40.1">(40.1)</a> that drive the Jordan canonical form. These vectors are similar to eigenvectors and are called <dfn class="terminology">generalized eigenvectors</dfn>.</p>
<article class="definition definition-like" id="definition-98"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">40.1</span><span class="period">.</span>
</h4>
<p id="p-6966">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> A <dfn class="terminology">generalized eigenvector</dfn> of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\)</span> is a non-zero vector <span class="process-math">\(\vx\)</span> satisfying</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(A - \lambda I_n)^m \vx = \vzero
\end{equation*}
</div>
<p class="continuation">for some positive integer <span class="process-math">\(m\text{.}\)</span></p></article><p id="p-6967">In other words, a generalized eigenvector of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\)</span> is a nonzero vector in <span class="process-math">\(\Nul (A - \lambda I_n)^m\)</span> for some <span class="process-math">\(m\text{.}\)</span> Note that every eigenvector of <span class="process-math">\(A\)</span> is a generalized eigenvector (with <span class="process-math">\(m=1\)</span>). In <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a>, <span class="process-math">\(A\)</span> is a <span class="process-math">\(3 \times 3\)</span> matrix with eigenvalue <span class="process-math">\(\lambda = 5\)</span> having algebraic multiplicity 2 and geometric multiplicity 1. We were able to see that <span class="process-math">\(A\)</span> is similar to a matrix of the form <span class="process-math">\(\left[ \begin{array}{ccc} 1 \amp 0\amp 0 \\ 0 \amp 5 \amp 1 \\ 0\amp 0\amp 5 \end{array} \right]\)</span> because of the existence of a generalized eigenvector for the eigenvalue <span class="process-math">\(5\text{.}\)</span></p>
<p id="p-6968">The example in <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a> presents the basic idea behind how we can find a “simple” matrix that is similar to any square matrix, even if that matrix is not diagonalizable. The key is to find generalized eigenvectors for eigenvalues whose algebraic multiplicities exceed their geometric multiplicities. One way to do this is indicated in <a href="" class="xref" data-knowl="./knowl/pa_JCF.html" title="Preview Activity 40.1">Preview Activity 40.1</a> and in the next activity.</p>
<article class="activity project-like" id="act_JCF_gev_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-701">
<p id="p-6969">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{ccr} 5\amp 1\amp -4\\4\amp 3\amp -5\\3\amp 1\amp -2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-6970">The matrix <span class="process-math">\(A\)</span> has <span class="process-math">\(\lambda = 2\)</span> as its only eigenvalue, and the geometric multiplicity of <span class="process-math">\(\lambda\)</span> as an eigenvalue is 1. For this activity you may use the fact that the reduced row echelon forms of <span class="process-math">\(A-2I\text{,}\)</span> <span class="process-math">\((A-2I)^2\text{,}\)</span> and <span class="process-math">\((A-2I)^3\)</span> are, respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccr} 1\amp 0\amp -1\\0\amp 1\amp -1\\0\amp 0\amp 0 \end{array}  \right], \ \left[ \begin{array}{ccr} 1\amp 0\amp -1\\0\amp 0\amp 0\\0\amp 0\amp 0 \end{array}  \right], \ \left[ \begin{array}{ccc} 0\amp 0\amp 0\\0\amp 0\amp 0\\0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-2382"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-6971">To begin, we look for a vector <span class="process-math">\(\vv_3\)</span> that is in <span class="process-math">\(\Nul (A-2I_3)^3\)</span> that is not in <span class="process-math">\(\Nul (A-2I_3)^2\text{.}\)</span> Find such a vector.</p></article><article class="task exercise-like" id="task-2383"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-6972">Let <span class="process-math">\(\vv_2 = (A-2I_3)\vv_3\text{.}\)</span> Show that <span class="process-math">\(\vv_2\)</span> is in <span class="process-math">\(\Nul (A-2I_3)^2\)</span> but is not in <span class="process-math">\(\Nul (A-2I_3)\text{.}\)</span></p></article><article class="task exercise-like" id="task-2384"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-6973">Let <span class="process-math">\(\vv_1 = (A-2I_3)\vv_2\text{.}\)</span> Show that <span class="process-math">\(\vv_1\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(2\text{.}\)</span> That is, <span class="process-math">\(\vv_1\)</span> is in <span class="process-math">\(\Nul (A-2I_3)\text{.}\)</span></p></article><article class="task exercise-like" id="task-2385"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-6974">Let <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \vv_3]\text{.}\)</span> Calculate the matrix product <span class="process-math">\(C^{-1}AC\text{.}\)</span> What do you notice?</p></article></article><p id="p-6975">It is the equations <span class="process-math">\((A- 2I)\vv_{i+1} = \vv_i\)</span> from <a href="" class="xref" data-knowl="./knowl/act_JCF_gev_2.html" title="Activity 40.3">Activity 40.3</a> that give us this simple form <span class="process-math">\(\left[ \begin{array}{ccc} 2\amp 1\amp 0 \\ 0\amp 2\amp 1 \\ 0\amp 0\amp 2 \end{array}  \right]\text{.}\)</span> To better understand why, notice that the equations imply that <span class="process-math">\(A\vv_{i+1} = 2\vv_{i+1} + \vv_i\text{.}\)</span> So if <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \vv_3]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_gev_2.html" id="md-261">
\begin{align*}
AC \amp = [A\vv_1 \ A\vv_2 \ A\vv_3]\\
\amp = [2 \vv_1 \ 2 \vv_2 + \vv_1 \ 2 \vv_3 + \vv_2]\\
\amp = [\vv_1 \ \vv_2 \ \vv_3] \left[ \begin{array}{ccc} 2\amp 1\amp 0\\
0\amp 2\amp 1\\
0\amp 0\amp 2 \end{array} \right]\text{.}
\end{align*}
</div>
<p id="p-6976">This method will provide us with the Jordan canonical form. The major reason that this method always works is contained in the following theorem whose proof follows from the proof of the existence of the Jordan canonical form (presented later).</p>
<article class="theorem theorem-like" id="thm_JCF_1"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">40.2</span><span class="period">.</span>
</h4>
<p id="p-6977">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with eigenvalue <span class="process-math">\(\lambda\)</span> of algebraic multiplicity <span class="process-math">\(m\text{.}\)</span> Then there is a positive integer <span class="process-math">\(p \leq m\)</span> such that <span class="process-math">\(\dim(\Nul(A-\lambda I_n)^p) = m\text{.}\)</span></p></article><p id="p-6978">To find generalized eigenvectors, then, we find a value of <span class="process-math">\(p\)</span> so that <span class="process-math">\(\dim(\Nul(A-\lambda I_n)^p) = m\)</span> and then find a vector <span class="process-math">\(\vv_p\)</span> that is in <span class="process-math">\(\Nul(A-\lambda I_n)^p\)</span> but not in <span class="process-math">\(\Nul(A-\lambda I_n)^{p-1}\text{.}\)</span> Successive multiplications by <span class="process-math">\(A - \lambda I_n\)</span> provide a sequence of generalized eigenvectors. The sequence</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_p \underset{A - \lambda I_n}{\rightarrow} \vv_{p-1} \underset{A - \lambda I_n}{\rightarrow}  \cdots \ \underset{A - \lambda I_n}{\rightarrow} \vv_1 \underset{A - \lambda I_n}{\rightarrow} \vzero
\end{equation*}
</div>
<p class="continuation">is called a <dfn class="terminology">generalized eigenvector chain</dfn>.</p>
<article class="activity project-like" id="act_JCF_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-702">
<p id="p-6979">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{rrrc} 0\amp 0\amp 0\amp 2 \\ -6\amp 0\amp -2\amp 10 \\ -1\amp -1\amp 1\amp 3 \\ -3\amp -1\amp -1\amp 7 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-6980">The only eigenvalue of <span class="process-math">\(A\)</span> is <span class="process-math">\(\lambda = 2\)</span> and <span class="process-math">\(\lambda\)</span> has geometric multiplicity 2. The vectors <span class="process-math">\([0 \ -1 \ 1 \ 0]\)</span> and <span class="process-math">\([1 \ 2\ 0 \  1]^{\tr}\)</span> are eigenvectors for <span class="process-math">\(A\text{.}\)</span> The reduced row echelon forms for <span class="process-math">\(A - \lambda I_4\text{,}\)</span> <span class="process-math">\((A - \lambda I_4)^2\text{,}\)</span> <span class="process-math">\((A - \lambda I_4)^3\)</span> are, respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccr} 1\amp 0\amp 0\amp -1 \\ 0\amp 1\amp 1\amp -2 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right], \ \left[ \begin{array}{cccr} 1\amp 1\amp 1\amp -3 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right], \ \text{ and }  \ \left[ \begin{array}{cccc} 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-2386"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-6981">Identify the smallest value of <span class="process-math">\(p\)</span> as in <a href="" class="xref" data-knowl="./knowl/thm_JCF_1.html" title="Theorem 40.2">Theorem 40.2</a>.</p></article><article class="task exercise-like" id="task-2387"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-6982">Find a vector <span class="process-math">\(\vv_3\)</span> in <span class="process-math">\(\Nul (A - \lambda I_4)^3\)</span> that is not in <span class="process-math">\(\Nul (A - \lambda I_4)^2\text{.}\)</span></p></article><article class="task exercise-like" id="task-2388"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-6983">Now let <span class="process-math">\(\vv_2 = (A-\lambda I_4) \vv_3\)</span> and <span class="process-math">\(\vv_1 = (A-\lambda I_4) \vv_2\text{.}\)</span> What special property does <span class="process-math">\(\vv_1\)</span> have?</p></article><article class="task exercise-like" id="task-2389"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-6984">Find a fourth vector <span class="process-math">\(\vv_0\)</span> so that <span class="process-math">\(\{\vv_0, \vv_1, \vv_2, \vv_3\}\)</span> is a basis of <span class="process-math">\(\R^4\)</span> consisting of generalized eigenvectors of <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(C = [\vv_0 \ \vv_1 \ \vv_2 \ \vv_3]\text{.}\)</span> Calculate the product <span class="process-math">\(C^{-1}AC\text{.}\)</span> What do you see?</p></article></article><p id="p-6985"> The previous activities illustrate the general idea for almost diagonalizing an arbitrary square matrix. First let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with an eigenvalue <span class="process-math">\(\lambda\)</span> of of algebraic multiplicity <span class="process-math">\(n\)</span> and geometric multiplicity <span class="process-math">\(k\text{.}\)</span> If <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> are linearly independent eigenvectors for <span class="process-math">\(A\text{,}\)</span> then we can extend the set as we did in <a href="" class="xref" data-knowl="./knowl/act_JCF_3.html" title="Activity 40.4">Activity 40.4</a> above with generalized eigenvectors to a basis <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k, \vv_{k+1}, \ldots, \vv_n\}\)</span> of <span class="process-math">\(\R^n\text{.}\)</span> The matrix <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \cdots \ \vv_n]\)</span> has the property that <span class="process-math">\(C^{-1}AC\)</span> is almost diagonal. By almost, we mean that <span class="process-math">\(C^{_1}AC\)</span> has block matrices along the diagonal that look like</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_3.html ./knowl/eq_JCF_10.html" id="eq_JCF_10">
\begin{equation}
\left[ \begin{array}{ccccccc} \lambda\amp 1\amp 0 \amp \cdots\amp 0\amp 0\amp 0 \\ 0\amp \lambda\amp 1\amp \cdots\amp 0\amp 0\amp 0 \\ 0\amp 0\amp \lambda\amp \cdots\amp 0\amp 0\amp 0 \\ \amp \amp \amp \ddots\amp \ddots\amp \amp  \\ 0\amp 0\amp 0\amp \cdots\amp \lambda\amp 1\amp 0 \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda\amp 1 \\  0\amp 0\amp 0\amp \cdots\amp 0\amp 0\amp \lambda \end{array}  \right]\text{.}\tag{40.2}
\end{equation}
</div>
<p class="continuation">and has zeros everywhere else. A matrix of the form <a href="" class="xref" data-knowl="./knowl/eq_JCF_10.html" title="Equation 40.2">(40.2)</a> is called a <dfn class="terminology">Jordan block</dfn>.</p>
<p id="p-6986"> If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix with eigenvalues <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_k\text{,}\)</span> we repeat this process with every eigenvalue of <span class="process-math">\(A\)</span> to construct an invertible matrix <span class="process-math">\(C\)</span> so that <span class="process-math">\(C^{-1}AC\)</span> is of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_JCF_11.html" id="eq_JCF_11">
\begin{equation}
\left[ \begin{array}{cccc} J_1\amp 0\amp \cdots\amp 0 \\ 0\amp J_2\amp \cdots\amp 0 \\ \vdots\amp \vdots\amp \ddots\amp \vdots \\ 0\amp 0\amp \cdots\amp J_t \end{array}  \right]\text{,}\tag{40.3}
\end{equation}
</div>
<p class="continuation">where each matrix <span class="process-math">\(J_i\)</span> is a Jordan block (note that a <span class="process-math">\(1 \times 1\)</span> Jordan block is allowable). The form in <a href="" class="xref" data-knowl="./knowl/eq_JCF_11.html" title="Equation 40.3">(40.3)</a> is called the <dfn class="terminology">Jordan canonical form</dfn> or <dfn class="terminology">Jordan normal form</dfn> of the matrix <span class="process-math">\(A\text{.}\)</span> Later in this section we will prove the following theorem.</p>
<article class="theorem theorem-like" id="thm_JCF"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">40.3</span><span class="period">.</span>
</h4>
<p id="p-6987">Every square matrix is similar to a matrix in Jordan canonical form.</p></article><p id="p-6988">Another example may help illustrate the process.</p>
<article class="activity project-like" id="activity-156"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-703"><p id="p-6989">Let <span class="process-math">\(A = \left[ \begin{array}{rrcccc} 4\amp -1\amp 1\amp 0\amp 0\amp 0 \\ 0\amp 3\amp 1\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 3\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 3\amp 1\amp 0 \\ -1\amp 1\amp 0\amp 0\amp 4\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 4 \end{array}  \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(3\)</span> and <span class="process-math">\(4\text{,}\)</span> both with algebraic multiplicity 3. A basis for the eigenspace <span class="process-math">\(E_3\)</span> corresponding to the eigenvalue <span class="process-math">\(3\)</span> is <span class="process-math">\(\{[1 \ 1 \ 0 \ 0 \ 0 \ 0]^{\tr}\}\)</span> and a basis for the eigenspace <span class="process-math">\(E_4\)</span> corresponding to the eigenvalue <span class="process-math">\(4\)</span> is <span class="process-math">\(\{[1 \ 0 \ 0 \ 0 \ 0 \ 1]^{\tr}, [1 \ 1 \ 1 \ 1 \ 1 \ 0]^{\tr}\}\text{.}\)</span> In this activity we find a Jordan canonical form of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2390"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-6990">Assume that the reduced row echelon forms of <span class="process-math">\(A -3 I_6\text{,}\)</span> <span class="process-math">\((A-3I_6)^2\text{,}\)</span> and <span class="process-math">\((A-3I_6)^3\)</span> are, respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{crcccc} 1\amp -1\amp 0\amp 0\amp 0\amp 0\\ 0\amp 0\amp 1\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 1\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right], \ \left[ \begin{array}{crcccc} 1\amp -1\amp 0\amp 0\amp 0\amp 0\\ 0\amp 0\amp 0\amp 1\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 1\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right],  \ \text{ and }  \  \left[ \begin{array}{crcccc} 1\amp -1\amp 0\amp 0\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 1\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 1\\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Find a vector <span class="process-math">\(\vv_3\)</span> that is in <span class="process-math">\(\Nul (A-3I_6)^3\)</span> but not in <span class="process-math">\(\Nul (A-3I_6)^2\text{.}\)</span> Then let <span class="process-math">\(\vv_2 = (A-3I_6)\vv_3\)</span> and <span class="process-math">\(\vv_1 = (A-3I_6)\vv_2\text{.}\)</span> Notice that we obtain a string of three generalized eigenvectors.</p></article><article class="task exercise-like" id="task-2391"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-6991">Assume that the reduced row echelon forms of <span class="process-math">\(A -4 I_6\)</span> and <span class="process-math">\((A-4I_6)^2\)</span> are, respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccccrr} 1\amp 0\amp 0\amp 0\amp -1\amp -1\\ 0\amp 1\amp 0\amp 0\amp -1\amp 0\\ 0\amp 0\amp 1\amp 0\amp -1\amp 0\\ 0\amp 0\amp 0\amp 1\amp -1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right] \  \text{ and }  \ \left[ \begin{array}{cccrcr} 1\amp 0\amp 0\amp -4\amp 3\amp -1\\ 0\amp 1\amp 0\amp -3\amp 2\amp 0 \\ 0\amp 0\amp 1\amp -2\amp 1\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Find a vector <span class="process-math">\(\vv_5\)</span> that is in <span class="process-math">\(\Nul (A-4I_6)^2\)</span> but not in <span class="process-math">\(\Nul (A-4I_6)\text{.}\)</span> Then let <span class="process-math">\(\vv_4 = (A-4I_6)\vv_5\text{.}\)</span> Notice that we obtain a string of two generalized eigenvectors.</p></article><article class="task exercise-like" id="task-2392"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-6992">Find a generalized eigenvector <span class="process-math">\(\vv_6\)</span> for <span class="process-math">\(A\)</span> such that <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \vv_4, \vv_5, \vv_6\}\)</span> is a basis for <span class="process-math">\(\R^6\text{.}\)</span> Let <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \vv_3 \ \vv_4 \ \vv_5 \ \vv_6]\text{.}\)</span> Calculate <span class="process-math">\(J=C^{-1}AC\text{.}\)</span> Make sure that <span class="process-math">\(J\)</span> is a matrix in Jordan canonical form.</p></article><article class="task exercise-like" id="task-2393"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-6993">How does the matrix <span class="process-math">\(J\)</span> tell us about the eigenvalues of <span class="process-math">\(A\)</span> and their algebraic multiplicities?</p></article><article class="task exercise-like" id="task-2394"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-6994">How many Jordan blocks are there in <span class="process-math">\(J\)</span> for the eigenvalue <span class="process-math">\(3\text{?}\)</span> How many Jordan blocks are there in <span class="process-math">\(J\)</span> for the eigenvalue <span class="process-math">\(4\text{?}\)</span> How do these numbers compare to the geometric multiplicities of <span class="process-math">\(3\)</span> and <span class="process-math">\(4\)</span> as eigenvalues of <span class="process-math">\(A\text{?}\)</span></p></article></article><p id="p-6995">The previous activities highlight some of the information that a Jordan canonical tells us about a matrix. Assuming that <span class="process-math">\(C^{-1}AC = J\text{,}\)</span> where <span class="process-math">\(J\)</span> is in Jordan canonical form, we can say the following.</p>
<ul class="disc">
<li id="li-980"><p id="p-6996">Since similar matrices have the same eigenvalues, the eigenvalues of <span class="process-math">\(J\text{,}\)</span> and therefore of <span class="process-math">\(A\text{,}\)</span> are the diagonal entries of <span class="process-math">\(J\text{.}\)</span> Moreover, the number of times a diagonal entry appears in <span class="process-math">\(J\)</span> is the algebraic multiplicity of the eigenvalue. This is also the sum of the sizes of all Jordan blocks corresponding to <span class="process-math">\(\lambda\text{.}\)</span></p></li>
<li id="li-981"><p id="p-6997">Given an eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> its geometric multiplicity is the number of Jordan blocks corresponding to <span class="process-math">\(\lambda\text{.}\)</span></p></li>
<li id="li-982">
<p id="p-6998">Each generalized eigenvector leads to a Jordan block for that eigenvector. The number of Jordan blocks corresponding to <span class="process-math">\(\lambda\)</span> of size at least <span class="process-math">\(j\)</span> is <span class="process-math">\(s_j = \dim\left(\Nul (A - \lambda I)^j\right) - \dim\left(\Nul (A -  \lambda I)^{j-1}\right)\text{.}\)</span> Thus, the number of Jordan blocks of size exactly <span class="process-math">\(j\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
s_j-s_{j+1} = 2 \dim\left(\Nul (A - \lambda I )^j\right) - \dim\left(\Nul (A - \lambda I )^{j+1}\right)  - \dim\left(\Nul (A - \lambda I)^{j-1}\right)\text{.}
\end{equation*}
</div>
</li>
</ul>
<p id="p-6999">One interesting consequence of the existence of the Jordan canonical form is the famous Cayley-Hamilton Theorem.</p>
<article class="corollary theorem-like" id="corollary-1"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">40.4</span><span class="period">.</span><span class="space"> </span><span class="title">The Cayley-Hamilton Theorem.</span>
</h4>
<p id="p-7000">Let <span class="process-math">\(A\)</span> be a square matrix with characteristic polynomial <span class="process-math">\(p(x)\text{.}\)</span> Then <span class="process-math">\(p(A) = 0\text{.}\)</span></p></article><p id="p-7001">The proof of the Cayley-Hamilton Theorem follows from <a href="" class="xref" data-knowl="./knowl/ex_8_d_upper_triangular.html" title="Exercise 22">Exercise 22</a> that shows that every upper triangular matrix satisfies its characteristic polynomial. If <span class="process-math">\(A\)</span> is a square matrix, then there exists a matrix <span class="process-math">\(C\)</span> such that <span class="process-math">\(C^{-1}AC = T\text{,}\)</span> where <span class="process-math">\(T\)</span> is in Jordan canonical form (that is, <span class="process-math">\(T\)</span> is upper triangular). So <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(T\text{.}\)</span> If <span class="process-math">\(p(x)\)</span> is the characteristic polynomial of <span class="process-math">\(A\text{,}\)</span> <a href="" class="xref" data-knowl="./knowl/act_4_c_2.html" title="Activity 19.5">Activity 19.5</a> in <a href="chap_diagonalization.html" class="internal" title="Section 19: Diagonalization">Section 19</a> tells us that <span class="process-math">\(p(x)\)</span> is the characteristic polynomial of <span class="process-math">\(T\text{.}\)</span> Therefore, <span class="process-math">\(p(T) = 0\text{.}\)</span> Then <a href="" class="xref" data-knowl="./knowl/ex_Cayley-Hamilton.html" title="Exercise 14">Exercise 14</a> in <a href="chap_diagonalization.html" class="internal" title="Section 19: Diagonalization">Section 19</a> shows that <span class="process-math">\(p(A) = Cp(T)C^{-1} = 0\)</span> and <span class="process-math">\(A\)</span> satisfies its characteristic polynomial.</p></section><section class="section" id="sec_mtx_jordan_geom"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Geometry of Matrix Transformations using the Jordan Canonical Form</span>
</h3>
<figure class="figure figure-like" id="F_JCF_geometry_1"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/JCF_geometry_1.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">40.5<span class="period">.</span></span><span class="space"> </span>The image of the matrix transformation <span class="process-math">\(T(\vx) = \frac{1}{3} { \left[ \begin{array}{rr} 8\amp -1 \\ -2 \amp 7
\end{array}  \right] }\vx\text{.}\)</span></figcaption></figure><p id="p-7002">Recall that we can visualize the action of a matrix transformation defined by a diagonalizable matrix by using a change of basis. For example, let <span class="process-math">\(T(\vx) = A\vx\text{,}\)</span> where <span class="process-math">\(A = \frac{1}{3}\left[ \begin{array}{rr} 8\amp -1\\-2\amp 7 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(\lambda_1 = 3\)</span> and <span class="process-math">\(\lambda_2 = 2\)</span> with corresponding eigenvectors <span class="process-math">\(\vv_1 = [-1 \ 1]^{\tr}\)</span> and <span class="process-math">\([1 \ 2]^{\tr}\text{.}\)</span> So <span class="process-math">\(A\)</span> is diagonalizable by the matrix <span class="process-math">\(P = \left[ \begin{array}{rc} -1\amp 1\\1\amp 2 \end{array} \right]\text{,}\)</span> with <span class="process-math">\(P^{-1}AP = D = \left[ \begin{array}{cc} 3\amp 0\\0\amp 2 \end{array} \right]\text{.}\)</span> Note that <span class="process-math">\(T(\vx) = PDP^{-1} \vx\text{.}\)</span> Now <span class="process-math">\(P^{-1}\)</span> is a change of basis matrix from the standard basis to the basis <span class="process-math">\(\CB = \{\vv_1, \vv_2\}\text{,}\)</span> and <span class="process-math">\(D\)</span> stretches space in the direction of <span class="process-math">\(\vv_1\)</span> by a factor of 3 and stretches space in the direction of <span class="process-math">\(\vv_2\)</span> by a factor of 2, and then <span class="process-math">\(P\)</span> changes basis back to the standard basis. This is illustrated in <a href="" class="xref" data-knowl="./knowl/F_JCF_geometry_1.html" title="Figure 40.5">Figure 40.5</a>.</p>
<p id="p-7003">In general, if an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable, then there is a basis <span class="process-math">\(\CB = \{\vv_1, \vv_2, \ldots, \vv_n\}\)</span> of <span class="process-math">\(\R^n\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span> Assume that <span class="process-math">\(A \vv_i = \lambda_i \vv_i\)</span> for each <span class="process-math">\(i\text{.}\)</span> Letting <span class="process-math">\(P = [\vv_1 \ \vv_2 \ \ldots \ \vv_n]\)</span> we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = D\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(D\)</span> is the diagonal matrix with <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> down the diagonal. If <span class="process-math">\(T\)</span> is the matrix transformation defined by <span class="process-math">\(T(\vx) = A\vx\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(\vx) = PDP^{-1} \vx\text{.}
\end{equation*}
</div>
<p id="p-7004">Now <span class="process-math">\(P^{-1}\)</span> is a change of basis matrix from the standard basis to the basis <span class="process-math">\(\CB\text{,}\)</span> and <span class="process-math">\(D\)</span> stretches or contracts space in the direction of <span class="process-math">\(\vv_i\)</span> by the factor <span class="process-math">\(\lambda_i\text{,}\)</span> and then <span class="process-math">\(P\)</span> changes basis back to the standard basis. In this way we can visualize the action of the matrix transformation using the basis <span class="process-math">\(\CB\text{.}\)</span> If <span class="process-math">\(A\)</span> is not a diagonalizable matrix, we can use the Jordan canonical form to understand the action of the transformation defined by <span class="process-math">\(A\text{.}\)</span> We start by analyzing shears.</p>
<figure class="figure figure-like" id="F_JCF_shear_1"><div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/JCF_shear_1.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/JCF_shear_2.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">40.6<span class="period">.</span></span><span class="space"> </span>Left: A shear in the <span class="process-math">\(x\)</span>-direction. Right: A shear in the direction of the line <span class="process-math">\(y=x\text{.}\)</span></figcaption></figure><article class="activity project-like" id="act_JCF_shears"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.6</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-2395"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7005">Recall from <a href="chap_matrix_transformations.html" class="internal" title="Section 7: Matrix Transformations">Section 7</a> that a matrix transformation <span class="process-math">\(T\)</span> defined by <span class="process-math">\(T(\vx) = A\vx\text{,}\)</span> where <span class="process-math">\(A\)</span> is of the form <span class="process-math">\(\left[ \begin{array}{cc} 1\amp a\\0\amp 1 \end{array}  \right]\)</span> performs a shear in the <span class="process-math">\(x\)</span> direction, as illustrated at left in <a href="" class="xref" data-knowl="./knowl/F_JCF_shear_1.html" title="Figure 40.6">Figure 40.6</a>. That is, while <span class="process-math">\(T(\ve_1) = \ve_1\text{,}\)</span> it is the case that <span class="process-math">\(T(\ve_2) = \ve_2 + [a \ 0]^{\tr}\text{.}\)</span> In other words, <span class="process-math">\(T(\ve_2)-\ve_2 = [a \ 0]^{\tr}\)</span> is in <span class="process-math">\(\Span \{\ve_1\}\text{.}\)</span> But we can say something more. Show that if <span class="process-math">\(\vx = [x_1 \ x_2]^{\tr}\)</span> is not in <span class="process-math">\(\Span \{\ve_1\}\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/chap_matrix_transformations.html ./knowl/F_JCF_shear_1.html">
\begin{equation*}
T(\vx) = \vx + x_2[a \ 0]^{\tr}\text{.}
\end{equation*}
</div>
<p id="p-7006">The result is that if <span class="process-math">\(\vx\)</span> is not in <span class="process-math">\(\Span \{\ve_1\}\text{,}\)</span> then <span class="process-math">\(T(\vx) - \vx\)</span> is in <span class="process-math">\(\Span \{\ve_1\}\text{.}\)</span> This leads us to a general definition of a shear.</p>
<article class="definition definition-like" id="definition-99"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">40.7</span><span class="period">.</span>
</h6>
<p id="p-7007">A matrix transformation <span class="process-math">\(T\)</span> is a <dfn class="terminology">shear</dfn> in the direction of the line <span class="process-math">\(\ell\)</span> (through the origin) in <span class="process-math">\(\R^2\)</span> if</p>
<ol class="decimal">
<li id="li-983"><p id="p-7008"><span class="process-math">\(T(\vx) = \vx\)</span> for all <span class="process-math">\(\vx\)</span> in <span class="process-math">\(\ell\)</span> and</p></li>
<li id="li-984"><p id="p-7009"><span class="process-math">\(T(\vx) - \vx\)</span> is in <span class="process-math">\(\ell\)</span> for all <span class="process-math">\(\vx\)</span> not in <span class="process-math">\(\ell\text{.}\)</span></p></li>
</ol></article></article><article class="task exercise-like" id="task-2396"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-704"><p id="p-7010">Let <span class="process-math">\(S(\vx) = M\vx\text{,}\)</span> where <span class="process-math">\(M = \left[ \begin{array}{cr} 3\amp -2\\2\amp -1 \end{array} \right]\text{.}\)</span> Also let <span class="process-math">\(\vv_1 = [1 \ 1]^{\tr}\)</span> and <span class="process-math">\(\vv_2 = [1 \ 0]^{\tr}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2397"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-7011">Let <span class="process-math">\(\vx = \left[ \begin{array}{c} t\\t \end{array} \right]\)</span> for some scalar <span class="process-math">\(t\text{.}\)</span> Calculate <span class="process-math">\(S(\vx) = \vx\text{.}\)</span> How is this related to the eigenvalues of <span class="process-math">\(M\text{?}\)</span></p></article><article class="task exercise-like" id="task-2398"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-7012">Let <span class="process-math">\(\vx\)</span> be any vector not in <span class="process-math">\(\Span\{ [1 \ 1]^{\tr}\}\text{.}\)</span> Show that <span class="process-math">\(S(\vx) - \vx\)</span> is in <span class="process-math">\(\Span\{ [1 \ 1]^{\tr}\}\text{.}\)</span></p></article><article class="task exercise-like" id="task-2399"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-7013">Explain why <span class="process-math">\(S\)</span> is a shear and how <span class="process-math">\(S\)</span> is related to the image at right in <a href="" class="xref" data-knowl="./knowl/F_JCF_shear_1.html" title="Figure 40.6">Figure 40.6</a>.</p></article></article></article><p id="p-7014">As we did with diagonalizable matrices, we can understand a general matrix transformation of the form <span class="process-math">\(T(\vx) = A\vx\)</span> by using a Jordan canonical form of <span class="process-math">\(A\text{.}\)</span> In this context, we will encounter matrices of the form <span class="process-math">\(B = \left[ \begin{array}{cc} c\amp a\\0\amp c \end{array} \right] = \left[ \begin{array}{cc} c\amp 0 \\ 0\amp c \end{array} \right] \left[ \begin{array}{cc} 1\amp \frac{a}{c} \\ 0\amp 1 \end{array} \right]\)</span> for some positive constant <span class="process-math">\(c\text{.}\)</span> If <span class="process-math">\(S(\vx) = B\vx\text{,}\)</span> then <span class="process-math">\(S\)</span> performs a shear in the direction of <span class="process-math">\(\ve_1\)</span> and then an expansion or contraction in all directions by a factor of <span class="process-math">\(c\text{.}\)</span> We illustrate with an example.</p>
<article class="activity project-like" id="act_JCF_geometry"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-705"><p id="p-7015">Let <span class="process-math">\(T(\vx) = A\vx\text{,}\)</span> where <span class="process-math">\(A = \left[ \begin{array}{cr} 3\amp -1\\1\amp 1 \end{array} \right]\text{.}\)</span> The only eigenvalue of <span class="process-math">\(A\)</span> is <span class="process-math">\(\lambda = 2\text{,}\)</span> and this eigenvalue has algebraic multiplicity 2 and geometric multiplicity 1. The vector <span class="process-math">\(\vv_1 = [1 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(2\text{,}\)</span> and <span class="process-math">\(\vv_2 = [1 \ 0]^{\tr}\)</span> satisfies <span class="process-math">\((A - 2I_2)\vv_2 = \vv_1\text{.}\)</span> Let <span class="process-math">\(C = \left[ \begin{array}{cc} 1\amp 1\\1\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2400"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7016">Explain why <span class="process-math">\(T(\vx) = CJC^{-1}\vx\text{,}\)</span> where <span class="process-math">\(J = \left[ \begin{array}{cc} 2\amp 1\\0\amp 2 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-2401"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7017">The matrix <span class="process-math">\(C\)</span> is a change of basis matrix <span class="process-math">\(\underset{\CB \leftarrow \CS}{P}\)</span> from some basis <span class="process-math">\(\CS\)</span> to another basis <span class="process-math">\(\CB\text{.}\)</span> Specifically identify <span class="process-math">\(\CS\)</span> and <span class="process-math">\(\CB\text{.}\)</span></p></article><article class="task exercise-like" id="task-2402"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7018">If we begin with an arbitrary vector <span class="process-math">\(\vx\text{,}\)</span> then <span class="process-math">\([\vx]_{\CS} = \vx\text{.}\)</span> How is <span class="process-math">\(C \vx\)</span> related to <span class="process-math">\(\CB\text{?}\)</span></p></article><article class="task exercise-like" id="task-2403"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7019">Describe in detail what <span class="process-math">\(J\)</span> does to a vector in the <span class="process-math">\(\CB\)</span> coordinate system.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-141" id="hint-141"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-141"><div class="hint solution-like"><p id="p-7020"><span class="process-math">\(J = \left[ \begin{array}{cc} 2\amp 0\\0\amp 2 \end{array} \right] \left[ \begin{array}{cc} 1\amp \frac{1}{2}\\0\amp 1 \end{array} \right]\text{.}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-2404"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-7021">Put this all together to describe the action of <span class="process-math">\(T\)</span> as illustrated in <a href="" class="xref" data-knowl="./knowl/F_JCF_shear_3.html" title="Figure 40.8">Figure 40.8</a>. The word shear should appear in your explanation.</p></article></article><figure class="figure figure-like" id="F_JCF_shear_3"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/JCF_shear_3.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">40.8<span class="period">.</span></span><span class="space"> </span>Change of basis, a shear, and scaling.</figcaption></figure><p id="p-7022"><a href="" class="xref" data-knowl="./knowl/act_JCF_geometry.html" title="Activity 40.7">Activity 40.7</a> provides the essential ideas to understand the geometry of a general linear transformation using the Jordan canonical form. Let <span class="process-math">\(T(\vx) = A\vx\)</span> with <span class="process-math">\(A \vv_1 = \lambda \vv_1\)</span> and <span class="process-math">\(A \vv_2 = \lambda \vv_2 + \vv_1\text{.}\)</span> Then <span class="process-math">\(T\)</span> maps <span class="process-math">\(\Span \{\vv_1\}\)</span> to <span class="process-math">\(\Span \{\vv_1\}\)</span> by a factor of <span class="process-math">\(\lambda\text{,}\)</span> and <span class="process-math">\(T\)</span> maps <span class="process-math">\(\Span\{\vv_2\}\)</span> to the line containing the terminal point of <span class="process-math">\(\vv_1\)</span> in the direction of <span class="process-math">\(\vv_2\text{.}\)</span> The matrix <span class="process-math">\(C\)</span> performs a change of basis from the standard basis to the basis <span class="process-math">\(\{\vv_1, \vv_2\}\text{,}\)</span> then the matrix <span class="process-math">\(\left[ \begin{array}{cc} 2\amp 1\\0\amp 2 \end{array} \right]\)</span> performs an expansion by a factor of 2 in all directions and a shear in the direction of <span class="process-math">\(\vv_1\text{.}\)</span></p></section><section class="section" id="sec_jordan_proof"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Proof of the Existence of the Jordan Canonical Form</span>
</h3>
<p id="p-7023">While we have constructed an algorithm to find a Jordan canonical form of a square matrix, we haven't yet addressed the question of whether every square matrix has a Jordan canonical form. We do that in this section.</p>
<p id="p-7024">Consider that any vector <span class="process-math">\([a \ b]^{\tr}\)</span> in <span class="process-math">\(\R^2\)</span> can be written as the sum <span class="process-math">\([a \ 0]^{\tr} + [0 \ b]^{\tr}\text{.}\)</span> The vector <span class="process-math">\([a \ 0]^{\tr}\)</span> is a vector in the subspace <span class="process-math">\(W_1 = \{ [x \ 0]^{\tr} | x \in \R\} = \Span \{[1 \ 0]^{\tr}\}\)</span> and the vector <span class="process-math">\([0 \ b]^{\tr}\)</span> is in the subspace <span class="process-math">\(W_2 = \{[0 \ y]^{\tr} | y \in \R\} = \Span\{[0 \ 1]^{\tr}\text{.}\)</span> Also notice that <span class="process-math">\(W_1 \cap W_2 = \{\vzero\}\text{.}\)</span> We can extend this idea to <span class="process-math">\(\R^3\text{,}\)</span> where any vector <span class="process-math">\([a \ b \ c]^{\tr}\)</span> can be written as <span class="process-math">\([a \ 0 \ 0]^{\tr} + [0 \ b \ 0]^{\tr} + [0 \ 0 \ c]^{\tr}\text{,}\)</span> with <span class="process-math">\([a \ 0 \ 0]^{\tr}\)</span> in <span class="process-math">\(W_1 = \Span\{[1 \ 0 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\([0 \ b \ 0]^{\tr}\)</span> in <span class="process-math">\(W_2 = \Span\{[0 \ 1 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\([0 \ 0 \ c]^{\tr}\)</span> in <span class="process-math">\(W_3 = \Span\{[0 \ 0 \ 1]^{\tr}\text{.}\)</span> In this situation we write <span class="process-math">\(\R^2 = W_1 \oplus W_2\)</span> and <span class="process-math">\(\R^3 = W_1 \oplus W_2 \oplus W_3\)</span> and say that <span class="process-math">\(\R^2\)</span> is the direct sum of <span class="process-math">\(W_1\)</span> and <span class="process-math">\(W_2\text{,}\)</span> while <span class="process-math">\(\R^3\)</span> is the direct sum of <span class="process-math">\(W_1\text{,}\)</span> <span class="process-math">\(W_2\text{,}\)</span> and <span class="process-math">\(W_3\text{.}\)</span></p>
<article class="definition definition-like" id="definition-100"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">40.9</span><span class="period">.</span>
</h4>
<p id="p-7025">A vector space <span class="process-math">\(V\)</span> is a <dfn class="terminology">direct sum</dfn> of subspaces <span class="process-math">\(V_1\text{,}\)</span> <span class="process-math">\(V_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(V_m\)</span> if every vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(V\)</span> can be written uniquely as a sum</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv = \vv_1+\vv_2+\vv_3+\cdots + \vv_m\text{,}
\end{equation*}
</div>
<p class="continuation">with <span class="process-math">\(\vv_i \in V_i\)</span> for each <span class="process-math">\(i\text{.}\)</span></p></article><p id="p-7026">If <span class="process-math">\(V\)</span> is a direct sum of subspaces <span class="process-math">\(V_1\text{,}\)</span> <span class="process-math">\(V_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(V_m\text{,}\)</span> then we write</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = V_1 \oplus V_2 \oplus \cdots \oplus V_m\text{.}
\end{equation*}
</div>
<p id="p-7027">Some useful facts about direct sums are given in the following theorem. The proofs are left for the exercises.</p>
<article class="theorem theorem-like" id="thm_Direct_sum_properties"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">40.10</span><span class="period">.</span>
</h4>
<p id="p-7028">Let <span class="process-math">\(V\)</span> be a vector space that is a direct sum <span class="process-math">\(V = V_1 \oplus V_2 \oplus \cdots \oplus V_m\)</span> for some positive integer <span class="process-math">\(m\text{.}\)</span></p>
<ol class="decimal">
<li id="li-985"><p id="p-7029"><span class="process-math">\(V_i \cap V_j = \{\vzero\}\)</span> whenever <span class="process-math">\(i \neq j\text{.}\)</span></p></li>
<li id="li-986"><p id="p-7030">If <span class="process-math">\(V\)</span> is finite dimensional, and if <span class="process-math">\(\CB_i\)</span> is a basis for <span class="process-math">\(V_i\text{,}\)</span> then the set <span class="process-math">\(\CB = \cup_{i=1}^m \CB_i\)</span> is a basis for <span class="process-math">\(V\text{.}\)</span></p></li>
<li id="li-987"><p id="p-7031"><span class="process-math">\(\dim(V) = \dim(V_1) + \dim(V_2) + \cdots + \dim(V_m)\text{.}\)</span></p></li>
</ol></article></section><section class="section" id="sec_mtx_nilpotent"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Nilpotent Matrices and Invariant Subspaces</span>
</h3>
<p id="p-7032">We will prove the existence of the Jordan canonical form in two steps. In the next subsection <a href="" class="xref" data-knowl="./knowl/lem_JCF_1.html" title="Lemma 40.14">Lemma 40.14</a> will show that every linear transformation can be diagonalized in some form, and <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> will provide the specific Jordan canonical form. Before we proceed to the lemmas, there are two concepts we need to introduce — nilpotent matrices and invariant subspaces. We don't need these concepts beyond our proof, so we won't spend a lot of time on them.</p>
<article class="activity project-like" id="act_nilpotent_intro"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-706"><p id="p-7033">Let <span class="process-math">\(A = \left[ \begin{array}{rr} 1\amp 1\\-1\amp -1 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{rcr} 2\amp 1\amp -3 \\ -2\amp 1\amp 1 \\ 2\amp 1\amp -3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2405"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7034">Calculate the positive integer powers of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{.}\)</span> What do you notice?</p></article><article class="task exercise-like" id="task-2406"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7035">Compare the eigenvalues of <span class="process-math">\(A\)</span> to the eigenvalues of <span class="process-math">\(B\text{.}\)</span> What do you notice?</p></article></article><p id="p-7036"><a href="" class="xref" data-knowl="./knowl/act_nilpotent_intro.html" title="Activity 40.8">Activity 40.8</a> shows that there are some matrices whose powers eventually become the zero matrix, and that there might be some connection to the eigenvalues of these matrices. Such matrices are given a special name.</p>
<article class="definition definition-like" id="definition-101"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">40.11</span><span class="period">.</span>
</h4>
<p id="p-7037">A square matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">nilpotent</dfn> if <span class="process-math">\(A^m =0\)</span> for some positive integer <span class="process-math">\(m\text{.}\)</span> Correspondingly, a linear transformation <span class="process-math">\(T\)</span> from a <span class="process-math">\(n\)</span>-dimensional vector space <span class="process-math">\(V\)</span> to <span class="process-math">\(V\)</span> is <dfn class="terminology">nilpotent</dfn> if <span class="process-math">\(T^m = 0\)</span> for some positive integer <span class="process-math">\(m\text{.}\)</span></p></article><p id="p-7038"> Nilpotent matrices are the essential obstacle to the diagonalization process. If <span class="process-math">\(A\)</span> is a nilpotent matrix, the smallest positive integer <span class="process-math">\(m\)</span> such that <span class="process-math">\(A^m = 0\)</span> is called the <dfn class="terminology">index</dfn> of <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-7039">A characterization of nilpotent matrices is given in the following theorem.</p>
<article class="theorem theorem-like" id="thm_nilpotent_evals"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">40.12</span><span class="period">.</span>
</h4>
<p id="p-7040">A square matrix <span class="process-math">\(A\)</span> is nilpotent if and only if <span class="process-math">\(0\)</span> is the only eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></article><p id="p-7041">The proof is left to the exercises.</p>
<p id="p-7042">We have seen that if <span class="process-math">\(T: V \to V\)</span> is a linear transformation from a vector space to itself, and if <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(T\)</span> with eigenvector <span class="process-math">\(\vv\text{,}\)</span> then <span class="process-math">\(T(\vv) = \lambda \vv\text{.}\)</span> In other words, <span class="process-math">\(T\)</span> maps every vector in <span class="process-math">\(W = \Span\{\vv\}\)</span> to a vector in <span class="process-math">\(W\text{.}\)</span> When this happens we say that <span class="process-math">\(W\)</span> is invariant under the transformation <span class="process-math">\(T\text{.}\)</span></p>
<article class="definition definition-like" id="def_JCF_invariant"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">40.13</span><span class="period">.</span>
</h4>
<p id="p-7043">A subspace <span class="process-math">\(W\)</span> of a vector space <span class="process-math">\(V\)</span> is <dfn class="terminology">invariant</dfn> under a linear transformation <span class="process-math">\(T: V \to V\)</span> if <span class="process-math">\(T(\vw) \in W\)</span> whenever <span class="process-math">\(\vw\)</span> is in <span class="process-math">\(W\text{.}\)</span></p></article><p id="p-7044">So, for example, every eigenspace of a transformation is invariant under the transformation. Other spaces that are always invariant are <span class="process-math">\(V\)</span> and <span class="process-math">\(\{\vzero\}\text{.}\)</span></p>
<article class="activity project-like" id="activity-160"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-707"><p id="p-7045">Let <span class="process-math">\(V\)</span> be a vector space and let <span class="process-math">\(T : V \to V\)</span> be a linear transformation.</p></div>
<article class="task exercise-like" id="task-2407"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7046">Let <span class="process-math">\(V = \R^2\)</span> and <span class="process-math">\(T\)</span> the linear transformation defined by <span class="process-math">\(T([x \ y]^{\tr}) = [x-y \ y-x]^{\tr}\text{.}\)</span> Find two invariant subspaces besides <span class="process-math">\(V\)</span> or <span class="process-math">\(\{\vzero\}\)</span> for <span class="process-math">\(T\text{.}\)</span></p></article><article class="task exercise-like" id="task-2408"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7047">Recall that <span class="process-math">\(\Ker(T) = \{\vv \in V : T(\vv) = \vzero\}\text{.}\)</span> Is <span class="process-math">\(\Ker(T)\)</span> invariant under <span class="process-math">\(T\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-2409"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7048">Recall that <span class="process-math">\(\Range(T) = \{\vw \in V : \vw = T(\vv) \text{ for some } \vv \in V\}\text{.}\)</span> Is <span class="process-math">\(\Range(T)\)</span> invariant under <span class="process-math">\(T\text{?}\)</span> Explain.</p></article></article></section><section class="section" id="sec_jordan"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Jordan Canonical Form</span>
</h3>
<p id="p-7049">We are now ready to prove the existence of the Jordan canonical form.</p>
<article class="lemma theorem-like" id="lem_JCF_1"><h4 class="heading">
<span class="type">Lemma</span><span class="space"> </span><span class="codenumber">40.14</span><span class="period">.</span>
</h4>
<p id="p-7050">Let <span class="process-math">\(V\)</span> be an <span class="process-math">\(n\)</span>-dimensional vector space and let <span class="process-math">\(T: V \to V\)</span> be a linear transformation. Let <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_r\)</span> be the distinct eigenvalues for <span class="process-math">\(T\text{.}\)</span> Then there are integers <span class="process-math">\(s_1\text{,}\)</span> <span class="process-math">\(s_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(s_r\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \Ker(T-\lambda_1 I)^{s_1} \oplus \Ker(T-\lambda_2 I)^{s_2} \oplus \Ker(T-\lambda_3 I)^{s_3} \oplus \cdots \oplus \Ker(T-\lambda_r I)^{s_r}\text{.}
\end{equation*}
</div></article><p id="p-7051">An example might help illustrate the lemma.</p>
<article class="activity project-like" id="act_JCF_Lemma_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.10</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-708">
<p id="p-7052">Let <span class="process-math">\(T:\pol_4 \to \pol_4\)</span> be defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-262">
\begin{align*}
T\left(a_0+a_1t+a_2t^2+a_3t^3+a_4t^4\right) = (2a_0+a_1) \amp + (a_1-a_2)t + (a_0+a_1)t^2\\
\amp \qquad + (-a_0-a_1+a_2+2a_3-a_4)t^3 + (2a_4)t^4\text{.}
\end{align*}
</div>
<p id="p-7053">The matrix of <span class="process-math">\(T\)</span> with respect to the standard basis <span class="process-math">\(\CS = \{1,t,t^2,t^3,t^4\}\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = [T]_{\CS} = \left[ \begin{array}{rrrcc} 2\amp 1\amp 0\amp 0\amp 0\\0\amp 1\amp -1\amp 0\amp 0 \\ 1\amp 1\amp 0\amp 0\amp 0 \\ -1\amp -1\amp 1\amp 2\amp -1 \\ 0\amp 0\amp 0\amp 0\amp 2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-7054">The eigenvalues of <span class="process-math">\(A\)</span> (and <span class="process-math">\(T\)</span>) are <span class="process-math">\(2\)</span> and <span class="process-math">\(1\text{,}\)</span> and the algebraic multiplicity of the eigenvalue <span class="process-math">\(2\)</span> is 2 while its geometric multiplicity is 1, and the algebraic multiplicity of the eigenvalue <span class="process-math">\(1\)</span> is 3 while its geometric multiplicity is also 1.</p>
<p id="p-7055">For every <span class="process-math">\(t\text{,}\)</span> we can find <span class="process-math">\(\Ker(T-\lambda I)^t\)</span> using <span class="process-math">\(\Nul (A- \lambda I)^t\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-2410"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7056">Technology shows that <span class="process-math">\(\dim(\Nul A-I) = 1\text{,}\)</span> <span class="process-math">\(\dim(\Nul A-I)^2 = 2\text{,}\)</span> and <span class="process-math">\(\dim(\Nul A-I)^3 = 3\text{.}\)</span> A basis for <span class="process-math">\(\Nul (A-I)^3\)</span> is <span class="process-math">\(\CC_1 = \left\{ [-1 \ 1 \ 0 \ 0 \ 0]^{\tr}, [1 \ 0 \ 1 \ 0 \ 0]^{\tr}, [1 \ 0 \ 0 \ 1 \ 0]^{\tr}\right\}\text{.}\)</span> Find a basis <span class="process-math">\(\CB_1\)</span> for <span class="process-math">\(\Ker\left((T-I)^3\right)\text{.}\)</span></p></article><article class="task exercise-like" id="task-2411"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7057">Technology also shows that <span class="process-math">\(\dim(\Nul A-2I) = 1\)</span> and <span class="process-math">\(\dim(\Nul A-2I)^2 = 2\text{.}\)</span> A basis for <span class="process-math">\(\Nul (A-2I)^2\)</span> is <span class="process-math">\(\CC_2 = \left\{ [0 \ 0 \ 0 \ 1 \ 0]^{\tr}, [0 \ 0 \ 0 \ 0 \ 1]^{\tr}\right\}\text{.}\)</span> Find a basis <span class="process-math">\(\CC_2\)</span> for <span class="process-math">\(\Ker\left((T-2I)^2\right)\text{.}\)</span></p></article><article class="task exercise-like" id="task-2412"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7058">Identify the <span class="process-math">\(\lambda_i\)</span> and <span class="process-math">\(s_i\)</span> in <a href="" class="xref" data-knowl="./knowl/act_JCF_Lemma_1.html" title="Activity 40.10">Activity 40.10</a>. Let <span class="process-math">\(\CB = \CB_1 \cup \CB_2\text{.}\)</span> Find the matrix <span class="process-math">\([T]_{\CB}\text{.}\)</span></p></article></article><p id="p-7059">Since each <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\)</span> in <a href="" class="xref" data-knowl="./knowl/act_JCF_Lemma_1.html" title="Activity 40.10">Activity 40.10</a> is <span class="process-math">\(T\)</span> invariant, <span class="process-math">\(T\)</span> maps vectors in <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\)</span> back into <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\text{.}\)</span> So <span class="process-math">\(T\)</span> applied to each <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\)</span> provides a matrix <span class="process-math">\(B_i\text{.}\)</span> Applying <span class="process-math">\(T\)</span> to each <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\)</span> produces the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_Lemma_1.html ./knowl/lem_JCF_2.html">
\begin{equation*}
\left[ \begin{array}{cccc} B_1  \amp  \amp \cdots \amp    \\  \amp B_2 \amp \cdots \amp  0  \\ 0  \amp  \amp  \ddots \amp    \\   \amp  \amp \cdots \amp   B_r \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where the <span class="process-math">\(B_i\)</span> are square matrices corresponding to the eigenvalues of <span class="process-math">\(T\text{.}\)</span> These blocks are determined by the restriction of <span class="process-math">\(T\)</span> to the spaces <span class="process-math">\(\Ker(T-\lambda_i I)^{s_i}\)</span> with respect to the found basis. To obtain the Jordan canonical form, we need to know that we can always choose these basis to create the correct block matrices. <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> will provide those details.</p>
<article class="proof" id="proof-20"><h4 class="heading"><span class="title">Proof of Lemma 40.14.</span></h4>
<p id="p-7060">Choose a <span class="process-math">\(\lambda_i\)</span> and, for convenience, label it <span class="process-math">\(\lambda\text{.}\)</span> For each positive integer <span class="process-math">\(j\text{,}\)</span> let <span class="process-math">\(W_j = \Ker(T - \lambda I)^j\text{.}\)</span> If <span class="process-math">\((T-\lambda I)^j\vx = \vzero\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(T-\lambda I)^{j+1}(\vx) = (T-\lambda I) (T-\lambda I)^j(\vx) = (T-\lambda I)(\vzero) = \vzero\text{,}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(W_j \subseteq W_{j+1}\text{.}\)</span> Thus we have the containments</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
W_1 \subseteq W_2 \subseteq W_3 \subseteq \cdots W_k \subseteq \cdots\text{.}
\end{equation*}
</div>
<p id="p-7061">Now <span class="process-math">\(V\)</span> is finite dimensional, so this sequence must reach equality at some integer <span class="process-math">\(t\text{.}\)</span> That is, <span class="process-math">\(W_t = W_{t+1} = \cdots\text{.}\)</span> Let <span class="process-math">\(s\)</span> be the smallest positive integer for which this happens.</p>
<p id="p-7062">We plan to show that <span class="process-math">\(V = \Ker(T - \lambda I)^s \oplus \Range(T - \lambda I)^s\text{.}\)</span> We begin by demonstrating that <span class="process-math">\(\Ker(T - \lambda I)^s\cap \Range(T - \lambda I)^s = \{0\}\text{.}\)</span> Let <span class="process-math">\(\vv \in \Ker(T - \lambda I)^s \cap \Range(T - \lambda I)^s\text{.}\)</span> Then <span class="process-math">\((T - \lambda I)^s(\vv) = \vzero\)</span> and there exists <span class="process-math">\(\vu \in V\)</span> such that <span class="process-math">\((T-\lambda I)^s(\vu) = \vv\text{.}\)</span> It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(T-\lambda I)^{2s}(\vu) = (T-\lambda I)^s(T-\lambda I)^{s}(\vu) = (T-\lambda I)^s(\vv) = \vzero\text{.}
\end{equation*}
</div>
<p id="p-7063">But <span class="process-math">\(\Ker(T - \lambda I)^{2s} = \Ker(T- \lambda I)^s\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vzero = (T-\lambda I)^{2s}(\vu) = (T-\lambda I)^{s}(\vu) = \vv\text{.}
\end{equation*}
</div>
<p id="p-7064">We conclude that <span class="process-math">\(\Ker(T - \lambda I)^s \cap \Range(T - \lambda I)^s = \{\vzero\}\text{.}\)</span></p>
<p id="p-7065">Now we will show that <span class="process-math">\(V =  \Ker(T - \lambda I)^s \oplus \Range(T - \lambda I)^s\text{.}\)</span> Let <span class="process-math">\(\vz = \vz_1 + \vz_2\)</span> with <span class="process-math">\(\vz_1 \in  \Ker(T - \lambda I)^s\)</span> and <span class="process-math">\(\vz_2 \in  \Range(T - \lambda I)^s\text{.}\)</span> First we will show that <span class="process-math">\(\vz\)</span> is uniquely represented in this way. Suppose <span class="process-math">\(\vz = \vz'_1+\vz'_2\)</span> with <span class="process-math">\(\vz'_1 \in  \Ker(T - \lambda I)^s\)</span> and <span class="process-math">\(\vz'_2 \in  \Range(T - \lambda I)^s\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vz_1+\vz_2 = \vz'_1+\vz'_2
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vz_1-\vz'_1 = \vz'_2-\vz_2\text{.}
\end{equation*}
</div>
<p id="p-7066">But <span class="process-math">\(\Ker(T - \lambda I)^s \cap \Range(T - \lambda I)^s = \{\vzero\}\text{,}\)</span> so <span class="process-math">\(\vz_1-\vz'_1 = \vzero\)</span> and <span class="process-math">\(\vz'_2-\vz_2=\vzero\)</span> which means <span class="process-math">\(\vz_1=\vz'_1\)</span> and <span class="process-math">\(\vz_2 = \vz'_2\text{.}\)</span> Now let <span class="process-math">\(Z =  \Ker(T - \lambda I)^s \oplus \Range(T - \lambda I)^s\text{.}\)</span> We then know that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\dim(Z) = \dim\left(\Ker(T - \lambda I)^s\right) + \dim\left(\Range(T - \lambda I)^s\right)\text{.}
\end{equation*}
</div>
<p id="p-7067">Also, the Rank-Nullity Theorem shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\dim(V) =  \dim\left(\Ker(T - \lambda I)^s\right) + \dim\left(\Range(T - \lambda I)^s\right)\text{.}
\end{equation*}
</div>
<p id="p-7068">So <span class="process-math">\(Z\)</span> is a subspace of <span class="process-math">\(V\)</span> with <span class="process-math">\(\dim(Z) = \dim(V)\text{.}\)</span> We conclude that <span class="process-math">\(Z = V\)</span> and that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V =  \Ker(T - \lambda I)^s \oplus \Range(T - \lambda I)^s\text{.}
\end{equation*}
</div>
<p id="p-7069">Next we demonstrate that <span class="process-math">\(\Ker(T - \lambda I)^s\)</span> and <span class="process-math">\(\Range(T - \lambda I)^s\)</span> are invariant under <span class="process-math">\(T\text{.}\)</span> Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(T - \lambda I) = T^2 - \lambda T = (T-\lambda I)T\text{,}
\end{equation*}
</div>
<p class="continuation">and <span class="process-math">\(T\)</span> commutes with <span class="process-math">\((T - \lambda I)\text{.}\)</span> By induction, <span class="process-math">\(T\)</span> commutes with <span class="process-math">\((T - \lambda I)^s\text{.}\)</span> Suppose that <span class="process-math">\(\vv \in \Ker(T - \lambda I)^s\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(T - \lambda I)^sT(\vv) = T(T - \lambda I)^s(\vv) = T(\vzero) = \vzero\text{.}
\end{equation*}
</div>
<p id="p-7070">So <span class="process-math">\(T(\vv) \in \Ker(T - \lambda I)^s\text{.}\)</span> Similarly, suppose that <span class="process-math">\(\vv \in \Range(T - \lambda I)^s\text{.}\)</span> Then there is a <span class="process-math">\(\vu \in V\)</span> such that <span class="process-math">\((T - \lambda I)^s(\vu) = \vv\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(\vv) = T\left((T - \lambda I)^s(\vu)\right) = \left(T(T - \lambda I)^s\right)(\vu) = \left((T - \lambda I)^sT\right)(\vu) = (T - \lambda I)^s(T(\vu))\text{,}
\end{equation*}
</div>
<p class="continuation">and <span class="process-math">\(T(\vv) \in \Range(T - \lambda I)^s\text{.}\)</span></p>
<p id="p-7071">We conclude our proof by induction on the number <span class="process-math">\(r\)</span> of eigenvalues of <span class="process-math">\(T\text{.}\)</span> Suppose that <span class="process-math">\(r=1\)</span> and so <span class="process-math">\(T\)</span> has exactly one eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> Then <span class="process-math">\(T-\lambda I\)</span> has only zero as an eigenvalue (otherwise, there is <span class="process-math">\(\mu \neq 0\)</span> such that <span class="process-math">\((T - \lambda I) - \mu I = T - (\lambda+\mu)I\)</span> has a nontrivial kernel. This makes <span class="process-math">\(\lambda+\mu\)</span> an eigenvalue of <span class="process-math">\(T\text{.}\)</span>) In this situation, <span class="process-math">\(T - \lambda I\)</span> is nilpotent and so <span class="process-math">\((T - \lambda I)^t = 0\)</span> for some positive integer <span class="process-math">\(t\text{.}\)</span> If <span class="process-math">\(s\)</span> is the smallest such power, then <span class="process-math">\(V =  \Ker(T - \lambda I)^s\)</span> and <span class="process-math">\(\Range(T - \lambda I)^s = \{\vzero\}\text{.}\)</span> So every vector in <span class="process-math">\(V\)</span> is in <span class="process-math">\(\Ker(T - ]lambda I)^s\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \Ker(T - \lambda I)^s \oplus \Range(T - \lambda I)^s = \Ker(T - \lambda I)^s\text{.}
\end{equation*}
</div>
<p id="p-7072">Thus, the statement is true when <span class="process-math">\(r=1\text{.}\)</span> Assume that the statement is true for linear transformations with fewer than <span class="process-math">\(r\)</span> eigenvalues. Now assume that <span class="process-math">\(T\)</span> has distinct eigenvalues <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_r\text{.}\)</span> By our previous work, we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \Ker(T - \lambda_1 I)^{s_1} \oplus \Range(T - \lambda_1 I)^{s_1}
\end{equation*}
</div>
<p class="continuation">for some positive integer <span class="process-math">\(s_1\text{.}\)</span> Let <span class="process-math">\(V_1 = \Range(T - \lambda_1 I)^{s_1}\text{.}\)</span> Since <span class="process-math">\(\Range(T - \lambda_1 I)^{s_1}\)</span> is <span class="process-math">\(T\)</span> invariant, we know that <span class="process-math">\(T\)</span> maps <span class="process-math">\(V_1\)</span> to <span class="process-math">\(V_1\text{.}\)</span> The eigenvalues of <span class="process-math">\(T\)</span> on <span class="process-math">\(V_1\)</span> are <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\lambda_3\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_r\text{.}\)</span> By our induction hypothesis, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V_1 = \Ker(T-\lambda_2 I)^{s_2} \oplus \Ker(T-\lambda_3 I)^{s_3} \oplus \cdots \oplus \Ker(T-\lambda_r I)^{s_r}\text{,}
\end{equation*}
</div>
<p class="continuation">for some positive integers <span class="process-math">\(s_2\text{,}\)</span> <span class="process-math">\(s_3\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(s_r\text{,}\)</span> which makes</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \Ker(T-\lambda_1 I)^{s_1} \oplus \Ker(T-\lambda_2 I)^{s_2} \oplus \Ker(T-\lambda_3 I)^{s_3} \oplus \cdots \oplus \Ker(T-\lambda_r I)^{s_r}\text{.}
\end{equation*}
</div></article><p id="p-7073"><a href="" class="xref" data-knowl="./knowl/lem_JCF_1.html" title="Lemma 40.14">Lemma 40.14</a> tells us that <span class="process-math">\(T\)</span> has a diagonal form with block matrices down the diagonal. To obtain a Jordan canonical form, we need to identify the correct bases for the summands of <span class="process-math">\(V\text{.}\)</span> (Lemma is due to Mark Wildon from <span class="articletitle">“A SHORT PROOF OF THE EXISTENCE OF JORDAN NORMAL FORM”</span>.)</p>
<article class="lemma theorem-like" id="lem_JCF_2"><h4 class="heading">
<span class="type">Lemma</span><span class="space"> </span><span class="codenumber">40.15</span><span class="period">.</span>
</h4>
<p id="p-7074">Let <span class="process-math">\(V\)</span> be an <span class="process-math">\(n\)</span>-dimensional vector space and let <span class="process-math">\(T : V \to V\)</span> be a linear transformation such that <span class="process-math">\(T^s = 0\)</span> for some positive integer <span class="process-math">\(s\text{.}\)</span> Then there exist vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_k\)</span> and natural numbers <span class="process-math">\(a_1\text{,}\)</span> <span class="process-math">\(a_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(a_k\)</span> such that <span class="process-math">\(T^{a_i}(\vu_i) = 0\)</span> for <span class="process-math">\(i\)</span> from <span class="process-math">\(1\)</span> to <span class="process-math">\(k\)</span> and the vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu_1, T(\vu_1), \ldots,T^{a_1-1}(\vu_1), \vu_2, T(\vu_2), \ldots,T^{a_2-1}(\vu_2), \ldots, \vu_k, T(\vu_k), \ldots,T^{a_k-1}(\vu_k)
\end{equation*}
</div>
<p class="continuation">are non-zero vectors that form a basis of <span class="process-math">\(V\text{.}\)</span></p></article><p id="p-7075">Notice the similarity of <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> to chains of generalized eigenvectors. An example might help illustrate <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a>.</p>
<article class="activity project-like" id="act_JCF_Lem_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">40.11</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-709">
<p id="p-7076">Let <span class="process-math">\(T: \pol_5 \to \pol_5\)</span> be defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(a_0+a_1t+a_2t^2+a_3t^3+a_4t^4+a_5t^5) = (-a_1-a_4+a_5)t + (-a_0-a_1+a_3-a_4+a_5)t^2 + (a_1+a_4)t^4\text{.}
\end{equation*}
</div>
<p id="p-7077">Let <span class="process-math">\(\CS = \{1,t,t^2,t^3,t^4,t^5\}\)</span> be the standard basis for <span class="process-math">\(\pol_5\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = [T]_{\CS} = \left[ \begin{array}{rrccrc} 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp -1\amp 0\amp 0\amp -1\amp 1 \\ -1\amp -1\amp 0\amp 1\amp -1\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 1\amp 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array} \right]\text{.}
\end{equation*}
</div>
<p id="p-7078">Technology shows that the only eigenvalue of <span class="process-math">\(A\)</span> is <span class="process-math">\(0\)</span> and that the geometric multiplicity of <span class="process-math">\(0\)</span> is <span class="process-math">\(3\text{.}\)</span> Since <span class="process-math">\(0\)</span> is the only eigenvalue of <span class="process-math">\(A\text{,}\)</span> we know that <span class="process-math">\(A\)</span> (and <span class="process-math">\(T\)</span>) is nilpotent. Using technology we find that the reduced row echelon forms of <span class="process-math">\(A\)</span> and <span class="process-math">\(A^2\)</span> and respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccrcc} 1\amp 0\amp 0\amp -1\amp 0\amp 0 \\ 0\amp 1\amp 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right], \ \left[ \begin{array}{cccrcc} 0\amp 0\amp 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">while <span class="process-math">\(A^3 = 0\text{.}\)</span> We see that <span class="process-math">\(\dim(\Ker(T^3)) \dim(\Nul A^3) = 6\)</span> while <span class="process-math">\(\dim(\Ker(T^2)) = \dim(\Nul A^2) = 5\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-2413"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7079">Notice that the vector <span class="process-math">\(\vv_1 = [0 \ 0 \ 0 \ 0 \ 0 \ 1]^{\tr}\)</span> is in <span class="process-math">\(\Nul A^3\)</span> but not in <span class="process-math">\(\Nul A^2\text{.}\)</span> Use this vector to construct one chain <span class="process-math">\(u_1\text{,}\)</span> <span class="process-math">\(T(u_1)\text{,}\)</span> and <span class="process-math">\(T^2(u_1)\)</span> of generalized eigenvectors starting with a vector <span class="process-math">\(u_1\)</span> that is in <span class="process-math">\(\Ker(T^3)\)</span> but not in <span class="process-math">\(\Ker(T^2)\text{.}\)</span> What can we say about the vector <span class="process-math">\(T^2(u_1)\)</span> in relation to eigenvectors of <span class="process-math">\(T\text{?}\)</span></p></article><article class="task exercise-like" id="task-2414"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7080">We know two other eigenvectors of <span class="process-math">\(T\text{,}\)</span> so we need another chain of generalized eigenvectors to provide a basis of <span class="process-math">\(\pol_5\)</span> of generalized eigenvectors. Use the fact that <span class="process-math">\(\vv_2 = [1 \ 0 \ 0 \ 0 \ 0 \ 0]^{\tr}\)</span> is in <span class="process-math">\(\Nul A^2\)</span> but not in <span class="process-math">\(\Nul A\)</span> to find another generalized eigenvector <span class="process-math">\(u_2\)</span> in <span class="process-math">\(\Ker(T^2)\)</span> that is not in <span class="process-math">\(\Ker(T)\text{.}\)</span> Then create a chain <span class="process-math">\(u_2\)</span> and <span class="process-math">\(T(u_2)\)</span> of generalized eigenvectors. What is true about <span class="process-math">\(T(u_2)\)</span> in relation to eigenvectors of <span class="process-math">\(T\text{?}\)</span></p></article><article class="task exercise-like" id="task-2415"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7081">Let <span class="process-math">\(u_3 = 1+t^3\)</span> be a third eigenvector of <span class="process-math">\(T\text{.}\)</span> Explain why <span class="process-math">\(\{u_1, T(u_1), T^2(u_1),
u_2, T(u_2), u_3\}\)</span> is a basis of <span class="process-math">\(\pol_5\text{.}\)</span> Identify the values of <span class="process-math">\(k\)</span> and the <span class="process-math">\(a_i\)</span> in Lemma 40.12.</p></article></article><p id="p-7082">Notice that if we let <span class="process-math">\(C = [[T^2(\vu_1)]_{\CS} \ [T(\vu_1)]_{\CS} \ [\vu_1]_{\CS} \  [T(\vu_4)]_{|CS} \ [\vu_4]_{|CS} \ [\vu_6]_{\CS}]\)</span> using the vectors from <a href="" class="xref" data-knowl="./knowl/act_JCF_Lem_2.html" title="Activity 40.11">Activity 40.11</a> we should find that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_Lem_2.html">
\begin{equation*}
C^{-1}AC = \left[ \begin{array}{cccccc} 0\amp 1\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">and this basis provides a matrix that produces a Jordan canonical form of <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-7083"><a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> provides the sequences of generalized eigenvectors that we need to make the block matrices in Jordan canonical form. This works as follows. Start, for example, with <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(T(\vu_1)\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span><span class="process-math">\(T^{a_1-1}(\vu_1)\text{.}\)</span> Since <span class="process-math">\(T^s = 0\text{,}\)</span> we know that <span class="process-math">\(T\)</span> is nilpotent and so has only <span class="process-math">\(0\)</span> as an eigenvalue. If <span class="process-math">\(T\)</span> has a nonzero eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> we replace <span class="process-math">\(T\)</span> with <span class="process-math">\(T - \lambda I\text{.}\)</span></p>
<p id="p-7084">Let <span class="process-math">\(\CB = \{T^{a_1-1}(\vu_1), T^{a_1-2}(\vu_1), \ldots, T^2(\vu_1), T(\vu_1), \vu_1\}\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-263">
\begin{align*}
_{\CB} \amp = [T^{a_1}(\vu_1)]_{\CB} = [0 \ 0 \ 0 \  \  \ldots \ 0 \ 0]^{\tr}\\
[T(T^{a_1-2}(\vu_1))]_{\CB} \amp = [T^{a_1-1}(\vu_1)]_{\CB} = [1 \ 0 \ 0 \ \  \ldots \ 0 \ 0]^{\tr}\\
[T(T^{a_1-3}(\vu_1))]_{\CB} \amp = [T^{a_1-3}(\vu_1)]_{\CB} = [0 \ 1 \ 0 \ \  \ldots \ 0 \ 0]^{\tr}\\
\amp \vdots\\
[T(T^2(\vu_1))]_{\CB} \amp = [T^3(\vu_1)]_{\CB} = [0 \ 0 \ 0 \  \ \ldots \ 0 \ 1 \ 0 \ 0 \ 0]^{\tr}\\
[T(T(\vu_1))]_{\CB} \amp = [T^2(\vu_1)]_{\CB} = [0 \ 0 \ 0 \  \ \ldots \ 0 \ 0 \ 1 \ 0 \ 0]^{\tr}\\
[T(\vu_1)]_{\CB} \amp = [T(\vu_1)]_{\CB} = [0 \ 0 \ 0 \  \ \ldots \ 0 \ 0 \ 0 \ 1 \ 0]^{\tr}\text{.}
\end{align*}
</div>
<p id="p-7085">This makes</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[T]_{\CB} =  \left[ \begin{array}{cccccccc} 0\amp 1\amp 0\amp 0\amp \cdots \amp  0 \amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0\amp \cdots \amp  0\amp 0\amp 0 \\ \amp \amp \ddots\amp \ddots \amp \amp   \amp \amp \\ \amp \amp \amp \amp \vdots \amp \amp \amp   \\ 0\amp 0\amp 0\amp 0\amp \cdots \amp  0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 0\amp \cdots \amp  0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0\amp \cdots \amp  0\amp 0\amp 0 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">which gives one Jordan block.</p>
<article class="proof" id="proof-21"><h4 class="heading"><span class="title">Proof of Lemma 40.15.</span></h4>
<p id="p-7086">If <span class="process-math">\(T(\vx) = \vzero\)</span> for all <span class="process-math">\(\vx \in V\text{,}\)</span> then we can choose <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_{\dim(V)}\)</span> to form any basis of <span class="process-math">\(V\)</span> and all <span class="process-math">\(a_i = 1\text{.}\)</span> So we can assume that <span class="process-math">\(T\)</span> is a nonzero transformation. Also, we claim that <span class="process-math">\(T(V)\)</span> is a proper subset of <span class="process-math">\(V\)</span> (recall that <span class="process-math">\(T(V)\)</span> is the same as <span class="process-math">\(\Range(T)\)</span>). If not, <span class="process-math">\(V = T(V) = T^2(V) = \cdots = T^m(V)\)</span> for any positive integer <span class="process-math">\(m\text{.}\)</span> But this contradicts the fact that <span class="process-math">\(T^s = 0\text{.}\)</span></p>
<p id="p-7087">We proceed by induction on <span class="process-math">\(\dim(V)\text{.}\)</span> If <span class="process-math">\(\dim(V) = 1\text{,}\)</span> since<span class="process-math">\(T(V)\)</span> is a proper subset of <span class="process-math">\(V\)</span> the only possibility is that <span class="process-math">\(T(V) = \{\vzero\}\text{.}\)</span> We have already discussed this case. For the inductive step assume that the lemma is true for any vector space of positive integer dimension less than <span class="process-math">\(\dim(V)\text{.}\)</span> Our assumption that <span class="process-math">\(T\)</span> is a nonzero transformation allows us to conclude that <span class="process-math">\(0 \subset T(V) \subset V\text{.}\)</span> Thus, <span class="process-math">\(1 \leq \dim(T(V)) \lt  \dim(V)\text{.}\)</span> We apply the inductive hypothesis to the transformation <span class="process-math">\(T: T(V) \to T(V)\)</span> to find integers <span class="process-math">\(b_1\text{,}\)</span> <span class="process-math">\(b_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(b_{\ell}\)</span> and vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_{\ell}\)</span> in <span class="process-math">\(T(V)\)</span> such that the vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_JCF_TV_basis">
\begin{equation}
\vv_1, T(\vv_1), \ldots, T^{b_1-1}(\vv_1), \ldots, \vv_{\ell}, T(\vv_{\ell}), \ldots, T^{b_{\ell}-1}(\vv_{\ell})\tag{40.4}
\end{equation}
</div>
<p class="continuation">form a basis for <span class="process-math">\(T(V)\)</span> and <span class="process-math">\(T^{b_i}(\vv_i) = \vzero\)</span> for <span class="process-math">\(1 \leq i \leq \ell\text{.}\)</span></p>
<p id="p-7088">Now <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_{\ell}\)</span> are in <span class="process-math">\(T(V)\text{,}\)</span> so there exist <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_{\ell}\)</span> in <span class="process-math">\(V\)</span> such that <span class="process-math">\(T(\vu_i) = \vv_i\)</span> for each <span class="process-math">\(1 \leq i \leq \ell\text{.}\)</span> This implies that <span class="process-math">\(T^j(\vu_i) = T^{j-1}(T(\vu_i)) = T^{j-1}(\vv_i)\)</span> for all <span class="process-math">\(i\)</span> and all positive integers <span class="process-math">\(j\text{.}\)</span> The vectors <span class="process-math">\(T^{b_1-1}(\vv_1)\text{,}\)</span> <span class="process-math">\(T^{b_2-1}(\vv_2)\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(T^{b_{\ell}-1}(\vv_{\ell})\)</span> are linearly independent and <span class="process-math">\(T\left(T^{b_i-1}(\vv_i)\right) = T^{b_i}(\vv_i) = 0\)</span> for <span class="process-math">\(1 \leq i \leq \ell\text{,}\)</span> so the vectors <span class="process-math">\(T^{b_1-1}(\vv_1)\text{,}\)</span> <span class="process-math">\(T^{b_2-1}(\vv_2)\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(T^{b_{\ell}-1}(\vv_{\ell})\)</span> are all in <span class="process-math">\(\Ker(T)\text{.}\)</span> Extend the set <span class="process-math">\(\left\{T^{b_1-1}(\vv_1), T^{b_2-1}(\vv_2), \ldots, T^{b_{\ell}-1}(\vv_{\ell})\right\}\)</span> to a basis of <span class="process-math">\(\Ker(T)\)</span> with the vectors <span class="process-math">\(\vw_1\text{,}\)</span> <span class="process-math">\(\vw_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vw_m\)</span> for <span class="process-math">\(m = \dim(\Ker(T)) - \ell\text{.}\)</span> That is, the set</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_JCF_Ker_basis">
\begin{equation}
\left\{T^{b_1-1}(\vv_1), T^{b_2-1}(\vv_2), \ldots, T^{b_{\ell}-1}(\vv_{\ell}), \vw_1, \vw_2, \ldots, \vw_m\right\}\tag{40.5}
\end{equation}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\Ker(T)\text{.}\)</span> We will now show that the vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_JCF_V_basis">
\begin{equation}
\vu_1, T(\vu_1), \ldots, T^{b_1}(\vu_1), \ldots, \vu_{\ell}, T(\vu_{\ell}), \ldots, T^{b_{\ell}}(\vu_{\ell}), \vw_1, \ldots, \vw_m\tag{40.6}
\end{equation}
</div>
<p class="continuation">form a basis for <span class="process-math">\(V\text{.}\)</span> To demonstrate linear independence, suppose that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-27">
\begin{align}
c_{1,0}\vu_1\amp +c_{1,1}T(\vu_1)+ \cdots + c_{1,b_1}T^{b_1}(\vu_1) +  \cdots\notag\\
\amp + c_{\ell,0}\vu_{\ell} +  c_{\ell,1}T(\vu_{\ell})+ \cdots + c_{\ell,b_{\ell}}T^{b_{\ell}}(\vu_{\ell}) +  d_1\vw_1+  \cdots +  d_m\vw_m = \vzero\tag{40.7}
\end{align}
</div>
<p class="continuation">for some scalars <span class="process-math">\(c_{i,j}\)</span> and <span class="process-math">\(d_k\text{.}\)</span> Apply <span class="process-math">\(T\)</span> to this linear combination to obtain the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-264">
\begin{align*}
c_{1,0}T(\vu_1)\amp +c_{1,1}T^2(\vu_1)+ \cdots + c_{1,b_1}T^{b_1+1}(\vu_1) +  \cdots\\
\amp + c_{\ell,0}T(\vu_{\ell}) +  c_{\ell,1}T^2(\vu_{\ell})+ \cdots + c_{\ell,b_{\ell}}T^{b_{\ell}+1}(\vu_{\ell}) +  d_1T(\vw_1)+  \cdots \\
\amp +  d_mT(\vw_m) = \vzero\text{.}
\end{align*}
</div>
<p id="p-7089">Using the relationship <span class="process-math">\(T^j(\vu_i) = T^{j-1}(\vv_i)\)</span> gives us the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-265">
\begin{align*}
c_{1,0}\vv_1\amp +c_{1,1}T(\vv_1)+ \cdots + c_{1,b_1}T^{b_1}(\vv_1) +  \cdots\\
\amp + c_{\ell,0}\vv_{\ell} +  c_{\ell,1}T(\vv_{\ell})+ \cdots + c_{\ell,b_{\ell}}T^{b_{\ell}}(\vv_{\ell}) +  d_1T(\vw_1)+  \cdots +  d_mT(\vw_m) = \vzero\text{.}
\end{align*}
</div>
<p id="p-7090">Recall that <span class="process-math">\(T^{b_i}(\vv_i) = 0\)</span> and that <span class="process-math">\(\vw_1\text{,}\)</span> <span class="process-math">\(\vw_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vw_m\)</span> are in <span class="process-math">\(\Ker(T)\)</span> to obtain the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-266">
\begin{align*}
c_{1,0}\vv_1 \amp +c_{1,1}T(\vv_1)+ \cdots + c_{1,b_1-1}T^{b_1-1}(\vv_1) +  \cdots + c_{\ell,0}\vv_{\ell} +  c_{\ell,1}T(\vv_{\ell})+ \cdots\\
\amp + c_{\ell,b_{\ell}-1}T^{b_{\ell}-1}(\vv_{\ell}) = \vzero\text{.}
\end{align*}
</div>
<p id="p-7091">But this final equation is a linear combination of the basis elements in <a href="" class="xref" data-knowl="./knowl/eq_JCF_TV_basis.html" title="Equation 40.4">(40.4)</a> of <span class="process-math">\(T(V)\text{,}\)</span> and so the scalars are all <span class="process-math">\(0\text{.}\)</span> Replacing these scalars with <span class="process-math">\(0\)</span> in <a href="" class="xref" data-knowl="./knowl/eq_JCF_Lemma_2.html" title="Equation 40.7">(40.7)</a> results in</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_JCF_TV_basis.html ./knowl/eq_JCF_Lemma_2.html">
\begin{equation*}
c_{1,b_1}T^{b_1}(\vu_1) +  \cdots + c_{\ell,b_{\ell}}T^{b_{\ell}}(\vu_{\ell}) +  d_1\vw_1+  \cdots +  d_m\vw_m = 0\text{.}
\end{equation*}
</div>
<p id="p-7092">But this is a linear combination of vectors in a basis for <span class="process-math">\(\Ker(T)\)</span> and so all of the scalars are also <span class="process-math">\(0\text{.}\)</span> Hence, the vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(T(\vu_1)\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(T^{b_1}(\vu_1)\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_{\ell}\text{,}\)</span> <span class="process-math">\(T(\vu_{\ell})\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(T^{b_{\ell}}(\vu_{\ell})\text{,}\)</span> <span class="process-math">\(\vw_1\text{,}\)</span> …, <span class="process-math">\(\vw_m\)</span> are linearly independent.</p>
<p id="p-7093">The Rank-Nullity Theorem shows tells us that <span class="process-math">\(\dim(V) = \dim(T(V)) + \dim(\Ker(T))\text{.}\)</span> The vectors in <a href="" class="xref" data-knowl="./knowl/eq_JCF_Ker_basis.html" title="Equation 40.5">(40.5)</a> form a basis for <span class="process-math">\(\Ker(T)\text{,}\)</span> and so <span class="process-math">\(\dim(\Ker(T)) = \ell + m\text{.}\)</span> The vectors in <a href="" class="xref" data-knowl="./knowl/eq_JCF_TV_basis.html" title="Equation 40.4">(40.4)</a> form a basis for <span class="process-math">\(T(V)\text{,}\)</span> so <span class="process-math">\(\dim(T(V)) = b_1+b_2+ \cdots + b_{\ell}\text{.}\)</span> Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_JCF_Ker_basis.html ./knowl/eq_JCF_TV_basis.html">
\begin{equation*}
\dim(V) = \ell+m + b_1+b_2+ \cdots + b_{\ell} = m + (b_1-1) + (b_2-1) + \cdots + (b_{\ell}-1)\text{.}
\end{equation*}
</div>
<p id="p-7094">But this is exactly the number of vectors in our claimed basis <a href="" class="xref" data-knowl="./knowl/eq_JCF_V_basis.html" title="Equation 40.6">(40.6)</a>. This verifies <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> with <span class="process-math">\(k=\ell+m\text{,}\)</span> <span class="process-math">\(a_i=b_i+1\)</span> for <span class="process-math">\(1 \leq i \leq \ell\text{,}\)</span> <span class="process-math">\(u_{j+\ell} = w_j\)</span> and <span class="process-math">\(a_{j+\ell} = 1\)</span> for <span class="process-math">\(1 \leq m\text{.}\)</span></p></article><p id="p-7095">We return to <a href="" class="xref" data-knowl="./knowl/act_JCF_Lemma_1.html" title="Activity 40.10">Activity 40.10</a> to illustrate the use of <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a>.</p>
<article class="example example-like" id="ex_JCF_Lemma_2_2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">40.16</span><span class="period">.</span>
</h4>
<p id="p-7096">We work with the transformation <span class="process-math">\(T:\pol_4 \to \pol_4\)</span> defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-267">
\begin{align*}
T\left(a_0+a_1t+a_2t^2+a_3t^3+a_4t^4\right) = (2a_0+a_1) \amp + (a_1-a_2)t + (a_0+a_1)t^2\\
\amp + (-a_0-a_1+a_2+2a_3-a_4)t^3 \\
\amp + (2a_4)t^4\text{.}
\end{align*}
</div>
<p id="p-7097">Recall from <a href="" class="xref" data-knowl="./knowl/act_JCF_Lemma_1.html" title="Activity 40.10">Activity 40.10</a> that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_Lemma_1.html">
\begin{equation*}
\pol_4 = \Ker(T-I)^{3} \oplus \Ker(T-2 I)^{2}\text{.}
\end{equation*}
</div>
<p class="continuation">and a basis for <span class="process-math">\(\Ker(T-I)^3\)</span> is <span class="process-math">\(\CB_1 = \{p_1(t), p_2(t),
p_3(t)\}\)</span> with <span class="process-math">\(p_1(t) = -1+t\text{,}\)</span> <span class="process-math">\(p_2(t) = 1+t^2\text{,}\)</span> and <span class="process-math">\(p_3(t)= 1+t^3\text{.}\)</span> Since</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_Lemma_1.html">
\begin{equation*}
(T-I)(p_1(t)) = 0, \ (T-I)(p_2(t)) = -p_1(t), \ \text{ and }  \ (T-I)(p_3(t)) = p_2(t)
\end{equation*}
</div>
<p class="continuation">we see that <span class="process-math">\(T-I\)</span> maps <span class="process-math">\(\Ker(T-I)^3\)</span> to <span class="process-math">\(\Ker(T-I)^3\text{.}\)</span> The matrix of <span class="process-math">\(T-I\)</span> with respect to <span class="process-math">\(\CB_1\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_JCF_Lemma_1.html">
\begin{equation*}
[T-I]_{\CB_1} = \left[ \begin{array}{crc} 0\amp -1\amp 0 \\ 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-7098">The reduced row echelon form of <span class="process-math">\([T-I]_{\CB_1}\)</span> and <span class="process-math">\([T-I]_{\CB_1}^2\)</span> are</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/lem_JCF_2.html">
\begin{equation*}
\left[ \begin{array}{ccc} 0\amp 1\amp 0 \\ 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \end{array}  \right] \ \text{ and }  \ \left[ \begin{array}{ccr} 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">while <span class="process-math">\([T-I]_{\CB_1}^3 = 0\text{.}\)</span> This makes <span class="process-math">\((T-I)^3 = 0\text{.}\)</span> We apply <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> to <span class="process-math">\(T-I : \Ker(T-I)^3 \to \Ker(T-I)^3\text{.}\)</span> We choose <span class="process-math">\(u_1\)</span> to be a vector in <span class="process-math">\(\Ker(T-I)^3\)</span> that is not in <span class="process-math">\(\Ker(T-I)^2\text{.}\)</span> Once such vector has <span class="process-math">\([u_1]_{\CB_1} = [0 \ 0 \ 1]^{\tr}\text{,}\)</span> or <span class="process-math">\(u_1=1+t^3\text{.}\)</span> We then let <span class="process-math">\(u_2 = (T-I)(u_1) = 1+t^2\)</span> and <span class="process-math">\(u_1 = (T-I)(u_2) = 1-t\text{.}\)</span> This gives us the basis <span class="process-math">\(\{1-t, 1+t^2, 1+t^3\}\)</span> for <span class="process-math">\(\Ker(T-I)^3\text{.}\)</span></p>
<p id="p-7099">We can also apply <a href="" class="xref" data-knowl="./knowl/lem_JCF_2.html" title="Lemma 40.15">Lemma 40.15</a> to <span class="process-math">\(T-2I : \Ker(T-I)^2 \to \Ker(T-I)^2\text{.}\)</span> Since</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/lem_JCF_2.html">
\begin{equation*}
(T-2I)(p_4(t)) = 0 \ \text{ and }  \ (T-2I)(p_5(t)) = -p_4(t)\text{,}
\end{equation*}
</div>
<p class="continuation">we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/lem_JCF_2.html">
\begin{equation*}
[T-2I]_{\CB_2} = \left[ \begin{array}{cr} 0\amp -1 \\ 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-7100">It follows that <span class="process-math">\((T-2I)^2 = 0\text{.}\)</span> Selecting <span class="process-math">\(u_4 = t^4\)</span> and letting <span class="process-math">\(u_5 = (T-2I)(u_4) = -p_4(t)\text{,}\)</span> we obtain the basis <span class="process-math">\(\{-t^3, t^4\}\)</span> for <span class="process-math">\(\Ker(T-I)^2\text{.}\)</span></p>
<p id="p-7101">Let <span class="process-math">\(q_1(t) = 1+t^3\text{,}\)</span> <span class="process-math">\(q_2(t) = 1+t^2\text{,}\)</span> <span class="process-math">\(q_3(t) = 1-t\text{,}\)</span> <span class="process-math">\(q_4(t) = t^4\text{,}\)</span> and <span class="process-math">\(q_5(t) = -t^3\text{,}\)</span> and let <span class="process-math">\(\CC = \{q_1(t), q_2(t),
q_3(t), q_4(t), q_5(t)\}\text{.}\)</span> Since</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-268">
\begin{align*}
T(q_1(t)) \amp = q_1(t)+q_2(t)\\
T(q_2(t)) \amp = q_2(t)+q_3(t)\\
T(q_3(t)) \amp = q_3(t)\\
T(q_4(t)) \amp = 2q_4(t)+q_5(t)\\
T(q_5(t)) \amp = 2q_5(t)
\end{align*}
</div>
<p class="continuation">it follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[T]_{\CC} = \left[ \begin{array}{ccccc} 1\amp 1\amp 0\amp 0\amp 0 \\ 0\amp 1\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 2\amp 1 \\ 0\amp 0\amp 0\amp 0\amp 2 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">and we have found a basis for <span class="process-math">\(\pol_4\)</span> for which the matrix <span class="process-math">\(T\)</span> has a Jordan canonical form.</p></article></section><section class="section" id="sec_jordan_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-7102">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-84"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">40.17</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-710"><p id="p-7103">Find a Jordan form <span class="process-math">\(J\)</span> for each of the following matrices. Find a matrix <span class="process-math">\(C\)</span> such that <span class="process-math">\(C^{-1}AC = J\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2416"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7104"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1\\1\amp 1 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-238">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-7105">The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(2\)</span> and <span class="process-math">\(0\)</span> with corresponding eigenvectors <span class="process-math">\([1 \ 1]^{\tr}\)</span> and <span class="process-math">\([-1 \ 1]^{\tr}\text{.}\)</span> Since we have a basis for <span class="process-math">\(\R^2\)</span> consisting of eigenvectors for <span class="process-math">\(A\text{,}\)</span> we know that <span class="process-math">\(A\)</span> is diagonalizable. Moreover, Jordan canonical form of <span class="process-math">\(A\)</span> is <span class="process-math">\(J = \left[ \begin{array}{cc} 2\amp 0\\0\amp 0 \end{array} \right]\)</span> and <span class="process-math">\(C^{-1}AC = J\text{,}\)</span> where <span class="process-math">\(C = \left[ \begin{array}{cr} 1\amp -1\\1\amp 1 \end{array} \right]\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-2417"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7106"><span class="process-math">\(A = \left[ \begin{array}{ccc} 0\amp 1\amp 1\\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-239">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-7107">Since <span class="process-math">\(A\)</span> is upper triangular, its eigenvalues are the diagonal entries. So the only eigenvalue of <span class="process-math">\(A\)</span> is 0, and technology shows that this eigenvalue has geometric multiplicity 2. An eigenvector for <span class="process-math">\(A\)</span> is <span class="process-math">\(\vv_1 = [1 \ 0 \ 0]^{\tr}\text{.}\)</span> A vector <span class="process-math">\(\vv_2\)</span> that satisfies <span class="process-math">\(A \vv_2 = \vv_1\)</span> is <span class="process-math">\(\vv_2 = [0 \ 0 \ 1]^{\tr}\text{.}\)</span> Letting <span class="process-math">\(C = \left[ \begin{array}{ccr} 1\amp 0\amp 0\\0\amp 0\amp -1\\0\amp 1\amp 1 \end{array}  \right]\)</span> gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\C^{-1}AC = \left[ \begin{array}{ccc} 0\amp 1\amp 0 \\ 0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-2418"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7108"><span class="process-math">\(A = \left[ \begin{array}{cccc} 1\amp 1\amp 1\amp 1\\0\amp 1\amp 0\amp 0\\0\amp 0\amp 2\amp 2 \\ 0\amp 0\amp 0\amp 2 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-240">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-7109">Again, <span class="process-math">\(A\)</span> is upper triangular, so the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(2\)</span> and <span class="process-math">\(1\text{,}\)</span> both of algebraic multiplicity 2 and geometric multiplicity 1. Technology shows that the reduced row echelon forms of <span class="process-math">\(A - 2I_4\)</span> and <span class="process-math">\((A-2I_4)^2\)</span> are</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccrc} 1\amp 0\amp -1\amp 0 \\ 0\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right] \ \text{ and }  \ \left[ \begin{array}{ccrc} 1\amp 0\amp -1\amp 1 \\ 0\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now <span class="process-math">\(\vv_2 = [-1 \ 0 \ 0 \ 1]^{\tr}\)</span> is in <span class="process-math">\(\Nul (A-2I_4)^2\text{,}\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_1 = (A-2I_4)\vv_2 = [2 \ 0 \ 2 \ 0]^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">Notice that  Let <span class="process-math">\(\vv_1\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(2\text{.}\)</span> Technology also shows that the reduced row echelon forms of <span class="process-math">\(A-I_4\)</span> and <span class="process-math">\((A-I_4)^2\)</span> are</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccc} 0\amp 1\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right] \ \text{ and }  \ \left[ \begin{array}{cccc} 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now <span class="process-math">\(\vv_4 = [0 \ 1 \ 0 \ 0]^{\tr}\)</span> is in <span class="process-math">\(\Nul (A-I_4)^2\text{,}\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_3 = (A-I_4)\vv_4 = [1 \ 0 \ 0 \ 0]^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">Notice that  Let <span class="process-math">\(\vv_3\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(1\text{.}\)</span> Letting <span class="process-math">\(C = \left[ \begin{array}{crcc} 2\amp -1\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 2\amp 0\amp 0\amp 0 \\ 0\amp 1\amp 0\amp 0 \end{array}  \right]\)</span> gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
C^{-1}AC = \left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 1 \\ 0\amp 0\amp 0\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article></article><figure class="figure figure-like" id="F_JCF_example_3_d"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/JCF_example_3_d.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">40.18<span class="period">.</span></span><span class="space"> </span>The effect of the transformation <span class="process-math">\(T\text{.}\)</span></figcaption></figure><article class="example example-like" id="example-85"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">40.19</span><span class="period">.</span>
</h4>
<p id="p-7110">Let <span class="process-math">\(T(\vx) = A\vx\text{,}\)</span> where <span class="process-math">\(A = \left[ \begin{array}{crc} 0\amp 1\amp 1 \\ 0\amp 1\amp 2 \\ 1\amp -1\amp 2 \end{array} \right]\text{.}\)</span> Assume that <span class="process-math">\(P^{-1}AP = \left[ \begin{array}{ccc} 1\amp 1\amp 0 \\ 0\amp 1\amp 1 \\ 0\amp 0\amp 1 \end{array} \right]\text{,}\)</span> where <span class="process-math">\(P = \left[ \begin{array}{ccc} 1\amp 0\amp 4 \\ 0\amp 2\amp 4 \\ 1\amp 2\amp 0 \end{array} \right]\text{.}\)</span> Find a specific coordinate system in which it is possible to succinctly describe the action of <span class="process-math">\(T\text{,}\)</span> then describe the action of <span class="process-math">\(T\)</span> on <span class="process-math">\(\R^3\)</span> in as much detail as possible.</p>
<div class="solution solution-like" id="solution-241">
<h4 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h4>
<p id="p-7111">First note that <span class="process-math">\(1\)</span> is the only eigenvalue of <span class="process-math">\(A\text{.}\)</span> Since <span class="process-math">\(A\)</span> does not have <span class="process-math">\(0\)</span> as an eigenvalue, it follows that <span class="process-math">\(A\)</span> is invertible and so <span class="process-math">\(T\)</span> is both one-to-one and onto. Let <span class="process-math">\(\vv_1 = [4 \ 4 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_2 = [0 \ 2 \ 2]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vv_3 = [1 \ 0 \ 1]^{\tr}\text{.}\)</span> We have that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-269">
\begin{align*}
(A-I_3)\vv_3 \amp = \vv_2\\
(A-I_3)\vv_2 \amp = \vv_1\\
(A-I_3) \vv_1 \amp = \vzero\text{.}
\end{align*}
</div>
<p class="continuation">and so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-270">
\begin{align*}
T(\vv_3) \amp = A \vv_3 = \vv_3+\vv_2\\
T(\vv_2) \amp = A \vv_2 = \vv_2+\vv_1\\
T(\vv_1) \amp = A\vv_1 = \vv_1\text{.}
\end{align*}
</div>
<p id="p-7112">If we consider the coordinate system in <span class="process-math">\(\R^3\)</span> defined by the basis <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> as shown in blue in <a href="" class="xref" data-knowl="./knowl/F_JCF_example_3_d.html" title="Figure 40.18">Figure 40.18</a>, the fact that <span class="process-math">\(T(\vv_1) = \vv_1\)</span> shows that <span class="process-math">\(T\)</span> fixes all vectors in <span class="process-math">\(\Span\{\vv_1\}\text{.}\)</span> That <span class="process-math">\(T(\vv_2) = \vv_2+\vv_1\)</span> tells us that <span class="process-math">\(T\)</span> maps <span class="process-math">\(\Span\{\vv_2\}\)</span> onto <span class="process-math">\(\Span\{\vv_1+\vv_2\}\text{,}\)</span> and <span class="process-math">\(T(\vv_3) = \vv_3+\vv_2\)</span> shows that <span class="process-math">\(T\)</span> maps <span class="process-math">\(\Span\{\vv_3\}\)</span> onto <span class="process-math">\(\Span\{\vv_2+\vv_3\}\text{.}\)</span> So <span class="process-math">\(T\)</span> sends the box defined by <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> onto the box defined by <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_1+\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_2+\vv_3\)</span> (in red in <a href="" class="xref" data-knowl="./knowl/F_JCF_example_3_d.html" title="Figure 40.18">Figure 40.18</a>. So the action of <span class="process-math">\(T\)</span> is conveniently viewed in the coordinate system determined by the columns of a matrix <span class="process-math">\(P\)</span> that converts <span class="process-math">\(A\)</span> into its Jordan canonical form.</p>
</div></article></section><section class="section" id="sec_jordan_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-988">
<p id="p-7113">Any square matrix <span class="process-math">\(A\)</span> is similar to a Jordan canonical form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccc} J_1\amp 0\amp \cdots\amp 0 \\ 0\amp J_2\amp \cdots\amp 0 \\ \vdots\amp \vdots\amp \ddots\amp \vdots \\ 0\amp 0\amp \cdots\amp J_t \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where each matrix <span class="process-math">\(J_i\)</span> is a Jordan block of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccccccc} \lambda\amp 1\amp 0 \amp \cdots\amp 0\amp 0\amp 0 \\ 0\amp \lambda\amp 1\amp \cdots\amp 0\amp 0\amp 0 \\ 0\amp 0\amp \lambda\amp \cdots\amp 0\amp 0\amp 0 \\ \amp \amp \amp \ddots\amp \ddots\amp \amp  \\ 0\amp 0\amp 0\amp \cdots\amp \lambda\amp 1\amp 0 \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda\amp 1 \\  0\amp 0\amp 0\amp \cdots\amp 0\amp 0\amp \lambda \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">with <span class="process-math">\(\lambda\)</span> as a eigenvalue of <span class="process-math">\(A\text{.}\)</span></p>
</li>
<li id="li-989">
<p id="p-7114">A generalized eigenvector of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> corresponding to an eigenvalue <span class="process-math">\(\lambda\)</span> of <span class="process-math">\(A\)</span> is a non-zero vector <span class="process-math">\(\vx\)</span> satisfying</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(A - \lambda I_n)^m \vx = \vzero
\end{equation*}
</div>
<p class="continuation">for some positive integer <span class="process-math">\(m\text{.}\)</span> If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, then we can find a basis of <span class="process-math">\(\R^n\)</span> consisting of generalized eigenvectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> of <span class="process-math">\(A\)</span> so that that matrix <span class="process-math">\(C = [\vv_1 \ \vv_2 \ \cdots \ \vv_n]\)</span> has the property that <span class="process-math">\(C^{-1}AC\)</span> is a Jordan canonical form.</p>
</li>
<li id="li-990">
<p id="p-7115">A vector space <span class="process-math">\(V\)</span> is a direct sum of subspaces <span class="process-math">\(V_1\text{,}\)</span> <span class="process-math">\(V_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(V_m\)</span> if every vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(V\)</span> can be written uniquely as a sum</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv = \vv_1+\vv_2+\vv_3+\cdots + \vv_m\text{,}
\end{equation*}
</div>
<p class="continuation">with <span class="process-math">\(\vv_i \in V_i\)</span> for each <span class="process-math">\(i\text{.}\)</span></p>
</li>
<li id="li-991"><p id="p-7116">A square matrix <span class="process-math">\(A\)</span> is nilpotent if and only if <span class="process-math">\(0\)</span> is the only eigenvalue of <span class="process-math">\(A\text{.}\)</span> The Jordan form of a matrix <span class="process-math">\(A\)</span> can always be written in the form <span class="process-math">\(D + N\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix and <span class="process-math">\(N\)</span> is a nilpotent matrix.</p></li>
<li id="li-992"><p id="p-7117">A subspace <span class="process-math">\(W\)</span> of a vector space <span class="process-math">\(V\)</span> is invariant under a linear transformation <span class="process-math">\(T: V \to V\)</span> if <span class="process-math">\(T(\vw) \in W\)</span> whenever <span class="process-math">\(\vw\)</span> is in <span class="process-math">\(W\text{.}\)</span></p></li>
</ul></section><section class="exercises" id="sec_jordan_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-427"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-711"><p id="p-7118">Find a Jordan canonical form for each of the following matrices.</p></div>
<article class="task exercise-like" id="task-2419"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7119"><span class="process-math">\(A=\left[ \begin{array}{rcr} 10\amp 6\amp 1\\2\amp 12\amp -1\\-4\amp 12\amp 14 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2420"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7121"><span class="process-math">\(B=\left[ \begin{array}{rcc} 8\amp 4\amp 1\\0\amp 9\amp 0\\-1\amp 4\amp 10 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2421"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7123"><span class="process-math">\(C=\left[ \begin{array}{crc} 6\amp 0\amp 0\\2\amp 4\amp 2\\8\amp -8\amp 14 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2422"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7125"><span class="process-math">\(D=\left[ \begin{array}{rrrr} 3\amp 3\amp -2\amp 1\\-2\amp -3\amp 3\amp -2\\0\amp -1\amp 2\amp -1\\5\amp 8\amp -6\amp 4 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-428"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-7127">Let <span class="process-math">\(a \neq 0\text{.}\)</span> Show that the Jordan canonical form of <span class="process-math">\(\left[ \begin{array}{cccc} 4\amp 1\amp 0\amp 0 \\ 0\amp 4\amp a\amp 0 \\ 0\amp 0\amp 4\amp 0 \\ 0\amp 0\amp 0\amp 4 \end{array} \right]\)</span> is independent of the value of <span class="process-math">\(a\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-429"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-7128">Show that the Jordan canonical form of <span class="process-math">\(\left[ \begin{array}{cccc} 2\amp 1\amp 0\amp 0 \\ 0\amp 2\amp 1\amp 0 \\ 0\amp 0\amp 2\amp a \\ 0\amp 0\amp 0\amp 4 \end{array} \right]\)</span> is independent of the value of <span class="process-math">\(a\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-430"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-7130">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be similar matrices with <span class="process-math">\(B = Q^{-1}AQ\text{.}\)</span> Let <span class="process-math">\(U = C_1^{-1}AC_1\)</span> be the Jordan canonical form of <span class="process-math">\(A\text{.}\)</span> Show that <span class="process-math">\(U = C_2^{-1}BC_2\)</span> is also the Jordan canonical form of <span class="process-math">\(B\)</span> with <span class="process-math">\(C_2 = Q^{-1}C_1\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-431"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-7131">Find all of the Jordan canonical forms for <span class="process-math">\(2 \times 2\)</span> matrices and <span class="process-math">\(3 \times 3\)</span> matrices.</p></article><article class="exercise exercise-like" id="exercise-432"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-7133">Find the Jordan canonical form of <span class="process-math">\(\left[ \begin{array}{crrcr} 1\amp 2\amp 2\amp 1\amp -2\\0\amp -1\amp 0\amp 0\amp 0 \\ 0\amp 0\amp -1\amp 1\amp 2 \\ 0\amp 2\amp 0\amp 1\amp 0 \\ 0\amp 1\amp 0\amp 1\amp 1 \end{array} \right]\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-433"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-7134">For the matrix <span class="process-math">\(A\text{,}\)</span> find a matrix <span class="process-math">\(C\)</span> so that <span class="process-math">\(J = C^{-1}AC\)</span> is the Jordan canonical form of <span class="process-math">\(A\text{,}\)</span> where first: the diagonal entries do not increase as we move down the matrix <span class="process-math">\(J\)</span> and, second: the Jordan blocks do not increase in size as we move down the matrix <span class="process-math">\(J\text{.}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A =  \left[ \begin{array}{rrrrrrrrrr} 3\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1 \\ 1\amp 1\amp 1\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1 \\ 1\amp -1\amp 3\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1\\ 1\amp -1\amp 1\amp 1\amp 1\amp 1\amp -1\amp 1\amp -1\amp 1  \\ 0\amp 0\amp 0\amp 0\amp 2\amp 2\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp 2\amp 2\amp 0\amp 0\amp 0\\ 0\amp 0\amp 0\amp 0\amp 0\amp 0\amp 2\amp 2\amp 0\amp 0\\ -1\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 3\amp 1\amp -1\\ 2\amp -2\amp 2\amp -2\amp 2\amp -2\amp 2\amp -2\amp 4\amp 0\\ 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1\amp -1\amp 1\amp 3 \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="exercise exercise-like" id="exercise-434"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-712">
<p id="p-7136">A polynomial in two variables is an object of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(s,t) = \sum a_{ij}s^it^j
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(i\)</span> and <span class="process-math">\(j\)</span> are integers greater than or equal to 0. For example,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
q(s,t) = 3 + 2st + 4s^2t - 10st^3+5s^2t^2
\end{equation*}
</div>
<p class="continuation">is a polynomial in two variables. The degree of a monomial <span class="process-math">\(s^it^j\)</span> is <span class="process-math">\(i+j\text{.}\)</span> The degree of a polynomial <span class="process-math">\(p(s,t)\)</span> is the largest degree of any monomial summand of <span class="process-math">\(p(s,t)\text{.}\)</span> So the degree of the example polynomial <span class="process-math">\(q(s,t)\)</span> is 4. Two polynomials in <span class="process-math">\(V\)</span> are equal if they have the same coefficients on like terms. We add two polynomials in the variables <span class="process-math">\(s\)</span> and <span class="process-math">\(t\)</span> by adding coefficients of like terms. Scalar multiplication is done by multiplying each coefficient by the given scalar. Let <span class="process-math">\(V\)</span> be the set of all polynomials of two variables of degree less than or equal to 2. You may assume that <span class="process-math">\(V\)</span> is a vector space under this addition and multiplication by scalars and has the standard additive identity and additive inverses. Define <span class="process-math">\(F: V \to V\)</span> and <span class="process-math">\(G: V \to V\)</span> by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
F(p(s,t)) = s\frac{\partial p}{\partial s}(s,t) + \frac{\partial p}{\partial t}(s,t)
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
G(p(s,t)) = \frac{\partial p}{\partial s}(s,t) + t\frac{\partial p}{\partial t}(s,t)\text{.}
\end{equation*}
</div>
<p class="continuation">That is,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-271">
\begin{align*}
F(a_0+a_1s+a_2t+a_3st +a_4s^2+a_5t^2) \amp = s(a_1+a_3t+2a_4s) + (a_2+a_3s+2a_5t)\\
\amp = a_2 + (a_1+a_3)s + 2a_5t + a_3st + 2a_4s^2
\end{align*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-272">
\begin{align*}
G(a_0+a_1s+a_2t+a_3st +a_4s^2+a_5t^2) \amp = (a_1+a_3t+2a_4s) + t(a_2+a_3s+2a_5t)\\
\amp = a_1 + 2a_4s + (a_2+a_3)t + a_3st + 2a_5t^2\text{.}
\end{align*}
</div>
<p class="continuation">You may assume that <span class="process-math">\(F\)</span> and <span class="process-math">\(G\)</span> are linear transformations.</p>
</div>
<article class="task exercise-like" id="task-2423"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7137">Explain why <span class="process-math">\(\CB = \{1,s,t,st,s^2,t^2\}\)</span> is a basis for <span class="process-math">\(V\text{.}\)</span></p></article><article class="task exercise-like" id="task-2424"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7138">Explain why <span class="process-math">\(F\)</span> and <span class="process-math">\(G\)</span> are not diagonalizable.</p></article><article class="task exercise-like" id="task-2425"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7139">Show that <span class="process-math">\([F]_{\CB}\)</span> and <span class="process-math">\([G]_{\CB}\)</span> have the same Jordan canonical form. (So different transformations can have the same Jordan canonical form.)</p></article><article class="task exercise-like" id="task-2426"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7140">Find ordered bases <span class="process-math">\(\CC_F = \{f_1, f_2, f_3, f_4, f_5, f_6\}\)</span> and <span class="process-math">\(\CC_G = \{g_1, g_2, g_3, g_4, g_5, g_6\}\)</span> of <span class="process-math">\(V\)</span> for which <span class="process-math">\([F]_{\CC_F}\)</span> and <span class="process-math">\([G]_{\CC_G}\)</span> are the Jordan canonical form from (c).</p></article><article class="task exercise-like" id="task-2427"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-7141">Recall that a linear transformation can be defined by its action on a basis. So define <span class="process-math">\(H : V \to V\)</span> satisfying <span class="process-math">\(H(g_i) = f_i\)</span> for <span class="process-math">\(i\)</span> from 1 to 6. Show that <span class="process-math">\(H\)</span> is invertible and that <span class="process-math">\(G = H^{-1}FH\text{.}\)</span> This is the essential argument to show that any two linear transformations with the same matrix with respect to some bases are similar.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-142" id="hint-142"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-142"><div class="hint solution-like"><p id="p-7142">What matrix is <span class="process-math">\([H]_{\CC_G}^{\CC_F}\text{?}\)</span></p></div></div>
</div></article></article><article class="exercise exercise-like" id="exercise-435"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-713">
<p id="p-7143">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_p \underset{A - \lambda I}{\rightarrow} \vv_{p-1} \underset{A - \lambda I}{\rightarrow}  \cdots \ \underset{A - \lambda I}{\rightarrow} \vv_1 \underset{A - \lambda I}{\rightarrow} \vzero
\end{equation*}
</div>
<p class="continuation">be a chain of generalized eigenvectors for a matrix <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> In this problem we show that the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_p\}\)</span> is linearly independent.</p>
</div>
<article class="task exercise-like" id="task-2428"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7144">Explain why <span class="process-math">\(\vv_k\)</span> is in <span class="process-math">\(\Nul (A-\lambda I)^k\)</span> for any <span class="process-math">\(k\)</span> between <span class="process-math">\(1\)</span> and <span class="process-math">\(p\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-143" id="hint-143"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-143"><div class="hint solution-like"><p id="p-7145">Show that <span class="process-math">\(\vv_{1} = (A-\lambda I)^{k-1} \vv_k\)</span> for each <span class="process-math">\(k\)</span> from <span class="process-math">\(2\)</span> to <span class="process-math">\(p\text{.}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-2429"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-714">
<p id="p-7146">Consider the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="ex_new_1">
\begin{equation}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_p \vv_p = \vzero\tag{40.8}
\end{equation}
</div>
<p class="continuation">for scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_p\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-2430"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-7147">Multiply both sides of <a href="" class="xref" data-knowl="./knowl/ex_new_1.html" title="Equation 40.8">(40.8)</a> on the left by <span class="process-math">\((A-\lambda I)^{p-1}\text{.}\)</span> Explain why we can then conclude that <span class="process-math">\(x_p = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-2431"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-7149">Rewrite <a href="" class="xref" data-knowl="./knowl/ex_new_1.html" title="Equation 40.8">(40.8)</a> using the result from part i. Explain how we can then demonstrate that <span class="process-math">\(x_{p-1} = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-2432"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-7151">Describe how we can use the process in parts i. and ii. to show that <span class="process-math">\(x_1 = x_2 = \cdots x_p = 0\text{.}\)</span> What does this tell us about the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_p\}\text{?}\)</span></p></article></article></article><article class="exercise exercise-like" id="exercise-436"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-7153">Find, if possible, a matrix transformation <span class="process-math">\(T:\R^3 \to \R^3\)</span> for which there is a one-dimensional invariant subspace but no two-dimensional invariant subspace. If not possible, explain why.</p></article><article class="exercise exercise-like" id="exercise-437"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-715"><p id="p-7154">Let <span class="process-math">\(A = \left[ \begin{array}{cr} 2\amp -1\\1\amp 0 \end{array} \right]\text{.}\)</span> It is the case that <span class="process-math">\(A\)</span> has a single eigenvalue of algebraic multiplicity 2 and geometric multiplicity 1.</p></div>
<article class="task exercise-like" id="task-2433"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7155">Find a matrix <span class="process-math">\(C\)</span> whose columns are generalized eigenvectors for <span class="process-math">\(A\)</span> so that <span class="process-math">\(C^{-1}AC=J\)</span> is in Jordan canonical form.</p></article><article class="task exercise-like" id="task-2434"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7157">Determine the entries of <span class="process-math">\(J^k\)</span> and then find the entries of <span class="process-math">\(A^k\)</span> for any positive integer <span class="process-math">\(k\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-438"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<p id="p-7159">Let <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_r\)</span> be eigenvectors of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> and let <span class="process-math">\(W = \Span\{\vv_1, \vv_2, \ldots, \vv_r\}\text{.}\)</span> Show that <span class="process-math">\(W\)</span> is invariant under the matrix transformation <span class="process-math">\(T\)</span> defined by <span class="process-math">\(T(\vx) = A\vx\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-439"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<p id="p-7160">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> Let <span class="process-math">\(S:\R^n \to \R^n\)</span> be defined by <span class="process-math">\(S(\vx) = B\vx\)</span> for some matrix <span class="process-math">\(B\text{.}\)</span> Show that if <span class="process-math">\(B\)</span> commutes with <span class="process-math">\(A\text{,}\)</span> then the eigenspace <span class="process-math">\(E_\lambda\)</span> of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\)</span> is invariant under <span class="process-math">\(S\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-144" id="hint-144"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-144"><div class="hint solution-like"><p id="p-7161">Show that <span class="process-math">\((A - \lambda I)S(\vx) = \vzero\)</span></p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-440"><h4 class="heading"><span class="codenumber">14<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-716"><p id="p-7162">Determine which of the following matrices is nilpotent. Justify your answers. For each nilpotent matrix, find its index.</p></div>
<article class="task exercise-like" id="task-2435"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7163"><span class="process-math">\(\left[ \begin{array}{rc} -2\amp 1\\-4\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2436"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7164"><span class="process-math">\(\left[ \begin{array}{cc} 0\amp 1\\1\amp 0 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2437"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7165"><span class="process-math">\(\left[ \begin{array}{rrc} -1\amp 1\amp 0\\0\amp -1\amp 1 \\1\amp -3\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-2438"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7166"><span class="process-math">\(\left[ \begin{array}{cc} xy\amp x^2\\-y^2\amp -xy \end{array} \right]\)</span> for any real numbers <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span></p></article></article><article class="exercise exercise-like" id="exercise-441"><h4 class="heading"><span class="codenumber">15<span class="period">.</span></span></h4>
<p id="p-7167">Find two different nonzero <span class="process-math">\(3 \times 3\)</span> nilpotent matrices whose index is <span class="process-math">\(2\text{.}\)</span> If no such matrices exist, explain why.</p></article><article class="exercise exercise-like" id="exercise-442"><h4 class="heading"><span class="codenumber">16<span class="period">.</span></span></h4>
<p id="p-7169">Find, if possible, <span class="process-math">\(4 \times 4\)</span> matrices whose indices are <span class="process-math">\(1\text{,}\)</span> <span class="process-math">\(2\text{,}\)</span> <span class="process-math">\(3\text{,}\)</span> and <span class="process-math">\(4\text{.}\)</span> If not possible, explain why.</p></article><article class="exercise exercise-like" id="exercise-443"><h4 class="heading"><span class="codenumber">17<span class="period">.</span></span></h4>
<p id="p-7170">Let <span class="process-math">\(V\)</span> be an <span class="process-math">\(n\)</span>-dimensional vector space and let <span class="process-math">\(W\)</span> be a subspace of <span class="process-math">\(V\text{.}\)</span> Show that <span class="process-math">\(V = W \oplus W^{\perp}\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-145" id="hint-145"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-145"><div class="hint solution-like"><p id="p-7171">Use a projection onto a subspace.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-444"><h4 class="heading"><span class="codenumber">18<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-717"><p id="p-7172">Let <span class="process-math">\(W\)</span> be a subspace of an <span class="process-math">\(n\)</span>-dimensional vector space <span class="process-math">\(V\)</span> that is invariant under a transformation <span class="process-math">\(T: V \to V\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2439"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7173">Show by example that <span class="process-math">\(W^{\perp}\)</span> need not be invariant under <span class="process-math">\(T\text{.}\)</span></p></article><article class="task exercise-like" id="task-2440"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7174">Show that if <span class="process-math">\(T\)</span> is an isometry, then <span class="process-math">\(W^{\perp}\)</span> is invariant under <span class="process-math">\(T\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-445"><h4 class="heading"><span class="codenumber">19<span class="period">.</span></span></h4>
<p id="p-7175">Let <span class="process-math">\(T: \pol_2 \to \pol_2\)</span> be defined by <span class="process-math">\(T(p(t)) = p(t) - p'(t)\text{,}\)</span> where <span class="process-math">\(p'(t)\)</span> is the derivative of <span class="process-math">\(p(t)\text{.}\)</span> That is, if <span class="process-math">\(p(t) = a_0+a_1t+a_2t^2\text{,}\)</span> then <span class="process-math">\(p'(t) = a_1 + 2a_2t\text{.}\)</span> Find a basis <span class="process-math">\(\CB\)</span> for <span class="process-math">\(\pol_2\)</span> in which the matrix <span class="process-math">\([T]_{\CB}\)</span> is in Jordan canonical form.</p></article><article class="exercise exercise-like" id="exercise-446"><h4 class="heading"><span class="codenumber">20<span class="period">.</span></span></h4>
<p id="p-7177">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> nilpotent matrix with index <span class="process-math">\(m\text{.}\)</span> Since <span class="process-math">\(A^{m-1}\)</span> is not zero, there is a vector <span class="process-math">\(\vv \in \R^n\)</span> such that <span class="process-math">\(A^{m-1} \vv \neq \vzero\text{.}\)</span> Prove that the vectors <span class="process-math">\(\vv\text{,}\)</span> <span class="process-math">\(A\vv\text{,}\)</span> <span class="process-math">\(A^2\vv\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(A^{m-1}\vv\)</span> are linearly independent.</p></article><article class="exercise exercise-like" id="exercise-447"><h4 class="heading"><span class="codenumber">21<span class="period">.</span></span></h4>
<article class="task exercise-like" id="task-2441"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-718"><p id="p-7178">Let <span class="process-math">\(A = \left[ \begin{array}{rcr} 2\amp 1\amp -3 \\ -2\amp 1\amp 1 \\ 2\amp 1\amp -3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2442"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-7179">Show that <span class="process-math">\(A\)</span> is nilpotent.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-146" id="hint-146"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-146"><div class="hint solution-like"><p id="p-7180">Calculate powers of <span class="process-math">\(A\text{.}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-2443"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-7181">Calculate the matrix product <span class="process-math">\((I_3-A)\left(I_3+A+A^2\right)\text{.}\)</span> What do you notice and what does this tell us about <span class="process-math">\((I_3-A)\text{?}\)</span></p></article></article><article class="task exercise-like" id="task-2444"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7183">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> nilpotent matrix, show that <span class="process-math">\(I - A\)</span> is nonsingular, where <span class="process-math">\(I\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix.</p></article></article><article class="exercise exercise-like" id="ex_8_d_upper_triangular"><h4 class="heading"><span class="codenumber">22<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-719"><p id="p-7185">In this exercise we show that every upper triangular matrix satisfies its characteristic polynomial.</p></div>
<article class="task exercise-like" id="task-2445"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-720"><p id="p-7186">To illustrate how this will work, consider a <span class="process-math">\(3 \times 3\)</span> example. Let <span class="process-math">\(T = \left[ \begin{array}{ccc} \lambda_1\amp a\amp b \\ 0\amp \lambda_2\amp c \\ 0\amp 0\amp \lambda_3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2446"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-7187">What is the characteristic polynomial <span class="process-math">\(p(x)\)</span> of <span class="process-math">\(T\text{?}\)</span></p></article><article class="task exercise-like" id="task-2447"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-7188">Consider the matrices <span class="process-math">\(S_1 = T-\lambda_1 I_3\text{,}\)</span> <span class="process-math">\(S_2 = T-\lambda_2 I_3\text{,}\)</span> and <span class="process-math">\(S_3 = T-\lambda_3 I_3\text{.}\)</span> Show that the first column of <span class="process-math">\(S_1\)</span> is <span class="process-math">\(\vzero^{\tr}\text{,}\)</span> the first two columns of <span class="process-math">\(S_1S_2\)</span> are <span class="process-math">\(\vzero^{\tr}\text{,}\)</span> and that every column of <span class="process-math">\(S_1S_2S_3\)</span> is <span class="process-math">\(\vzero^{\tr}\text{.}\)</span> Conclude that <span class="process-math">\(T\)</span> satisfies its characteristic polynomial.</p></article></article><article class="task exercise-like" id="task-2448"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7189">Now we consider the general case. Suppose <span class="process-math">\(T\)</span> is an <span class="process-math">\(n \times n\)</span> upper triangular matrix with diagonal entries <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> in order. For <span class="process-math">\(i\)</span> from <span class="process-math">\(1\)</span> to <span class="process-math">\(n\)</span> let <span class="process-math">\(S_i = T - \lambda_i I_n\text{.}\)</span> Show that for each <span class="process-math">\(k\)</span> from 1 to <span class="process-math">\(n\text{,}\)</span> the first <span class="process-math">\(k\)</span> columns of <span class="process-math">\(S_1S_2 \cdots S_k\)</span> are equal to <span class="process-math">\(\vzero{\tr}\text{.}\)</span> Then explain how this demonstrates that <span class="process-math">\(T\)</span> satisfies its characteristic polynomial.</p></article></article><article class="exercise exercise-like" id="exercise-449"><h4 class="heading"><span class="codenumber">23<span class="period">.</span></span></h4>
<p id="p-7190">Prove <a href="" class="xref" data-knowl="./knowl/thm_nilpotent_evals.html" title="Theorem 40.12">Theorem 40.12</a> that a square matrix <span class="process-math">\(A\)</span> is nilpotent if and only if 0 is the only eigenvalue of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-147" id="hint-147"><span class="type">Hint</span><span class="space"> </span><span class="codenumber">1</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-147"><div class="hint solution-like"><p id="p-7191">For one direction, use the Cayley-Hamilton Theorem.</p></div></div>
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-148" id="hint-148"><span class="type">Hint</span><span class="space"> </span><span class="codenumber">2</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-148"><div class="hint solution-like"><p id="p-7192">If <span class="process-math">\(A\)</span> is nilpotent and <span class="process-math">\(\vx\)</span> is an eigenvector of <span class="process-math">\(A\text{,}\)</span> what is <span class="process-math">\(A^m \vx\)</span> for every positive integer <span class="process-math">\(m\text{?}\)</span> If <span class="process-math">\(0\)</span> is the only eigenvalue of <span class="process-math">\(A\text{,}\)</span> what is the characteristic polynomial of <span class="process-math">\(A\text{?}\)</span></p></div></div>
</div></article><article class="exercise exercise-like" id="ex_Direct_sum_properties"><h4 class="heading"><span class="codenumber">24<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-721"><p id="p-7193">Let <span class="process-math">\(V\)</span> be a vector space that is a direct sum <span class="process-math">\(V = V_1 \oplus V_2 \oplus \cdots \oplus V_m\)</span> for some positive integer <span class="process-math">\(m\text{.}\)</span> Prove the following.</p></div>
<article class="task exercise-like" id="task-2449"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7194"><span class="process-math">\(V_i \cap V_j = \{\vzero\}\)</span> whenever <span class="process-math">\(i \neq j\text{.}\)</span></p></article><article class="task exercise-like" id="task-2450"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7195">If <span class="process-math">\(V\)</span> is finite dimensional, and if <span class="process-math">\(\CB_i\)</span> is a basis for <span class="process-math">\(V_i\text{,}\)</span> then the set <span class="process-math">\(\CB = \cup_{i=1}^m \CB_i\)</span> is a basis for <span class="process-math">\(V\text{.}\)</span></p></article><article class="task exercise-like" id="task-2451"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7196"><span class="process-math">\(\dim(V) = \dim(V_1) + \dim(V_2) + \cdots + \dim(V_m)\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-451"><h4 class="heading"><span class="codenumber">25<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-722"><p id="p-7197">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-2452"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7198">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> nilpotent matrix, then the index of <span class="process-math">\(A\)</span> is <span class="process-math">\(n\text{.}\)</span></p></article><article class="task exercise-like" id="task-2453"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7200">The Jordan canonical form of a matrix is unique.</p></article><article class="task exercise-like" id="task-2454"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7201">Every nilpotent matrix is singular.</p></article><article class="task exercise-like" id="task-2455"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7203">Eigenvectors of a linear transformation <span class="process-math">\(T\)</span> are also generalized eigenvectors of <span class="process-math">\(T\text{.}\)</span></p></article><article class="task exercise-like" id="task-2456"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7204">It is possible for a generalized eigenvector of a matrix <span class="process-math">\(A\)</span> to correspond to a scalar that is not an eigenvalue for <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-2457"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7206">The vectors in a cycle of generalized eigenvectors of a matrix are linearly independent.</p></article><article class="task exercise-like" id="task-2458"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7207">A Jordan canonical form of a diagonal matrix <span class="process-math">\(A\)</span> is <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-2459"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7209">Let <span class="process-math">\(V\)</span> be a finite-dimensional vector space and let <span class="process-math">\(T\)</span> be a linear transformation from <span class="process-math">\(V\)</span> to <span class="process-math">\(V\text{.}\)</span> Let <span class="process-math">\(J\)</span> be a Jordan canonical form for <span class="process-math">\(T\text{.}\)</span> If <span class="process-math">\(\CB\)</span> is a basis of <span class="process-math">\(V\text{,}\)</span> then a Jordan canonical form of <span class="process-math">\([T]_{\CB}\)</span> is <span class="process-math">\(J\text{.}\)</span></p></article><article class="task exercise-like" id="task-2460"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7210">Matrices with the same Jordan canonical form are similar.</p></article><article class="task exercise-like" id="task-2461"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7212">Let <span class="process-math">\(V\)</span> be a finite-dimensional vector space and let <span class="process-math">\(T\)</span> be a linear transformation from <span class="process-math">\(V\)</span> to <span class="process-math">\(V\text{.}\)</span> If <span class="process-math">\(\CB\)</span> is an ordered basis for <span class="process-math">\(V\text{,}\)</span> then <span class="process-math">\(T\)</span> is nilpotent if and only if <span class="process-math">\([T]_{\CB}\)</span> is nilpotent.</p></article><article class="task exercise-like" id="task-2462"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7213">If <span class="process-math">\(T\)</span> is a linear transformation whose only eigenvalue is 0, then <span class="process-math">\(T\)</span> is the zero transformation.</p></article><article class="task exercise-like" id="task-2463"><h5 class="heading">
<span class="codenumber">(l)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7215">Let <span class="process-math">\(V\)</span> be a finite-dimensional vector space and let <span class="process-math">\(T\)</span> be a linear transformation from <span class="process-math">\(V\)</span> to <span class="process-math">\(V\text{.}\)</span> Then <span class="process-math">\(V = T(V) \oplus \Ker(T)\text{.}\)</span></p></article><article class="task exercise-like" id="task-2464"><h5 class="heading">
<span class="codenumber">(m)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-7216">Let <span class="process-math">\(V\)</span> be a finite-dimensional vector space and let <span class="process-math">\(T\)</span> be a linear transformation from <span class="process-math">\(V\)</span> to <span class="process-math">\(V\text{.}\)</span> If <span class="process-math">\(\CB\)</span> is an ordered basis for <span class="process-math">\(V\)</span> of generalized eigenvectors of <span class="process-math">\(T\text{,}\)</span> then <span class="process-math">\([T]_{\CB}\)</span> is a Jordan canonical form for <span class="process-math">\(T\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_epidemic"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Modeling an Epidemic</span>
</h3>
<p id="p-7218">The COVID-19 epidemic has generated many mathematical and statistical models to try to understand the spread of the virus. In this project we examine a simple stochastic model of the spread of an epidemic proposed by Norman Bailey in 1950.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-65" id="fn-65"><sup> 65 </sup></a> This is a model of a relatively mild epidemic in which no one dies from the disease. Of course, mathematicians build on simple models to form more complicated and realistic ones, but this is a good, and accessible, starting point. Bailey writes about the the difficulties in the stochastic<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-66" id="fn-66"><sup> 66 </sup></a> analysis of epidemics. For example, the overall epidemic “can often be broken down into smaller epidemics occurring in separate regional subdivisions” and that these regional epidemics “are not necessarily in phase and often interact with each other”. This is behavior that has been clearly evident in the COVID-19 epidemic in the US. Even within a single district, “it is obvious that a given infectious individual has not the same chance of infecting each inhabitant. He will probably be in close contact with a small number of people only, perhaps of the order of 10-50, depending on the nature of his activities.” But then the epidemic for the whole district will “be built up from epidemics taking place in several relatively small groups of associates and acquaintances.” So we can see in this analysis that an epidemic can spread from small, localized areas.</p>
<p id="p-7219">Bailey begins by considering a community of <span class="process-math">\(n\)</span> persons who are susceptible to a disease, and supposes introducing a single infected individual into the community. Bailey makes the following assumptions: “We shall assume that the infection spreads by contact between the members of the community, and that it is not sufficiently serious for cases to be withdrawn from circulation by isolation or death; also that no case becomes clear of infection during the course of the main part of the epidemic.”</p>
<p id="p-7220">To see how the Bailey's model is constructed, we make some assumption. We split the population at any time into two groups, those infected with the disease, and those susceptible, i.e., not currently infected. We assume that once an individual is infected, that individual is always infected. A person catches the disease by interacting with an infected individual. That is, if a susceptible individual meets an infected individual, the chance that the susceptible person contracts the disease is <span class="process-math">\(\beta\)</span> (the <em class="emphasis">infection rate</em>). For example, there many be a <span class="process-math">\(5\%\)</span> chance that an encounter between a susceptible individual and an infected individual results in the susceptible individual contracting the disease. (Of course, there are many variables involved in such an interaction — if no one is wearing masks and the interaction involves close contact, the infection rate would be higher than if everyone practices social distancing. For the sake of simplicity, we assume one infection rate for the entire population.) With this simple model we assume assume homogeneous mixing in the population. That is, it is equally likely that any one individual will interact with any other in a given time frame. Let <span class="process-math">\(y\)</span> be the number of susceptible individuals in the population at time <span class="process-math">\(t\text{.}\)</span> Then the number of infected individuals is the total population minus <span class="process-math">\(y\text{,}\)</span> or <span class="process-math">\(n+1-y\)</span> (recall that we introduced an infected individual into the population). So the change in the number of susceptible individuals in the population at time <span class="process-math">\(s\)</span> is <span class="process-math">\(-\beta y(n+1-y)\)</span> (since the <span class="process-math">\(n+1-y\)</span> susceptible individuals interact with the <span class="process-math">\(y\)</span> infected individuals). That is, <span class="process-math">\(\frac{dy}{ds} = -\beta y (n+1-y)\text{.}\)</span> Bailey makes the substitution of <span class="process-math">\(t\)</span> for <span class="process-math">\(\beta s\)</span> to simplify the equation. This substitution makes <span class="process-math">\(ds = \frac{1}{\beta} dt\text{,}\)</span> which produces the differential equation <span class="process-math">\(\beta \frac{dy}{dt} =  -\beta y (n+1-y)\text{.}\)</span> The <span class="process-math">\(\beta\)</span>s cancel, producing the differential equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Bailey_1">
\begin{equation}
\frac{dy}{dt} = -y(n+1-y)\tag{40.9}
\end{equation}
</div>
<p class="continuation">with <span class="process-math">\(y(0) = n\text{.}\)</span></p>
<p id="p-7221">The above analysis is just to provide some background. Bailey's stochastic model deals with probabilities instead of actual numbers, so we now take that approach. For <span class="process-math">\(r\)</span> from <span class="process-math">\(0\)</span> to <span class="process-math">\(n\text{,}\)</span> let <span class="process-math">\(p_r(t)\)</span> be the probability that there are <span class="process-math">\(r\)</span> susceptible individuals still uninfected at time <span class="process-math">\(t\text{.}\)</span> Similar to the case describe above, if there are <span class="process-math">\(r\)</span> susceptible individuals, any one of them can be come infected by interacting with the <span class="process-math">\(n-r+1\)</span> infected individuals. With that in mind, Bailey's model of the spread of the disease is the system</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{cases}\frac{d p_r(t)}{dt} = (r+1)(n-r)p_{r+1}(t) - r(n-r+1)p_r(t) \amp \text{ for }  0 \leq r \leq n-1\\ \frac{dp_n(t)}{dt} = -np_n(t). \amp \end{cases}
\end{equation*}
</div>
<p id="p-7222">That is,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-273">
\begin{align*}
\frac{d p_0(t)}{dt} \amp = np_1(t)\\
\frac{d p_1(t)}{dt} \amp = 2(n-1)p_2(t) - np_1(t)\\
\frac{d p_2(t)}{dt} \amp = 3(n-2)p_3(t) - 2(n-1)p_2(t)\\
\vdots \amp\\
\frac{d p_{n-1}(t)}{dt} \amp = np_n(t) - (n-1)(2)p_{n-1}(t)\\
\frac{dp_n(t)}{dt} \amp = -np_n(t)\text{.}
\end{align*}
</div>
<p id="p-7223">Since we start with <span class="process-math">\(n\)</span> susceptible individuals, at time <span class="process-math">\(0\)</span> we have <span class="process-math">\(p_r(0) = 0\)</span> if <span class="process-math">\(0 \leq r \leq n-1\)</span> and <span class="process-math">\(p_n(0)=1\text{.}\)</span></p>
<p id="p-7224">This system can be written in matrix form. Let <span class="process-math">\(P(t) = \left[ \begin{array}{c} p_0(t)\\p_1(t) \\ \vdots \\ p_n(t) \end{array}  \right]\text{.}\)</span> Assuming that we can differentiate a vector function component-wise, our system becomes</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{dP(t)}{dt} = A P(t)
\end{equation*}
</div>
<p class="continuation">with initial condition <span class="process-math">\(P(0) = [0 \ 0 \ \ldots \ 0 \ 1]^{\tr}\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\left[ \begin{array}{ccccccccc} 0\amp n\amp 0\amp 0\amp 0\amp  \cdots \amp 0\amp 0\amp 0 \\ 0\amp -n\amp 2(n-1)\amp 0 \amp 0\amp \cdots \amp 0\amp 0\amp 0 \\ 0\amp 0\amp -2(n-1)\amp 3(n-2) \amp 0 \amp  \cdots \amp  0\amp 0\amp 0 \\ \amp \amp \amp \amp \vdots\amp \amp \amp \amp  \\ 0\amp 0\amp  \cdots \amp -r(n-r+1) \amp (r+1)(n-r)\amp  0 \amp  \cdots \amp  0\amp 0 \\ \amp \amp \amp \amp \vdots\amp \amp \amp \amp   \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp 0 \amp 0\amp -2(n-1)\amp n \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp 0\amp 0\amp 0\amp -n \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-7225">The solution to this system involves a matrix exponential <span class="process-math">\(e^{At}\text{.}\)</span> The matrix exponential acts much like our familiar exponential function in that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{d}{dx}e^{At} = Ae^{At}\text{.}
\end{equation*}
</div>
<p id="p-7226">With this in mind it is not difficult to see that Bailey's system has solution <span class="process-math">\(P(t)= e^{At}P(0)\text{.}\)</span> To truly understand this solution, we need to make sense of the matrix exponential <span class="process-math">\(e^{At}\text{.}\)</span></p>
<p id="p-7227">We can make sense of the matrix exponential by utilizing the Taylor series of the exponential function centered at the origin. From calculus we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_exponential">
\begin{equation}
e^x = 1 + x + \frac{1}{2!}x^2 + \frac{1}{3!}x^3 + \cdots + \frac{1}{n!}x^n + \cdots = \sum_{k\geq 0} \frac{1}{k!}x^k\text{.}\tag{40.10}
\end{equation}
</div>
<p id="p-7228">Since powers of square matrices are defined, the matrix exponential <span class="process-math">\(e^M\)</span> of a square matrix <span class="process-math">\(M\)</span> is then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Matrix_exponential">
\begin{equation}
e^M = I_n + M + \frac{1}{2!}M^2 + \frac{1}{3!}M^3 + \cdots + \frac{1}{n!}M^n + \cdots = \sum_{k\geq 0} \frac{1}{k!}M^k\text{.}\tag{40.11}
\end{equation}
</div>
<p id="p-7229">Just as in calculus, <span class="process-math">\(e^M\)</span> converges for any square matrix <span class="process-math">\(M\text{.}\)</span></p>
<article class="project project-like" id="project-148"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">40.12</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-723"><p id="p-7230">If <span class="process-math">\(M\)</span> is diagonalizable, then <span class="process-math">\(e^M\)</span> can be found fairly easily. Assume that there is an invertible matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}MP = D\text{,}\)</span> where <span class="process-math">\(D = \left[ \begin{array}{ccccc} \lambda_1\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  \lambda_2\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  \lambda_n \end{array}  \right]\)</span> is a diagonal matrix.</p></div>
<article class="task exercise-like" id="task-2465"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7231">Use <a href="" class="xref" data-knowl="./knowl/eq_Matrix_exponential.html" title="Equation 40.11">(40.11)</a> to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Matrix_exponential.html">
\begin{equation*}
e^M = Pe^DP^{-1}\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-2466"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7232">Now show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^M = P\left[ \begin{array}{ccccc} e^{\lambda_1}\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  e^{\lambda_2}\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  e^{\lambda_n} \end{array}  \right]P^{-1}\text{.}
\end{equation*}
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-149" id="hint-149"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-149"><div class="hint solution-like"><p id="p-7233">What is <span class="process-math">\(D^k\)</span> for any positive integer <span class="process-math">\(k\text{?}\)</span> Then add corresponding components and compare to <a href="" class="xref" data-knowl="./knowl/eq_exponential.html" title="Equation 40.10">(40.10)</a>.</p></div></div>
</div></article></article><p id="p-7234">As we will see, the matrix <span class="process-math">\(A\)</span> in Bailey's model is not diagonalizable, so we need to learn how to consider the matrix exponential in this new situation. In these cases we can utilize the Jordan canonical form. Of course, the computations are more complicated. We first illustrate with the <span class="process-math">\(2 \times 2\)</span> case.</p>
<article class="project project-like" id="project-149"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">40.13</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-724">
<p id="p-7235">Assume <span class="process-math">\(A\)</span> is a <span class="process-math">\(2 \times 2\)</span> matrix with Jordan canonical form<span class="process-math">\(J = \left[ \begin{array}{cc} \lambda\amp 1\\0\amp \lambda \end{array}  \right]\text{,}\)</span> where <span class="process-math">\(C^{-1}AC = J\text{.}\)</span> The same argument as above shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^A = Ce^JC^{-1}
\end{equation*}
</div>
<p class="continuation">and so we only have to be able to find <span class="process-math">\(e^J\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-2467"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7236">We can write <span class="process-math">\(J\)</span> in the form <span class="process-math">\(J = D+N\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix and <span class="process-math">\(N\)</span> is a nilpotent matrix. Find <span class="process-math">\(D\)</span> and <span class="process-math">\(N\)</span> in this case and explain why <span class="process-math">\(N\)</span> is a nilpotent matrix.</p></article><article class="task exercise-like" id="task-2468"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7237">Find the index of <span class="process-math">\(N\text{.}\)</span> That is, find the smallest positive power <span class="process-math">\(s\)</span> of <span class="process-math">\(N\)</span> such that <span class="process-math">\(N^s = 0\text{.}\)</span> Then use <a href="" class="xref" data-knowl="./knowl/eq_Matrix_exponential.html" title="Equation 40.11">(40.11)</a> to find <span class="process-math">\(e^N\text{.}\)</span></p></article><article class="task exercise-like" id="task-2469"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7238">Assume that the matrix exponential satisfies the standard property of exponential functions that <span class="process-math">\(e^{R+S} = e^Re^S\)</span> for any <span class="process-math">\(n \times n\)</span> matrices <span class="process-math">\(R\)</span> and <span class="process-math">\(S\text{.}\)</span> Use this property to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^J = \left[ \begin{array}{cc} e^{\lambda}\amp e^{\lambda}\\0\amp e^{\lambda} \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-2470"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7239">Use the previous information to calculate <span class="process-math">\(e^M\)</span> where <span class="process-math">\(M = \left[ \begin{array}{cr} 3 \amp -1 \\ 4 \amp 7 \end{array} \right]\text{.}\)</span></p></article></article><p id="p-7240">Now we turn to the general case of finding the matrix exponential <span class="process-math">\(e^M\)</span> when <span class="process-math">\(M\)</span> is not diagonalizable. Suppose <span class="process-math">\(C\)</span> is an invertible matrix and <span class="process-math">\(C^{-1}MC = J\text{,}\)</span> where <span class="process-math">\(J\)</span> is a Jordan canonical form of <span class="process-math">\(M\text{.}\)</span> Then we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^M = e^{CJC^{-1}} = C e^J C^{-1}\text{.}
\end{equation*}
</div>
<p id="p-7241">We know that <span class="process-math">\(J\)</span> can be written in the form <span class="process-math">\(D+N\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix and <span class="process-math">\(N\)</span> is an upper triangular matrix with zeros on the diagonal and some ones along the superdiagonal. It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^M = Ce^De^NC^{-1}\text{.}
\end{equation*}
</div>
<p id="p-7242">We know that if</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = \left[ \begin{array}{cccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0\amp 0 \\  0\amp \lambda_2\amp 0\amp \cdots\amp 0\amp 0 \\ \amp \amp \amp \ddots\amp \amp  \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda_n \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^D = \left[ \begin{array}{cccccc} e^{\lambda_1}\amp 0\amp 0\amp \cdots\amp 0\amp 0 \\  0\amp e^{\lambda_2}\amp 0\amp \cdots\amp 0\amp 0 \\ \amp \amp \amp \ddots\amp \amp  \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp e^{\lambda_n} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-7243">So finding <span class="process-math">\(e^M\)</span> boils down to determining <span class="process-math">\(e^N\text{.}\)</span></p>
<p id="p-7244">Now <span class="process-math">\(N\)</span> has only zero as an eigenvalue, so <span class="process-math">\(N\)</span> is nilpotent. If <span class="process-math">\(k\)</span> is the index of <span class="process-math">\(N\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^N = I + N + \frac{1}{2}N^2 + \frac{1}{3!}N^3 + \cdots + \frac{1}{(k-1)!}N^{k-1}\text{.}
\end{equation*}
</div>
<article class="project project-like" id="project-150"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">40.14</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-725"><p id="p-7245">Let us apply this analysis to a specific case of Bailey's model, with <span class="process-math">\(n = 5\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-2471"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-7246">Find the entries of <span class="process-math">\(A\)</span> when <span class="process-math">\(n = 5\text{.}\)</span></p></article><article class="task exercise-like" id="task-2472"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-7247">Let <span class="process-math">\(J\)</span> be a Jordan canonical form for <span class="process-math">\(A\text{.}\)</span> Explain why the solution to Bailey's model has the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P(t)= e^{At}P(0) = Ce^{Dt}e^{Nt}C^{-1}P(0)\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(C\)</span> is an invertible matrix, <span class="process-math">\(Dt\)</span> is a diagonal matrix, and <span class="process-math">\(Nt\)</span> is a nilpotent matrix.</p></article><article class="task exercise-like" id="task-2473"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-7248">Find a Jordan canonical form <span class="process-math">\(J\)</span> for <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-2474"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-7249">Find a diagonal matrix <span class="process-math">\(D\)</span> and a nilpotent matrix <span class="process-math">\(N\)</span> so that <span class="process-math">\(J = D+N\text{.}\)</span></p></article><article class="task exercise-like" id="task-2475"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-7250">Find <span class="process-math">\(e^{Dt}\)</span> and <span class="process-math">\(e^{Nt}\text{.}\)</span> Then show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P(t) = \left[  \begin{array}{c} 1+\frac{172}{3}e^{-5t}-80te^{-5t}+\frac{125}{3}e^{-8t}-200te^{-8t}-100e^{-9t} \\ -\frac{220}{3}e^{-5t}+80te^{-5t}-\frac {320}{3}e^{-8t}+320te^{-8t} +180e^{-9t} \\ 10e^{-5t}+80e^{-8t}-120te^{-8t}-90e^{-9t} \\ \frac{10}{3}e^{-5t}-\frac{40}{3}e^{-8t}+10e^{-9t} \\ \frac{5}{3}e^{-5t}- \frac{5}{3}e^{-8t} \\ e^{-5t} \end{array}  \right]\text{.}
\end{equation*}
</div></article></article><p id="p-7251">One use for mathematical models like Bailey's is to make predictions that can help set policies. Recall that we made the substitution of <span class="process-math">\(t\)</span> for <span class="process-math">\(\beta s\)</span> in our original equation in order to make the equations dimensionless, where <span class="process-math">\(\beta\)</span> is the infection rate — the rate at which people catch the disease. Let us replace <span class="process-math">\(t\)</span> with <span class="process-math">\(\beta s\)</span> in our solution and analyze the effect of changing the value of <span class="process-math">\(\beta\text{.}\)</span></p>
<article class="project project-like" id="project-151"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">40.15</span><span class="period">.</span>
</h4>
<p id="p-7252">If <span class="process-math">\(\beta = 1\text{,}\)</span> then the disease is easily transmitted from person to person. If <span class="process-math">\(\beta\)</span> can be made smaller, then the disease is not so easily transmitted. We continue to work with the case where <span class="process-math">\(n=5\text{.}\)</span> Plot the curves <span class="process-math">\(p_0(t)\)</span> through <span class="process-math">\(p_5(t)\)</span> on the same set of axes for the following values of <span class="process-math">\(\beta\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(a) \beta =1  (b) \beta = 0.5  (c) \beta = 0.25\text{.}
\end{equation*}
</div>
<p id="p-7253">Explain what you see and how this might be related to the phrase “flattening the curve” used during the COVID-19 pandemic of 2020.</p></article><p id="p-7254">In general, the matrix <span class="process-math">\(A\)</span> has eigenvalues of algebraic multiplicity 1 and 2. When <span class="process-math">\(n\)</span> is even, <span class="process-math">\(n+1\)</span> is odd and the eigenvalues of <span class="process-math">\(A\)</span> will occur in pairs except for the single eigenvalue <span class="process-math">\(0\)</span> of multiplicity 1. When <span class="process-math">\(n\)</span> is odd, <span class="process-math">\(n+1\)</span> is even and we have two eigenvalues of multiplicity 1: <span class="process-math">\(0\)</span> and the eigenvalue <span class="process-math">\(-r(n-r+1)\)</span> when <span class="process-math">\(r = \frac{n+1}{2}\text{,}\)</span> at which <span class="process-math">\(-r(n-r+1) = -\frac{(n+1)^2}{4}\text{.}\)</span> It can be shown, although we won't do it here, that every eigenvalue of algebraic multiplicity 2 has geometric multiplicity 1. This information completely determines the Jordan canonical formof <span class="process-math">\(A\text{.}\)</span></p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-65"><div class="fn">Bailey, N. T. J. (1950) A simple stochastic epidemic. <span class="booktitle">Biometrika</span> 37</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-66"><div class="fn">The word <dfn class="terminology">stochastic</dfn> refers to quantities that have a random pattern that can be analyzed statistically, but generally cannot be predicted precisely.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
