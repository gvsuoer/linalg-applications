<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<article class="theorem theorem-like"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.6</span><span class="period">.</span>
</h4>
<p>Let <span class="process-math">\(A\)</span> be a real symmetric matrix. Then <span class="process-math">\(A\)</span> is orthogonally diagonalizable.</p></article><article class="proof"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p>Let <span class="process-math">\(A\)</span> be a real <span class="process-math">\(n \times n\)</span> symmetric matrix. The proof proceeds by induction on <span class="process-math">\(n\text{.}\)</span> If <span class="process-math">\(n = 1\text{,}\)</span> then <span class="process-math">\(A\)</span> is diagonal and orthogonally diagonalizable. So assume that any real <span class="process-math">\((n-1) \times (n-1)\)</span> symmetric matrix is orthogonally diagonalizable. Assume that <span class="process-math">\(A\)</span> is a real <span class="process-math">\(n \times n\)</span> symmetric matrix. By Theorem 25.4 (find reference), the eigenvalues of <span class="process-math">\(A\)</span> are real. Let <span class="process-math">\(\lambda_1\)</span> be a real eigenvalue of <span class="process-math">\(A\)</span> with corresponding unit eigenvector <span class="process-math">\(\vp_1\text{.}\)</span> We can use the Gram-Schmidt process to extend <span class="process-math">\(\{\vp_1\}\)</span> to an orthonormal basis <span class="process-math">\(\{\vp_1, \vp_2, \ldots, \vp_n\}\)</span> for <span class="process-math">\(\R^n\text{.}\)</span> Let <span class="process-math">\(P_1 = [\vp_1 \ \vp_2 \ \ldots \ \vp_n]\text{.}\)</span> Then <span class="process-math">\(P_1\)</span> is an orthogonal matrix. Also,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{align*}
P_1^{-1}AP_1 \amp = P_1^{\tr}AP_1\\
\amp = P_1^{\tr} [A\vp_1 \ A\vp_2 \ \ldots \ A\vp_n]\\
\amp = \left[ \begin{array}{c} \vp_1^{\tr}\\
\vp_2^{\tr}\\
\vdots\\
\vp_n^{\tr} \end{array} \right]  [\lambda \vp_1 \ A\vp_2 \ \ldots \ A\vp_n]\\
\amp = \left[ \begin{array}{ccccc} \vp_1^{\tr} \lambda_1 \vp_1 \amp  \vp_1^{\tr} A\vp_2 \amp  \vp_1 A\vp_3 \amp  \cdots \amp  \vp_1^{\tr} A \vp_n\\
\vp_2^{\tr} \lambda_1 \vp_1 \amp  \vp_2^{\tr} A\vp_2 \amp  \vp_2 A\vp_3 \amp \cdots \amp  \vp_2^{\tr} A \vp_n\\
\amp   \amp  \vdots   \amp  \amp\\
\vp_n^{\tr} \lambda_1 \vp_1 \amp  \vp_n^{\tr} A\vp_2 \amp  \vp_n A\vp_3 \amp \cdots \amp  \vp_n^{\tr} A \vp_n \end{array} \right]\\
\amp = \left[ \begin{array}{ccccc} \lambda_1\amp  \vp_1^{\tr} A\vp_2 \amp  \vp_1 A\vp_3 \amp  \cdots \amp  \vp_1^{\tr} A \vp_n\\
0 \amp  \vp_2^{\tr} A\vp_2 \amp  \vp_2 A\vp_3 \amp \cdots \amp  \vp_2^{\tr} A \vp_n\\
\amp   \amp  \vdots   \amp  \amp\\
0 \amp  \vp_n^{\tr} A\vp_2 \amp  \vp_n A\vp_3 \amp \cdots \amp  \vp_n^{\tr} A \vp_n \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
\vzero \amp  A_1 \end{array} \right]
\end{align*}
</div>
<p class="continuation">where <span class="process-math">\(\vx\)</span> is a <span class="process-math">\((n-1)\times 1\)</span> vector, <span class="process-math">\(\vzero\)</span> is the zero vector in <span class="process-math">\(\R^{n-1}\text{,}\)</span> and <span class="process-math">\(A_1\)</span> is an <span class="process-math">\((n-1) \times (n-1)\)</span> matrix. Letting <span class="process-math">\(R = P_1^{\tr}AP_1\)</span> we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
R^{\tr} = \left(P_1^{\tr}AP_1\right)^{\tr} = P_1^{\tr}A^{\tr}P_1 = P_1^{\tr}AP_1 = R\text{,}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(R\)</span> is a symmetric matrix. Therefore, <span class="process-math">\(\vx = \vzero\)</span> and <span class="process-math">\(A_1\)</span> is a symmetric matrix. By our induction hypothesis, <span class="process-math">\(A_1\)</span> is orthogonally diagonalizable. That is, there exists an <span class="process-math">\((n-1) \times (n-1)\)</span> orthogonal matrix <span class="process-math">\(Q\)</span> such that <span class="process-math">\(Q^{\tr}A_1Q = D_1\text{,}\)</span> where <span class="process-math">\(D_1\)</span> is a diagonal matrix. Now define <span class="process-math">\(P_2\)</span> by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_2 = \left[ \begin{array}{cc} 1\amp \vzero^{\tr} \\ \vzero \amp  Q \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\vzero\)</span> is the zero vector in <span class="process-math">\(\R^{n-1}\text{.}\)</span> By construction, the columns of <span class="process-math">\(P_2\)</span> are orthonormal, so <span class="process-math">\(P_2\)</span> is an orthogonal matrix. Since <span class="process-math">\(P_1\)</span> is also an orthogonal matrix,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{\tr} = (P_1P_2)^{\tr} = P_2^{\tr}P_1^{\tr} = P_2^{-1}P_1^{-1} = (P_1P_2)^{-1}  = P^{-1}
\end{equation*}
</div>
<p class="continuation">and <span class="process-math">\(P\)</span> is an orthogonal matrix. Finally,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{align*}
P^{\tr}AP \amp = (P_1P_2)^{\tr}A(P_1P_2)\\
\amp = P_2^{\tr}\left(P_1^{\tr}AP_1\right)P_2\\
\amp = \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]^{\tr} \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
0 \amp  A_1 \end{array} \right] \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q^{\tr} \end{array} \right] \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
0 \amp  A_1 \end{array} \right]\left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vzero^{\tr}\\
\vzero \amp  Q^{\tr}A_1Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vzero^{\tr}\\
\vzero \amp  D_1 \end{array} \right]\text{.}
\end{align*}
</div>
<p>Therefore, <span class="process-math">\(P^{\tr}AP\)</span> is a diagonal matrix and <span class="process-math">\(P\)</span> orthogonally diagonalizes <span class="process-math">\(A\text{.}\)</span> This completes our proof.</p></article><span class="incontext"><a href="chap_orthogonal_diagonalization.html#theorem-68" class="internal">in-context</a></span>
</body>
</html>
