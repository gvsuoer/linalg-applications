<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<p>In general, PCA is most useful for larger data sets. The process is the same.</p>
<ul class="disc">
<li><p>Start with a set of data that forms the rows of an <span class="process-math">\(m \times n\)</span> matrix. We center the data by subtracting the mean of each row from the entries of that row to create a centered data set in a matrix <span class="process-math">\(X\text{.}\)</span></p></li>
<li><p>The principal components of <span class="process-math">\(X\)</span> are the eigenvectors of <span class="process-math">\(XX^{\tr}\text{,}\)</span> ordered so that they correspond to the eigenvalues of <span class="process-math">\(XX^{\tr}\)</span> in decreasing order.</p></li>
<li><p>Let <span class="process-math">\(P\)</span> be the matrix whose rows are the principal components of <span class="process-math">\(X\text{,}\)</span> ordered from highest to lowest. Then <span class="process-math">\(Y = PX\)</span> is suitably transformed to identify the important aspects of the data.</p></li>
<li>
<p>If <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> are the eigenvalues of <span class="process-math">\(XX^{\tr}\)</span> in decreasing order, then the amount of variance in the data accounted for by the first <span class="process-math">\(r\)</span> principal components is given by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{\lambda_1+\lambda_2 + \cdots + \lambda_r}{\lambda_1+\lambda_2 + \cdots + \lambda_n}\text{.}
\end{equation*}
</div>
</li>
<li><p>The first <span class="process-math">\(r\)</span> rows of <span class="process-math">\(Y=PX\)</span> provide the projection of the data set <span class="process-math">\(X\)</span> onto an <span class="process-math">\(r\)</span>-dimensional space spanned by the first <span class="process-math">\(r\)</span> principal components of <span class="process-math">\(X\text{.}\)</span></p></li>
</ul>
<span class="incontext"><a href="chap_dimension.html#p-5889" class="internal">in-context</a></span>
</body>
</html>
