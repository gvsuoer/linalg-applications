<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>The outer product decomposition of <span class="process-math">\(A\)</span> writes <span class="process-math">\(A\)</span> as a sum of rank 1 matrices (the summands <span class="process-math">\(\sigma_i \vu_i \vv_i^{\tr})\text{.}\)</span> Each summand contains some information about the matrix <span class="process-math">\(A\text{.}\)</span> Since <span class="process-math">\(\sigma_1\)</span> is the largest of the singular values, it is reasonable to expect that the summand <span class="process-math">\(A_1 = \sigma_1 \vu_1  \vv_1^{\tr}\)</span> contains the most information about <span class="process-math">\(A\)</span> among all of the summands. To get a measure of how much information <span class="process-math">\(A_1\)</span> contains of <span class="process-math">\(A\text{,}\)</span> we can think of <span class="process-math">\(A\)</span> as simply a long vector in <span class="process-math">\(\R^{mn}\)</span> where we have folded the data into a rectangular array (we will see later why taking the norm as the norm of the vector in <span class="process-math">\(\R^{nm}\)</span> makes sense, but for now, just use this definition). If we are interested in determining the error in approximating an image by a compressed image, it makes sense to use the standard norm in <span class="process-math">\(\R^{mn}\)</span> to determine length and distance, which is really just the Frobenius norm that comes from the Frobenius inner product defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_7_d_Frobenius_ip.html">
\begin{equation}
\langle U,V \rangle = \sum u_{ij}v_{ij}\text{,}\tag{30.1}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(U = [u_{ij}]\)</span> and <span class="process-math">\(V = [v_{ij}]\)</span> are <span class="process-math">\(m \times n\)</span> matrices. (That <a href="" class="xref" data-knowl="./knowl/eq_7_d_Frobenius_ip.html" title="Equation 30.1">(30.1)</a> defines an inner product on the set of all <span class="process-math">\(n \times n\)</span> matrices is left to discuss in a later section.) So in this section all the norms for matrices will refer to the Frobenius norm. Rather than computing the distance between <span class="process-math">\(A_1\)</span> and <span class="process-math">\(A\)</span> to measure the error, we are more interested in the relative error</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_7_d_Frobenius_ip.html">
\begin{equation*}
\frac{||A-A_1||}{||A||}\text{.}
\end{equation*}
</div>
<span class="incontext"><a href="chap_pseudoinverses.html#p-5106" class="internal">in-context</a></span>
</body>
</html>
