<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The Characteristic Equation</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
},
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script><script src="https://unpkg.com/lunr/lunr.js"></script><script src="lunr-pretext-search-index.js"></script><script src="https://pretextbook.org/js/0.13/pretext_search.js"></script><link href="https://pretextbook.org/css/0.4/pretext_search.css" rel="stylesheet" type="text/css">
<script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{colortbl}\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div>
<div id="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms"></span>
</h2>
<ol id="searchresults"></ol>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_determinants.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_diagonalization.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_determinants.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_diagonalization.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: B√©zier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating B√©zier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_characteristic_equation"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">18</span> <span class="title">The Characteristic Equation</span>
</h2>
<section class="introduction" id="introduction-279"><article class="objectives goal-like" id="objectives-18"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-280"><p id="p-3034">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-543"><p id="p-3035">What is the characteristic polynomial of a matrix?</p></li>
<li id="li-544"><p id="p-3036">What is the characteristic equation of a matrix?</p></li>
<li id="li-545"><p id="p-3037">How and why is the characteristic equation of a matrix useful?</p></li>
<li id="li-546"><p id="p-3038">How many different eigenvalues can an <span class="process-math">\(n \times n\)</span> matrix have?</p></li>
<li id="li-547"><p id="p-3039">How large can the dimension of the eigenspace corresponding to an eigenvalue be?</p></li>
</ul></article></section><section class="section" id="sec_appl_thermo"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: Modeling the Second Law of Thermodynamics</span>
</h3>
<p id="p-3040">Pour cream into your cup of coffee and the cream spreads out; straighten up your room and it soon becomes messy again; when gasoline is mixed with air in a car's cylinders, it explodes if a spark is introduced. In each of these cases a transition from a low energy state (your room is straightened up) to a higher energy state (a messy, disorganized room) occurs. This can be described by entropy ‚Äî a measure of the energy in a system. Low energy is organized (like ice cubes) and higher energy is not (like water vapor). It is a fundamental property of energy (as described by the second law of thermodynamics) that the entropy of a system cannot decrease. In other words, in the absence of any external intervention, things never become more organized.</p>
<p id="p-3041">The Ehrenfest model<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-34" id="fn-34"><sup>‚Äâ34‚Äâ</sup></a> is a Markov process proposed to explain the statistical interpretation of the second law of thermodynamics using the diffusion of gas molecules. This process can be modeled as a problem of balls and bins, as we will do later in this section. The characteristic polynomial of the transition matrix will help us find the eigenvalues and allow us to analyze our model.</p></section><section class="section" id="sec_chareq_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-3042">We have seen that the eigenvalues of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> are the scalars <span class="process-math">\(\lambda\)</span> so that <span class="process-math">\(A - \lambda I_n\)</span> has a nontrivial null space. Since a matrix has a nontrivial null space if and only if the matrix is not invertible, we can also say that <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\)</span> if</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_PA5_2_1">
\begin{equation}
\det(A - \lambda I_n) = 0\text{.}\tag{18.1}
\end{equation}
</div>
<p id="p-3043">This equation is called the <dfn class="terminology">characteristic equation</dfn> of <span class="process-math">\(A\text{.}\)</span> It provides us an <dfn class="terminology">algebraic</dfn> way to find eigenvalues, which can then be used in finding eigenvectors corresponding to each eigenvalue. Suppose we want to find the eigenvalues of <span class="process-math">\(A=\left[ \begin{array}{cc} 1 \amp  1 \\ 1\amp  3 \end{array}  \right]\text{.}\)</span> Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A- \lambda I_2 = \left[ \begin{array}{cc} 1-\lambda \amp  1 \\ 1\amp  3-\lambda \end{array}  \right]\,\text{,}
\end{equation*}
</div>
<p class="continuation">with determinant <span class="process-math">\((1-\lambda)(3-\lambda)-1=\lambda^2-4\lambda+2\text{.}\)</span> Hence, the eigenvalues <span class="process-math">\(\lambda_1, \lambda_2\)</span> are the solutions of the characteristic equation <span class="process-math">\(\lambda^2-4\lambda+2=0\text{.}\)</span> Using quadratic formula, we find that <span class="process-math">\(\lambda_1=2+\sqrt{2}\)</span> and <span class="process-math">\(\lambda_2=2-\sqrt{2}\)</span> are the eigenvalues.</p>
<p id="p-3044">In this activity, our goal will be to use the characteristic equation to obtain information about eigenvalues and eigenvectors of a matrix with real entries.</p>
<article class="exploration project-like" id="pa_4_b"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">18.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-997"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-281"><p id="p-3045">For each of the following parts, use the characteristic equation to determine the eigenvalues of <span class="process-math">\(A\text{.}\)</span> Then, for each eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> find a basis of the corresponding eigenspace, i.e., <span class="process-math">\(\Nul(A-\lambda I)\text{.}\)</span> You might want to recall how to find a basis for the null space of a matrix from <a href="chap_null_space.html" class="internal" title="Section 13: The Null Space and Column Space of a Matrix">Section¬†13</a>. Also, make sure that your eigenvalue candidate <span class="process-math">\(\lambda\)</span> yields nonzero eigenvectors in <span class="process-math">\(\Nul(A-\lambda I)\)</span> for otherwise <span class="process-math">\(\lambda\)</span> will not be an eigenvalue.</p></div>
<article class="task exercise-like" id="task-998"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3046"><span class="process-math">\(A=\left[ \begin{array}{cr} 2 \amp 0 \\ 0 \amp -3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-999"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3047"><span class="process-math">\(A=\left[ \begin{array}{cc} 1 \amp 2 \\ 0 \amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1000"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3048"><span class="process-math">\(A=\left[ \begin{array}{cc} 1 \amp 4 \\2 \amp 3 \end{array} \right]\)</span></p></article></article><article class="task exercise-like" id="task-1001"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-282"><p id="p-3049">Use your eigenvalue and eigenvector calculations of the above problem as a guidance to answer the following questions about a matrix with real entries.</p></div>
<article class="task exercise-like" id="task-1002"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3050">At most how many eigenvalues can a <span class="process-math">\(2\times 2\)</span> matrix have? Is it possible to have no eigenvalues? Is it possible to have only one eigenvalue? Explain.</p></article><article class="task exercise-like" id="task-1003"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3051">If a matrix is an upper-triangular matrix (i.e., all entries below the diagonal are 0's, as in the first two matrices of the previous problem), what can you say about its eigenvalues? Explain.</p></article><article class="task exercise-like" id="task-1004"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3052">How many linearly independent eigenvectors can be found for a <span class="process-math">\(2\times 2\)</span> matrix? Is it possible to have a matrix without 2 linearly independent eigenvectors? Explain.</p></article></article><article class="task exercise-like" id="task-1005"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3053">Using the characteristic equation, determine which matrices have 0 as an eigenvalue.</p></article></article></section><section class="section" id="sec_chareq"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Characteristic Equation</span>
</h3>
<p id="p-3054">Until now, we have been given eigenvalues or eigenvectors of a matrix and determined eigenvectors and eigenvalues from the known information. In this section we use determinants to find (or approximate) the eigenvalues of a matrix. From there we can find (or approximate) the corresponding eigenvectors. The tool we will use is a polynomial equation, the characteristic equation, of a square matrix whose roots are the eigenvalues of the matrix. The characteristic equation will then provide us with an algebraic way of finding the eigenvalues of a square matrix.</p>
<p id="p-3055">We have seen that the eigenvalues of a square matrix <span class="process-math">\(A\)</span> are the scalars <span class="process-math">\(\lambda\)</span> so that <span class="process-math">\(A - \lambda I\)</span> has a nontrivial null space. Since a matrix has a nontrivial null space if and only if the matrix is not invertible, we can also say that <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\)</span> if</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_b_1">
\begin{equation}
\det(A - \lambda I) = 0\text{.}\tag{18.2}
\end{equation}
</div>
<p id="p-3056">Note that if <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, then <span class="process-math">\(\det(A - \lambda I)\)</span> is a polynomial of degree <span class="process-math">\(n\text{.}\)</span> Furthermore, if <span class="process-math">\(A\)</span> has real entries, the polynomial has real coefficients. This polynomial, and the equation <a href="" class="xref" data-knowl="./knowl/eq_4_b_1.html" title="Equation 18.2">(18.2)</a> are given special names.</p>
<article class="definition definition-like" id="definition-39"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">18.1</span><span class="period">.</span>
</h4>
<p id="p-3057">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. The <dfn class="terminology">characteristic polynomial</dfn> of <span class="process-math">\(A\)</span> is the polynomial</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A-\lambda I_n)\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix. The <dfn class="terminology">characteristic equation</dfn> of <span class="process-math">\(A\)</span> is the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A-\lambda I_n) = 0\text{.}
\end{equation*}
</div></article><p id="p-3058">So the characteristic equation of <span class="process-math">\(A\)</span> gives us an algebraic way of finding the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p>
<article class="activity project-like" id="act_4_b_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">18.2</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1006"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3059">Find the characteristic polynomial of the matrix <span class="process-math">\(A = \left[ \begin{array}{crc} 3\amp -2\amp 5 \\ 1\amp 0\amp 7 \\ 0\amp 0\amp 1 \end{array} \right]\text{,}\)</span> and use the characteristic polynomial to find all of the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1007"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3060">Verify that 1 and 2 are the only eigenvalues of the matrix <span class="process-math">\(\left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 1\\ 1\amp 2\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 1 \end{array} \right]\text{.}\)</span></p></article></article><p id="p-3061">As we argued in <a href="" class="xref" data-knowl="./knowl/pa_4_b.html" title="Preview Activity 18.1">Preview Activity¬†18.1</a>, a <span class="process-math">\(2 \times 2\)</span> matrix can have at most 2 eigenvalues. For an <span class="process-math">\(n \times n\)</span> matrix, the characteristic polynomial will be a degree <span class="process-math">\(n\)</span> polynomial, and we know from algebra that a degree <span class="process-math">\(n\)</span> polynomial can have at most <span class="process-math">\(n\)</span> roots. Since an eigenvalue of a matrix is a root of the characteristic polynomial of that matrix, we can conclude that an <span class="process-math">\(n \times n\)</span> matrix can have at most <span class="process-math">\(n\)</span> distinct eigenvalues. <a href="" class="xref" data-knowl="./knowl/act_4_b_1.html" title="Activity 18.2">Activity¬†18.2</a> (b) shows that a <span class="process-math">\(4 \times 4\)</span> matrix may have fewer than <span class="process-math">\(4\)</span> eigenvalues, however. Note that one of these eigenvalues, the eigenvalue 1, appears three times as a root of the characteristic polynomial of the matrix. The number of times an eigenvalue appears as a root of the characteristic polynomial is called the <dfn class="terminology">(algebraic) multiplicity</dfn> of the eigenvalue. More formally:</p>
<article class="definition definition-like" id="definition-40"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">18.2</span><span class="period">.</span>
</h4>
<p id="p-3062">The <dfn class="terminology">(algebraic) multiplicity</dfn> of an eigenvalue <span class="process-math">\(\lambda\)</span> of a matrix <span class="process-math">\(A\)</span> is the largest integer <span class="process-math">\(m\)</span> so that <span class="process-math">\((x-\lambda)^m\)</span> divides the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span></p></article><p id="p-3063">Thus, in <a href="" class="xref" data-knowl="./knowl/act_4_b_1.html" title="Activity 18.2">Activity¬†18.2</a> (b) the eigenvalue 1 has multiplicity 3 and the eigenvalue 2 has multiplicity 1. Notice that if we count the eigenvalues of an <span class="process-math">\(n \times n\)</span> matrix with their multiplicities, the total will always be <span class="process-math">\(n\text{.}\)</span></p>
<p id="p-3064">If <span class="process-math">\(A\)</span> is a matrix with real entries, then the characteristic polynomial will have real coefficients. It is possible that the characteristic polynomial can have complex roots, and that the matrix <span class="process-math">\(A\)</span> has complex eigenvalues. The Fundamental Theorem of Algebra shows us that if a real matrix has complex eigenvalues, then those eigenvalues will appear in conjugate pairs, i.e., if <span class="process-math">\(\lambda_1=a+ib\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\lambda_2=a-ib\)</span> is another eigenvalue of <span class="process-math">\(A\text{.}\)</span> Furthermore, for an odd degree polynomial, since the complex eigenvalues will come in conjugate pairs, we will be able to find at least one real eigenvalue.</p>
<p id="p-3065">We now summarize the information we have so far about eigenvalues of an <span class="process-math">\(n\times n\)</span> real matrix:</p>
<article class="theorem theorem-like" id="theorem-40"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">18.3</span><span class="period">.</span>
</h4>
<p id="p-3066">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix with real entries. Then</p>
<ol class="decimal">
<li id="li-548"><p id="p-3067">There are at most <span class="process-math">\(n\)</span> eigenvalues of <span class="process-math">\(A\text{.}\)</span> If each eigenvalue (including complex eigenvalues) is counted with its multiplicity, there are exactly <span class="process-math">\(n\)</span> eigenvalues.</p></li>
<li id="li-549"><p id="p-3068">If <span class="process-math">\(A\)</span> has a complex eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> the complex conjugate of <span class="process-math">\(\lambda\)</span> is also an eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-550"><p id="p-3069">If <span class="process-math">\(n\)</span> is odd, <span class="process-math">\(A\)</span> has at least one real eigenvalue.</p></li>
<li id="li-551"><p id="p-3070">If <span class="process-math">\(A\)</span> is upper or lower-triangular, the eigenvalues are the entries on the diagonal.</p></li>
</ol></article></section><section class="section" id="sec_egspace_geom"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Eigenspaces, A Geometric Example</span>
</h3>
<p id="p-3071">Recall that for each eigenvalue <span class="process-math">\(\lambda\)</span> of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\)</span> is <span class="process-math">\(\Nul (A - \lambda I_n)\text{.}\)</span> These eigenspaces can tell us important information about the matrix transformation defined by <span class="process-math">\(A\text{.}\)</span> For example, consider the matrix transformation <span class="process-math">\(T\)</span> from <span class="process-math">\(\R^3\)</span> to <span class="process-math">\(\R^3\)</span> defined by <span class="process-math">\(T(\vx) = A \vx\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{ccc} 1\amp 0\amp 1\\0\amp 1\amp 1\\0\amp 0\amp 2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3072">We are interested in understanding what this matrix transformation does to vectors in <span class="process-math">\(\R^3\text{.}\)</span> First we note that <span class="process-math">\(A\)</span> has eigenvalues <span class="process-math">\(\lambda_1 = 1\)</span> and <span class="process-math">\(\lambda_2 = 2\text{,}\)</span> with <span class="process-math">\(\lambda_1\)</span> having multiplicity <span class="process-math">\(2\text{.}\)</span> There is a pair <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 1\\0\\0 \end{array}  \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 0\\1\\0 \end{array}  \right]\)</span> of linearly independent eigenvectors for <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda_1\)</span> and an eigenvector <span class="process-math">\(\vv_3=\left[ \begin{array}{c} 1\\1\\1 \end{array}  \right]\)</span> for <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda_2\text{.}\)</span> Note that the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> are linearly independent (recall from Theorem that eigenvectors corresponding to different eigenvalues are always linearly independent). So any vector <span class="process-math">\(\vb\)</span> in <span class="process-math">\(\R^3\)</span> can be written uniquely as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> Let's now consider the action of the matrix transformation <span class="process-math">\(T\)</span> on a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span> Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-15">
\begin{align}
T(c_1\vv_1 + c_2 \vv_2 + c_3 \vv_3) \amp = c_1T(\vv_1) + c_2T(\vv_2) + c_3 T(\vv_3)\notag\\
\amp = c_1 \lambda_1 \vv_1 + c_2 \lambda_1 \vv_2 + c_3 \lambda_2 \vv_3\notag\\
\amp = (1)(c_1\vv_1 + c_2 \vv_2) + (2)c_3 \vv_3\text{.}\tag{18.3}
\end{align}
</div>
<p id="p-3073">Equation <a href="" class="xref" data-knowl="./knowl/eq_4_b_2.html" title="Equation 18.3">(18.3)</a> illustrates that it is most convenient to view the action of <span class="process-math">\(T\)</span> in the coordinate system where <span class="process-math">\(\Span \{\vv_1\}\)</span> serves as the <span class="process-math">\(x\)</span>-axis, <span class="process-math">\(\Span \{\vv_2\}\)</span> serves as the <span class="process-math">\(y\)</span>-axis, and <span class="process-math">\(\Span \{\vv_3\}\)</span> as the <span class="process-math">\(z\)</span>-axis. In this case, we can visualize that when we apply the transformation <span class="process-math">\(T\)</span> to a vector <span class="process-math">\(\vb = c_1 \vv_1 + c_2 \vv_2 + c_3 \vv_3\)</span> in <span class="process-math">\(\R^3\)</span> the result is an output vector that is unchanged in the <span class="process-math">\(\vv_1\)</span>-<span class="process-math">\(\vv_2\)</span> plane and scaled by a factor of <span class="process-math">\(2\)</span> in the <span class="process-math">\(\vv_3\)</span> direction. For example, consider the box whose sides are determined by the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> as shown in <a href="" class="xref" data-knowl="./knowl/F_4_b_1.html" title="Figure 18.4">Figure¬†18.4</a>. The transformation <span class="process-math">\(T\)</span> stretches this box by a factor of <span class="process-math">\(2\)</span> in the <span class="process-math">\(\vv_3\)</span> direction and leaves everything else alone, as illustrated in <a href="" class="xref" data-knowl="./knowl/F_4_b_1.html" title="Figure 18.4">Figure¬†18.4</a>. So the entire <span class="process-math">\(\Span \{\vv_1, \vv_2\})\)</span> is unchanged by <span class="process-math">\(T\text{,}\)</span> but <span class="process-math">\(\Span \{\vv_3\})\)</span> is scaled by <span class="process-math">\(2\text{.}\)</span> In this situation, the eigenvalues and eigenvectors provide the most convenient perspective through which to visualize the action of the transformation <span class="process-math">\(T\text{.}\)</span></p>
<figure class="figure figure-like" id="F_4_b_1"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/4_b_Eigenspaces.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">18.4<span class="period">.</span></span><span class="space"> </span>A box and a transformed box.</figcaption></figure><p id="p-3074">This geometric perspective illustrates how each eigenvalue and the corresponding eigenspace of <span class="process-math">\(A\)</span> tells us something important about <span class="process-math">\(A\text{.}\)</span> So it behooves us to learn a little more about eigenspaces.</p></section><section class="section" id="sec_egspace_dims"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Dimensions of Eigenspaces</span>
</h3>
<p id="p-3075">There is a connection between the dimension of the eigenspace of a matrix corresponding to an eigenvalue and the multiplicity of that eigenvalue as a root of the characteristic polynomial. Recall that the dimension of a subspace of <span class="process-math">\(\R^n\)</span> is the number of vectors in a basis for the eigenspace. We investigate the connection between dimension and multiplicity in the next activity.</p>
<article class="activity project-like" id="act_4_b_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">18.3</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1008"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3076">Find the dimension of the eigenspace for each eigenvalue of matrix <span class="process-math">\(A = \left[ \begin{array}{crc} 3\amp -2\amp 5 \\ 1\amp 0\amp 7 \\ 0\amp 0\amp 1 \end{array} \right]\)</span> from <a href="" class="xref" data-knowl="./knowl/act_4_b_1.html" title="Activity 18.2">Activity¬†18.2</a> (a).</p></article><article class="task exercise-like" id="task-1009"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3077">Find the dimension of the eigenspace for each eigenvalue of matrix <span class="process-math">\(A=\left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 1\\ 1\amp 2\amp 0\amp 0 \\ 0\amp 0\amp 1\amp 0 \\ 0\amp 0\amp 0\amp 1 \end{array} \right]\)</span> from <a href="" class="xref" data-knowl="./knowl/act_4_b_1.html" title="Activity 18.2">Activity¬†18.2</a> (b).</p></article><article class="task exercise-like" id="task-1010"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-283"><p id="p-3078">Consider now a <span class="process-math">\(3\times 3\)</span> matrix with 3 distinct eigenvalues <span class="process-math">\(\lambda_1, \lambda_2, \lambda_3\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1011"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3079">Recall that a polynomial of degree can have at most three distinct roots. What does that say about the multiplicities of <span class="process-math">\(\lambda_1, \lambda_2, \lambda_3\text{?}\)</span></p></article><article class="task exercise-like" id="task-1012"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3080">Use the fact that eigenvectors corresponding to distinct eigenvalues are linearly independent to find the dimensions of the eigenspaces for <span class="process-math">\(\lambda_1, \lambda_2, \lambda_3\text{.}\)</span></p></article></article></article><p id="p-3081">The examples in <a href="" class="xref" data-knowl="./knowl/act_4_b_3.html" title="Activity 18.3">Activity¬†18.3</a> all provide instances of the principle that the dimension of an eigenspace corresponding to an eigenvalue <span class="process-math">\(\lambda\)</span> cannot exceed the multiplicity of <span class="process-math">\(\lambda\text{.}\)</span> Specifically:</p>
<article class="theorem theorem-like" id="theorem-41"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">18.5</span><span class="period">.</span>
</h4>
<p id="p-3082">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> the dimension of the eigenspace corresponding to <span class="process-math">\(\lambda\)</span> is less than or equal to the multiplicity of <span class="process-math">\(\lambda\text{.}\)</span></p></article><p id="p-3083">The examples we have seen raise another important point. The matrix <span class="process-math">\(A = \left[ \begin{array}{ccc} 1\amp 0\amp 1\\0\amp 1\amp 1\\0\amp 0\amp 2 \end{array} \right]\)</span> from our geometric example has two eigenvalues <span class="process-math">\(1\)</span> and <span class="process-math">\(2\text{,}\)</span> with the eigenvalue 1 having multiplicity 2. If we let <span class="process-math">\(E_{\lambda}\)</span> represent the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> then <span class="process-math">\(\dim(E_1)=2\)</span> and <span class="process-math">\(\dim(E_2) = 1\text{.}\)</span> If we change this matrix slightly to the matrix <span class="process-math">\(B = \left[ \begin{array}{crc} 2\amp 0\amp 1 \\ 0\amp 1\amp 1 \\ 0\amp 0\amp 1 \end{array} \right]\)</span> we see that <span class="process-math">\(B\)</span> has two eigenvalues <span class="process-math">\(1\)</span> and <span class="process-math">\(2\text{,}\)</span> with the eigenvalue 1 having multiplicity 2. However, in this case we have <span class="process-math">\(\dim(E_1) = 1\)</span> (like the example in from <a href="" class="xref" data-knowl="./knowl/act_4_b_1.html" title="Activity 18.2">Activity¬†18.2</a> (a) and <a href="" class="xref" data-knowl="./knowl/act_4_b_3.html" title="Activity 18.3">Activity¬†18.3</a> (a)). In this case the vector <span class="process-math">\(\vv_1 = [1 \ 0 \ 0]^{\tr}\)</span> forms a basis for <span class="process-math">\(E_2\)</span> and the vector <span class="process-math">\(\vv_2 = [0 \ 1 \ 0]^{\tr}\)</span> forms a basis for <span class="process-math">\(E_1\text{.}\)</span> We can visualize the action of <span class="process-math">\(B\)</span> on the square formed by <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> in the <span class="process-math">\(xy\)</span>-plane as a scaling by 2 in the <span class="process-math">\(\vv_1\)</span> direction as shown in <a href="" class="xref" data-knowl="./knowl/F_4_b_2.html" title="Figure 18.6">Figure¬†18.6</a>, but since we do not have a third linearly independent eigenvector, the action of <span class="process-math">\(B\)</span> in the direction of <span class="process-math">\([0 \ 0 \ 1]^{\tr}\)</span> is not so clear.</p>
<figure class="figure figure-like" id="F_4_b_2"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/4_b_Eigenspaces_2.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">18.6<span class="period">.</span></span><span class="space"> </span>A box and a transformed box.</figcaption></figure><p id="p-3084">So the action of a matrix transformation can be more easily visualized if the dimension of each eigenspace is equal to the multiplicity of the corresponding eigenvalue. This geometric perspective leads us to define the geometric multiplicity of an eigenvalue.</p>
<article class="definition definition-like" id="definition-41"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">18.7</span><span class="period">.</span>
</h4>
<p id="p-3085">The <dfn class="terminology">geometric multiplicity</dfn> of an eigenvalue of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is the dimension of the corresponding eigenspace <span class="process-math">\(\Nul (A-\lambda I_n)\text{.}\)</span></p></article></section><section class="section" id="sec_chareq_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-3086">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-36"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">18.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-284"><p id="p-3087">Let <span class="process-math">\(A = \left[ \begin{array}{rcr} -1\amp 0\amp -2 \\ 2\amp 1\amp 2 \\ 0\amp 0\amp 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1013"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3088">Find the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-110">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3089">The characteristic polynomial of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-126">
\begin{align*}
p(\lambda) \amp = \det(A - \lambda I_3)\\
\amp = \det\left( \left[ \begin{array}{ccc} -1-\lambda\amp 0\amp -2\\
2\amp 1-\lambda\amp 2\\
0\amp 0\amp 1-\lambda \end{array}\right] \right)\\
\amp = (-1-\lambda)(1-\lambda)(1-\lambda)\text{.}
\end{align*}
</div>
</div></article><article class="task exercise-like" id="task-1014"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3090">Factor the characteristic polynomial and find the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-111">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3091">The eigenvalues of <span class="process-math">\(A\)</span> are the solutions to the characteristic equation. Since</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(\lambda) = (-1-\lambda)(1-\lambda)(1-\lambda) = 0
\end{equation*}
</div>
<p class="continuation">implies <span class="process-math">\(\lambda = -1\)</span> or <span class="process-math">\(\lambda = 1\text{,}\)</span> the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1015"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3092">Find a basis for each eigenspace of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-112">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3093">To find a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{,}\)</span> we find a basis for <span class="process-math">\(\Nul (A-I_3)\text{.}\)</span> The reduced row echelon form of <span class="process-math">\(A - I_ 3 = \left[ \begin{array}{rcr} -2\amp 0\amp -2 \\ 2\amp 0\amp 2 \\ 0\amp 0\amp 0 \end{array} \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccc} 1\amp 0\amp 1 \\ 0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array} \right]\text{.}\)</span> If <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1\\x_2\\x_3 \end{array}  \right]\text{,}\)</span> then <span class="process-math">\((A-I_3)\vx = \vzero\)</span> has general solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = \left[ \begin{array}{c} x_1\\x_2\\x_3 \end{array}  \right] = \left[ \begin{array}{r} -x_3\\x_2\\x_3 \end{array}  \right] = x_2 \left[ \begin{array}{c} 0\\1\\0 \end{array}  \right] + x_3\left[ \begin{array}{r} -1\\0\\1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, <span class="process-math">\(\{[0 \ 1 \ 0]^{\tr}, [-1 \ 0 \ 1]^{\tr}\}\)</span> is a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{.}\)</span> To find a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(-1\text{,}\)</span> we find a basis for <span class="process-math">\(\Nul (A+I_3)\text{.}\)</span> The reduced row echelon form of <span class="process-math">\(A + I_ 3 = \left[ \begin{array}{ccr} 0\amp 0\amp -2 \\ 2\amp 2\amp 2 \\ 0\amp 0\amp 2 \end{array} \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccc} 1\amp 1\amp 0 \\ 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \end{array} \right]\text{.}\)</span> If <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1\\x_2\\x_3 \end{array}  \right]\text{,}\)</span> then <span class="process-math">\((A+I_3)\vx = \vzero\)</span> has general solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = \left[ \begin{array}{c} x_1\\x_2\\x_3 \end{array}  \right] = \left[ \begin{array}{r} -x_2\\x_2\\0 \end{array}  \right] = x_2 \left[ \begin{array}{r} -1\\1\\0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(-1\)</span> is <span class="process-math">\(\{[-1 \ 1 \ 0]^{\tr}\}\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1016"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3094">Is it possible to find a basis for <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{?}\)</span> Explain.</p>
<div class="solution solution-like" id="solution-113">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3095">Let <span class="process-math">\(\vv_1 = [0 \ 1 \ 0]^{\tr}, [-1 \ 0 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_2 = [-1 \ 0 \ 1]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vv_3 = [-1 \ 1 \ 0]^{\tr}\text{.}\)</span> Since eigenvectors corresponding to different eigenvalues are linearly independent, and since neither <span class="process-math">\(\vv_1\)</span> nor <span class="process-math">\(\vv_2\)</span> is a scalar multiple of the other, we can conclude that the set <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> is a linearly independent set with <span class="process-math">\(3 = \dim(\R^3)\)</span> vectors. Therefore, <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> is a basis for <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span></p>
</div></article></article><article class="example example-like" id="example-37"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">18.9</span><span class="period">.</span>
</h4>
<p id="p-3096">Find a <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(A\)</span> that has an eigenvector <span class="process-math">\(\vv_1 = [1 \ 0 \ 1]^{\tr}\)</span> with corresponding eigenvalue <span class="process-math">\(\lambda_1 = 2\text{,}\)</span> an eigenvector <span class="process-math">\(\vv_2 = [0 \ 2 \ -3]^{\tr}\)</span> with corresponding eigenvalue <span class="process-math">\(\lambda_2 = -3\text{,}\)</span> and an eigenvector <span class="process-math">\(\vv_3 = [-4 \ 0 \ 5]^{\tr}\)</span> with corresponding eigenvalue <span class="process-math">\(\lambda_3 = 5\text{.}\)</span> Explain your process.</p>
<div class="solution solution-like" id="solution-114">
<h4 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h4>
<p id="p-3097">We are looking for a <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(A \vv_1 = 2 \vv_1\text{,}\)</span> <span class="process-math">\(A \vv_2 = -3 \vv_2\)</span> and <span class="process-math">\(A \vv_3 = 5 \vv_3\text{.}\)</span> Since <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> are eigenvectors corresponding to different eigenvalues, <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> are linearly independent. So the matrix <span class="process-math">\([\vv_1 \ \vv_2 \ \vv_3]\)</span> is invertible. It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-127">
\begin{align*}
A[\vv_1 \ \vv_2 \ \vv_3] \amp = [A\vv_1 \ A\vv_2 \ A\vv_3]\\
A \left[\begin{array}{rcr} 1\amp 0\amp -4\\
0\amp 2\amp 0\\
1\amp -3\amp 5 \end{array} \right] \amp = [2\vv_1 \ -3\vv_2 \ 5\vv_3]\\
A \left[\begin{array}{crr} 1\amp 0\amp -4\\
0\amp 2\amp 0\\
1\amp -3\amp 5 \end{array} \right] \amp = \left[ \begin{array}{crr} 2\amp 0\amp -20\\
0\amp -6\amp 0\\
2\amp 9\amp 25 \end{array} \right]\\
A \amp =  \left[ \begin{array}{crr} 2\amp 0\amp -20\\
0\amp -6\amp 0\\
2\amp 9\amp 25 \end{array} \right] \left[\begin{array}{crr} 1\amp 0\amp -4\\
0\amp 2\amp 0\\
1\amp -3\amp 5 \end{array} \right]^{-1}\\
A \amp = \left[ \begin{array}{crr} 2\amp 0\amp -20\\
0\amp -6\amp 0\\
2\amp 9\amp 25 \end{array} \right]  \left[ \begin{array}{rcc} \frac{5}{9}\amp \frac{2}{3}\amp \frac{4}{9}\\
0\amp \frac{1}{2}\amp 0\\
-\frac{1}{9}\amp \frac{1}{6}\amp \frac{1}{9} \end{array} \right]\\
A \amp = \left[ \begin{array}{rrr} \frac{10}{3}\amp -2\amp -\frac{4}{3}\\
0\amp -3\amp 0\\
-\frac{5}{3}\amp 10\amp \frac{11}{3} \end{array} \right]\text{.}
\end{align*}
</div>
</div></article></section><section class="section" id="sec_chareq_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<p id="p-3098">In this section we studied the characteristic polynomial of a matrix and similar matrices.</p>
<ul class="disc">
<li id="li-552">
<p id="p-3099">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, the characteristic polynomial of <span class="process-math">\(A\)</span> is the polynomial</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A-\lambda I_n)\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix.</p>
</li>
<li id="li-553">
<p id="p-3100">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, the characteristic equation of <span class="process-math">\(A\)</span> is the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A-\lambda I_n) = 0\text{.}
\end{equation*}
</div>
</li>
<li id="li-554"><p id="p-3101">The characteristic equation of a square matrix provides us an algebraic method to find the eigenvalues of the matrix.</p></li>
<li id="li-555"><p id="p-3102">The eigenvalues of an upper or lower-triangular matrix are the entries on the diagonal.</p></li>
<li id="li-556"><p id="p-3103">There are at most <span class="process-math">\(n\)</span> eigenvalues of an <span class="process-math">\(n\times n\)</span> matrix.</p></li>
<li id="li-557"><p id="p-3104">For a real matrix <span class="process-math">\(A\text{,}\)</span> if an eigenvalue <span class="process-math">\(\lambda\)</span> of <span class="process-math">\(A\)</span> is complex, then the complex conjugate of <span class="process-math">\(\lambda\)</span> is also an eigenvalue.</p></li>
<li id="li-558"><p id="p-3105">The algebraic multiplicity of an eigenvalue <span class="process-math">\(\lambda\)</span> is the multiplicity of <span class="process-math">\(\lambda\)</span> as a root of the characteristic equation.</p></li>
<li id="li-559"><p id="p-3106">The dimension of the eigenspace corresponding to an eigenvalue <span class="process-math">\(\lambda\)</span> is less than or equal to the algebraic multiplicity of <span class="process-math">\(\lambda\text{.}\)</span></p></li>
</ul></section><section class="exercises" id="sec_chareq_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="ex_determinant_eigenvalues"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-285"><p id="p-3107">There is a useful relationship between the determinant and eigenvalues of a matrix <span class="process-math">\(A\)</span> that we explore in this exercise.</p></div>
<article class="task exercise-like" id="task-1017"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3108">Let <span class="process-math">\(B = \left[ \begin{array}{cc} 2\amp 3\\8\amp 4 \end{array} \right]\text{.}\)</span> Find the determinant of <span class="process-math">\(B\)</span> and the eigenvalues of <span class="process-math">\(B\text{,}\)</span> and compare <span class="process-math">\(\det(B)\)</span> to the eigenvalues of <span class="process-math">\(B\text{.}\)</span></p></article><article class="task exercise-like" id="task-1018"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-286"><p id="p-3110">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. In this part of the exercise we argue the general case illustrated in the previous part ‚Äî that <span class="process-math">\(\det(A)\)</span> is the product of the eigenvalues of <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(p(\lambda) = \det(A - \lambda I_n)\)</span> be the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1019"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3111">Let <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> be the eigenvalues of <span class="process-math">\(A\)</span> (note that these eigenvalues may not all be distinct). Recall that if <span class="process-math">\(r\)</span> is a root of a polynomial <span class="process-math">\(q(x)\text{,}\)</span> then <span class="process-math">\((x-r)\)</span> is a factor of <span class="process-math">\(q(x)\text{.}\)</span> Use this idea to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(\lambda) = (-1)^{n} (\lambda-\lambda_1)(\lambda- \lambda_2) \cdots (\lambda - \lambda_n)\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1020"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3113">Explain why <span class="process-math">\(p(0) = \lambda_1 \lambda_2 \cdots \lambda_n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1021"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3115">Why is <span class="process-math">\(p(0)\)</span> also equal to <span class="process-math">\(\det(A)\text{.}\)</span> Explain how we have shown that <span class="process-math">\(\det(A)\)</span> is the product of the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p></article></article></article><article class="exercise exercise-like" id="exercise-170"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-287"><p id="p-3117">Find the eigenvalues of the following matrices. For each eigenvalue, determine its algebraic and geometric multiplicity.</p></div>
<article class="task exercise-like" id="task-1022"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3118"><span class="process-math">\(A=\left[ \begin{array}{ccc} 1\amp 1\amp 1\\1\amp 1\amp 1\\1\amp 1\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1023"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3119"><span class="process-math">\(A=\left[ \begin{array}{ccc} 2\amp 0\amp 3\\0\amp 1\amp 0\\0\amp 1\amp 2 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-171"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-3120">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. Use the characteristic equation to explain why <span class="process-math">\(A\)</span> and <span class="process-math">\(A^\tr\)</span> have the same eigenvalues.</p></article><article class="exercise exercise-like" id="exercise-172"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-3122">Find three <span class="process-math">\(3 \times 3\)</span> matrices whose eigenvalues are 2 and 3, and for which the dimensions of the eigenspaces for <span class="process-math">\(\lambda=2\)</span> and <span class="process-math">\(\lambda=3\)</span> are different.</p></article><article class="exercise exercise-like" id="exercise-173"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-3123">Suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> matrix and <span class="process-math">\(B\)</span> is an invertible <span class="process-math">\(n\times n\)</span> matrix. Explain why the characteristic polynomial of <span class="process-math">\(A\)</span> is the same as the characteristic polynomial of <span class="process-math">\(BAB^{-1}\text{,}\)</span> and hence, as a result, the eigenvalues of <span class="process-math">\(A\)</span> and <span class="process-math">\(BAB^{-1}\)</span> are the same.</p></article><article class="exercise exercise-like" id="exercise-174"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-288"><p id="p-3125">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1024"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3126">If the determinant of a <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(A\)</span> is positive, then <span class="process-math">\(A\)</span> has two distinct real eigenvalues.</p></article><article class="task exercise-like" id="task-1025"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3128">If two <span class="process-math">\(2 \times 2\)</span> matrices have the same eigenvalues, then the have the same eigenvectors.</p></article><article class="task exercise-like" id="task-1026"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3129">The characteristic polynomial of an <span class="process-math">\(n \times n\)</span> matrix has degree <span class="process-math">\(n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1027"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3131">If <span class="process-math">\(R\)</span> is the reduced row echelon form of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(A\)</span> and <span class="process-math">\(R\)</span> have the same eigenvalues.</p></article><article class="task exercise-like" id="task-1028"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3132">If <span class="process-math">\(R\)</span> is the reduced row echelon form of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> and <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(R\text{.}\)</span></p></article><article class="task exercise-like" id="task-1029"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3134">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be <span class="process-math">\(n \times n\)</span> matrices with characteristic polynomials <span class="process-math">\(p_A(\lambda)\)</span> and <span class="process-math">\(p_B(\lambda)\text{,}\)</span> respectively. If <span class="process-math">\(A \neq B\text{,}\)</span> then <span class="process-math">\(p_A(\lambda) \neq p_B(\lambda)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1030"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3135">Every matrix has at least one eigenvalue.</p></article><article class="task exercise-like" id="task-1031"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3137">Suppose <span class="process-math">\(A\)</span> is a <span class="process-math">\(3 \times 3\)</span> matrix with three distinct eigenvalues. Then any three eigenvectors, one for each eigenvalue, will form a basis of <span class="process-math">\(\R^3\text{.}\)</span></p></article><article class="task exercise-like" id="task-1032"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3138">If an eigenvalue <span class="process-math">\(\lambda\)</span> is repeated 3 times among the eigenvalues of a matrix, then there are at most 3 linearly independent eigenvectors corresponding to <span class="process-math">\(\lambda\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_ehrenfest"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: The Ehrenfest Model</span>
</h3>
<p id="p-3140">To realistically model the diffusion of gas molecules we would need to consider a system with a large number of balls as substitutes for the gas molecules. However, the main idea can be seen in a model with a much smaller number of balls, as we will do now. Suppose we have two bins that contain a total of <span class="process-math">\(4\)</span> balls between them. Label the bins as Bin 1 and Bin 2. In this case we can think of entropy as the number of different possible ways the balls can be arranged in the system. For example, there is only <span class="process-math">\(1\)</span> way for all of the balls to be in Bin 1 (low entropy), but there are <span class="process-math">\(4\)</span> ways that we can have one ball in Bin 1 (choose any one of the four different balls, which can be distinguished from each other) and <span class="process-math">\(3\)</span> balls in Bin 2 (higher entropy). The highest entropy state has the balls equally distributed between the bins (with <span class="process-math">\(6\)</span> different ways to do this).</p>
<p id="p-3141">We assume that there is a way for balls to move from one bin to the other (like having gas molecules pass through a permeable membrane). A way to think about this is that we select a ball (from ball 1 to ball 4, which are different balls) and move that ball from its current bin to the other bin. Consider a ‚Äúmove‚Äù to be any instance when a ball changes bins. A <dfn class="terminology">state</dfn> is any configuration of balls in the bins at a given time, and the state changes when a ball is chosen at random and moved to the other bin. The possible states are to have 0 balls in Bin 1 and 4 balls in Bin 2 (State 0, entropy 1), 1 ball in Bin 1 and 3 in Bin 2 (State 1, entropy 4), 2 balls in each Bin (State 2, entropy 6), 3 balls in Bin 1 and 1 ball in Bin 2 (State 3, entropy 4), and 4 balls in Bin 1 and 0 balls in Bin 2 (State 4, entropy 1). These states are shown in <a href="" class="xref" data-knowl="./knowl/F_Ehrenfest.html" title="Figure 18.10">Figure¬†18.10</a>.</p>
<figure class="figure figure-like" id="F_Ehrenfest"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/4_b_states.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">18.10<span class="period">.</span></span><span class="space"> </span>States</figcaption></figure><article class="project project-like" id="act_Eherenfest_model"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">18.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-289">
<p id="p-3142">To model the system of balls in bins we need to understand how the system can transform from one state to another. It suffices to count the number of balls in Bin 1 (since the remaining balls will be in Bin 2). Even though the balls are labeled, our count only cares about how many balls are in each bin. Let <span class="process-math">\(\vx_0 = [x_0, x_1, x_2, x_3, x_4]^{\tr}\text{,}\)</span> where <span class="process-math">\(x_i\)</span> is the probability that Bin 1 contains <span class="process-math">\(i\)</span> balls, and let <span class="process-math">\(\vx_1 = \left[ x_0^1, x_1^1, x_2^1, x_3^1, x_4^1 \right]^{\tr}\text{,}\)</span> where <span class="process-math">\(x_i^1\)</span> is the probability that Bin 1 contains <span class="process-math">\(i\)</span> balls after the first move. We will call the vectors <span class="process-math">\(\vx_0\)</span> and <span class="process-math">\(\vx_1\)</span> <dfn class="terminology">probability distributions</dfn> of balls in bins. Note that since all four balls have to be placed in some bin, the sum of the entries in our probability distribution vectors must be <span class="process-math">\(1\text{.}\)</span> Recall that a move is an instance when a ball changes bins. We want to understand how <span class="process-math">\(\vx_1\)</span> is obtained from <span class="process-math">\(\vx_0\text{.}\)</span> In other words, we want to figure out what the probability that Bin 1 contains 0, 1, 2, 3, or 4 balls after one ball changes bins if our initial probability distribution of balls in bins is <span class="process-math">\(\vx_0\text{.}\)</span></p>
<p id="p-3143">We begin by analyzing the ways that a state can change. For example,</p>
<ul class="disc">
<li id="li-560"><p id="p-3144">Suppose there are <span class="process-math">\(0\)</span> balls in Bin 1. (In our probability distribution <span class="process-math">\(\vx_0\text{,}\)</span> this happens with probability <span class="process-math">\(x_0\text{.}\)</span>) Then there are four balls in Bin 2. The only way for a ball to change bins is if one of the four balls moves from Bin 2 to Bin 1, putting us in State 1. Regardless of which ball moves, we will always be put in State 1, so this happens with a probability of <span class="process-math">\(1\text{.}\)</span> In other words, if the probability that Bin 1 contains <span class="process-math">\(0\)</span> balls is <span class="process-math">\(x_0\text{,}\)</span> then there is a probability of <span class="process-math">\((1)x_0\)</span> that Bin 1 will contain 1 ball after the move.</p></li>
<li id="li-561">
<p id="p-3145">Suppose we have 1 ball in Bin 1. There are four ways this can happen (since there are four balls, and the one in Bin 1 is selected at random from the four balls), so the probability of a given ball being in Bin 1 is <span class="process-math">\(\frac{1}{4}\text{.}\)</span></p>
<ul class="circle">
<li id="li-562"><p id="p-3146">If the ball in Bin 1 moves, that move puts us in State <span class="process-math">\(0\text{.}\)</span> In other words, if the probability that Bin 1 contains 1 ball is <span class="process-math">\(x_1\text{,}\)</span> then there is a probability of <span class="process-math">\(\frac{1}{4}x_1\)</span> that Bin 1 will contain <span class="process-math">\(0\)</span> balls after a move.</p></li>
<li id="li-563"><p id="p-3147">If any of the <span class="process-math">\(3\)</span> balls in Bin 2 moves (each moves with probability <span class="process-math">\(\frac{3}{4}\)</span>), that move puts us in State 2. In other words, if the probability that Bin 1 contains 1 ball is <span class="process-math">\(x_1\text{,}\)</span> then there is a probability of <span class="process-math">\(\frac{3}{4}x_1\)</span> that Bin 1 will contain <span class="process-math">\(2\)</span> balls after a move.</p></li>
</ul>
</li>
</ul>
</div>
<article class="task exercise-like" id="task-1033"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3148">Complete this analysis to explain the probabilities if there are <span class="process-math">\(2\text{,}\)</span> <span class="process-math">\(3\text{,}\)</span> or <span class="process-math">\(4\)</span> balls in Bin 1.</p></article><article class="task exercise-like" id="task-1034"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3149">Explain how the results of part (a) show that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-128">
\begin{alignat*}{6}
{}x_0^1  \amp =  \amp {0}x_0   \amp {+}  \amp {\frac{1}{4}}x_1  \amp {+}  \amp {0}x_2  \amp {+} \amp {0}x_3 \amp {+} \amp {0}x_4\\
{}x_1^1  \amp =  \amp {1}x_0   \amp {+}  \amp {0}x_1  \amp {+}  \amp {\frac{1}{2}}x_2  \amp {+} \amp {0}x_3 \amp {+} \amp {0}x_4\\
{}x_2^1  \amp =  \amp {0}x_0   \amp {+}  \amp {\frac{3}{4}}x_1  \amp {+}  \amp {0}x_2  \amp {+} \amp {\frac{3}{4}}x_3 \amp {+} \amp {0}x_4\\
{}x_3^1  \amp =  \amp {0}x_0   \amp {+}  \amp {0}x_1  \amp {+}  \amp {\frac{1}{2}}x_2  \amp {+} \amp {0}x_3 \amp {+} \amp {1}x_4\\
{}x_4^1  \amp =  \amp {0}x_0   \amp {+}  \amp {0}x_1  \amp {+}  \amp {0}x_2  \amp {+} \amp {\frac{1}{4}}x_3 \amp {+} \amp {0}x_4
\end{alignat*}
</div></article></article><p id="p-3150">The system we developed in <a href="" class="xref" data-knowl="./knowl/act_Eherenfest_model.html" title="Project Activity 18.4">Project Activity¬†18.4</a> has matrix form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_Eherenfest_model.html">
\begin{equation*}
\vx_1 = T \vx_0\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(T\)</span> is the <dfn class="terminology">transition matrix</dfn></p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_Eherenfest_model.html">
\begin{equation*}
T = \left[  \begin{array}{ccccc} 0 \amp  \frac{1}{4}  \amp  0       \amp  0       \amp  0 \\ 1 \amp  0       \amp  \frac{1}{2}  \amp  0       \amp  0 \\ 0 \amp  \frac{3}{4} \amp  0       \amp  \frac{3}{4}   \amp  0 \\ 0 \amp  0       \amp  \frac{1}{2}   \amp  0       \amp  1 \\ 0 \amp  0       \amp  0       \amp  \frac{1}{4}  \amp  0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3151">Subsequent moves give probability distribution vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-129">
\begin{align*}
\vx_2 \amp = T\vx_1\\
\vx_3 \amp = T\vx_2\\
\vdots \amp   \vdots\\
\vx_k \amp = T\vx_{k-1} \text{.}
\end{align*}
</div>
<p id="p-3152">This example is an example of a Markov process (see <a href="" class="xref" data-knowl="./knowl/def_Markov.html" title="Definition 9.4">Definition¬†9.4</a>). There are several questions we can ask about this model. For example, what is the long-term behavior of this system, and how does this model relate to entropy? That is, given an initial probability distribution vector <span class="process-math">\(\vx_0\text{,}\)</span> the system will have probability distribution vectors <span class="process-math">\(\vx_1\text{,}\)</span> <span class="process-math">\(\vx_2\text{,}\)</span> <span class="process-math">\(\ldots\)</span> after subsequent moves. What happens to the vectors <span class="process-math">\(\vx_k\)</span> as <span class="process-math">\(k\)</span> goes to infinity, and what does this tell us about entropy? To answer these questions, we will first explore the sequence <span class="process-math">\(\{\vx_k\}\)</span> numerically, and then use the eigenvalues and eigenvectors of <span class="process-math">\(T\)</span> to analyze the sequence <span class="process-math">\(\{\vx_k\}\text{.}\)</span></p>
<article class="project project-like" id="act_Ehrenfest_numeric"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">18.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-290"><p id="p-3153">Use appropriate technology to do the following.</p></div>
<article class="task exercise-like" id="task-1035"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3154">Suppose we begin with a probability distribution vector <span class="process-math">\(\vx_0 = [1 \ 0 \ 0 \ 0 \ 0]^{\tr}\text{.}\)</span> Calculate vectors <span class="process-math">\(\vx_k\)</span> for enough values of <span class="process-math">\(k\)</span> so that you can identify the long term behavior of the sequence. Describe this behavior.</p></article><article class="task exercise-like" id="task-1036"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-291"><p id="p-3155">Repeat part (a) with</p></div>
<article class="task exercise-like" id="task-1037"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3156"><span class="process-math">\(\vx_0 = \left[0 \ \frac{1}{2} \ \frac{1}{2} \ 0 \ 0\right]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1038"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3157"><span class="process-math">\(\vx_0 = \left[0 \ \frac{1}{3} \ \frac{1}{3} \ 0 \ \frac{1}{3}\right]^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1039"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3158"><span class="process-math">\(\vx_0 = \left[\frac{1}{5} \ \frac{1}{5} \ \frac{1}{5} \ \frac{1}{5} \ \frac{1}{5}\right]^{\tr}\)</span></p></article></article></article><p id="p-3160">In what follows, we investigate the behavior of the sequence <span class="process-math">\(\{\vx_k\}\)</span> that we uncovered in <a href="" class="xref" data-knowl="./knowl/act_Ehrenfest_numeric.html" title="Project Activity 18.5">Project Activity¬†18.5</a>.</p>
<article class="project project-like" id="act_Ehrenfest_eigenvalues"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">18.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-292"><p id="p-3161">We use the characteristic polynomial to find the eigenvalues of <span class="process-math">\(T\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1040"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3162">Find the characteristic polynomial of <span class="process-math">\(T\text{.}\)</span> Factor the characteristic polynomial into a product of linear polynomials to show that the eigenvalues of <span class="process-math">\(T\)</span> are <span class="process-math">\(0\text{,}\)</span> <span class="process-math">\(1\text{,}\)</span> <span class="process-math">\(-1\text{,}\)</span> <span class="process-math">\(\frac{1}{2}\)</span> and <span class="process-math">\(-\frac{1}{2}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1041"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3163">As we will see a bit later, certain eigenvectors for <span class="process-math">\(T\)</span> will describe the end behavior of the sequence <span class="process-math">\(\{\vx_k\}\text{.}\)</span> Find eigenvectors for <span class="process-math">\(T\)</span> corresponding to the eigenvalues <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{.}\)</span> Explain how the eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(1\)</span> explains the behavior of one of the sequences was saw in <a href="" class="xref" data-knowl="./knowl/act_Ehrenfest_numeric.html" title="Project Activity 18.5">Project Activity¬†18.5</a>. (Any eigenvector of <span class="process-math">\(T\)</span> with eigenvalue <span class="process-math">\(1\)</span> is called an <em class="emphasis">equilibrium</em> or <em class="emphasis">steady state</em> vector.)</p></article></article><p id="p-3164">Now we can analyze the behavior of the sequence <span class="process-math">\(\{\vx_k\}\text{.}\)</span></p>
<article class="project project-like" id="act_Ehrenfest_basis"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">18.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-293"><p id="p-3165">To make the notation easier, we will let <span class="process-math">\(\vv_1\)</span> be an eigenvector of <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(0\text{,}\)</span> <span class="process-math">\(\vv_2\)</span> an eigenvector of <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{,}\)</span> <span class="process-math">\(\vv_3\)</span> an eigenvector of <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(-1\text{,}\)</span> <span class="process-math">\(\vv_4\)</span> an eigenvector of <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(\frac{1}{2}\text{,}\)</span> and <span class="process-math">\(\vv_5\)</span> an eigenvector of <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(-\frac{1}{2}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1042"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3166">Explain why <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \vv_4, \vv_5\}\)</span> is a basis of <span class="process-math">\(\R^5\text{.}\)</span></p></article><article class="task exercise-like" id="task-1043"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3167">Let <span class="process-math">\(\vx_0\)</span> be any initial probability distribution vector. Explain why we can write <span class="process-math">\(\vx_0\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_0 = a_1 \vv_1 + a_2 \vv_2 + a_3 \vv_3 + a_4 \vv_4 + a_5 \vv_5 = \sum_{i=1}^5 a_i \vv_i
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(a_1\text{,}\)</span> <span class="process-math">\(a_2\text{,}\)</span> <span class="process-math">\(a_3\text{,}\)</span> <span class="process-math">\(a_4\text{,}\)</span> and <span class="process-math">\(a_5\text{.}\)</span></p></article></article><p id="p-3168">We can now use the eigenvalues and eigenvectors of <span class="process-math">\(T\)</span> to write the vectors <span class="process-math">\(\vx_k\)</span> in a convenient form. Let <span class="process-math">\(\lambda_1 = 0\text{,}\)</span> <span class="process-math">\(\lambda_2=1\text{,}\)</span> <span class="process-math">\(\lambda_3=-1\text{,}\)</span> <span class="process-math">\(\lambda_4=\frac{1}{2}\text{,}\)</span> and <span class="process-math">\(\lambda_5=-\frac{1}{2}\text{.}\)</span> Notice that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-130">
\begin{align*}
\vx_1 \amp = T \vx_0\\
\amp = T(a_1  \vv_1 + a_2 \vv_2 + a_3  \vv_3 + a_4  \vv_4 + a_5 \vv_5)\\
\amp = a_1  T\vv_1 + a_2 T\vv_2 + a_3  T\vv_3 + a_4 T\vv_4 + a_5 T\vv_5\\
\amp = a_1\lambda_1 \vv_1 + a_2\lambda_2 \vv_2 + a_3 \lambda_3 \vv_3 + a_4 \lambda_4 \vv_4 + a_5 \lambda_5 \vv_5\\
\amp = \sum_{i=1}^5 a_i \lambda_i \vv_i\text{.}
\end{align*}
</div>
<p id="p-3169">Similarly</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_2 = T \vx_1 = T\left(\sum_{i=1}^5 a_i \lambda_i\vv_i\right) = \sum_{i=1}^5 a_i \lambda_i T\vv_i = \sum_{i=1}^5 a_i\lambda_i^2 \vv_i\text{.}
\end{equation*}
</div>
<p id="p-3170">We can continue in this manner to ultimately show that for each positive integer <span class="process-math">\(k\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Ehrenfest_sum">
\begin{equation}
\vx_k = \sum_{i=1}^5 a_i\lambda_i^k \vv_i\tag{18.4}
\end{equation}
</div>
<p class="continuation">when <span class="process-math">\(\vx_0 = \sum_{i=1}^5 a_i \vv_i\text{.}\)</span></p>
<article class="project project-like" id="act_Ehrenfest_entropy"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">18.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-294"><p id="p-3171">Recall that we are interested in understanding the behavior of the sequence <span class="process-math">\(\{\vx_k\}\)</span> as <span class="process-math">\(k\)</span> goes to infinity.</p></div>
<article class="task exercise-like" id="task-1044"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3172">Equation <a href="" class="xref" data-knowl="./knowl/eq_Ehrenfest_sum.html" title="Equation 18.4">(18.4)</a> shows that we need to know <span class="process-math">\(\lim_{k \to \infty} \lambda_i^k\)</span> for each <span class="process-math">\(i\)</span> in order to analyze <span class="process-math">\(\lim_{k \to \infty} \vx_k\text{.}\)</span> Calculate or describe these limits.</p></article><article class="task exercise-like" id="task-1045"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3173">Use the result of part (a), Equation <a href="" class="xref" data-knowl="./knowl/eq_Ehrenfest_sum.html" title="Equation 18.4">(18.4)</a>, and <a href="" class="xref" data-knowl="./knowl/act_Ehrenfest_eigenvalues.html" title="Project Activity 18.6">Project Activity¬†18.6</a> (b) to explain why the sequence <span class="process-math">\(\{\vx_k\}\)</span> is either eventually fixed or oscillates between two states. Compare to the results from <a href="" class="xref" data-knowl="./knowl/act_Ehrenfest_numeric.html" title="Project Activity 18.5">Project Activity¬†18.5</a>. How are these results related to entropy? You may use the facts that</p>
<ul class="disc">
<li id="li-564"><p id="p-3174"><span class="process-math">\(\vv_1 = [1 \ 0 \ -2 \ 0 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(0\text{,}\)</span></p></li>
<li id="li-565"><p id="p-3175"><span class="process-math">\(\vv_2 = [1 \ 4 \ 6 \ 4 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{,}\)</span></p></li>
<li id="li-566"><p id="p-3176"><span class="process-math">\(\vv_3 = [1 \ -4 \ 6 \ -4 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(-1\text{,}\)</span></p></li>
<li id="li-567"><p id="p-3177"><span class="process-math">\(\vv_4 = [-1 \ -2 \ 0\ 2 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(\frac{1}{2}\text{,}\)</span></p></li>
<li id="li-568"><p id="p-3178"><span class="process-math">\(\vv_5 = [-1 \ 2 \ 0 \ -2 \ 1]^{\tr}\)</span> is an eigenvector for <span class="process-math">\(T\)</span> corresponding to the eigenvalue <span class="process-math">\(-\frac{1}{2}\text{.}\)</span></p></li>
</ul></article></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-34"><div class="fn">named after Paul and Tatiana Ehrenfest who introduced it in ‚Äú√úber zwei bekannte Einw√§nde gegen das Boltzmannsche H-Theorem,‚Äù <span class="booktitle">Physikalishce Zeitschrift</span>, vol. 8 (1907), pp. 311-314)</div></div>
</div></main>
</div>
</body>
</html>
