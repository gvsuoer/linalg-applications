<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-23T15:00:21-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Bases for Vector Spaces</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_vector_spaces.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-vec-spaces.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_dimension.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_vector_spaces.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-vec-spaces.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_dimension.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_bases"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span>
</h2>
<section class="introduction" id="introduction-544"><article class="objectives goal-like" id="objectives-32"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-545"><p id="p-5552">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-849"><p id="p-5553">What does it mean for a set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> to be linearly independent?</p></li>
<li id="li-850"><p id="p-5554">What is another equivalent characterization of a linearly independent set?</p></li>
<li id="li-851"><p id="p-5555">What does is mean for a set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> to be linearly dependent?</p></li>
<li id="li-852"><p id="p-5556">Describe another characterization of a linearly dependent set.</p></li>
<li id="li-853"><p id="p-5557">What is a basis for a vector space <span class="process-math">\(V\text{?}\)</span></p></li>
<li id="li-854"><p id="p-5558">What makes a basis for a vector space useful?</p></li>
<li id="li-855"><p id="p-5559">How can we find a basis for a vector space <span class="process-math">\(V\text{?}\)</span></p></li>
</ul></article></section><section class="section" id="sec_img_compress"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: Image Compression</span>
</h3>
<blockquote class="blockquote" id="blockquote-21">
<p id="p-5560">If you painted a picture with a sky, clouds, trees, and flowers, you would use a different size brush depending on the size of the features. Wavelets are like those brushes.</p>
<cite class="attribution">―Ingrid Daubechies</cite>
</blockquote>
<p id="p-5561">The advent of the digital age has presented many new opportunities for the collection, analysis, and dissemination of information. Along with these opportunities come new difficulties as well. All of this digital information must be stored in some way and be retrievable in an efficient manner. One collection of tools that is used to deal with these problems is wavelets. For example, the FBI fingerprint files contain millions of cards, each of which contains 10 rolled fingerprint impressions. Each card produces about 10 megabytes of data. To store all of these cards would require an enormous amount of space, and transmitting one full card over existing data lines is slow and inefficient. Without some sort of image compression, a sortable and searchable electronic fingerprint database would be next to impossible. To deal with this problem, the FBI adopted standards for fingerprint digitization using a wavelet compression standard.</p>
<p id="p-5562">Another problem with electronics is noise. Noise can be a big problem when collecting and transmitting data. Wavelet decomposition filters data by averaging and detailing. The detailing coefficients indicate where the details are in the original data set. If some details are very small in relation to others, eliminating them may not substantially alter the original data set. Similar ideas may be used to restore damaged audio,<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-58" id="fn-58"><sup> 58 </sup></a> video, photographs, and medical information.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-59" id="fn-59"><sup> 59 </sup></a></p>
<p id="p-5563">We will consider wavelets as a tool for image compression. The basic idea behind using wavelets to compress images is that we start with a digital image, made up of pixels. Each pixel can be assigned a number or a vector (depending on the makeup of the image). The image can then be represented as a matrix (or a set of matrices) <span class="process-math">\(M\text{,}\)</span> where each entry in <span class="process-math">\(M\)</span> represents a pixel in the image. As a simple example, consider the <span class="process-math">\(16 \times 16\)</span> image of a flower as shown at left in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a>. (We will work with small images like this to make the calculations more manageable, but the ideas work for any size image. We could also extend our methods to consider color images, but for the sake of simplicity we focus on grayscale.)</p>
<figure class="figure figure-like" id="F_Flower_1"><div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/flower.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/flower_2.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">32.1<span class="period">.</span></span><span class="space"> </span>Left: A 16 by 16 pixel image. Right: The image compressed.</figcaption></figure><p id="p-5564">This flower image is a gray-scale image, so each pixel has a numeric representation between 0 and 255, where 0 is black, 255 is white, and numbers between 0 and 255 represent shades of gray. The matrix for this flower image is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_flower_image_matrix">
\begin{equation}
\left[ {\scriptsize \begin{array}{cccccccccccccccc} 240\amp 240\amp 240\amp 240\amp 130\amp 130\amp 240\amp 130\amp 130\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\\240\amp 240\amp 240\amp 130 \amp 175\amp 175\amp 130\amp 175\amp 175\amp 130\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\\ 240\amp 240\amp 130\amp 130\amp 175\amp 175\amp 130\amp 175\amp 175\amp 130\amp 130\amp 240\amp 240\amp 240\amp 240\amp 240 \\240\amp 130\amp 175\amp 175\amp 130\amp 175\amp 175\amp 175\amp 130\amp 175\amp 175\amp 130\amp 240\amp 240\amp 240\amp 240\\240\amp 240\amp 130\amp 175\amp 175\amp 130\amp 175\amp 130\amp 175 \amp 175\amp 130\amp 240\amp 240\amp 240\amp 240\amp 240\\255\amp 240\amp 240\amp 130\amp 130\amp 175\amp 175\amp 175\amp 130\amp 130\amp 240\amp 240\amp 225\amp 240\amp 240\amp 240\\240\amp 240 \amp 130\amp 175\amp 175\amp 130\amp 130\amp 130\amp 175\amp 175\amp 130\amp 240\amp 225\amp 255\amp 240\amp 240 \\240\amp 240\amp 130\amp 175\amp 130\amp 240\amp 130\amp 240\amp 130\amp 175\amp 130\amp 240\amp 255\amp 255\amp 255\amp 240\\240\amp 240\amp 240\amp 130\amp 240\amp 240\amp 75\amp 240\amp 240\amp 130\amp 240\amp 255\amp 255\amp 255\amp 255\amp 255\\240\amp 240\amp 240\amp 240\amp 240\amp 240 \amp 75\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\\240\amp 240\amp 240 \amp 75\amp 75\amp 240\amp 75\amp 240\amp 75\amp 75\amp 240\amp 240\amp 240\amp 240\amp 240\amp 240\\50\amp 240\amp 240\amp 240\amp 75\amp 240\amp 75\amp 240\amp 75\amp 240\amp 240\amp 240\amp 240\amp 50\amp 240\amp 240 \\240\amp 75\amp 240\amp 240\amp 240\amp 75\amp 75\amp 75\amp 240\amp 240\amp 50\amp 240\amp 50\amp 240\amp 240\amp 50\\240\amp 240\amp 75\amp 240\amp 240\amp 240\amp 75\amp 240\amp 240\amp 50\amp 240\amp 50\amp 240\amp 240\amp 50\amp 240\\75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\\75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75\amp 75 \end{array}  }\right]\text{.}\tag{32.1}
\end{equation}
</div>
<p id="p-5565">Now we can apply wavelets to the image and compress it. Essentially, wavelets act by averaging and differencing. The averaging creates smaller versions of the image and the differencing keeps track of how far the smaller version is from a previous copy. The differencing often produces many small (close to 0) entries, and so replacing these entries with 0 doesn't have much effect on the image (this is called <em class="emphasis">thresholding</em>). By introducing long strings of zeros into our data, we are able to store a (compressed) copy of the image in a smaller amount of space. For example, using a threshold value of 10 produces the flower image shown at right in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a>.</p>
<p id="p-5566">The averaging and differencing is done with special vectors (wavelets) that form a basis for a suitable function space. More details of this process can be found at the end of this section.</p></section><section class="section" id="sec_bases_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-5567">In <span class="process-math">\(\R^n\)</span> we defined a basis for a subspace <span class="process-math">\(W\)</span> of <span class="process-math">\(\R^n\)</span> to be a minimal spanning set for <span class="process-math">\(W\text{,}\)</span> or a linearly independent spanning set (see <a href="" class="xref" data-knowl="./knowl/def_1_f_basis.html" title="Definition 6.8">Definition 6.8</a>). So to consider the idea of a basis in a vector space, we will need the notion of linear independence in that context.</p>
<p id="p-5568">Since we can add vectors and multiply vectors by scalars in any vector space, and because we have a zero vector in any vector space, we can define linear independence of a finite set of vectors in any vector space as follows (compare to <a href="" class="xref" data-knowl="./knowl/def_linear_independence_Rn.html" title="Definition 6.2">Definition 6.2</a>).</p>
<article class="definition definition-like" id="def_vs_linear_independence"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">32.2</span><span class="period">.</span>
</h4>
<p id="p-5569">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is <dfn class="terminology">linearly independent</dfn> if the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero
\end{equation*}
</div>
<p class="continuation">for scalars <span class="process-math">\(x_1, x_2, \ldots,
x_k\)</span> has only the trivial solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 = x_2 = x_3 = \cdots = x_k = 0\text{.}
\end{equation*}
</div>
<p id="p-5570">If a set of vectors is not linearly independent, then the set is <dfn class="terminology">linearly dependent</dfn>.</p></article><p id="p-5571">Alternatively, we say that the vectors <span class="process-math">\(\vv_1, \vv_2, \ldots, \vv_k\)</span> are linearly independent (or dependent) if the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> is linearly independent (or dependent).</p>
<article class="exploration project-like" id="pa_5_b"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">32.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1872"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-546">
<p id="p-5572">We can use the tools we developed to determine if a set of vectors in <span class="process-math">\(\R^n\)</span> is linearly independent to answer the same questions for sets of vectors in other vector spaces. For example, consider the question of whether the set <span class="process-math">\(\{1+t, 1-t\}\)</span> in <span class="process-math">\(\pol_1\)</span> is linearly independent or dependent. To answer this question we need to determine if there is a non-trivial solution to the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA_5_b_1.html" id="eq_PA_5_b_1">
\begin{equation}
x_1 (1+t) + x_2(1-t) = 0\text{.}\tag{32.2}
\end{equation}
</div>
<p class="continuation">Note that equation <a href="" class="xref" data-knowl="./knowl/eq_PA_5_b_1.html" title="Equation 32.2">(32.2)</a> can also be written in the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA_5_b_1.html">
\begin{equation*}
(x_1+x_2) + (x_1-x_2)t = 0\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-1873"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-5573">Recall that two polynomials are equal if all coefficients of like powers are the same. By equating coefficients of like power terms, rewrite equation <a href="" class="xref" data-knowl="./knowl/eq_PA_5_b_1.html" title="Equation 32.2">(32.2)</a> as an equivalent system of two equations in the two unknowns <span class="process-math">\(x_1\)</span> and <span class="process-math">\(x_2\text{,}\)</span> and solve for <span class="process-math">\(x_1, x_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-1874"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-5574">What does your answer to the previous part tell you about the linear independence or dependence of the set <span class="process-math">\(\{1+t, 1-t\}\)</span> in <span class="process-math">\(\pol_1\text{?}\)</span></p></article><article class="task exercise-like" id="task-1875"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-5575">Recall that in <span class="process-math">\(\R^n\text{,}\)</span> a set of two vectors is linearly dependent if and only if one of the vectors in the set is a scalar multiple of the other and linearly independent if neither vector is a scalar multiple of the other. Verify your answer to part (c) from a similar perspective in <span class="process-math">\(\pol_1\text{.}\)</span></p></article></article><article class="task exercise-like" id="task-1876"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-547">
<p id="p-5576">We can use the same type of method as in problem (1) to address the question of whether the set</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA_5_b_2.html">
\begin{equation*}
\left\{ \left[ \begin{array}{cc} 1\amp 3 \\ 1\amp 2 \end{array}  \right], \left[ \begin{array}{cr} 1\amp -9 \\ 1\amp 8 \end{array}  \right], \left[ \begin{array}{cr} 1\amp -1 \\ 1\amp 4 \end{array}  \right] \right\}
\end{equation*}
</div>
<p class="continuation">is linearly independent or dependent in <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span> To answer this question we need to determine if there is a non-trivial solution to the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA_5_b_2.html" id="eq_PA_5_b_2">
\begin{equation}
x_1\left[ \begin{array}{cc} 1\amp 3 \\ 1\amp 2 \end{array}  \right] + x_2\left[ \begin{array}{cr} 1\amp -9 \\ 1\amp 8 \end{array}  \right] + x_3 \left[ \begin{array}{cr} 1\amp -1 \\ 1\amp 4 \end{array}  \right] = \vzero\tag{32.3}
\end{equation}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> and <span class="process-math">\(x_3\text{.}\)</span> Note that the linear combination on the left side of equation <a href="" class="xref" data-knowl="./knowl/eq_PA_5_b_2.html" title="Equation 32.3">(32.3)</a> has entries</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA_5_b_2.html">
\begin{equation*}
\left[ \begin{array}{cc} x_1+x_2+x_3\amp 3x_1-9x_2-x_3 \\ x_1+x_2+x_3\amp 2x_1+8x_2+4x_3 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-1877"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-5577">Recall that two matrices are equal if all corresponding entries are the same. Equate corresponding entries of the matrices in equation <a href="" class="xref" data-knowl="./knowl/eq_PA_5_b_2.html" title="Equation 32.3">(32.3)</a> to rewrite the equation as an equivalent system of four equations in the three unknowns <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> and <span class="process-math">\(x_3\text{.}\)</span></p></article><article class="task exercise-like" id="task-1878"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-5578">Use appropriate matrix tools and techniques to find all solutions to the system from part (a).</p></article><article class="task exercise-like" id="task-1879"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-5579">What does the set of solutions to the system from part (a) tell you about the linear independence or dependence of the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ \begin{array}{cc} 1\amp 3 \\ 1\amp 2 \end{array}  \right], \left[ \begin{array}{cr} 1\amp -9 \\ 1\amp 8 \end{array}  \right], \left[ \begin{array}{cr} 1\amp -1 \\ 1\amp 4 \end{array}  \right] \right\}?
\end{equation*}
</div></article><article class="task exercise-like" id="task-1880"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-5580">Recall that in <span class="process-math">\(\R^n\text{,}\)</span> a set of vectors is linearly dependent if and only if one of the vectors in the set is a linear combination of the others and linearly independent if no vector in the set is a linear combination of the others. Verify your answer to part (c) from a similar perspective in <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span></p></article></article><article class="task exercise-like" id="task-1881"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5581">We will define a basis for a vector space to be a linearly independent spanning set. Which, if any, of the sets in parts (1) and (2) is a basis for its vector space? Explain.</p></article></article></section><section class="section" id="sec_lin_indep"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Linear Independence</span>
</h3>
<p id="p-5582">The concept of linear independence, which we formally defined in <a href="" class="xref" data-knowl="./knowl/pa_5_b.html" title="Preview Activity 32.1">Preview Activity 32.1</a>, provides us with a process to determine if there is redundancy in a spanning set to obtain an efficient spanning set.</p>
<p id="p-5583">The definition tells us that a set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly dependent if there are scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_n\text{,}\)</span> not all of which are 0 so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero\text{.}
\end{equation*}
</div>
<p id="p-5584">As examples, we saw in <a href="" class="xref" data-knowl="./knowl/pa_5_b.html" title="Preview Activity 32.1">Preview Activity 32.1</a> that the set <span class="process-math">\(\{1+t, 1-t\}\)</span> is linearly independent in <span class="process-math">\(\pol_1\text{.}\)</span> The set <span class="process-math">\(\{1+t, -1+2t+t^2, 1-8t-3t^2\}\text{,}\)</span> on the other hand, is linearly dependent in <span class="process-math">\(\pol_2\)</span> since <span class="process-math">\(2(1+t) + 3(-1+2t+t^2) + (1-8t-3t^2) = 0\text{.}\)</span></p>
<p id="p-5585">In addition to the definition, there are other ways to characterize linearly independent and dependent sets in vector spaces as the next theorems illustrate. These characterizations are the same as those we saw in <span class="process-math">\(\R^n\text{,}\)</span> and the proofs are essentially the same as well. The proof of <a href="" class="xref" data-knowl="./knowl/thm_5_b_1.html" title="Theorem 32.3">Theorem 32.3</a> is similar to that of <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a> and is left for the exercises.</p>
<article class="theorem theorem-like" id="thm_5_b_1"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">32.3</span><span class="period">.</span>
</h4>
<p id="p-5586">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly dependent if and only if at least one of the vectors in the set can be written as a linear combination of the remaining vectors in the set.</p></article><p id="p-5587"><a href="" class="xref" data-knowl="./knowl/thm_5_b_1.html" title="Theorem 32.3">Theorem 32.3</a> is equivalent to the following theorem that provides the corresponding result for linearly independent sets.</p>
<article class="theorem theorem-like" id="thm_5_b_2"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">32.4</span><span class="period">.</span>
</h4>
<p id="p-5588">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly independent if and only if no vector in the set can be written as a linear combination of the remaining vectors in the set.</p></article><p id="p-5589">One consequence of <a href="" class="xref" data-knowl="./knowl/thm_5_b_1.html" title="Theorem 32.3">Theorem 32.3</a> and <a href="" class="xref" data-knowl="./knowl/thm_5_b_2.html" title="Theorem 32.4">Theorem 32.4</a> is that if a spanning set is linearly dependent, then one of the vectors in the set can be written as a linear combination of the others. In other words, at least one of the vectors is redundant. In that case, we can find a smaller spanning set as the next theorem states. The proof of this theorem is similar to that of <a href="" class="xref" data-knowl="./knowl/thm_minimal_spanning_set.html" title="Theorem 6.7">Theorem 6.7</a> and is left for the exercises.</p>
<article class="theorem theorem-like" id="thm_5_b_3"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">32.5</span><span class="period">.</span>
</h4>
<p id="p-5590">Let <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> be a set of vectors in a vector space <span class="process-math">\(V\text{.}\)</span> If for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{,}\)</span> <span class="process-math">\(\vv_i\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span\{\vv_1, \vv_2, \ldots, \vv_k\} = \Span\{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{.}
\end{equation*}
</div></article></section><section class="section" id="sec_bases"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Bases</span>
</h3>
<p id="p-5591">A basis for a vector space is a spanning set that is as small as it can be. We already saw how to define bases formally in <span class="process-math">\(\R^n\text{.}\)</span> We will now formally define a basis for a vector space and understand why with this definition a basis is a minimal spanning set. Bases are important because any vector in a vector space can be uniquely represented as a linear combination of basis vectors. We will see in later sections that this representation will allow us to identify any vector space with a basis of <span class="process-math">\(n\)</span> vectors with <span class="process-math">\(\R^n\text{.}\)</span></p>
<p id="p-5592">To obtain the formal definition of a basis, which is a minimal spanning set, we consider what additional property makes a spanning set a <dfn class="terminology">minimal</dfn> spanning set. As a consequence of <a href="" class="xref" data-knowl="./knowl/thm_5_b_3.html" title="Theorem 32.5">Theorem 32.5</a>, if <span class="process-math">\(S\)</span> is a spanning set that is linearly dependent, then we can find a proper subset of <span class="process-math">\(S\)</span> that has the same span. Thus, the set <span class="process-math">\(S\)</span> cannot be a minimal spanning set. However, if <span class="process-math">\(S\)</span> is linearly independent, then no vector in <span class="process-math">\(S\)</span> is a linear combination of the others and we need all of the vectors in <span class="process-math">\(S\)</span> to form the span. This leads us to the following formal characterization of a minimal spanning set, called a <dfn class="terminology">basis</dfn>.</p>
<article class="definition definition-like" id="definition-73"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">32.6</span><span class="period">.</span>
</h4>
<p id="p-5593">A <dfn class="terminology">basis</dfn> for a vector space <span class="process-math">\(V\)</span> is a subset <span class="process-math">\(S\)</span> of <span class="process-math">\(V\)</span> if</p>
<ol class="decimal">
<li id="li-856"><p id="p-5594"><span class="process-math">\(\Span \ S = V\)</span> and</p></li>
<li id="li-857"><p id="p-5595"><span class="process-math">\(S\)</span> is a linearly independent set.</p></li>
</ol></article><p id="p-5596">In other words, a basis for a vector space <span class="process-math">\(V\)</span> is a linearly independent spanning set for <span class="process-math">\(V\text{.}\)</span> To put it another way, a basis for a vector space is a minimal spanning set for the vector space. Similar reasoning will show that a basis is also a maximal linearly independent set.</p>
<p id="p-5597">The key ideas to take from the previous theorems are:</p>
<ul class="disc">
<li id="li-858"><p id="p-5598">A basis for a vector space <span class="process-math">\(V\)</span> is a minimal spanning set for <span class="process-math">\(V\text{.}\)</span></p></li>
<li id="li-859">
<p id="p-5599">A basis for <span class="process-math">\(V\)</span> is a subset <span class="process-math">\(S\)</span> of <span class="process-math">\(V\)</span> so that</p>
<ol class="decimal">
<li id="li-860"><p id="p-5600"><span class="process-math">\(S\)</span> spans <span class="process-math">\(V\)</span> and</p></li>
<li id="li-861"><p id="p-5601"><span class="process-math">\(S\)</span> is linearly independent.</p></li>
</ol>
</li>
<li id="li-862"><p id="p-5602">No vector in a basis can be written as a linear combination of the other vectors in the basis.</p></li>
<li id="li-863"><p id="p-5603">If a subset <span class="process-math">\(S\)</span> of a vector space <span class="process-math">\(V\)</span> has the property that one of the vectors in <span class="process-math">\(S\)</span> is a linear combination of the other vectors in <span class="process-math">\(S\text{,}\)</span> then <span class="process-math">\(S\)</span> is not a basis for <span class="process-math">\(V\text{.}\)</span></p></li>
</ul>
<p id="p-5604">As an example of a basis of a vector space, we saw in <a href="" class="xref" data-knowl="./knowl/pa_5_b.html" title="Preview Activity 32.1">Preview Activity 32.1</a> that the set <span class="process-math">\(S = \{1-t, 1+t\}\)</span> is both linearly independent and spans <span class="process-math">\(\pol_1\text{,}\)</span> and so <span class="process-math">\(S\)</span> is a basis for <span class="process-math">\(\pol_1\text{.}\)</span></p>
<article class="activity project-like" id="act_5_b_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">32.2</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1882"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5605">Is <span class="process-math">\(S = \{1+t, t, 1-t\}\)</span> a basis for <span class="process-math">\(\pol_1\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-1883"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5606">Explain why the set <span class="process-math">\(S = \{1, t, t^2, \ldots,
t^n\}\)</span> is a basis for <span class="process-math">\(\pol_n\text{.}\)</span> This basis is called the <dfn class="terminology">standard basis</dfn> for <span class="process-math">\(\pol_n\text{.}\)</span></p></article><article class="task exercise-like" id="task-1884"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5607">Show that the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ \begin{array}{cc} 1\amp 0 \\ 1\amp 1 \end{array}  \right], \left[ \begin{array}{cc} 0\amp 1 \\ 1\amp 1 \end{array}  \right], \left[ \begin{array}{cc} 1\amp 1 \\ 1\amp 0 \end{array}  \right], \left[ \begin{array}{cc} 1\amp 1 \\ 0\amp 1 \end{array}  \right] \right\}
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span></p></article></article><p id="p-5608">It should be noted that not every vector space has a finite basis. For example, the space <span class="process-math">\(\pol\)</span> of all polynomials with real coefficients (of any degree) is a vector space, but no finite set of vectors will span <span class="process-math">\(\pol\text{.}\)</span> In fact, the infinite set <span class="process-math">\(\{1, t, t^2, \ldots\}\)</span> is both linearly independent and spans <span class="process-math">\(\pol\text{,}\)</span> so <span class="process-math">\(\pol\)</span> has an infinite basis.</p></section><section class="section" id="sec_basis_vec_space"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Finding a Basis for a Vector Space</span>
</h3>
<p id="p-5609">We already know how to find bases for certain vector spaces, namely <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\text{,}\)</span> where <span class="process-math">\(A\)</span> is any matrix. Finding a basis for a different kind of vector space will require other methods. Since a basis for a vector space is a minimal spanning set, to find a basis for a given vector space we might begin from scratch, starting with a given vector in the space and adding one vector at a time until we have a spanning set.</p>
<article class="activity project-like" id="act_5_b_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">32.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-548"><p id="p-5610">Let <span class="process-math">\(W = \{a + bt + ct^3 \mid a, b, c \text{ are scalars } \}\text{.}\)</span> We will find a basis of <span class="process-math">\(W\)</span> that contains the polynomial <span class="process-math">\(3+t-t^3\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1885"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5611">Let <span class="process-math">\(\CS_1 = \{3+t-t^3\}\text{.}\)</span> Find a polynomial <span class="process-math">\(p(t)\)</span> in <span class="process-math">\(W\)</span> that is not in <span class="process-math">\(\Span \ \CS_1\text{.}\)</span> Explain why this means that the set <span class="process-math">\(\CS_1\)</span> does not span <span class="process-math">\(W\text{.}\)</span></p></article><article class="task exercise-like" id="task-1886"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5612">Let <span class="process-math">\(\CS_2 = \{3+t-t^3, p(t)\}\text{.}\)</span> Find a polynomial <span class="process-math">\(q(t)\)</span> that is not in <span class="process-math">\(\Span \ \CS_2\text{.}\)</span> What does this mean about <span class="process-math">\(\CS_2\)</span> being a possible spanning set of <span class="process-math">\(W\text{?}\)</span></p></article><article class="task exercise-like" id="task-1887"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5613">Let <span class="process-math">\(\CS_3 = \{3+t-t^3, p(t), q(t)\}\text{.}\)</span> Explain why the set <span class="process-math">\(\CS_3\)</span> is a basis for <span class="process-math">\(W\text{.}\)</span></p></article></article><p id="p-5614">Alternatively, we might construct a basis from a known spanning set.</p>
<article class="activity project-like" id="act_5_b_2_b"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">32.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-549"><p id="p-5615">Let <span class="process-math">\(W = \left\{\left[ \begin{array}{cc} v+z\amp w+z \\ x\amp y \end{array} \right] \left. \right| v, w, x, y, z \text{ are scalars } \right\}\text{.}\)</span> Assume that <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1888"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5616">Find a set <span class="process-math">\(S\)</span> of five <span class="process-math">\(2 \times 2\)</span> matrices that spans <span class="process-math">\(W\)</span> (since <span class="process-math">\(W\)</span> is a span of a set of vectors in <span class="process-math">\(\M_{2 \times 2}\text{,}\)</span> <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\)</span>). Without doing any computation, can this set <span class="process-math">\(S\)</span> be a basis for <span class="process-math">\(W\text{?}\)</span> Why or why not?</p></article><article class="task exercise-like" id="task-1889"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5617">Find a subset <span class="process-math">\(\CB\)</span> of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(W\text{.}\)</span></p></article></article><p id="p-5618"><a href="" class="xref" data-knowl="./knowl/act_5_b_2.html" title="Activity 32.3">Activity 32.3</a> and <a href="" class="xref" data-knowl="./knowl/act_5_b_2_b.html" title="Activity 32.4">Activity 32.4</a> give us two ways of finding a basis for a subspace <span class="process-math">\(W\)</span> of a vector space <span class="process-math">\(V\text{,}\)</span> assuming <span class="process-math">\(W\)</span> has a basis with finitely many vectors. One way (illustrated in <a href="" class="xref" data-knowl="./knowl/act_5_b_2.html" title="Activity 32.3">Activity 32.3</a>) is to start by choosing any non-zero vector <span class="process-math">\(\vw_1\)</span> in <span class="process-math">\(W\text{.}\)</span> Let <span class="process-math">\(\CS_1 = \{\vw_1\}\text{.}\)</span> If <span class="process-math">\(\CS_1\)</span> spans <span class="process-math">\(W\text{,}\)</span> then <span class="process-math">\(\CS_1\)</span> is a basis for <span class="process-math">\(W\text{.}\)</span> If not, there is a vector <span class="process-math">\(\vw_2\)</span> in <span class="process-math">\(W\)</span> that is not in <span class="process-math">\(\Span \ \CS_1\text{.}\)</span> Then <span class="process-math">\(\CS_2 = \{\vw_1, \vw_2\}\)</span> is a linearly independent set. If <span class="process-math">\(\Span \ \CS_2 = W\text{,}\)</span> then <span class="process-math">\(\CS_2\)</span> is a basis for <span class="process-math">\(W\)</span> and we are done. If not, repeat the process. We will show later that this process must stop as long as we know that <span class="process-math">\(W\)</span> has a basis with fini tely many vectors.</p>
<p id="p-5619">Another way (illustrated in <a href="" class="xref" data-knowl="./knowl/act_5_b_2_b.html" title="Activity 32.4">Activity 32.4</a>) to find a basis for <span class="process-math">\(W\)</span> is to start with a spanning set <span class="process-math">\(\CS_1\)</span> of <span class="process-math">\(W\text{.}\)</span> If <span class="process-math">\(\CS_1\)</span> is linearly independent, then <span class="process-math">\(\CS_1\)</span> is a basis for <span class="process-math">\(W\text{.}\)</span> If <span class="process-math">\(\CS_1\)</span> is linearly dependent, then one vector in <span class="process-math">\(\CS_1\)</span> is a linear combination of the others and we can remove that vector to obtain a new set <span class="process-math">\(\CS_2\)</span> that also spans <span class="process-math">\(W\text{.}\)</span> If <span class="process-math">\(\CS_2\)</span> is linearly independent, then <span class="process-math">\(\CS_2\)</span> is a basis for <span class="process-math">\(W\text{.}\)</span> If not, we repeat the process as many times as needed until we arrive until at a subset <span class="process-math">\(\CS_k\)</span> of <span class="process-math">\(\CS_1\)</span> that is linearly independent and spans <span class="process-math">\(W\text{.}\)</span> We summarize these results in the following theorem.</p>
<article class="theorem theorem-like" id="theorem-80"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">32.7</span><span class="period">.</span>
</h4>
<p id="p-5620">Let <span class="process-math">\(W\)</span> be a subspace of a finite-dimensional vector space <span class="process-math">\(V\text{.}\)</span> Then</p>
<ol class="decimal">
<li id="li-864"><p id="p-5621">any linearly independent subset of <span class="process-math">\(W\)</span> can be extended to a basis of <span class="process-math">\(W\text{,}\)</span></p></li>
<li id="li-865"><p id="p-5622">any subset of <span class="process-math">\(W\)</span> that spans <span class="process-math">\(W\)</span> can be reduced to a basis of <span class="process-math">\(W\text{.}\)</span></p></li>
</ol></article><p id="p-5623">We conclude this section with the result mentioned in the introduction — that every vector in a vector space with basis <span class="process-math">\(\B\)</span> can be written in one and only one way as a linear combination of basis vectors. The proof is similar to that of <a href="" class="xref" data-knowl="./knowl/thm_1_f_unique_representation.html" title="Theorem 6.6">Theorem 6.6</a> and is left to the exercises.</p>
<article class="theorem theorem-like" id="thm_5_b_4"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">32.8</span><span class="period">.</span>
</h4>
<p id="p-5624">Let <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> be vectors in a vector space <span class="process-math">\(V\)</span> that make up a basis <span class="process-math">\(\B\)</span> for <span class="process-math">\(V\text{.}\)</span> If <span class="process-math">\(\vu\)</span> is a vector in <span class="process-math">\(V\text{,}\)</span> then <span class="process-math">\(\vu\)</span> can be written in one and only one way as a linear combination of vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> in <span class="process-math">\(\B\text{.}\)</span></p></article></section><section class="section" id="sec_bases_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-5625">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-67"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">32.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-550"><p id="p-5626">Let <span class="process-math">\(S = \{1, 1+t, 2-t^2, 1+t+t^2, t-t^2\}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1890"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5627">Does <span class="process-math">\(S\)</span> span <span class="process-math">\(\pol_2\text{?}\)</span> Explain.</p>
<div class="solution solution-like" id="solution-192">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-5628">Let <span class="process-math">\(p(t) = a_0+a_1t+a_2t^2\)</span> be an arbitrary vector in <span class="process-math">\(\pol_2\text{.}\)</span> If <span class="process-math">\(p(t)\)</span> is in <span class="process-math">\(\Span \ S\text{,}\)</span> then there are weights <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> <span class="process-math">\(c_3\text{,}\)</span> <span class="process-math">\(c_4\text{,}\)</span> and <span class="process-math">\(c_5\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_0+a_1t+a_2t^2 = c_1(1) + c_2(1+t) + c_3(2-t^2) + c_4(1+t+t^2) + c_5(t-t^2)\text{.}
\end{equation*}
</div>
<p class="continuation">Equating coefficients of like powers gives us the system</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-220">
\begin{align*}
{}c_1   \amp {}+{}   \amp {}c_2   \amp {}+{}  \amp {2}c_3  \amp {}+{}  \amp {}c_4  \amp {}{}  \amp {}     \amp = a_0\amp {}\\
{}     \amp {}{}     \amp {}c_2   \amp {}{}    \amp {}    \amp {}+{}  \amp {}c_4  \amp {}+{}  \amp {}c_5     \amp = a_1\amp {}\\
{}     \amp {}{}     \amp {}     \amp {}{}    \amp {-}c_3  \amp {}+{}  \amp {}c_4  \amp {}-{}  \amp {}c_5     \amp = a_2\amp {.}
\end{align*}
</div>
<p class="continuation">The reduced row echelon form of the coefficient matrix <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccrr} 1\amp 0\amp 0\amp 2\amp -3 \\ 0\amp 1\amp 0\amp 1\amp 1 \\ 0\amp 0\amp 1\amp -1\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Since there is a pivot in every row of <span class="process-math">\(A\text{,}\)</span> the system <span class="process-math">\(A \vx = \vb\)</span> is always consistent. We conclude that <span class="process-math">\(S\)</span> does span <span class="process-math">\(\pol_2\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1891"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5629">Explain why <span class="process-math">\(S\)</span> is not a basis for <span class="process-math">\(\pol_2\text{.}\)</span></p>
<div class="solution solution-like" id="solution-193">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-5630">The fact that the coefficient matrix <span class="process-math">\(A\)</span> of our system has non-pivot columns means that each vector in <span class="process-math">\(\pol_2\)</span> can be written in more than one way as a linear combination of vectors in <span class="process-math">\(S\text{.}\)</span> This means that <span class="process-math">\(S\)</span> is not linearly independent and so cannot be a basis for <span class="process-math">\(\pol_2\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1892"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5631">Find a subset of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(\pol_2\text{.}\)</span> Explain your reasoning.</p>
<div class="solution solution-like" id="solution-194">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-5632">That the first three columns of <span class="process-math">\(A\)</span> are pivot columns implies that the polynomials <span class="process-math">\(1\text{,}\)</span> <span class="process-math">\(1+t\text{,}\)</span> and <span class="process-math">\(2-t^2\)</span> are linearly independent. Since there is a pivot in every row of <span class="process-math">\(A\text{,}\)</span> the three polynomials <span class="process-math">\(1\text{,}\)</span> <span class="process-math">\(1+t\text{,}\)</span> and <span class="process-math">\(2-t^2\)</span> also span <span class="process-math">\(\pol_2\text{.}\)</span> So <span class="process-math">\(\{1, 1+t, 2-t^2\}\)</span> is a subset of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(\pol_2\text{.}\)</span></p>
</div></article></article><article class="example example-like" id="example-68"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">32.10</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-551"><p id="p-5633">Let <span class="process-math">\(U\)</span> be the set of all matrices of real numbers of the form <span class="process-math">\(\left[ \begin{array}{cc} u \amp -u-x \\ 0 \amp x \end{array} \right]\)</span> and <span class="process-math">\(W\)</span> be the set of all real matrices of the form <span class="process-math">\(\left[ \begin{array}{cc} v \amp 0 \\ w \amp -v \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1893"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5634">Find a basis for <span class="process-math">\(U\)</span> and a basis for <span class="process-math">\(W\text{.}\)</span></p>
<div class="solution solution-like" id="solution-195">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-5635">Every matrix in <span class="process-math">\(U\)</span> has the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} u \amp  -u-x \\  0 \amp    x \end{array}  \right] = u\left[ \begin{array}{cr} 1 \amp  -1 \\  0 \amp  0 \end{array}  \right] + x\left[ \begin{array}{cr} 0 \amp  -1 \\  0 \amp  1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Let <span class="process-math">\(S_U = \left\{ \left[ \begin{array}{cr} 1 \amp  -1 \\  0 \amp  0 \end{array}  \right], \left[ \begin{array}{cr} 0 \amp  -1 \\  0 \amp  1 \end{array}  \right] \right\}\text{.}\)</span> Then <span class="process-math">\(U = \Span \ S_U\)</span> and <span class="process-math">\(U\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span> If</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
c_1\left[ \begin{array}{cr} 1 \amp  -1 \\  0 \amp  0 \end{array}  \right] + c_2\left[ \begin{array}{cr} 0 \amp  -1 \\  0 \amp  1 \end{array}  \right] = 0\text{,}
\end{equation*}
</div>
<p class="continuation">then <span class="process-math">\(c_1=c_2=0\)</span> and <span class="process-math">\(S_U\)</span> is also linearly independent. This makes <span class="process-math">\(S_U\)</span> a basis for <span class="process-math">\(U\text{.}\)</span> Similarly, every matrix in <span class="process-math">\(W\)</span> has the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc}   v \amp   0 \\ w \amp  -v \end{array}  \right] = v \left[ \begin{array}{cr} 1 \amp  0 \\  0 \amp  -1 \end{array}  \right] + w\left[ \begin{array}{cc} 0 \amp  0 \\  1 \amp  0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Let <span class="process-math">\(S_W = \left\{ \left[ \begin{array}{cr} 1 \amp  0 \\  0 \amp  -1 \end{array}  \right] , \left[ \begin{array}{cc} 0 \amp  0 \\  1 \amp  0 \end{array}  \right] \right\}\text{.}\)</span> Then <span class="process-math">\(W = \Span \ S_W\)</span> and <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span> If</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
c_1\left[ \begin{array}{cr} 1 \amp  0 \\  0 \amp  -1 \end{array}  \right] + c_2\left[ \begin{array}{cc} 0 \amp  0 \\  1 \amp  0 \end{array}  \right]  = 0\text{,}
\end{equation*}
</div>
<p class="continuation">then <span class="process-math">\(c_1=c_2=0\)</span> and <span class="process-math">\(S_W\)</span> is also linearly independent. This makes <span class="process-math">\(S_W\)</span> a basis for <span class="process-math">\(W\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1894"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5636">Let <span class="process-math">\(U + W = \{A+B : A \text{ is in } U \text{ and } B \text{ is in } W\}\text{.}\)</span> Show that <span class="process-math">\(U+W\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\)</span> and find a basis for <span class="process-math">\(U + W\text{.}\)</span></p>
<div class="solution solution-like" id="solution-196">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-5637">Every matrix in <span class="process-math">\(U+W\)</span> has the form</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-221">
\begin{align*}
\left[ \begin{array}{cc} u \amp  -u-x\\
0 \amp    x \end{array} \right] \amp + \left[ \begin{array}{cc}   v \amp   0\\
w \amp  -v \end{array} \right] = \left[ \begin{array}{cc}   u+v \amp   -u-x\\
w \amp  x-v \end{array} \right]\\
\amp = u\left[ \begin{array}{cr}   1 \amp   -1\\
0 \amp  0 \end{array} \right] + x\left[ \begin{array}{cr}   0 \amp   -1\\
0 \amp  1 \end{array} \right]\\
\amp \qquad + v\left[ \begin{array}{cr}   1 \amp   0\\
0 \amp  -1 \end{array} \right] + w\left[ \begin{array}{cc}   0 \amp   0\\
1 \amp  0 \end{array} \right]\text{.}
\end{align*}
</div>
<p class="continuation">Let <span class="process-math">\(S = \left\{ \left[ \begin{array}{cr}   1 \amp   -1 \\ 0 \amp  0 \end{array}  \right], \left[ \begin{array}{cr}   0 \amp   -1 \\ 0 \amp  1 \end{array}  \right], \left[ \begin{array}{cr}   1 \amp   0 \\ 0 \amp  -1 \end{array}  \right], \left[ \begin{array}{cc}   0 \amp   0 \\ 1 \amp  0 \end{array}  \right] \right\}\text{.}\)</span> Then <span class="process-math">\(U+W = \Span \ S\)</span> and <span class="process-math">\(U+W\)</span> is a subspace of <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span> If</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
c_1\left[ \begin{array}{cr}   1 \amp   -1 \\ 0 \amp  0 \end{array}  \right] + c_2\left[ \begin{array}{cr}   0 \amp   -1 \\ 0 \amp  1 \end{array}  \right] + c_3\left[ \begin{array}{cr}   1 \amp   0 \\ 0 \amp  -1 \end{array}  \right] + c_4\left[ \begin{array}{cc}   0 \amp   0 \\ 1 \amp  0 \end{array}  \right] = 0\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-222">
\begin{align*}
{}c_1   \amp {}     \amp {}    \amp {}+{}  \amp {}c_3  \amp {}  \amp {}    \amp = \amp 0\amp {}\\
{-}c_1   \amp {}-{}   \amp {}c_2  \amp {}    \amp {}    \amp {}  \amp {}    \amp = \amp 0\amp {}\\
{}     \amp {}     \amp {}    \amp {}    \amp {}    \amp {}  \amp {}c_4  \amp = \amp 0\amp {}\\
{}       \amp {}     \amp {}c_2  \amp {}-{}  \amp {}c_3  \amp {}  \amp {}    \amp = \amp 0\amp {.}
\end{align*}
</div>
<p class="continuation">The reduced row echelon form of <span class="process-math">\(\left[ \begin{array}{rrrc} 1\amp 0\amp 1\amp 0 \\ -1\amp -1\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 0\amp 1\amp -1\amp 0 \end{array}  \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccrc} 1\amp 0\amp 1\amp 0 \\ 0\amp 1\amp -1\amp 0 \\ 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> The vectors that correspond to the pivot columns are linearly independent and span <span class="process-math">\(U+W\text{,}\)</span> so a basis for <span class="process-math">\(U+W\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ \begin{array}{cr}   1 \amp   -1 \\ 0 \amp  0 \end{array}  \right], \left[ \begin{array}{cr}   0 \amp   -1 \\ 0 \amp  1 \end{array}  \right], \left[ \begin{array}{cc}   0 \amp   0 \\ 1 \amp  0 \end{array}  \right] \right\}\text{.}
\end{equation*}
</div>
</div></article></article></section><section class="section" id="sec_bases_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<p id="p-5638">The important idea in this section is that of a basis for a vector space. A basis is a minimal spanning set and another equivalent characterization of the “minimal” property is linear independence.</p>
<ul class="disc">
<li id="li-866">
<p id="p-5639">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly independent if the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero
\end{equation*}
</div>
<p class="continuation">for scalars <span class="process-math">\(x_1, x_2, \ldots,
x_k\)</span> has only the trivial solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 = x_2 = x_3 = \cdots = x_k = 0\text{.}
\end{equation*}
</div>
<p class="continuation">If a set of vectors is not linearly independent, then the set is linearly dependent.</p>
</li>
<li id="li-867"><p id="p-5640">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly independent if and only if none of the vectors in the set can be written as a linear combination of the remaining vectors in the set.</p></li>
<li id="li-868"><p id="p-5641">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in a vector space <span class="process-math">\(V\)</span> is linearly dependent if and only if at least one of the vectors in the set can be written as a linear combination of the remaining vectors in the set.</p></li>
<li id="li-869">
<p id="p-5642">A basis for a vector space <span class="process-math">\(V\)</span> is a subset <span class="process-math">\(S\)</span> of <span class="process-math">\(V\)</span> if</p>
<ol class="decimal">
<li id="li-870"><p id="p-5643"><span class="process-math">\(\Span \ S = V\)</span> and</p></li>
<li id="li-871"><p id="p-5644"><span class="process-math">\(S\)</span> is a linearly independent set.</p></li>
</ol>
</li>
<li id="li-872"><p id="p-5645">A basis is important in that it provides us with an efficient way to represent any vector in the vector space — any vector can be written in one and only one way as a linear combination of vectors in a basis.</p></li>
<li id="li-873"><p id="p-5646">To find a basis of a vector space, we can start with a spanning set <span class="process-math">\(S\)</span> and toss out any vector in <span class="process-math">\(S\)</span> that can be written as a linear combination of the remaining vectors in <span class="process-math">\(S\text{.}\)</span> We repeat the process with the remaining subset of <span class="process-math">\(S\)</span> until we arrive at a linearly independent spanning set. Alternatively, we can find a spanning set for the space and remove any vector that is a linear combination of the others in the spanning set. We can repeat this process until we wind up with a linearly independent spanning set.</p></li>
</ul></section><section class="exercises" id="sec_bases_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-323"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-552"><p id="p-5647">Determine if the given sets are linearly independent or dependent in the indicated vector space. If dependent, write one of the vectors as a linear combination of the others. If independent, determine if the set is a basis for the vector space.</p></div>
<article class="task exercise-like" id="task-1895"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5648"><span class="process-math">\(\{[1 \ 4 \ 6]^{\tr}, [2 \ -1 \ 3]^{\tr}, [0 \ 1 \ 5]^{\tr}\}\)</span> in <span class="process-math">\(\R^3\)</span></p></article><article class="task exercise-like" id="task-1896"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5650"><span class="process-math">\(\{1-2t^2+t^3, 3-t+4t^3, 2-3t\}\)</span> in <span class="process-math">\(\pol_3\)</span></p></article><article class="task exercise-like" id="task-1897"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5652"><span class="process-math">\(\{1+t, -1-5t+4t^2+t^3, 1+t^2+t^3, t+2t^3\}\)</span> in <span class="process-math">\(\pol_3\)</span></p></article><article class="task exercise-like" id="task-1898"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-5654"><span class="process-math">\(\left\{ \left[ \begin{array}{ccc} 1\amp 2\amp 0\\0\amp 1\amp 1 \end{array} \right], \left[ \begin{array}{crc} 1\amp -2\amp 0\\0\amp -1\amp 1 \end{array} \right], \left[ \begin{array}{ccr} 1\amp 2\amp 0\\0\amp 1\amp -1 \end{array} \right] \right\}\)</span> in <span class="process-math">\(\M_{3 \times 2}\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-324"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-553"><p id="p-5656">Let <span class="process-math">\(S = \{1+t+t^2, t+t^2, 1+t, 1+t^2\}\)</span> in <span class="process-math">\(\pol_2\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1899"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5657">Show that the set <span class="process-math">\(S\)</span> spans <span class="process-math">\(\pol_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-1900"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5658">Show that the set <span class="process-math">\(S\)</span> is linearly dependent.</p></article><article class="task exercise-like" id="task-1901"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5659">Find a subset of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(\pol_2\text{.}\)</span> Be sure to verify that you have a basis.</p></article></article><article class="exercise exercise-like" id="exercise-325"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-5660">Find two different bases for <span class="process-math">\(\M_{2 \times 2}\text{.}\)</span> Explain how you know that each set is a basis.</p></article><article class="exercise exercise-like" id="exercise-326"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-554"><p id="p-5662">The set <span class="process-math">\(W = \{at+bt^2 \mid a \text{ and } b \text{ are scalars } \}\)</span> is a subspace of <span class="process-math">\(\pol_3\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1902"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5663">Find a set of vectors in <span class="process-math">\(\pol_3\)</span> that spans <span class="process-math">\(W\text{.}\)</span></p></article><article class="task exercise-like" id="task-1903"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5664">Find a basis for <span class="process-math">\(W\text{.}\)</span> Be sure to verify that you have a basis.</p></article></article><article class="exercise exercise-like" id="exercise-327"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-5665">Suppose that the set <span class="process-math">\(\{\vu, \vv, \vw\}\)</span> is a basis for a vector space <span class="process-math">\(V\text{.}\)</span> Is the set <span class="process-math">\(\{\vu+\vv, \vu+\vw, \vv+\vw\}\)</span> a basis for <span class="process-math">\(V\text{?}\)</span> Verify your result.</p></article><article class="exercise exercise-like" id="exercise-328"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-5667">Determine all scalars <span class="process-math">\(c\)</span> so that the set <span class="process-math">\(\{c^2+t^2, c+2t, 1+t^2\}\)</span> is a basis for <span class="process-math">\(\pol_2\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-329"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-5668">A symmetric matrix is a matrix <span class="process-math">\(A\)</span> so that <span class="process-math">\(A^{\tr} = A\text{.}\)</span> Is it possible to find a basis for <span class="process-math">\(\M_{2 \times 2}\)</span> consisting entirely of symmetric matrices? If so, exhibit one such basis. If not, explain why not.</p></article><article class="exercise exercise-like" id="exercise-330"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<p id="p-5670">Find a basis of the subspace of <span class="process-math">\(\M_{2 \times 3}\)</span> consisting of all matrices of the form <span class="process-math">\(\left[ \begin{array}{ccc} a\amp b\amp c \\ d\amp e\amp f \end{array} \right]\)</span> where <span class="process-math">\(c=a-2d\)</span> and <span class="process-math">\(f = b+3e\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-331"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-5671">Prove <a href="" class="xref" data-knowl="./knowl/thm_5_b_1.html" title="Theorem 32.3">Theorem 32.3</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-85" id="hint-85"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-85"><div class="hint solution-like"><p id="p-5672">Mimic the proof of <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-332"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-5673">Prove <a href="" class="xref" data-knowl="./knowl/thm_5_b_3.html" title="Theorem 32.5">Theorem 32.5</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-86" id="hint-86"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-86"><div class="hint solution-like"><p id="p-5674">Mimic the proof of <a href="" class="xref" data-knowl="./knowl/thm_minimal_spanning_set.html" title="Theorem 6.7">Theorem 6.7</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-333"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<p id="p-5675">Prove <a href="" class="xref" data-knowl="./knowl/thm_5_b_4.html" title="Theorem 32.8">Theorem 32.8</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-87" id="hint-87"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-87"><div class="hint solution-like"><p id="p-5676">Compare to <a href="" class="xref" data-knowl="./knowl/thm_1_f_unique_representation.html" title="Theorem 6.6">Theorem 6.6</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="problem_disjoint_subspaces"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<p id="p-5677">Show that if <span class="process-math">\(W_1, W_2\)</span> are subspaces of <span class="process-math">\(V\)</span> such that <span class="process-math">\(W_1\cap W_2 = \{ \vzero \}\text{,}\)</span> then for any linearly independent vectors <span class="process-math">\(\vu_1, \vu_2, \ldots, \vu_k\)</span> in <span class="process-math">\(W_1\)</span> and <span class="process-math">\(\vv_1, \vv_2, \ldots, \vv_\ell\)</span> in <span class="process-math">\(W_2\text{,}\)</span> the set <span class="process-math">\(\{ \vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_k\text{,}\)</span> <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_\ell\}\)</span> is linearly independent in <span class="process-math">\(V\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-335"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-555"><p id="p-5678">Label each of the following statements as True or False. Provide justification for your response. Throughout, let <span class="process-math">\(V\)</span> be a vector space.</p></div>
<article class="task exercise-like" id="task-1904"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5679">If <span class="process-math">\(\vv\)</span> is in <span class="process-math">\(V\text{,}\)</span> then the set <span class="process-math">\(\{\vv\}\)</span> is linearly independent.</p></article><article class="task exercise-like" id="task-1905"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5681">If a set of vectors span a subspace, then the set forms a basis of this subspace.</p></article><article class="task exercise-like" id="task-1906"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5682">If a linearly independent set of vectors spans a subspace, then the set forms a basis of this subspace.</p></article><article class="task exercise-like" id="task-1907"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5684">If the set <span class="process-math">\(S\)</span> spans <span class="process-math">\(V\)</span> and removing any vector from <span class="process-math">\(S\)</span> makes it not a spanning set anymore, then <span class="process-math">\(S\)</span> is a basis.</p></article><article class="task exercise-like" id="task-1908"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5685">If <span class="process-math">\(S\)</span> is a linearly independent set in <span class="process-math">\(V\)</span> and for every <span class="process-math">\(\vu\)</span> in <span class="process-math">\(V\text{,}\)</span> adding <span class="process-math">\(\vu\)</span> to <span class="process-math">\(S\)</span> makes it not linearly independent anymore, then <span class="process-math">\(S\)</span> is a basis.</p></article><article class="task exercise-like" id="task-1909"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5687">If a subset <span class="process-math">\(S\)</span> of <span class="process-math">\(V\)</span> spans <span class="process-math">\(V\text{,}\)</span> then <span class="process-math">\(S\)</span> must be linearly independent.</p></article><article class="task exercise-like" id="task-1910"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5688">If a subset <span class="process-math">\(S\)</span> of <span class="process-math">\(V\)</span> is linearly independent, then <span class="process-math">\(S\)</span> must span <span class="process-math">\(V\text{.}\)</span></p></article><article class="task exercise-like" id="task-1911"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5690">If <span class="process-math">\(S\)</span> is a linearly dependent set in <span class="process-math">\(V\text{,}\)</span> then every vector in <span class="process-math">\(S\)</span> is a linear combination of the other vectors in <span class="process-math">\(S\text{.}\)</span></p></article><article class="task exercise-like" id="task-1912"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5691">A vector space cannot have more than one basis.</p></article><article class="task exercise-like" id="task-1913"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5693">If <span class="process-math">\(\vu\)</span> is a non-zero vector in <span class="process-math">\(V\text{,}\)</span> then there is a basis of <span class="process-math">\(V\)</span> containing <span class="process-math">\(\vu\text{.}\)</span></p></article><article class="task exercise-like" id="task-1914"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5694">If <span class="process-math">\(\vu, \vv\)</span> are two linearly independent vectors in <span class="process-math">\(V\text{,}\)</span> then there is a basis of <span class="process-math">\(V\)</span> containing <span class="process-math">\(\vu, \vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-1915"><h5 class="heading">
<span class="codenumber">(l)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5696">If <span class="process-math">\(\vu\)</span> is in a basis of <span class="process-math">\(V\text{,}\)</span> then <span class="process-math">\(2\vu\)</span> cannot be in a basis of <span class="process-math">\(V\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_img_compress"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Image Compression with Wavelets</span>
</h3>
<p id="p-5697">We return to the problem of image compression introduced at the beginning of this section. The first step in the wavelet compression process is to digitize an image. There are two important ideas about digitalization to understand here: intensity levels and resolution. In grayscale image processing, it is common to think of 256 different intensity levels, or scales, of gray ranging from 0 (black) to 255 (white). A digital image can be created by taking a small grid of squares (called pixels) and coloring each pixel with some shade of gray. The resolution of this grid is a measure of how many pixels are used per square inch. An example of a 16 by 16 pixel picture of a flower was shown in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a>.</p>
<p id="p-5698">An image can be thought of in several ways: as a two-dimensional array; as one long vector by stringing the columns together one after another; or as a collection of column vectors. For simplicity, we will use the last approach in this project. We call each column vector in a picture a <dfn class="terminology">signal</dfn>. Wavelets are used to process signals. After processing we can apply some technique to compress the processed signals.</p>
<p id="p-5699">To process a signal we select a family of wavelets. There are many different families of wavelets — which family to use depends on the problem to be addressed. The simplest family of wavelets is the Haar family. More complicated families of wavelets are usually used in applications, but the basic ideas in wavelets can be seen through working with the Haar wavelets, and their relative simplicity will make the details easier to follow. Each family of wavelets has a father wavelet (usually denoted <span class="process-math">\(\varphi\)</span>) and a mother wavelet (<span class="process-math">\(\psi\)</span>).</p>
<p id="p-5700">Wavelets are generated from the mother wavelet by scalings and translations. To further simplify our work we will restrict ourselves to wavelets on [0,1], although this is not necessary. The advantage the wavelets have over other methods of data analysis (Fourier analysis for example) is that with the scalings and translations we are able to analyze both frequency on large intervals and isolate signal discontinuities on very small intervals. The way this is done is by using a large collection (infinite, in fact) of basis functions with which to transform the data. We'll begin by looking at how these basis functions arise.</p>
<p id="p-5701">If we sample data at various points, we can consider our data to represent a piecewise constant function obtained by partitioning [0,1] into <span class="process-math">\(n\)</span> equal sized subintervals, where <span class="process-math">\(n\)</span> represents the number of sample points. For the purposes of this project we will always choose <span class="process-math">\(n\)</span> to be a power of 2. So we can consider all of our data to represent functions. For us, then, it is natural to look at these functions in the vector space of all functions from <span class="process-math">\(\R\)</span> to <span class="process-math">\(\R\text{.}\)</span> Since our data is piecewise constant, we can really restrict ourselves to a subspace of this larger vector space — subspaces of piecewise constant functions. The most basic piecewise constant function on the interval <span class="process-math">\([0,1]\)</span> is the one whose value is 1 on the entire interval. We define <span class="process-math">\(\varphi\)</span> to be this constant function (called the characteristic function of the unit interval). That is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\varphi(x) = \begin{cases}1 \amp \text{ if }  0 \leq x \lt  1 \\ 0,   \amp  \text{ otherwise. } \end{cases}
\end{equation*}
</div>
<p id="p-5702">This function <span class="process-math">\(\varphi\)</span> is the Father Haar wavelet.</p>
<figure class="figure figure-like" id="F_phi_graphs_1"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/5_b_Haar_1.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">32.11<span class="period">.</span></span><span class="space"> </span>Graphs of <span class="process-math">\(\varphi(x)\text{,}\)</span> <span class="process-math">\(\varphi(2x)\text{,}\)</span> and <span class="process-math">\(\varphi(2x-1)\)</span> from left to right.</figcaption></figure><p id="p-5703">This function <span class="process-math">\(\varphi\)</span> may seem to be a very simple function but it has properties that will be important to us. One property is that <span class="process-math">\(\varphi\)</span> satisfies a scaling equation. For example, <a href="" class="xref" data-knowl="./knowl/F_phi_graphs_1.html" title="Figure 32.11">Figure 32.11</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_phi_graphs_1.html ./knowl/F_phi_graphs_2.html">
\begin{equation*}
\varphi(x) = \varphi(2x) + \varphi(2x-1)
\end{equation*}
</div>
<p class="continuation">while <a href="" class="xref" data-knowl="./knowl/F_phi_graphs_2.html" title="Figure 32.12">Figure 32.12</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_phi_graphs_1.html ./knowl/F_phi_graphs_2.html">
\begin{equation*}
\varphi(x) = \varphi(2^2x) + \varphi(2^2x-1) +  \varphi(2^2x-2) + \varphi(2^2x-3)\text{.}
\end{equation*}
</div>
<figure class="figure figure-like" id="F_phi_graphs_2"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/5_b_Haar_2.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">32.12<span class="period">.</span></span><span class="space"> </span>Graphs of <span class="process-math">\(\varphi(2^2x)\text{,}\)</span> <span class="process-math">\(\varphi(2^2x-1)\text{,}\)</span> <span class="process-math">\(\varphi(2^2x-2)\text{,}\)</span> and <span class="process-math">\(\varphi(2^2x-3)\text{,}\)</span> from left to right.</figcaption></figure><p id="p-5704">So <span class="process-math">\(\varphi\)</span> is a sum of scalings and translations of itself. In general, for each positive integer <span class="process-math">\(n\)</span> and integers <span class="process-math">\(k\)</span> between 0 and <span class="process-math">\(2^n-1\)</span> we define</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\varphi_{n,k}(x) = \varphi\left(2^nx-k\right)\text{.}
\end{equation*}
</div>
<p id="p-5705">Then <span class="process-math">\(\varphi(x) = \sum_{k=0}^{2^{n}-1} \varphi_{n,k}(x)\)</span> for each <span class="process-math">\(n\text{.}\)</span></p>
<p id="p-5706">These functions <span class="process-math">\(\varphi_{n,k}\)</span> are useful in that they form a basis for the vector space <span class="process-math">\(V_n\)</span> of all piecewise constant functions on <span class="process-math">\([0,1]\)</span> that have possible breaks at the points <span class="process-math">\(\frac{1}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{2}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{3}{2^n}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\frac{2^n-1}{2^n}\text{.}\)</span> This is exactly the kind of space in which digital signals live, especially if we sample signals at <span class="process-math">\(2^n\)</span> evenly spaced points on <span class="process-math">\([0,1]\text{.}\)</span> Let <span class="process-math">\(\CB_n = \{ \varphi_{n,k} : 0 \leq k \leq 2^n-1\}\text{.}\)</span> You may assume without proof that <span class="process-math">\(\CB_n\)</span> is a basis of <span class="process-math">\(V_n\text{.}\)</span></p>
<article class="project project-like" id="project-105"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">32.5</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1916"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5707">Draw the linear combination <span class="process-math">\(2\varphi_{2,0} - 3\varphi_{2,1} + 17 \varphi_{2,2} + 30 \varphi_{2,3}\text{.}\)</span> What does this linear combination look like? Explain the statement made previously ``Notice that these <span class="process-math">\(2^n\)</span> functions <span class="process-math">\(\varphi_{n,k}\)</span> form a basis for the vector space of all piecewise constant functions on <span class="process-math">\([0,1]\)</span> that have possible breaks at the points <span class="process-math">\(\frac{1}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{2}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{3}{2^n}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\frac{2^n-1}{2^n}\)</span>".</p></article><article class="task exercise-like" id="task-1917"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5708">Remember that we can consider our data to represent a piecewise constant function obtained by partitioning <span class="process-math">\([0,1]\)</span> into <span class="process-math">\(n\)</span> subintervals, where <span class="process-math">\(n\)</span> represents the number of sample points. Suppose we collect the following data: <span class="process-math">\(10\text{,}\)</span> <span class="process-math">\(13\text{,}\)</span> <span class="process-math">\(21\text{,}\)</span> <span class="process-math">\(55\text{,}\)</span> <span class="process-math">\(3\text{,}\)</span> <span class="process-math">\(12\text{,}\)</span> <span class="process-math">\(4\text{,}\)</span> <span class="process-math">\(18\text{.}\)</span> Explain how we can use this data to define a piecewise constant function <span class="process-math">\(f\)</span> on <span class="process-math">\([0,1]\text{.}\)</span> Express <span class="process-math">\(f\)</span> as a linear combination of suitable functions <span class="process-math">\(\varphi_{n,k}\text{.}\)</span> Plot this linear combination of <span class="process-math">\(\varphi_{n,k}\)</span> to verify.</p></article></article><p id="p-5709">Working with functions can be more cumbersome than working with vectors in <span class="process-math">\(\R^n\text{,}\)</span> but the digital nature of our data makes it possible to view our piecewise constant functions as vectors in <span class="process-math">\(\R^n\)</span> for suitable <span class="process-math">\(n\text{.}\)</span> More specifically, if <span class="process-math">\(f\)</span> is an element in <span class="process-math">\(V_n\text{,}\)</span> then <span class="process-math">\(f\)</span> is a piecewise constant function on <span class="process-math">\([0,1]\)</span> with possible breaks at the points <span class="process-math">\(\frac{1}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{2}{2^n}\text{,}\)</span> <span class="process-math">\(\frac{3}{2^n}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\frac{2^n-1}{2^n}\text{.}\)</span> If <span class="process-math">\(f\)</span> has the value of <span class="process-math">\(y_i\)</span> on the interval between <span class="process-math">\(\frac{i-1}{2^n}\)</span> and <span class="process-math">\(\frac{i}{2^n}\text{,}\)</span> then we can identify <span class="process-math">\(f\)</span> with the vector <span class="process-math">\(\left[y_1 \ y_1 \ \ldots \ y_{2^n}\right]^{\tr}\text{.}\)</span></p>
<article class="project project-like" id="act_wavelets_vectors"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">32.6</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1918"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5710">Determine the vector in <span class="process-math">\(\R^8\)</span> that is identified with <span class="process-math">\(\varphi\text{.}\)</span></p></article><article class="task exercise-like" id="task-1919"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5711">Determine the value of <span class="process-math">\(m\)</span> and the vectors in <span class="process-math">\(\R^m\)</span> that are identified with <span class="process-math">\(\varphi_{2,0}\text{,}\)</span> <span class="process-math">\(\varphi_{2,1}\text{,}\)</span> <span class="process-math">\(\varphi_{2,2}\text{,}\)</span> and <span class="process-math">\(\varphi_{2,3}\text{.}\)</span></p></article></article><p id="p-5712">We can use the functions <span class="process-math">\(\varphi_{n,k}\)</span> to represent digital signals, but to manipulate the data in useful ways we need a different perspective. A different basis for <span class="process-math">\(V_n\)</span> (a <dfn class="terminology">wavelet basis</dfn>) will allow us to identify the pieces of the data that are most important. We illustrate in the next activity with the spaces <span class="process-math">\(V_1\)</span> and <span class="process-math">\(V_2\text{.}\)</span></p>
<article class="project project-like" id="act_psi"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">32.7</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-556"><p id="p-5713">The space <span class="process-math">\(V_1\)</span> consists of all functions that are piecewise constant on <span class="process-math">\([0,1]\)</span> with a possible break at <span class="process-math">\(x=\frac{1}{2}\text{.}\)</span> The functions <span class="process-math">\(\varphi = \varphi_{n,k}\)</span> are used to records the values of a signal, and by summing these values we can calculate their average. Wavelets act by averaging and differencing, and so <span class="process-math">\(\varphi\)</span> does the averaging. We need functions that will perform the differencing.</p></div>
<article class="task exercise-like" id="task-1920"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5714">Define <span class="process-math">\(\{\psi_{0,0}\}\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/F_psi_graphs.html">
\begin{equation*}
\psi_{0,0}(x) = \begin{cases}1 \amp \text{ if }  0 \leq x \lt  \frac{1}{2} \\ -1 \amp \text{ if }  \frac{1}{2} \leq x \lt  1 \\ 0 \amp \text{ otherwise } \end{cases}\text{.}
\end{equation*}
</div>
<p class="continuation">A picture of <span class="process-math">\(\psi_{0,0}\)</span> is shown in <a href="" class="xref" data-knowl="./knowl/F_psi_graphs.html" title="Figure 32.13">Figure 32.13</a>. Since <span class="process-math">\(\psi_{0,0}\)</span> assumes values of <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{,}\)</span> we can use <span class="process-math">\(\psi_{0,0}\)</span> to perform differencing. The function <span class="process-math">\(\psi = \psi_{0,0}\)</span> is the Mother Haar wavelet.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-60" id="fn-60"><sup> 60 </sup></a> Show that <span class="process-math">\(\{\varphi, \psi\}\)</span> is a basis for <span class="process-math">\(V_1\text{.}\)</span></p>
<figure class="figure figure-like" id="F_psi_graphs"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/5_b_Haar_3.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">32.13<span class="period">.</span></span><span class="space"> </span>The graphs of <span class="process-math">\(\psi_{0,0}\text{,}\)</span> <span class="process-math">\(\psi_{1,0}\)</span> and <span class="process-math">\(\psi_{1,1}\)</span> from left to right.</figcaption></figure></article><article class="task exercise-like" id="task-1921"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5715">We continue in a manner similar to the one in which we constructed bases for <span class="process-math">\(V_n\text{.}\)</span> For <span class="process-math">\(k=0\)</span> and <span class="process-math">\(k=1\text{,}\)</span> let <span class="process-math">\(\psi_{1,k} = \psi\left(2^1x-k\right)\text{.}\)</span> Graphs of <span class="process-math">\(\psi_{1,0}\)</span> and <span class="process-math">\(\psi_{1,1}\)</span> are shown in <a href="" class="xref" data-knowl="./knowl/F_psi_graphs.html" title="Figure 32.13">Figure 32.13</a>. The functions <span class="process-math">\(\psi_{1,k}\)</span> assume the values of <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\)</span> on smaller intervals, and so can be used to perform differencing on smaller scale than <span class="process-math">\(\psi_{0,0}\text{.}\)</span> Show that <span class="process-math">\(\{\varphi_{0,0}, \psi_{0,0}, \psi_{1,0}, \psi_{1,1}\}\)</span> is a basis for <span class="process-math">\(V_2\text{.}\)</span></p></article></article><p id="p-5716">As <a href="" class="xref" data-knowl="./knowl/act_psi.html" title="Project Activity 32.7">Project Activity 32.7</a> suggests, we can make a basis for <span class="process-math">\(V_n\)</span> from <span class="process-math">\(\varphi_{0,0}\)</span> and functions of the form <span class="process-math">\(\psi_{n,k}\)</span> defined by <span class="process-math">\(\psi_{n,k}(x) = \psi\left(2^nx-k\right)\)</span> for <span class="process-math">\(k\)</span> from 0 to <span class="process-math">\(2^n-1\text{.}\)</span> More specifically, if we let <span class="process-math">\(\CS_n = \{\psi_{n,k} : 0 \leq k \leq 2^n-1\}\text{,}\)</span> then the set</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_psi.html">
\begin{equation*}
\CW_n = \{\varphi_{0,0}\} \cup \bigcup_{j=0}^{n-1} \CS_j
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(V_n^{\perp}\)</span> (we state this without proof). The functions <span class="process-math">\(\psi_{n,k}\)</span> are the <em class="emphasis">wavelets</em>.</p>
<article class="project project-like" id="act_wavelets_differencing"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">32.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-557"><p id="p-5717">We can now write any function in <span class="process-math">\(V_n\)</span> using the basis <span class="process-math">\(\CW_n\text{.}\)</span> As an example, the string 50, 16, 14, 28 represents a piecewise constant function which can be written as <span class="process-math">\(50 \varphi_{2,0} + 16 \varphi_{2,1} + 14 \varphi_{2,2} + 28 \varphi_{2,3}\text{,}\)</span> an element in <span class="process-math">\(V_2\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1922"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5718">Specifically identify the functions in <span class="process-math">\(\CW_0\text{,}\)</span> <span class="process-math">\(\CW_1\text{,}\)</span> and <span class="process-math">\(\CW_2\text{,}\)</span> and <span class="process-math">\(\CW_3\text{.}\)</span></p></article><article class="task exercise-like" id="task-1923"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-558"><p id="p-5719">As mentioned earlier, we can identify a signal, and each wavelet function, with a vector in <span class="process-math">\(\R^m\)</span> for an appropriate value of <span class="process-math">\(m\text{.}\)</span> We can then use this identification to decompose any signal as a linear combination of wavelets. We illustrate this idea with the signal <span class="process-math">\([50 \ 16 \ 14 \ 28]^{\tr}\)</span> in <span class="process-math">\(\R^4\text{.}\)</span> Recall that we can represent this signal as the function <span class="process-math">\(f = 50 \varphi_{2,0} + 16 \varphi_{2,1} + 14 \varphi_{2,2} + 28 \varphi_{2,3}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1924"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-5720">Find the the vectors <span class="process-math">\(\vw_1\text{,}\)</span> <span class="process-math">\(\vw_2\text{,}\)</span> <span class="process-math">\(\vw_3\text{,}\)</span> and <span class="process-math">\(\vw_4\)</span> in <span class="process-math">\(\R^m\)</span> that are identified with <span class="process-math">\(\varphi_{0,0}\text{,}\)</span> <span class="process-math">\(\psi_{0,0}\text{,}\)</span> <span class="process-math">\(\psi_{1,0}\text{,}\)</span> and <span class="process-math">\(\psi_{1,1}\text{,}\)</span> respectively.</p></article><article class="task exercise-like" id="task-1925"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-5721">Any linear combination <span class="process-math">\(c_1\varphi_{0,0} + c_2 \psi_{0,0} + c_3 \psi_{1,0} + c_4\psi_{1,1}\)</span> is then identified with the linear combination <span class="process-math">\(c_1 \vw_1 + c_2 \vw_2 + c_3 \vw_3 + c_4 \vw_4\text{.}\)</span> Use this idea to find the weights to write the function <span class="process-math">\(f\)</span> as a linear combination of <span class="process-math">\(\varphi_{0,0}\text{,}\)</span> <span class="process-math">\(\psi_{0,0}\text{,}\)</span> <span class="process-math">\(\psi_{1,0}\text{,}\)</span> and <span class="process-math">\(\psi_{1,1}\text{.}\)</span></p></article></article></article><p id="p-5722">Although is it not necessarily easy to observe, the weights in the decomposition <span class="process-math">\(f = 27 \varphi_{0,0} + 6 \psi_{0,0} + 17 \psi_{1,0} - 7 \psi_{1,1}\)</span> are just averages and differences of the original weights in <span class="process-math">\(f = 50 \varphi_{2,0} + 16 \varphi_{2,1} + 14 \varphi_{2,2} + 28 \varphi_{2,3}\text{.}\)</span> To see how, notice that if we take the overall average of the original weights we obtain the value of <span class="process-math">\(27\text{.}\)</span> If we average the original weights in pairs (<span class="process-math">\(50\)</span> and <span class="process-math">\(16\text{,}\)</span> and <span class="process-math">\(14\)</span> and <span class="process-math">\(28\)</span>) we obtain the values <span class="process-math">\(33\)</span> and <span class="process-math">\(21\text{,}\)</span> and if we take average differences of the original weights in pairs (<span class="process-math">\(50\)</span> and <span class="process-math">\(16\text{,}\)</span> and <span class="process-math">\(14\)</span> and <span class="process-math">\(28\)</span>) we obtain the values <span class="process-math">\(17\)</span> and <span class="process-math">\(-7\text{.}\)</span> We can treat the signal <span class="process-math">\([33 \ 21]^{\tr}\)</span> formed from the average of the pairs of the original weights as a smaller copy of the original signal. The average difference of the entries of this new signal is <span class="process-math">\(6\text{.}\)</span> So the weights in our final decomposition are obtained by differences between successive averages and certain coefficients. The coefficients in our final decomposition <span class="process-math">\(27 \varphi_{0,0} + 6 \psi_{0,0} + 17 \psi_{1,0} - 7 \psi_{1,1}\)</span> are called <dfn class="terminology">wavelet coefficients</dfn>. This is the idea that makes wavelets so useful for image compression. In many images, pixels that are near to each other often have similar coloring or shading. These pixels are coded with numbers that are close in value. In the differencing process, these numbers are replaced with numbers that are close to 0. If there is little difference in the shading of the adjacent pixels, the image will be changed only a little if the shadings are made the same. This results in replacing these small wavelet coefficients with zeros. If the processed vectors contain long strings of zeros, the vectors can be significantly compressed.</p>
<p id="p-5723">Once we have recognized the pattern in expressing our original function as an overall average and wavelet coefficients we can perform these operations more quickly with matrices.</p>
<article class="project project-like" id="act_wavelets_matrices"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">32.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-559"><p id="p-5724">The process of averaging and differencing discussed in and following <a href="" class="xref" data-knowl="./knowl/act_wavelets_differencing.html" title="Project Activity 32.8">Project Activity 32.8</a> can be viewed as a matrix-vector problem. As we saw in <a href="" class="xref" data-knowl="./knowl/act_wavelets_differencing.html" title="Project Activity 32.8">Project Activity 32.8</a>, we can translate the problem of finding wavelet coefficients to the matrix world.</p></div>
<article class="task exercise-like" id="task-1926"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5725">Consider again the problem of finding the wavelet coefficients contained in the vector <span class="process-math">\([27 \ 6 \ 17 \ - 7]^{\tr}\)</span> for the signal <span class="process-math">\([50 \ 16 \ 14 \ 28]^{\tr}\text{.}\)</span> Find the matrix <span class="process-math">\(A_4\)</span> that has the property that <span class="process-math">\(A_4 [50 \ 16 \ 14 \ 28]^{\tr} = [27 \ 6 \ 17 \ - 7]^{\tr}\text{.}\)</span> (You have already done part of this problem in <a href="" class="xref" data-knowl="./knowl/act_wavelets_differencing.html" title="Project Activity 32.8">Project Activity 32.8</a>.) Explain how <span class="process-math">\(A_4\)</span> performs the averaging and differencing discussed earlier.</p></article><article class="task exercise-like" id="task-1927"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5726">Repeat the process in part (a) to find the matrix <span class="process-math">\(A_8\)</span> that converts a signal to its wavelet coefficients.</p></article><article class="task exercise-like" id="task-1928"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5727">The matrix <span class="process-math">\(A_i\)</span> is called a <dfn class="terminology">forward wavelet transformation matrix</dfn> and <span class="process-math">\(A_i^{-1}\)</span> is the <dfn class="terminology">inverse wavelet transform matrix</dfn>. Use <span class="process-math">\(A_8\)</span> to show that the wavelet coefficients for the data string <span class="process-math">\([80 \ 48 \ 4 \ 36 \ 28 \ 64 \ 6 \ 50]^{\tr}\)</span> are contained in the vector <span class="process-math">\([39.5 \ 2.5 \ 22 \ 9 \ 16 \ -16 \ -18 \ -22]^{\tr}\text{.}\)</span></p></article></article><p id="p-5728">Now we have all of the necessary background to discuss image compression. Suppose we want to store an image. We partition the image vertically and horizontally and record the color or shade at each grid entry. The grid entries will be our pixels. This gives a matrix, <span class="process-math">\(M\text{,}\)</span> of colors, indexed by pixels or horizontal and vertical position. To simplify our examples we will work in gray-scale, where our grid entries are integers between 0 (black) and 255 (white). We can treat each column of our grid as a piecewise constant function. As an example, the image matrix <span class="process-math">\(M\)</span> that produced the picture at left in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a> is given in <a href="" class="xref" data-knowl="./knowl/eq_flower_image_matrix.html" title="Equation 32.1">(32.1)</a>.</p>
<p id="p-5729">We can then apply a 16 by 16 forward wavelet transformation matrix <span class="process-math">\(A_{16}\)</span> to <span class="process-math">\(M\)</span> to convert the columns to averages and wavelet coefficients that will appear in the matrix <span class="process-math">\(A_{16}M\text{.}\)</span> These wavelet coefficients allow us to compress the image — that is, create a smaller set of data that contains the essence of the original image.</p>
<p id="p-5730">Recall that the forward wavelet transformation matrix computes weighted differences of consecutive entries in the columns of the image matrix <span class="process-math">\(M\text{.}\)</span> If two entries in <span class="process-math">\(M\)</span> are close in values, the weighted difference in <span class="process-math">\(A_{16}M\)</span> will be close to 0. For our example, the matrix <span class="process-math">\(A_{16}M\)</span> is approximately</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ {\tiny{ \begin{array}{cccccccccccccccc}  208.0\amp  202.0\amp  178.0\amp  165.0\amp 155.0\amp  172.0\amp  118.0\amp  172.0\amp  155.0\amp  153.0\amp  176.0\amp  202.0\amp  208.0\amp  210.0\amp 209.0\amp  208.0\\ 33.4\amp  24.1\amp - 0.625\amp  0.938\amp - 2.50\amp - 5.94\amp  42.8\amp - 5.94\amp - 2.50\amp  12.8\amp  0.938\amp  24.7\amp  30.6\amp  33.4\amp  32.5\amp  31.6 \\- 1.88\amp - 13.8\amp  19.4\amp  2.50\amp  0.0\amp - 2.50\amp  8.12\amp - 2.50 \amp  0.0\amp  2.50\amp  19.4\amp - 13.8\amp  1.88\amp - 3.75\amp - 1.88\amp  0.0\\ 17.5\amp  61.9\amp  61.9\amp  6.88\amp  0.0\amp  61.9\amp  0.0\amp  61.9\amp  0.0\amp  30.6\amp  65.0\amp  66.9\amp 66.9\amp  19.4\amp  66.9\amp  66.9\\ 0.0\amp  27.5\amp  43.8\amp  16.2\amp  0.0 \amp - 11.2\amp  16.2\amp - 11.2\amp  0.0\amp  16.2\amp  43.8\amp  27.5\amp  0.0\amp  0.0\amp  0.0\amp  0.0 \\ 3.75\amp  0.0\amp  27.5\amp - 11.2\amp  0.0\amp - 16.2\amp  22.5\amp - 16.2\amp 0.0\amp - 11.2\amp  27.5\amp  0.0\amp - 3.75\amp - 7.50\amp - 3.75\amp  0.0\\ 47.5\amp  0.0\amp  0.0\amp  13.8\amp  82.5\amp  0.0\amp  0.0\amp  0.0\amp  82.5\amp  13.8\amp  0.0\amp  3.75\amp 3.75\amp  51.2\amp  3.75\amp  3.75\\ 82.5\amp  41.2\amp  41.2\amp  82.5\amp 82.5\amp  41.2\amp  0.0\amp  41.2\amp  82.5\amp  35.0\amp  35.0\amp  35.0\amp  35.0\amp  82.5\amp  35.0\amp  35.0 \\ 0.0\amp  0.0\amp  0.0\amp  55.0\amp - 22.5\amp - 22.5\amp  55.0\amp - 22.5\amp - 22.5\amp  55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\\ 0.0\amp 55.0\amp - 22.5\amp - 22.5\amp  22.5\amp  0.0\amp - 22.5\amp  0.0\amp  22.5\amp - 22.5\amp - 22.5\amp  55.0\amp 0.0\amp  0.0\amp  0.0\amp  0.0\\- 7.50\amp  0.0\amp - 55.0\amp  22.5\amp  22.5\amp - 22.5\amp  0.0\amp - 22.5\amp  22.5\amp  22.5\amp - 55.0\amp  0.0\amp  7.50\amp  0.0\amp  0.0\amp  0.0 \\ 0.0\amp  0.0\amp  0.0\amp  0.0\amp  22.5\amp - 55.0\amp  0.0\amp - 55.0\amp  22.5 \amp  0.0\amp  0.0\amp  0.0\amp - 15.0\amp  0.0\amp - 7.50\amp  0.0\\ 0.0\amp  0.0\amp 0.0\amp - 55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp - 55.0\amp  0.0\amp  7.50\amp  7.50\amp  7.50\amp 7.50\amp  7.50\\ 95.0\amp  0.0\amp  0.0\amp - 82.5\amp  0.0\amp  0.0\amp  0.0\amp 0.0\amp  0.0\amp - 82.5\amp  0.0\amp  0.0\amp  0.0\amp  95.0\amp  0.0\amp  0.0\\ 0.0\amp - 82.5\amp  82.5\amp  0.0\amp  0.0\amp - 82.5\amp  0.0\amp - 82.5\amp  0.0\amp  95.0\amp - 95.0\amp  95.0 \amp - 95.0\amp  0.0\amp  95.0\amp - 95.0\\ 0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp 0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0 \end{array}  }} \right]\text{.}
\end{equation*}
</div>
<p id="p-5731">Note that there are many wavelet coefficients that are quite small compared to others — the ones where the weighted averages are close to 0. In a sense, the weighted differences tell us how much “detail” about the whole that each piece of information contains. If a piece of information contains only a small amount of information about the whole, then we shouldn't sacrifice much of the picture if we ignore the small “detail” coefficients. One way to ignore the small “detail” coefficients is to use <dfn class="terminology">thresholding</dfn>.</p>
<p id="p-5732">With thresholding (this is <dfn class="terminology">hard thresholding</dfn> or <dfn class="terminology">keep or kill</dfn>), we decide on how much of the detail we want to remove (this is called the <dfn class="terminology">tolerance</dfn>). So we set a tolerance and then replace each entry in our matrix <span class="process-math">\(A_{16}M\)</span> whose absolute value is below the tolerance with 0 to obtain a new matrix <span class="process-math">\(M_1\text{.}\)</span> In our example, if you use a threshold value of 10 we obtain the new matrix <span class="process-math">\(M_1\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ {\tiny{\begin{array}{cccccccccccccccc}  208.0\amp  202.0\amp  178.0\amp  165.0\amp 155.0\amp  172.0\amp  118.0\amp  172.0\amp  155.0\amp  153.0\amp  176.0\amp  202.0\amp  208.0\amp  210.0\amp 209.0\amp  208.0\\ 33.4\amp  24.1\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  42.8 \amp  0.0\amp  0.0\amp  12.8\amp  0.0\amp  24.7\amp  30.6\amp  33.4\amp  32.5\amp  31.6 \\ 0.0\amp - 13.8\amp  19.4\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp 0.0\amp  19.4\amp - 13.8\amp  0.0\amp  0.0\amp  0.0\amp  0.0\\ 17.5\amp  61.9\amp 61.9\amp  0.0\amp  0.0\amp  61.9\amp  0.0\amp  61.9\amp  0.0\amp  30.6\amp  65.0\amp  66.9\amp  66.9\amp  19.4\amp 66.9\amp  66.9\\ 0.0\amp  27.5\amp  43.8\amp  16.2\amp  0.0\amp - 11.2\amp 16.2\amp - 11.2\amp  0.0\amp  16.2\amp  43.8\amp  27.5\amp  0.0\amp  0.0\amp  0.0\amp  0.0 \\ 0.0\amp  0.0\amp  27.5\amp - 11.2\amp  0.0\amp - 16.2\amp  22.5\amp - 16.2\amp 0.0\amp - 11.2\amp  27.5\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\\ 47.5\amp 0.0\amp  0.0\amp  13.8\amp  82.5\amp  0.0\amp  0.0\amp  0.0\amp  82.5\amp  13.8\amp  0.0\amp  0.0\amp  0.0\amp  51.2\amp 0.0\amp  0.0\\ 82.5\amp  41.2\amp  41.2\amp  82.5\amp  82.5\amp  41.2\amp  0.0\amp 41.2\amp  82.5\amp  35.0\amp  35.0\amp  35.0\amp  35.0\amp  82.5\amp  35.0\amp  35.0 \\ 0.0\amp  0.0\amp  0.0\amp  55.0\amp - 22.5\amp - 22.5\amp  55.0\amp - 22.5\amp - 22.5\amp  55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\\ 0.0\amp 55.0\amp - 22.5\amp - 22.5\amp  22.5\amp  0.0\amp - 22.5\amp  0.0\amp  22.5\amp - 22.5\amp - 22.5\amp  55.0\amp 0.0\amp  0.0\amp  0.0\amp  0.0\\ 0.0\amp  0.0\amp - 55.0\amp  22.5\amp  22.5\amp - 22.5\amp  0.0\amp - 22.5\amp  22.5\amp  22.5\amp - 55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0 \\ 0.0\amp  0.0\amp  0.0\amp  0.0\amp  22.5\amp - 55.0\amp  0.0\amp - 55.0\amp  22.5 \amp  0.0\amp  0.0\amp  0.0\amp - 15.0\amp  0.0\amp  0.0\amp  0.0\\ 0.0\amp  0.0\amp 0.0\amp - 55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp - 55.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp 0.0\\ 95.0\amp  0.0\amp  0.0\amp - 82.5\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp 0.0\amp - 82.5\amp  0.0\amp  0.0\amp  0.0\amp  95.0\amp  0.0\amp  0.0\\ 0.0\amp - 82.5\amp  82.5\amp  0.0\amp  0.0\amp - 82.5\amp  0.0\amp - 82.5\amp  0.0\amp  95.0\amp - 95.0\amp  95.0\amp - 95.0\amp  0.0\amp  95.0\amp - 95.0\\ 0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp 0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0\amp  0.0 \end{array}  }} \right]\text{.}
\end{equation*}
</div>
<p id="p-5733">We now have introduced many zeros in our matrix. This is where we compress the image. To store the original image, we need to store every pixel. Once we introduce strings of zeros we can identify a new code (say 256) that indicates we have a string of zeros. We can then follow that code with the number of zeros in the string. So if we had a string of 15 zeros in a signal, we could store that information in 2 bytes rather than 15 and obtain significant savings in storage. This process removes some detail from our picture, but only the small detail. To convert back to an image, we just undo the forward processing by multiplying our thresholded matrix <span class="process-math">\(M_1\)</span> by <span class="process-math">\(A_{16}^{-1}\text{.}\)</span> The ultimate goal is to obtain significant compression but still have <span class="process-math">\(A_{16}^{-1}M_1\)</span> retain all of the essence of the original image.</p>
<p id="p-5734">In our example using <span class="process-math">\(M_1\text{,}\)</span> the reconstructed image matrix is <span class="process-math">\(A_{16}^{-1}M_1\)</span> (rounded to the nearest whole number) is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[  \begin{array}{cccccccccccccccc}  242\amp  240\amp  241\amp  237\amp 132\amp  138\amp  232\amp  138\amp  132\amp  238\amp  239\amp  240\amp  238\amp  244\amp 242\amp  240\\ 242\amp  240\amp  241\amp  127\amp  178\amp 183\amp  122\amp  183\amp  178\amp  128\amp  239\amp  240\amp  238\amp  244\amp  242\amp 240\\ 242\amp  240\amp  131\amp  127\amp  178\amp  183\amp 122\amp  183\amp  178\amp  128\amp  129\amp  240\amp  238\amp  244\amp  242\amp  240 \\ 242\amp  130\amp  176\amp  172\amp  132\amp  183\amp  167\amp 183\amp  132\amp  172\amp  174\amp  130\amp  238\amp  244\amp  242\amp  240 \\ 242\amp  240\amp  131\amp  177\amp  178\amp  133\amp  183\amp 133\amp  178\amp  178\amp  129\amp  240\amp  238\amp  244\amp  242\amp  240 \\ 242\amp  240\amp  241\amp  132\amp  132\amp  178\amp  183\amp 178\amp  132\amp  132\amp  239\amp  240\amp  238\amp  244\amp  242\amp  240 \\ 242\amp  240\amp  131\amp  177\amp  178\amp  133\amp  138\amp 133\amp  178\amp  178\amp  129\amp  240\amp  223\amp  244\amp  242\amp  240 \\ 242\amp  240\amp  131\amp  177\amp  132\amp  243\amp  138\amp 243\amp  132\amp  178\amp  129\amp  240\amp  253\amp  244\amp  242\amp  240 \\ 240\amp  240\amp  239\amp  124\amp  238\amp  234\amp  75\amp 234\amp  238\amp  130\amp  241\amp  244\amp  244\amp  248\amp  244\amp  244 \\ 240\amp  240\amp  239\amp  234\amp  238\amp  234\amp  75\amp 234\amp  238\amp  240\amp  241\amp  244\amp  244\amp  248\amp  244\amp  244 \\ 240\amp  240\amp  239\amp  69\amp  73\amp  234\amp  75\amp 234\amp  73\amp  75\amp  241\amp  244\amp  244\amp  240\amp  244\amp  244 \\ 50\amp  240\amp  239\amp  234\amp  73\amp  234\amp  75\amp 234\amp  73\amp  240\amp  241\amp  244\amp  244\amp  50\amp  244\amp  244 \\ 240\amp  75\amp  239\amp  248\amp  238\amp  69\amp  75\amp 69\amp  238\amp  240\amp  51\amp  240\amp  50\amp  240\amp  240\amp  50 \\ 240\amp  240\amp  74\amp  248\amp  238\amp  234\amp  75\amp 234\amp  238\amp  50\amp  241\amp  50\amp  240\amp  240\amp  50\amp  240 \\ 75\amp  75\amp  74\amp  83\amp  73\amp  69\amp  75\amp  69\amp 73\amp  75\amp  76\amp  75\amp  75\amp  75\amp  75\amp  75\\ 75\amp  75\amp  74\amp  83\amp  73\amp  69\amp  75\amp  69\amp  73\amp  75\amp  76\amp 75\amp  75\amp  75\amp  75\amp  75 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p id="p-5735">We convert this into a gray-scale image and obtain the image at right in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a>. Compare this image to the original at right in <a href="" class="xref" data-knowl="./knowl/F_Flower_1.html" title="Figure 32.1">Figure 32.1</a>. It is difficult to tell the difference.</p>
<p id="p-5736">There is a Sage file you can use at <a class="external" href="http://faculty.gvsu.edu/schlicks/Wavelets_Sage.html" target="_blank"><code class="code-inline tex2jax_ignore">faculty.gvsu.edu/schlicks/Wavelets_Sage.html</code></a> that allows you to create your own 16 by 16 image and process, process your image with the Haar wavelets in <span class="process-math">\(\R^{16}\text{,}\)</span> apply thresholding, and reconstruct the compressed image. matrix. You can create your own image, experiment with several different threshold levels, and choose the one that you feel gives the best combination of strings of 0s while reproducing a reasonable copy of the original image.</p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-58"><div class="fn">see <a class="external" href="https://ccrma.stanford.edu/groups/edison/brahms/brahms.html" target="_blank"><code class="code-inline tex2jax_ignore">ccrma.stanford.edu/groups/edison/brahms/brahms.html</code></a> for a discussion of the denoising of a Brahms recording</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-59"><div class="fn">A review of wavelets in biomedical applications. M. Unser, A. Aldroubi. <span class="booktitle">Proceedings of the IEEE</span>, Volume: 84, Issue: 4 , Apr 1996</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-60"><div class="fn">The first mention of wavelets appeared in an appendix to the thesis of A. Haar in 1909.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
