<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-08T14:56:13-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Introduction to Eigenvalues and Eigenvectors</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_matrix_operations.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-matrices.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_matrix_inverse.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_matrix_operations.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-matrices.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_matrix_inverse.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Sqaures Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_intro_eigenvals_eigenvects"><h2 class="heading">
<span class="type">Chapter</span> <span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span>
</h2>
<section class="introduction" id="introduction-136"><article class="objectives goal-like" id="objectives-9"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-137"><p id="p-1525">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-273"><p id="p-1526">What is an eigenvalue of a matrix?</p></li>
<li id="li-274"><p id="p-1527">What is an eigenvector of a matrix?</p></li>
<li id="li-275"><p id="p-1528">How do we find eigenvectors of a matrix corresponding to an eigenvalue?</p></li>
<li id="li-276"><p id="p-1529">How can the action of a matrix on an eigenvector be visualized?</p></li>
<li id="li-277"><p id="p-1530">Why do we study eigenvalues and eigenvectors?</p></li>
<li id="li-278"><p id="p-1531">What are discrete dynamical systems and how do we analyze the long-term behavior in them?</p></li>
</ul></article></section><section class="section" id="sec_appl_pagerank"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Application: The Google PageRank Algorithm</span>
</h3>
<p id="p-1532">The World Wide Web is a vast collection of information, searchable via search engines. A search engine looks for pages that are of interest to the user. In order to be effective, a search engine needs to be able to identify those pages that are relevant to the search criteria provided by the user. This involves determining the relative importance of different web pages by ranking the results of thousands or millions of pages fitting the search criteria. For Google, the PageRank algorithm is their method and is “the heart of our software” as they say. It is this PageRank algorithm that we will learn about later in this section. Eigenvalues and eigenvectors play an important role in this algorithm.</p></section><section class="section" id="sec_eigen_intro"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-1533">Given a matrix <span class="process-math">\(A\text{,}\)</span> for some special non-zero vectors <span class="process-math">\(\vv\)</span> the action of <span class="process-math">\(A\)</span> on <span class="process-math">\(\vv\)</span> will be same as scalar multiplication, i.e., <span class="process-math">\(A\vv=\lambda \vv\)</span> for some scalar <span class="process-math">\(\lambda\text{.}\)</span> Geometrically, this means that the transformation <span class="process-math">\(T\)</span> defined by <span class="process-math">\(T(\vx) = A\vx\)</span> simply stretches or contracts the vector <span class="process-math">\(\vv\)</span> but does not change its direction. Such a <em class="emphasis">nonzero</em> vector is called an <dfn class="terminology">eigenvector</dfn> of <span class="process-math">\(A\text{,}\)</span> while the scalar <span class="process-math">\(\lambda\)</span> is called the corresponding <dfn class="terminology">eigenvalue</dfn> of <span class="process-math">\(A\text{.}\)</span> The eigenvectors of a matrix tell us quite a bit about the transformation the matrix defines.</p>
<p id="p-1534">Eigenvalues and eigenvectors are used in many applications. Social media like Facebook and Google use eigenvalues to determine the influence of individual members on the network (which can affect advertising) or to rank the importance of web pages. Eigenvalues and eigenvectors appear in quantum physics, where atomic and molecular orbitals can be defined by the eigenvectors of a certain operator. They appear in principal component analysis, used to study large data sets, to diagonalize certain matrices and determine the long term behavior of systems as a result, and in the important singular value decomposition of a matrix. Matrices with real entries can have real or complex eigenvalues, and complex eigenvalues reveal a rotation that is encoded in every real matrix with complex eigenvalues which allows us to better understand certain matrix transformations.</p>
<article class="definition definition-like" id="def_eigenvector"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">9.1</span><span class="period">.</span>
</h4>
<p id="p-1535">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix. A non-zero vector <span class="process-math">\(\vx\)</span> is an <dfn class="terminology">eigenvector</dfn> (or <dfn class="terminology">characteristic vector</dfn>) of <span class="process-math">\(A\)</span> if there is a scalar <span class="process-math">\(\lambda\)</span> such that <span class="process-math">\(A\vx = \lambda \vx\text{.}\)</span> The scalar <span class="process-math">\(\lambda\)</span> is an <dfn class="terminology">eigenvalue</dfn> (or <dfn class="terminology">characteristic value</dfn>) of <span class="process-math">\(A\text{.}\)</span></p></article><p id="p-1536">For example, <span class="process-math">\(\vv= \left[ \begin{array}{c} 1\\1 \end{array} \right]\)</span> is an eigenvector of <span class="process-math">\(A=\left[ \begin{array}{cc} 2 \amp 1 \\ 3 \amp 0 \end{array} \right]\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda=3\)</span> because <span class="process-math">\(A\vv = \left[ \begin{array}{c} 3\\3 \end{array} \right]\text{,}\)</span> which is equal to <span class="process-math">\(3\vv\text{.}\)</span> On the other hand, <span class="process-math">\(\vw= \left[ \begin{array}{c} 1\\2 \end{array} \right]\)</span> is not an eigenvector of <span class="process-math">\(A=\left[ \begin{array}{cc} 2 \amp 1 \\ 3 \amp 0 \end{array} \right]\)</span> because <span class="process-math">\(A\vw = \left[ \begin{array}{c} 4\\3 \end{array} \right]\text{,}\)</span> which is not a multiple of <span class="process-math">\(\vw\text{.}\)</span></p>
<article class="exploration project-like" id="pa_2_b_1"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">9.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-471"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-138"><p id="p-1537">For each of the following parts, use the definition of an eigenvector to determine whether the given vector <span class="process-math">\(\vv\)</span> is an eigenvector for the given matrix <span class="process-math">\(A\text{.}\)</span> If it is, determine the corresponding eigenvalue.</p></div>
<article class="task exercise-like" id="task-472"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1538"><span class="process-math">\(A=\left[ \begin{array}{cc} 3 \amp 2 \\ 3 \amp 8 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{r} -2\\1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-473"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1539"><span class="process-math">\(A=\left[ \begin{array}{cr} 2 \amp 0 \\ 0 \amp -3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{c} 0\\1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-474"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1540"><span class="process-math">\(A=\left[ \begin{array}{cc} 3 \amp 2 \\ 3 \amp 8 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{c} 1\\1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-475"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-1541"><span class="process-math">\(A=\left[ \begin{array}{cc} 1 \amp 2 \\ 2 \amp 4 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{r} -2\\1 \end{array} \right]\)</span></p></article></article><article class="task exercise-like" id="task-476"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-139"><p id="p-1542">We now consider how we can find the eigenvectors corresponding to an eigenvalue using the definition. Suppose <span class="process-math">\(A=\left[ \begin{array}{cr} 6 \amp -2\\2 \amp 1 \end{array} \right]\text{.}\)</span> We consider whether we can find eigenvectors corresponding to eigenvalues 3, and 5. Effectively, this will help us determine whether 3 and/or 5 are eigenvalues of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-477"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1543">Rewrite the vector equation <span class="process-math">\(A\vv=5\vv\)</span> where <span class="process-math">\(\vv = \left[ \begin{array}{c} x \\y \end{array} \right]\)</span> as a vector equation.</p></article><article class="task exercise-like" id="task-478"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1544">After writing <span class="process-math">\(5\vv\)</span> as <span class="process-math">\(5I\vv\)</span> where <span class="process-math">\(I\)</span> is the identity matrix, rearrange the variables to turn this vector equation into the homogeneous matrix equation <span class="process-math">\(B\vv=\vzero\)</span> where <span class="process-math">\(B=\left[ \begin{array}{cr} 1 \amp -2\\2 \amp -4 \end{array} \right]\text{.}\)</span> If possible, find a non-zero (i.e. a non-trivial) solution to <span class="process-math">\(B\vv=\vzero\text{.}\)</span> Explain what this means about 5 being an eigenvalue of <span class="process-math">\(A\)</span> or not.</p></article><article class="task exercise-like" id="task-479"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1545">Similarly, determine whether the vector equation <span class="process-math">\(A\vv=3\vv\)</span> has non-zero solutions. Using your result, determine whether 3 is an eigenvalue of <span class="process-math">\(A\)</span> or not.</p></article></article></article></section><section class="section" id="sec_eigval_eigvec"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Eigenvalues and Eigenvectors</span>
</h3>
<p id="p-1546">Eigenvectors are especially useful in understanding the long-term behavior of dynamical systems, an example of which we will see shortly. The long-term behavior of a dynamical system is quite simple when the initial state vector is an eigenvector and this fact helps us analyze the system in general.</p>
<p id="p-1547">To find eigenvectors, we are interested in determining the vectors <span class="process-math">\(\vx\)</span> for which <span class="process-math">\(A\vx\)</span> has the same direction as <span class="process-math">\(\vx\text{.}\)</span> This will happen when</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/def_eigenvector.html">
\begin{equation*}
A\vx = \lambda \vx
\end{equation*}
</div>
<p class="continuation">for some scalar <span class="process-math">\(\lambda\text{.}\)</span> Of course, <span class="process-math">\(A\vx = \lambda \vx\)</span> when <span class="process-math">\(\vx = \vzero\)</span> for every <span class="process-math">\(A\)</span> and every <span class="process-math">\(\lambda\text{,}\)</span> but that is uninteresting. So we really want to consider when there is a <em class="emphasis">non-zero</em> vector <span class="process-math">\(\vx\)</span> so that <span class="process-math">\(A\vx = \lambda \vx\text{.}\)</span> This prompts the definition of eigenvectors and eigenvalues as in <a href="" class="xref" data-knowl="./knowl/def_eigenvector.html" title="Definition 9.1">Definition 9.1</a></p>
<p id="p-1548"> In order for a matrix <span class="process-math">\(A\)</span> to have an eigenvector, one condition <span class="process-math">\(A\)</span> must satisfy is that <span class="process-math">\(A\)</span> has to be a square matrix, i.e. an <span class="process-math">\(n \times n\)</span> matrix. We will find that each <span class="process-math">\(n\times n\)</span> matrix has only finitely many eigenvalues.</p>
<p id="p-1549">The terms eigenvalue and eigenvector seem to come from Hilbert, using the German “eigen” (roughly translated as “own”, “proper”, or “characteristic”) to emphasize how eigenvectors and eigenvalues are connected to their matrices. To find the eigenvalues and eigenvectors of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we need to find the solutions to the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \vx = \lambda \vx \,\text{.}
\end{equation*}
</div>
<p id="p-1550">In <a href="" class="xref" data-knowl="./knowl/pa_2_b_1.html" title="Preview Activity 9.1">Preview Activity 9.1</a>, we considered this equation for <span class="process-math">\(A=\left[ \begin{array}{cr} 6\amp -2 \\ 2\amp 1 \end{array}  \right]\)</span> and <span class="process-math">\(\lambda=5\text{.}\)</span> The homogeneous matrix equation we came up with was</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_2_b_1.html">
\begin{equation*}
\left[ \begin{array}{cr} 1\amp -2 \\ 2\amp -4 \end{array} \right] \vx = \vzero \,\text{.}
\end{equation*}
</div>
<p id="p-1551">To see the relationship between this homogeneous matrix equation and the eigenvalue-eigenvector equation better, let us consider the eigenvector equation using matrix algebra:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-98">
\begin{align*}
A\vx \amp = \lambda\vx\\
A\vx - \lambda \vx \amp = \vzero\\
A\vx - \lambda I_n\vx \amp = \vzero\\
(A-\lambda I_n)\vx \amp = \vzero\text{,}
\end{align*}
</div>
<p class="continuation">where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix. Notice that this description matches the homogenous equation matrix example above since we simply subtracted 5 from the diagonal terms of the matrix <span class="process-math">\(A\text{.}\)</span> Hence, to find eigenvalues, we need to find the values of <span class="process-math">\(\lambda\)</span> so that the homogeneous equation <span class="process-math">\((A - \lambda I_n)\vx=\vzero\)</span> has non-trivial solutions.</p>
<article class="activity project-like" id="activity-35"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">9.2</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-480"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1552">Under what conditions on <span class="process-math">\(A-\lambda I_n\)</span> will the matrix equation <span class="process-math">\((A-\lambda I_n)\vx=\vzero\)</span> have non-trivial solutions? Describe at least two different but equivalent conditions.</p></article><article class="task exercise-like" id="task-481"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1553">The real number 0 is an eigenvalue of <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 4 \end{array} \right]\text{.}\)</span> Check that your criteria in the previous part agrees with this result.</p></article><article class="task exercise-like" id="task-482"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1554">Determine if 5 is an eigenvalue of the matrix <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 4 \end{array} \right]\)</span> using your criterion above.</p></article><article class="task exercise-like" id="task-483"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1555">What are the two eigenvalues of the matrix <span class="process-math">\(A = \left[ \begin{array}{cc} 3\amp 2\\4\amp 5 \end{array} \right]\text{?}\)</span></p></article></article><p id="p-1556">Since an eigenvector of <span class="process-math">\(A\)</span> corresponding to eigenvalue <span class="process-math">\(\lambda\)</span> is a non-trivial solution to the homogeneous equation <span class="process-math">\((A - \lambda I_n)\vx = \vzero\text{,}\)</span> the eigenvalues <span class="process-math">\(\lambda\)</span> which work are those for which the matrix <span class="process-math">\(A-\lambda I_n\)</span> has linearly dependent columns, or for which the row echelon form of the matrix <span class="process-math">\(A-\lambda I_n\)</span> does not have a pivot in every column. When we need to test if a specific <span class="process-math">\(\lambda\)</span> is an eigenvalue, this method works fine. However, finding which <span class="process-math">\(\lambda\)</span>'s will work in general involves row reducing a matrix with <span class="process-math">\(\lambda\)</span>'s subtracted on the diagonal algebraically. For certain types of matrices, this method still provides us the eigenvalues quickly. For general matrices though, row reducing algebraically is not efficient. We will later see an algebraic method which uses the determinants to find the eigenvalues.</p>
<article class="activity project-like" id="activity-36"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">9.3</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-484"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1557">For <span class="process-math">\(\lambda\)</span> to be an eigenvalue of <span class="process-math">\(A\text{,}\)</span> we noted that <span class="process-math">\(A-\lambda I_n\)</span> must have a non-pivot column. Use this criterion to explain why <span class="process-math">\(A=\left[ \begin{array}{rc} -2\amp 2\\0\amp 4 \end{array} \right]\)</span> has eigenvalues <span class="process-math">\(\lambda=-2\)</span> and <span class="process-math">\(\lambda=4\text{.}\)</span></p></article><article class="task exercise-like" id="task-485"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1558">Determine the eigenvalues of <span class="process-math">\(A = \left[ \begin{array}{ccrc} 3\amp 0\amp 1\amp 0 \\ 0\amp 2\amp -1\amp 0 \\ 0\amp 0\amp 2\amp 0 \\ 0\amp 0\amp 0\amp 1 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-486"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1559">Generalize your results from the above parts in the form of a theorem in the most general <span class="process-math">\(n\times n\)</span> case.</p></article></article></section><section class="section" id="sec_dynam_sys"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Dynamical Systems</span>
</h3>
<p id="p-1560">One real-life application of eigenvalues and eigenvectors is in analyzing the long-term behavior of <dfn class="terminology">discrete dynamical systems</dfn>. A <dfn class="terminology">dynamical system</dfn> is a system of variables whose values change with time. In discrete systems, the change is described by defining the values of the variables at time <span class="process-math">\(t+1\)</span> in terms of the values at time <span class="process-math">\(t\text{.}\)</span> For example, the discrete dynamical system</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
y_{t+1} = y_t + t
\end{equation*}
</div>
<p class="continuation">relates the value of <span class="process-math">\(y\)</span> at time <span class="process-math">\(t+1\)</span> to the value of <span class="process-math">\(y\)</span> at time <span class="process-math">\(t\text{.}\)</span> This is in contrast with a differential equation<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-13" id="fn-13"><sup> 13 </sup></a> such as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{dy}{dt} = y+t\text{,}
\end{equation*}
</div>
<p class="continuation">which describes the instantaneous rate of change of <span class="process-math">\(y(t)\)</span> in terms of <span class="process-math">\(y\)</span> and <span class="process-math">\(t\text{.}\)</span></p>
<p id="p-1561">Discrete dynamical systems can be used in population modeling to provide a simplified model of predator-prey interactions in biology (see <a href="" class="xref" data-knowl="./knowl/pa_2_b_2.html" title="Activity 9.4">Activity 9.4</a>). Other applications include Markov chains (see <a href="" class="xref" data-knowl="./knowl/ex_2_b_Markov.html" title="Exercise 5">Exercise 5</a>), age structured population growth models, distillation of a binary ideal mixture of two liquids, cobweb model in economics concerning the interaction of supply and demand for a single good, queuing theory and traffic flow.</p>
<p id="p-1562">Eigenvectors can be used to analyze the long-term behavior of dynamical systems.</p>
<article class="activity project-like" id="pa_2_b_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">9.4</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-487"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-140">
<p id="p-1563">Consider a discrete dynamical system providing a simplified model of predator-prey interactions in biology, such as the system describing the populations of rabbits and foxes in a certain area. Suppose, for example, for a specific area the model is given by the following equations:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_PA5_1_3">
\begin{equation}
\begin{alignedat}{4} r_{k+1}  \amp {}={}   \amp {1.14}r_k   \amp {}-{}  \amp {0.12}f_k \\ f_{k+1}  \amp {}={}   \amp {0.08}r_k   \amp {}+{}  \amp {0.86}f_k \end{alignedat}\tag{9.1}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(r_i\)</span> represents the number of rabbits in the area <span class="process-math">\(i\)</span> years after a starting time value, and <span class="process-math">\(f_i\)</span> represents the number of foxes in year <span class="process-math">\(i\text{.}\)</span> We use <span class="process-math">\(r_0, f_0\)</span> to denote the initial population values.</p>
</div>
<article class="task exercise-like" id="task-488"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1564">Suppose <span class="process-math">\(r_k=300\)</span> and <span class="process-math">\(f_k=100\)</span> for one year. Calculate rabbit and fox population values for the next year. In other words, find <span class="process-math">\(r_{k+1}, f_{k+1}\)</span> values.</p></article><article class="task exercise-like" id="task-489"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1565">Consider the coefficients of the variables <span class="process-math">\(r_k, f_k\)</span> in the the system of equations in <a href="" class="xref" data-knowl="./knowl/eq_PA5_1_3.html" title="Equation 9.1">(9.1)</a>. Can you explain the reasoning behind the signs and absolute sizes of the coefficients from the story that it models?</p></article><article class="task exercise-like" id="task-490"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1566">Let <span class="process-math">\(\vx_k=\left[ \begin{array}{c} r_k \\ f_k \end{array}  \right]\text{.}\)</span> The vector <span class="process-math">\(\vx_k\)</span> is called the <dfn class="terminology">state vector</dfn> of the system at time <span class="process-math">\(k\text{,}\)</span> because it describes the state of the whole system at time <span class="process-math">\(k\text{.}\)</span> We can rewrite the system of equations in <a href="" class="xref" data-knowl="./knowl/eq_PA5_1_3.html" title="Equation 9.1">(9.1)</a> as a matrix-vector equation in terms of the state vectors at time <span class="process-math">\(k\)</span> and <span class="process-math">\(k+1\text{.}\)</span> More specifically, the equation will be of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_3.html" id="eq_PA5_1_4">
\begin{equation}
\vx_{k+1} = A\vx_k\tag{9.2}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(A = \left[ \begin{array}{cr} 1.14 \amp  -0.12 \\ 0.08 \amp  0.86 \end{array}  \right]\text{.}\)</span> We will call this matrix the <dfn class="terminology">transition matrix</dfn> of the system. Check that <span class="process-math">\(A \left[ \begin{array}{c} 300\\100 \end{array}  \right]\)</span> gives us the population values you calculated in the first part above.</p></article><article class="task exercise-like" id="task-491"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-1567">The transition matrix will help us simplify calculations of the population values. Note that equation <a href="" class="xref" data-knowl="./knowl/eq_PA5_1_4.html" title="Equation 9.2">(9.2)</a> implies that <span class="process-math">\(\vx_1 = A\vx_0\text{,}\)</span> <span class="process-math">\(\vx_2=A\vx_1\text{,}\)</span> <span class="process-math">\(\vx_3=A\vx_2\text{,}\)</span> and so on. This is a recursive method to find the population values as each year's population values depend on the previous year's population values. Using this approach, calculate <span class="process-math">\(\vx_k\)</span> for <span class="process-math">\(k\)</span> values up to 5 corresponding to the following <em class="emphasis">three different</em> initial rabbit-fox population values (all in thousands):</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_4.html">
\begin{equation*}
r_0=300 \;,\;  f_0=100
\end{equation*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_4.html">
\begin{equation*}
r_0=100 \;,\;  f_0=200
\end{equation*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_4.html">
\begin{equation*}
r_0=1200 \;,\; f_0=750
\end{equation*}
</div>
<p class="continuation">Can you guess the long-term behavior of the population values in each case? Are they both increasing? Decreasing? One increasing, one decreasing? How do the rabbit and fox populations compare?</p></article></article></article><p id="p-1568">A dynamical system is a system of variables whose values change with time. In <a href="" class="xref" data-knowl="./knowl/pa_2_b_2.html" title="Activity 9.4">Activity 9.4</a>, we considered the discrete dynamical system modeling the rabbit and fox population in an area, which is an example of a predator-prey system. The system was given by the equations from <a href="" class="xref" data-knowl="./knowl/eq_PA5_1_3.html" title="Equation 9.1">(9.1)</a>, where <span class="process-math">\(r_i\)</span> represented the number of rabbits in the area <span class="process-math">\(i\)</span> years after a starting time value, and <span class="process-math">\(f_i\)</span> represented the number of foxes in year <span class="process-math">\(i\text{.}\)</span> In this notation, <span class="process-math">\(r_0, f_0\)</span> corresponded to the initial population values.</p>
<p id="p-1569"> As we saw in <a href="" class="xref" data-knowl="./knowl/pa_2_b_2.html" title="Activity 9.4">Activity 9.4</a>, if we define the state vector as <span class="process-math">\(\vx_k=\begin{bmatrix}r_k \\ f_k \end{bmatrix}\text{,}\)</span> the system of equations representing the dynamical system can be expressed as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_2_b_2.html ./knowl/eq_state_vector_recursive_formula.html" id="eq_state_vector_recursive_formula">
\begin{equation}
\vx_{k+1} = A \vx_k\tag{9.3}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(A=\left[ \begin{array}{cr} 1.14 \amp  -0.12 \\ 0.08 \amp  0.86 \end{array}  \right]\)</span> represents the transition matrix. Note that equation <a href="" class="xref" data-knowl="./knowl/eq_state_vector_recursive_formula.html" title="Equation 9.3">(9.3)</a> encodes infinitely many equations including <span class="process-math">\(\vx_1 = A\vx_0\text{,}\)</span> <span class="process-math">\(\vx_2=A\vx_1\text{,}\)</span> <span class="process-math">\(\vx_3=A\vx_2\text{,}\)</span> and so on. This is a recursive formula for the population values as each year's population values are expressed in terms of the previous year's population values. If we want to calculate <span class="process-math">\(\vx_{10}\text{,}\)</span> this formula requires first finding the population values for years 1-9. However, we can obtain a non-recursive formula using matrix algebra. If we substitute <span class="process-math">\(\vx_1 = A\vx_0\)</span> into <span class="process-math">\(\vx_2=A\vx_1\)</span> and simplify, we find that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_2_b_2.html ./knowl/eq_state_vector_recursive_formula.html">
\begin{equation*}
\vx_2=A\vx_1= A(A\vx_0) = A^2 \vx_0 \,\text{.}
\end{equation*}
</div>
<p id="p-1570">Similarly, substituting <span class="process-math">\(\vx_2=A^2\vx_1\)</span> into the formula for <span class="process-math">\(\vx_3\)</span> gives</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_3 = A\vx_2=A(A^2 \vx_0) = A^3 \vx_0 \,\text{.}
\end{equation*}
</div>
<p id="p-1571">This process can be continued inductively to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_state_vector_closed_formula">
\begin{equation}
\vx_k=A^k \vx_0\tag{9.4}
\end{equation}
</div>
<p class="continuation">for every <span class="process-math">\(k\)</span> value. So to find the population values at any year <span class="process-math">\(k\text{,}\)</span> we only need to know the initial state vector <span class="process-math">\(\vx_0\text{.}\)</span></p>
<article class="activity project-like" id="act_dynamical_system"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">9.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-141">
<p id="p-1572">In this activity the matrix <span class="process-math">\(A\)</span> is the transition matrix for the rabbit and fox population model,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{cr} 1.14 \amp  -0.12 \\ 0.08 \amp  0.86 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-492"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1573">Suppose that the initial state vector <span class="process-math">\(\vx_0\)</span> is an eigenvector of <span class="process-math">\(A\)</span> corresponding to eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> In this case, explain why <span class="process-math">\(\vx_1=\lambda \vx_0\)</span> and <span class="process-math">\(\vx_2=\lambda^2 \vx_0\text{.}\)</span> Find the formula for <span class="process-math">\(\vx_k\)</span> in terms of <span class="process-math">\(\lambda,
k\)</span> and <span class="process-math">\(\vx_0\)</span> by applying equation <a href="" class="xref" data-knowl="./knowl/eq_state_vector_recursive_formula.html" title="Equation 9.3">(9.3)</a> iteratively.</p></article><article class="task exercise-like" id="task-493"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1574">The initial state vector <span class="process-math">\(\vx_0=\left[ \begin{array}{c} 300\\100 \end{array} \right]\)</span> is an eigenvector of <span class="process-math">\(A\text{.}\)</span> Find the corresponding eigenvalue and, using your formula from (a) for <span class="process-math">\(\vx_k\)</span> in terms of <span class="process-math">\(\lambda,
k\)</span> and <span class="process-math">\(\vx_0\text{,}\)</span> find the state vector <span class="process-math">\(\vx_k\)</span> in this case.</p></article><article class="task exercise-like" id="task-494"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1575">The initial state vector <span class="process-math">\(\vx_0=\left[ \begin{array}{c} 100\\200 \end{array} \right]\)</span> is an eigenvector of <span class="process-math">\(A\text{.}\)</span> Find the corresponding eigenvalue and, using your formula from (a) for <span class="process-math">\(\vx_k\)</span> in terms of <span class="process-math">\(\lambda,
k\)</span> and <span class="process-math">\(\vx_0\text{,}\)</span> find the state vector <span class="process-math">\(\vx_k\)</span> in this case.</p></article><article class="task exercise-like" id="task-495"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1576">Consider now an initial state vector of the form <span class="process-math">\(\vx_0=a\vv_0+b\vw_0\)</span> where <span class="process-math">\(a, b\)</span> are constants, <span class="process-math">\(\vv_0\)</span> is an eigenvector corresponding to eigenvalue <span class="process-math">\(\lambda_1\)</span> and <span class="process-math">\(\vw_0\)</span> corresponding to eigenvalue <span class="process-math">\(\lambda_2\)</span> (<span class="process-math">\(\vv_0\)</span> and <span class="process-math">\(\vw_0\)</span> are not necessarily the eigenvectors from parts (b) and (c)). Use matrix algebra and equation <a href="" class="xref" data-knowl="./knowl/eq_state_vector_closed_formula.html" title="Equation 9.4">(9.4)</a> to explain why <span class="process-math">\(\vx_k=a\lambda_1^k\vv_0+b\lambda_2^k\vw_0\text{.}\)</span></p></article><article class="task exercise-like" id="task-496"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-1577">Express the initial state vector <span class="process-math">\(\vx_0=\left[ \begin{array}{c} 1200 \\ 750 \end{array} \right]\)</span> as a linear combination of the eigenvectors <span class="process-math">\(\vv_0=\left[ \begin{array}{c}300\\ 100 \end{array} \right], \vw_0=\left[ \begin{array}{c} 100\\200 \end{array} \right]\)</span> and use your result from the previous part to find a formula for <span class="process-math">\(\vx_k\text{.}\)</span> What happens to the population values as <span class="process-math">\(k\to \infty?\)</span></p></article></article><p id="p-1578">As you discovered in <a href="" class="xref" data-knowl="./knowl/act_dynamical_system.html" title="Activity 9.5">Activity 9.5</a>, we can use linearly independent eigenvectors of the transition matrix to find a closed formula for the state vector of a dynamical system, as long as the initial state vector can be expressed as a linear combination of the eigenvectors.</p></section><section class="section" id="sec_eigen_exam"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-1579">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-17"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">9.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-142"><p id="p-1580">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2\\2\amp 4 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-497"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1581">Find all of the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-49">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1582">Recall that a scalar <span class="process-math">\(\lambda\)</span> is a eigenvalue for <span class="process-math">\(A\)</span> if there is a nonzero vector <span class="process-math">\(\vx\)</span> such that <span class="process-math">\(A \vx = \lambda \vx\)</span> or <span class="process-math">\((A-\lambda I_2) \vx = \vzero\text{.}\)</span> For this matrix <span class="process-math">\(A\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A - \lambda I_2 = \left[ \begin{array}{cc} 1-\lambda\amp 2\\2\amp 4-\lambda \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">To solve the homogeneous system <span class="process-math">\((A-\lambda I_2) \vx = \vzero\text{,}\)</span> we row reduce <span class="process-math">\(A - \lambda I_2\text{.}\)</span> To do this, we first interchange rows to get the following matrix that is row equivalent to <span class="process-math">\(A - \lambda I_2\)</span> (we do this to ensure that we have a nonzero entry in the first row and column)</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} 2\amp 4-\lambda \\ 1-\lambda\amp 2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Next we replace row two with <span class="process-math">\(\frac{1}{2}(1-\lambda)\)</span> times row one minus row two to obtain the row equivalent matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[  \begin{array}{cc} 2\amp 4-\lambda \\ 0\amp \frac{1}{2}(4-\lambda)(1-\lambda)-2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">There will be a nontrivial solution to <span class="process-math">\((A-\lambda I_2)\vx = \vzero\)</span> if there is a row of zeros in this row echelon form. Thus, we look for values of <span class="process-math">\(\lambda\)</span> that make</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{1}{2}(4-\lambda)(1-\lambda)-2 = 0\text{.}
\end{equation*}
</div>
<p class="continuation">Applying a little algebra shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-99">
\begin{align*}
\frac{1}{2}(4-\lambda)(1-\lambda)-2 \amp = 0\\
(4-\lambda)(1-\lambda) - 4 \amp = 0\\
\lambda^2 - 5 \lambda \amp = 0\\
\lambda(\lambda-5) \amp = 0\text{.}
\end{align*}
</div>
<p class="continuation">So the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(\lambda = 0\)</span> and <span class="process-math">\(\lambda = 5\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-498"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1583">Find a corresponding eigenvector for each eigenvalue found in part (a).</p>
<div class="solution solution-like" id="solution-50">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1584">Recall that an eigenvector for the eigenvalue <span class="process-math">\(\lambda\)</span> is a nonzero vector <span class="process-math">\(\vx\)</span> such that <span class="process-math">\((A - \lambda I_2) \vx = \vzero\text{.}\)</span> We consider each eigenvalue in turn.</p>
<ul class="disc">
<li id="li-279">
<p id="p-1585">When <span class="process-math">\(\lambda = 0\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A - 0 I_2 = A = \left[ \begin{array}{cc} 1\amp 2\\2\amp 4 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Technology shows that the reduced row echelon form of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} 1\amp 2 \\ 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">If <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1\\x_2 \end{array}  \right]\text{,}\)</span> then <span class="process-math">\(A \vx = \vzero\)</span> implies that <span class="process-math">\(x_2\)</span> is free and <span class="process-math">\(x_1 = -2x_2\text{.}\)</span> Choosing <span class="process-math">\(x_2 = 1\)</span> gives us the eigenvector <span class="process-math">\(\left[ \begin{array}{r} -2\\1 \end{array}  \right]\text{.}\)</span> As a check, note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} 1\amp 2\\2\amp 4 \end{array}  \right] \left[ \begin{array}{r} -2\\1 \end{array}  \right] = \left[ \begin{array}{c} 0\\0 \end{array}  \right]\text{.}
\end{equation*}
</div>
</li>
<li id="li-280">
<p id="p-1586">When <span class="process-math">\(\lambda = 5\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A - 5 I_2 = \left[ \begin{array}{rr} -4\amp 2\\2\amp -1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Technology shows that the reduced row echelon form of <span class="process-math">\(A-5I_2\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[  \begin{array}{cr} 1\amp -\frac{1}{2} \\ 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">If <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1\\x_2 \end{array}  \right]\text{,}\)</span> then <span class="process-math">\((A - 5I_2)\vx = \vzero\)</span> implies that <span class="process-math">\(x_2\)</span> is free and <span class="process-math">\(x_1 = \frac{1}{2}x_2\text{.}\)</span> Choosing <span class="process-math">\(x_2 = 2\)</span> gives us the eigenvector <span class="process-math">\(\left[ \begin{array}{c} 1\\2 \end{array}  \right]\text{.}\)</span> As a check, note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[  \begin{array}{cr} 1\amp -\frac{1}{2} \\ 0\amp 0 \end{array}  \right] \left[ \begin{array}{c} 1\\2 \end{array}  \right] = \left[ \begin{array}{c} 0\\0 \end{array}  \right]\text{.}
\end{equation*}
</div>
</li>
</ul>
</div></article></article><article class="example example-like" id="example-18"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">9.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-143">
<p id="p-1587">Accurately predicting the weather has long been an important task. Meteorologists use science, mathematics, and technology to construct models that help us understand weather patterns. These models are very sophisticated, but we will consider only a simple model. Suppose, for example, we want to learn something about whether it will be wet or dry in Grand Rapids, Michigan. To do this, we might begin by collecting some data about weather conditions in Grand Rapids and then use that to make predictions. Information taken over the course of 2017 from the National Weather Service Climate Data shows that if it was dry (meaning no measurable precipitation, either rain or snow) on a given day in Grand Rapids, it would be dry the next day with a probability of 64% and wet with a probability of 36%. Similarly, if it was wet on a given day it would be dry the next day with a probability of 47% and dry with a probability of 53%. Assuming that this pattern is one that continues in the long run, we can develop a mathematical model to make predictions about the weather.</p>
<p id="p-1588">This data tells us how the weather transitions from one day to the next, and we can succinctly represent this data in a <dfn class="terminology">transition matrix</dfn>:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_weather_transition">
\begin{equation}
T = \left[ \begin{array}{cc} 0.64\amp 0.47 \\ 0.36\amp 0.53 \end{array}  \right]\text{.}\tag{9.5}
\end{equation}
</div>
<p id="p-1589">Whether it is dry or wet on a given day is called the <dfn class="terminology">state</dfn> of that day. So our transition matrix tells us about the transition between states. Notice that if <span class="process-math">\(T = [t_{ij}]\text{,}\)</span> then the probability of moving from state <span class="process-math">\(j\)</span> to state <span class="process-math">\(i\)</span> is given by <span class="process-math">\(t_{ij}\text{.}\)</span> We can represent a state by a vector: the vector <span class="process-math">\(\left[ \begin{array}{c} 1\\0 \end{array} \right]\)</span> represents the dry state and the vector <span class="process-math">\(\left[ \begin{array}{c} 0\\1 \end{array} \right]\)</span> represents the wet state.</p>
</div>
<article class="task exercise-like" id="task-499"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1590">Calculate <span class="process-math">\(T\left[ \begin{array}{c} 1\\0 \end{array} \right]\text{.}\)</span> Interpret the meaning of this output.</p>
<div class="solution solution-like" id="solution-51">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1591">Here we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T\left[ \begin{array}{c} 1\\0 \end{array} \right]  = \left[ \begin{array}{cc} 0.64\amp 0.47 \\ 0.36\amp 0.53 \end{array}  \right] \left[ \begin{array}{c} 1\\0 \end{array} \right]  = \left[ \begin{array}{c} 0.64\\0.36 \end{array} \right]\text{.}
\end{equation*}
</div>
<p class="continuation">This output tells us the different probabilities of whether it will be dry or wet the day following a dry day.</p>
</div></article><article class="task exercise-like" id="task-500"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1592">Calculate <span class="process-math">\(T\left[ \begin{array}{c} 0\\1 \end{array} \right]\text{.}\)</span> Interpret the meaning of this output.</p>
<div class="solution solution-like" id="solution-52">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1593">Here we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T\left[ \begin{array}{c} 0\\1 \end{array} \right]  = \left[ \begin{array}{cc} 0.64\amp 0.47 \\ 0.36\amp 0.53 \end{array}  \right] \left[ \begin{array}{c} 0\\1 \end{array} \right]  = \left[ \begin{array}{c} 0.47\\0.53 \end{array} \right]\text{.}
\end{equation*}
</div>
<p class="continuation">This output tells us the different probabilities of whether it will be dry or wet the day following a wet day.</p>
</div></article><article class="task exercise-like" id="task-501"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1594">Calculate <span class="process-math">\(T\left[ \begin{array}{c} 0.3\\0.7 \end{array} \right]\text{.}\)</span> Interpret the meaning of this output.</p>
<div class="solution solution-like" id="solution-53">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1595">Here we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T\left[ \begin{array}{c} 0.3\\0.7 \end{array} \right]  = \left[ \begin{array}{cc} 0.64\amp 0.47 \\ 0.36\amp 0.53 \end{array}  \right] \left[ \begin{array}{c} 0.3\\0.7 \end{array} \right]  \approx \left[ \begin{array}{c} 0.52\\0.48 \end{array} \right]\text{.}
\end{equation*}
</div>
<p class="continuation">This output tells us there is a 52% chance of it being dry and a 48% chance of it being wet following a day when there is a 30% chance of it being dry and a 70% chance of it being wet.</p>
</div></article><article class="task exercise-like" id="task-502"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<div class="introduction" id="introduction-144">
<p id="p-1596">We can use the transition matrix to build a chain of probability vectors. We begin with an initial state, say it is dry on a given day. This initial state is represented by the initial state vector <span class="process-math">\(\vx_0 = \left[ \begin{array}{c} 1\\0 \end{array} \right]\text{.}\)</span> The probabilities that it will be dry or wet the following day are given by the vector</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_3.html">
\begin{equation*}
\vx_1 = T\vx_0 = \left[ \begin{array}{c} 0.64\\0.36 \end{array} \right]\text{.}
\end{equation*}
</div>
<p class="continuation">This output vector tells us that the next day will be dry with a 64% probability and wet with a 36% probability. For each <span class="process-math">\(k \geq 1\text{,}\)</span> we let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_3.html" id="eq_weather_chain">
\begin{equation}
\vx_{k} = T\vx_{k-1}\text{.}\tag{9.6}
\end{equation}
</div>
<p class="continuation">Thus we create a sequence of vectors that tell us the probabilities of it being dry or wet on subsequent days. The vector <span class="process-math">\(\vx_k\)</span> is called the <dfn class="terminology">state vector</dfn> of the system at time <span class="process-math">\(k\text{,}\)</span> because it describes the state of the whole system at time <span class="process-math">\(k\text{.}\)</span> We can rewrite the system of equations in <a href="" class="xref" data-knowl="./knowl/eq_PA5_1_3.html" title="Equation 9.1">(9.1)</a> as a matrix-vector equation in terms of the state vectors at time <span class="process-math">\(k\)</span> and <span class="process-math">\(k+1\text{.}\)</span> More specifically, the equation will be of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_PA5_1_3.html" id="eq_weather_chain2">
\begin{equation}
\vx_{k+1} = T\vx_k\tag{9.7}
\end{equation}
</div>
<p class="continuation">for <span class="process-math">\(k \geq 0\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-503"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1597">Starting with <span class="process-math">\(\vx_0 = \left[ \begin{array}{c} 1\\0 \end{array} \right]\text{,}\)</span> use appropriate technology to calculate <span class="process-math">\(\vx_k\)</span> for <span class="process-math">\(k\)</span> values up to 10. Round to three decimal places. What do you notice about the entries?</p>
<div class="solution solution-like" id="solution-54">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-1598">Technology shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{array}{ll} \vx_1 = \left[ \begin{array}{c} 0.640\\0.360 \end{array}  \right] \amp \vx_2 = \left[ \begin{array}{c} 0.579\\0.421 \end{array}  \right]  \\ \vx_3 = \left[ \begin{array}{c} 0.568\\0.432 \end{array}  \right] \amp \vx_4 = \left[ \begin{array}{c} 0.567\\0.433 \end{array}  \right]    \\ \vx_5 = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right] \amp \vx_6 = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right]    \\ \vx_7 = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right] \amp \vx_8 = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right]    \\ \vx_9 = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right] \amp \vx_{10} = \left[ \begin{array}{c} 0.566\\0.434 \end{array}  \right]. \end{array}
\end{equation*}
</div>
<p class="continuation">We can see that our vectors <span class="process-math">\(\vx_k\)</span> are essentially the same as we let <span class="process-math">\(k\)</span> increase.</p>
</div></article><article class="task exercise-like" id="task-504"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1599">What does the result of the previous part tell us about eigenvalues of <span class="process-math">\(T\text{?}\)</span> Explain.</p>
<div class="solution solution-like" id="solution-55">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-1600">Since our sequence seems to be converging to a vector <span class="process-math">\(\vx\)</span> satisfying <span class="process-math">\(T \vx = \vx\text{,}\)</span> we conclude that 1 is an eigenvalue of <span class="process-math">\(T\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-505"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1601">Rewrite <span class="process-math">\(T\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T = \left[  \begin{array}{cc} \frac{64}{100}\amp \frac{47}{100} \\ \frac{36}{100}\amp \frac{53}{100} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">We do this so we can use exact arithmetic. Let <span class="process-math">\(\vx = \left[  \begin{array}{c} \frac{47}{83} \\ \frac{36}{83} \end{array}  \right]\text{.}\)</span> What is <span class="process-math">\(T\vx\text{?}\)</span> (Use exact arithmetic, no decimals.) Explain how <span class="process-math">\(\vx\)</span> is related to the previous two parts of this problem. What does the vector <span class="process-math">\(\vx\)</span> tells us about weather in Grand Rapids?</p>
<div class="solution solution-like" id="solution-56">
<h6 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h6>
<p id="p-1602">A matrix vector multiplication shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T \vx = \left[  \begin{array}{cc} \frac{64}{100}\amp \frac{47}{100} \\ \frac{36}{100}\amp \frac{53}{100} \end{array}  \right]\left[  \begin{array}{c} \frac{47}{83} \\ \frac{36}{83} \end{array}  \right] = \left[  \begin{array}{c} \frac{47}{83} \\ \frac{36}{83} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">In other words, <span class="process-math">\(\vx\)</span> is an eigenvector for <span class="process-math">\(T\)</span> with eigenvalue 1. Notice that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{47}{83} \approx 0.566 \ \text{ and }  \ \frac{36}{83} \approx 0.434\text{,}
\end{equation*}
</div>
<p class="continuation">so these fractions give the same results we obtained with our sequence of vectors <span class="process-math">\(\vx_k\text{.}\)</span> These vectors provide a steady-state vector for Grand Rapids weather. In other words, if there is a <span class="process-math">\(56.6\%\)</span> chance of it being dry on a given day in Grand Rapids, then there is a <span class="process-math">\(56.6\%\)</span> chance it will be dry again the next day.</p>
</div></article></article><div class="conclusion" id="conclusion-1">
<p id="p-1603">This is an example of a Markov process. Markov processes (named after Andrei Andreevich Markov) are widely used to model phenomena in biology, chemistry, business, physics, engineering, the social sciences, and much more. More specifically,</p>
<article class="definition definition-like" id="def_Markov"><h5 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">9.4</span><span class="period">.</span>
</h5>
<p id="p-1604">A <dfn class="terminology">Markov process</dfn> is a process in which the probability of the system being in a given state depends only on the previous state.</p></article><p id="p-1605">If <span class="process-math">\(\vx_0\)</span> is a vector which represents the initial state of a Markov process, then there is a matrix <span class="process-math">\(T\)</span> (the <dfn class="terminology">transition matrix</dfn>) such that the state of the system after one iteration is given by the vector <span class="process-math">\(T\vx_0\text{.}\)</span> This produces a chain of state vectors <span class="process-math">\(T\vx_0\text{,}\)</span> <span class="process-math">\(T^2 \vx_0\text{,}\)</span> <span class="process-math">\(T^3 \vx_0\text{,}\)</span> etc., where the state of the system after <span class="process-math">\(n\)</span> iterations is given by <span class="process-math">\(T^n \vx_0\text{.}\)</span> Such a chain of vectors is called a <dfn class="terminology">Markov chain</dfn>. A Markov process is characterized by two properties:</p>
<ul class="disc">
<li id="li-281"><p id="p-1606">the total number of observations remains fixed (this is reflected in the fact that the sum of the entries in each column of the matrix <span class="process-math">\(T\)</span> is 1), and</p></li>
<li id="li-282"><p id="p-1607">no observation is lost (this means the entries in the matrix <span class="process-math">\(T\)</span> cannot be negative).</p></li>
</ul>
</div></article></section><section class="section" id="sec_eigen_summ"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<p id="p-1608">We learned about eigenvalues and eigenvectors of a matrix in this section.</p>
<ul class="disc">
<li id="li-283"><p id="p-1609">A scalar <span class="process-math">\(\lambda\)</span> is an eigenvalue (or characteristic value) of a square matrix <span class="process-math">\(A\)</span> if there is a non-zero vector <span class="process-math">\(\vx\)</span> so that <span class="process-math">\(A\vx = \lambda \vx\text{.}\)</span></p></li>
<li id="li-284"><p id="p-1610">A non-zero vector <span class="process-math">\(\vx\)</span> is an eigenvector (or characteristic vector) of a square matrix <span class="process-math">\(A\)</span> if there is a scalar <span class="process-math">\(\lambda\)</span> so that <span class="process-math">\(A\vx = \lambda \vx\text{.}\)</span></p></li>
<li id="li-285"><p id="p-1611">To find the eigenvectors of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> corresponding to an eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> we determine the non-trivial solutions to <span class="process-math">\((A - \lambda I_n)\vx=\vzero\)</span> where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n\times n\)</span> identity matrix.</p></li>
<li id="li-286"><p id="p-1612">We study eigenvectors and eigenvalues because the eigenvectors tell us quite a bit about the transformation corresponding to the matrix. These eigenvectors arise in many applications in physics, chemistry, statistics, economics, biology, sociology and other areas, and help understand the long-term behavior of dynamical systems.</p></li>
<li id="li-287">
<p id="p-1613">A dynamical system is a system of variables whose values change with time. In linear dynamical systems, the change in the state vector from one time period to the next is expressed by matrix multiplication by the transition matrix <span class="process-math">\(A\text{.}\)</span> The eigenvectors of <span class="process-math">\(A\)</span> provide us a simple method to express the state vector at any given time period in terms of the initial state vector. Specifically, if the initial state vector is <span class="process-math">\(\vx_0=a\vv_0+b\vw_0\)</span> where <span class="process-math">\(\vv_0, \vw_0\)</span> are eigenvectors corresponding to eigenvalues <span class="process-math">\(\lambda_1, \lambda_2\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_k = A^k \vx_0 = \lambda_1^k a \vv_0 + \lambda_2^k b \vw_0\,\text{.}
\end{equation*}
</div>
</li>
</ul></section><section class="exercises" id="sec_eigen_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-90"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-145"><p id="p-1614">For each of the following matrix-vector pairs, determine whether the given vector is an eigenvector of the matrix.</p></div>
<article class="task exercise-like" id="task-506"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1615"><span class="process-math">\(A=\left[ \begin{array}{cc} 1\amp 2 \\ 4\amp 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{r} 1\\-1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-507"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1617"><span class="process-math">\(A=\left[ \begin{array}{cc} 1\amp 2 \\ 0\amp 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{r} 1\\1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-508"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1619"><span class="process-math">\(A=\left[ \begin{array}{rcc} 2\amp 1\amp 0 \\ 0\amp 1\amp 0 \\ -1\amp 0\amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv=\left[ \begin{array}{r} -1\\0\\1 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-91"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-146"><p id="p-1621">For each of the following matrix-eigenvalue pairs, determine an eigenvector of <span class="process-math">\(A\)</span> for the given eigenvalue.</p></div>
<article class="task exercise-like" id="task-509"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1622"><span class="process-math">\(A=\left[ \begin{array}{rc} 1\amp 2 \\ -1\amp 4 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=3\)</span></p></article><article class="task exercise-like" id="task-510"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1623"><span class="process-math">\(A=\left[ \begin{array}{cc} 1\amp 4 \\ 1\amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=3\)</span></p></article><article class="task exercise-like" id="task-511"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1624"><span class="process-math">\(A=\left[ \begin{array}{rcc} -1\amp 4\amp 1 \\ 3\amp 3\amp 0 \\ 0\amp 0\amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=5\)</span></p></article><article class="task exercise-like" id="task-512"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1625"><span class="process-math">\(A=\left[ \begin{array}{cccc} 4\amp 0\amp 0\amp 0 \\ 0\amp 2\amp 0\amp 2 \\ 2\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=4\)</span></p></article></article><article class="exercise exercise-like" id="exercise-92"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-147"><p id="p-1626">For each of the following matrix-<span class="process-math">\(\lambda\)</span> pairs, determine whether the given <span class="process-math">\(\lambda\)</span> will work as an eigenvalue. You do not need to find an eigenvector as long you can justify if <span class="process-math">\(\lambda\)</span> is a valid eigenvalue or not.</p></div>
<article class="task exercise-like" id="task-513"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1627"><span class="process-math">\(A=\left[ \begin{array}{cc} 4\amp 3 \\ 4\amp 8 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=2\)</span></p></article><article class="task exercise-like" id="task-514"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1629"><span class="process-math">\(A=\left[ \begin{array}{cr} 4\amp -2 \\ 2\amp -1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=0\)</span></p></article><article class="task exercise-like" id="task-515"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1631"><span class="process-math">\(A=\left[ \begin{array}{rc} 1\amp 2 \\ -1\amp 4 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=-1\)</span></p></article><article class="task exercise-like" id="task-516"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1633"><span class="process-math">\(A=\left[ \begin{array}{rr} 0\amp -2 \\ -1\amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\lambda=-2\)</span></p></article></article><article class="exercise exercise-like" id="exercise-93"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-148"><p id="p-1635">For a matrix <span class="process-math">\(A\)</span> with eigenvector <span class="process-math">\(\vv_1=\left[ \begin{array}{c} 1\\1 \end{array} \right]\)</span> with eigenvalue <span class="process-math">\(\lambda_1=2\text{,}\)</span> and eigenvector <span class="process-math">\(\vv_2=\left[ \begin{array}{c} 1\\2 \end{array} \right]\)</span> with eigenvalue <span class="process-math">\(\lambda_2=-1\text{,}\)</span> determine the value of the following expressions using matrix-vector product properties:</p></div>
<article class="task exercise-like" id="task-517"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1636"><span class="process-math">\(A(2\vv_1+3\vv_2)\)</span></p></article><article class="task exercise-like" id="task-518"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1637"><span class="process-math">\(A(A(\vv_1+2\vv_2))\)</span></p></article><article class="task exercise-like" id="task-519"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1638"><span class="process-math">\(A^{20} (4\vv_1-2\vv_2)\)</span></p></article></article><article class="exercise exercise-like" id="ex_2_b_Markov"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-149"><p id="p-1639">In this problem we consider a discrete dynamical system that forms what is called a <dfn class="terminology">Markov chain</dfn> (see <a href="" class="xref" data-knowl="./knowl/def_Markov.html" title="Definition 9.4">Definition 9.4</a>) which models the number of students attending and skipping a linear algebra class in a semester. Assume the course starts with 1,000,000 students on day 0. For any given class day, 90% of the students who attend a class attend the next class (and 10% of these students skip next class) while only 30% of those absent are there the next time (and 70% of these students continue skipping class).</p></div>
<article class="task exercise-like" id="task-520"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1640">We know that there will be 900,000 students in class on the second day and 100,000 students skipping class. On the third day, 90% of the 900,000 students (attenders) and 30% of the 100,000 students (skippers) will come back to class. Therefore, 840,000 students will attend class on the third day. On the other hand, 10% of 900,000 students and 70% of 100,000 students skip class on the third day, for a total of 160,000 students skipping class. We can use variables to represent these numbers. Let <span class="process-math">\(a_n\)</span> represent the number of students attending class <span class="process-math">\(n\)</span> days after first day. So <span class="process-math">\(a_0=1,000,000, a_1=900,000, a_2=840,000\text{.}\)</span> Let <span class="process-math">\(s_n\)</span> represent the students skipping class. So <span class="process-math">\(s_0=0, s_1=100,000, s_2=160,000\text{.}\)</span> Find <span class="process-math">\(a_3, s_3, a_4, s_4\text{.}\)</span></p></article><article class="task exercise-like" id="task-521"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1642">Find a linear expression for <span class="process-math">\(a_{k+1}\)</span> in terms of the previous day values, <span class="process-math">\(a_k\)</span> and <span class="process-math">\(s_k\text{,}\)</span> using the story given in the problem. Similarly, express <span class="process-math">\(s_{k+1}\)</span> in terms of <span class="process-math">\(a_k\)</span> and <span class="process-math">\(s_k\text{.}\)</span></p></article><article class="task exercise-like" id="task-522"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1644">Let <span class="process-math">\(\vb_k\)</span> represent the state vector: <span class="process-math">\(\vx_k=\begin{bmatrix}a_k\\s_k \end{bmatrix}\text{.}\)</span> It describes the state of the whole system (students attending class and skipping class) in one vector. For example, <span class="process-math">\(\vx_0=\begin{bmatrix}1,000,000\\0 \end{bmatrix}\)</span> is the initial state. The state next day is <span class="process-math">\(\vx_1=\begin{bmatrix}900,000\\100,000 \end{bmatrix}\text{.}\)</span> Using your answer to the previous part, find a matrix <span class="process-math">\(A\)</span> which describes how the system changes from one day to the other so that <span class="process-math">\(\vx_{k+1} = A\textbf{x}_k\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-95"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-150"><p id="p-1646">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-523"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1647">The number 0 cannot be an eigenvalue.</p></article><article class="task exercise-like" id="task-524"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1649">The <span class="process-math">\(\vzero\)</span> vector cannot be an eigenvector.</p></article><article class="task exercise-like" id="task-525"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1650">If <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\text{,}\)</span> then so is <span class="process-math">\(2\vv\text{.}\)</span></p></article><article class="task exercise-like" id="task-526"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1652">If <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\text{,}\)</span> then it is also an eigenvector of <span class="process-math">\(A^2\text{.}\)</span></p></article><article class="task exercise-like" id="task-527"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1653">If <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\vu\)</span> are eigenvectors of <span class="process-math">\(A\)</span> with the same eigenvalue, then <span class="process-math">\(\vv+\vu\)</span> is also an eigenvector with the same eigenvalue.</p></article><article class="task exercise-like" id="task-528"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1655">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\lambda^2\)</span> is an eigenvalue of <span class="process-math">\(A^2\text{.}\)</span></p></article><article class="task exercise-like" id="task-529"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1656">A projection matrix satisfies <span class="process-math">\(P^2=P\text{.}\)</span> If <span class="process-math">\(P\)</span> is a projection matrix, then the eigenvalues of <span class="process-math">\(P\)</span> can only be 0 and 1.</p></article><article class="task exercise-like" id="task-530"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1658">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(1+\lambda\)</span> is an eigenvalue of <span class="process-math">\(I_n+A\text{.}\)</span></p></article><article class="task exercise-like" id="task-531"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1659">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of two matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> of the same size, then <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A+B\text{.}\)</span></p></article><article class="task exercise-like" id="task-532"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1661">If <span class="process-math">\(\vv\)</span> is an eigenvector of two matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> of the same size, then it is also an eigenvector of <span class="process-math">\(A+B\text{.}\)</span></p></article><article class="task exercise-like" id="task-533"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1662">A matrix <span class="process-math">\(A\)</span> has 0 as an eigenvalue if and only if <span class="process-math">\(A\)</span> has linearly dependent columns.</p></article></article></section><section class="section" id="sec_proj_pagerank"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Project: Understanding the PageRank Algorithm</span>
</h3>
<p id="p-1664">Sergey Brin and Lawrence Page, the founders of Google, decided that the importance of a web page can be judged by the number of links to it as well as the importance of those pages. It is this idea that leads to the PageRank algorithm.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-14" id="fn-14"><sup> 14 </sup></a> Google uses this algorithm (and others) to order search engine results. According to Google:<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-15" id="fn-15"><sup> 15 </sup></a></p>
<blockquote class="blockquote" id="blockquote-9">PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other websites.</blockquote>
<p id="p-1665">To rank how “important” a website is, we need to make some assumptions. We assume that a person visits a page and then surfs the web by selecting a link from that page — all links on a given page are assigned the same probability of being chosen. As an example, assume a small set of seven pages 1, 2, 3, 4, 5, 6, and 7 with links between the pages given by the arrows as shown in <a href="" class="xref" data-knowl="./knowl/F_seven_page.html" title="Figure 9.5">Figure 9.5</a>.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-16" id="fn-16"><sup> 16 </sup></a> So, for example, there is a hyperlink from page 4 to page 3, but no hyperlink in the opposite direction. If a web surfer starts on page 5, then there is probability of <span class="process-math">\(\frac{1}{2}\)</span> that this person will surf to page 6 and a probability of <span class="process-math">\(\frac{1}{2}\)</span> that the surfer will move to page 4. If there is no link leaving a page, as in the case of page 3, then the probability of remaining there is 1.</p>
<figure class="figure figure-like" id="F_seven_page"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/seven_page_1.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">9.5<span class="period">.</span></span><span class="space"> </span>A seven page internet</figcaption></figure><p id="p-1666">To rank pages, we need to know how likely it is that a surfer will land on a given page. In our seven page example, a person can land on page 3 from page 4 with a probability of <span class="process-math">\(\frac{1}{2}\)</span> or from page 6 with a probability of <span class="process-math">\(\frac{1}{3}\text{.}\)</span> If there is a link from a page we assume that the surfer leaves the page, and if there are no links from a page then the surfer stays on that page. We also assume that the surfer does not use the “Back” key. This information for our seven page internet example can be summarized in a <dfn class="terminology">transition matrix</dfn> <span class="process-math">\(T\)</span> whose <span class="process-math">\(i,j\)</span>th entry is the probability that a surfer lands on page <span class="process-math">\(i\)</span> from page <span class="process-math">\(j\text{.}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T= \left[  \begin{array}{ccccccc} 0\amp \frac{1}{2}\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 1\amp 0\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 1\amp \frac{1}{2}\amp 0\amp \frac{1}{3}\amp 0 \\ 0\amp \frac{1}{2}\amp 0\amp 0\amp \frac{1}{2}\amp 0\amp 0 \\ 0\amp 0\amp 0\amp \frac{1}{2}\amp 0\amp \frac{1}{3}\amp 1 \\ 0\amp 0\amp 0\amp 0\amp \frac{1}{2}\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0\amp \frac{1}{3}\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1667">Let us assume in our seven page internet that a user starts on page 6. That is, the probability that the user is initially on page 6 is 1, and so the probability that the user is on some other page is 0. This information can be encapsulated in a <dfn class="terminology">state vector</dfn></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_0 = \left[ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0  \right]^{\tr}\text{.}
\end{equation*}
</div>
<p id="p-1668">Since there are links from page 6 to pages 3, 5, and 7, there is a <span class="process-math">\(\frac{1}{3}\)</span> probability that the surfer will next move to one of these pages. That means that at the next step, the state vector <span class="process-math">\(\vx_1\)</span> for this user will be</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_1 = \left[ 0 \ 0 \ \frac{1}{3} \ 0 \ \frac{1}{3} \ 0 \ \frac{1}{3} \right]^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_1 = T\vx_0\text{.}
\end{equation*}
</div>
<p class="continuation">As the user continues to surf the internet, the probabilities that the surfer is on a given page after the second, third, and fourth steps are given in the state vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_2 = T\vx_1 = T^2 \vx_0, \ \ \vx_3 = T\vx_2 = T^3 \vx_0, \ \ \vx_4 = T\vx_3 = T^4 \vx_0\text{.}
\end{equation*}
</div>
<p id="p-1669">In general, the probabilities that the surfer is on a given page after the <span class="process-math">\(n\)</span>th step is given by the state vector</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_n = T \vx_{n-1} = T^n \vx_0\text{.}
\end{equation*}
</div>
<p id="p-1670">This example illustrates the general nature of what is called a <dfn class="terminology">Markov process</dfn> (see <a href="" class="xref" data-knowl="./knowl/def_Markov.html" title="Definition 9.4">Definition 9.4</a>). The two properties of the transition matrix <span class="process-math">\(T\)</span> make <span class="process-math">\(T\)</span> a special kind of matrix.</p>
<article class="definition definition-like" id="definition-25"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">9.6</span><span class="period">.</span>
</h4>
<p id="p-1671">A <dfn class="terminology">stochastic</dfn> matrix is a matrix in which entries are nonnegative and the sum of the entries in every column is one.</p></article><p id="p-1672">In a Markov process, each generation depends only on the preceding generation and there may be a limiting value as we let the process continue indefinitely. We can test to see if that happens for this Markov process defined by <span class="process-math">\(T\)</span> by doing some experimentation.</p>
<article class="project project-like" id="act_limit"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">9.6</span><span class="period">.</span>
</h4>
<p id="p-1673">Use appropriate technology to do the following. Choose several different initial state vectors <span class="process-math">\(\vx_0\)</span> and calculate the vectors in the sequence <span class="process-math">\(\{T^n\vx_0\}\)</span> for large values of <span class="process-math">\(n\text{.}\)</span> (Note that, as state vectors, the entries of <span class="process-math">\(\vx_0\)</span> cannot be negative and the sum of the entries of <span class="process-math">\(\vx_0\)</span> must be <span class="process-math">\(1\text{.}\)</span>) Explain the behavior of the sequence <span class="process-math">\(\{\vx_n\}\)</span> as <span class="process-math">\(n\)</span> gets large. Do you notice anything strange? What aspects of our seven page internet do you think explain this behavior? Clearly communicate all of the experimentation that you do. You may use the GeoGebra applet at <a class="external" href="https://www.geogebra.org/m/b3dybnux" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/b3dybnux</code></a>.</p></article><p id="p-1674">If there is a limit of the sequence <span class="process-math">\(\{T^n\vx_0\}\)</span> (in other words, if there is a vector <span class="process-math">\(\vv\)</span> such that <span class="process-math">\(\vv = \ds \lim_{n \to \infty} T^n \vx_0\)</span>), we call this limit a <dfn class="terminology">steady-state</dfn> or <dfn class="terminology">equilibrium</dfn> vector. Such a steady-state vector has another important property. Since <span class="process-math">\(T\)</span> is independent of <span class="process-math">\(n\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Google_evector">
\begin{equation}
T \vv = T\left(\lim_{n \to \infty} T^n \vx_0 \right) = \lim_{n \to \infty} T^{n+1} \vx_0 = \vv\text{.}\tag{9.8}
\end{equation}
</div>
<p id="p-1675">Equation <a href="" class="xref" data-knowl="./knowl/eq_Google_evector.html" title="Equation 9.8">(9.8)</a> shows that a steady state vector <span class="process-math">\(\vv\)</span> is an eigenvector for <span class="process-math">\(T\)</span> with eigenvalue 1. We can interpret the steady-state vector for <span class="process-math">\(T\)</span> in an important way. Let <span class="process-math">\(t_j\)</span> be the fraction of time we spend on page <span class="process-math">\(j\)</span> and let <span class="process-math">\(l_j\)</span> be the number of links on page <span class="process-math">\(j\text{.}\)</span> Then the fraction of the time that we end up on page <span class="process-math">\(i\)</span> coming from page <span class="process-math">\(j\)</span> is <span class="process-math">\(\frac{t_j}{l_j}\text{.}\)</span> If we sum over all the pages linked to page <span class="process-math">\(i\)</span> we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Google_evector.html">
\begin{equation*}
t_i = \sum \frac{t_j}{l_j}\text{.}
\end{equation*}
</div>
<p id="p-1676">Notice that this is essentially the same process we used to obtain <span class="process-math">\(\vx_n\)</span> from <span class="process-math">\(\vx_{n-1}\text{,}\)</span> and so we can interpret the steady-state vector <span class="process-math">\(\vv\)</span> as telling us what fraction of a random web surfer's time was spent at each web page. If we assume that the time spent at a web page is a measure of its importance, then the steady-state vector tells us the relative importance of each web page. So this steady-state vector provides the page rankings for us. In other words, <blockquote class="blockquote" id="blockquote-10">The importance of a webpage may be measured by the relative size of the corresponding entry in the steady-state vector for an appropriately chosen Markov chain.</blockquote></p>
<article class="project project-like" id="project-27"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">9.7</span><span class="period">.</span>
</h4>
<p id="p-1677">Show that the limiting vector you found in <a href="" class="xref" data-knowl="./knowl/act_limit.html" title="Project Activity 9.6">Project Activity 9.6</a> is an eigenvector of <span class="process-math">\(T\)</span> with eigenvalue 1.</p></article><p id="p-1678"><a href="" class="xref" data-knowl="./knowl/act_limit.html" title="Project Activity 9.6">Project Activity 9.6</a> illustrates one problem with our seven page internet. The steady-state vector shows that page 3 is the only important page, but that hardly seems reasonable in the example since there are other pages that must have some importance. The problem is that page 3 is a “dangling” page and does not lead anywhere. Once a surfer reaches that page, they are stuck there, overemphasizing its importance. So this dangling page acts like a sink, ultimately drawing all surfers to it. To adjust for dangling pages, we make the assumption that if a surfer reaches a dangling page (one with no links emanating from it), the surfer will jump to any page on the web with equal probability. So in our seven page example, once a surfer reaches page 3 the surfer will jump to any page on the web with probability <span class="process-math">\(\frac{1}{7}\text{.}\)</span></p>
<article class="project project-like" id="LQ_G2"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">9.8</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-534"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1679">Determine the transition matrix for our seven page internet with this adjustment.</p></article><article class="task exercise-like" id="task-535"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1680">Approximate the steady-state vector for this adjusted matrix so that the entries are accurate to four decimal places. Use any appropriate technology to row reduce matrices.</p></article><article class="task exercise-like" id="task-536"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1681">According to this adjusted model, which web page is now the most important? Why? Does this seem reasonable? Why?</p></article></article><p id="p-1682">There is one more issue to address before we can consider ourselves ready to rank web pages. Consider the example of the five page internet shown in <a href="" class="xref" data-knowl="./knowl/F_five_page.html" title="Figure 9.7">Figure 9.7</a>.</p>
<figure class="figure figure-like" id="F_five_page"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/five_page_1.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">9.7<span class="period">.</span></span><span class="space"> </span>A five page internet</figcaption></figure><article class="project project-like" id="Q_no_limit"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">9.9</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-537"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1683">Explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccccc} 0\amp 0\amp 1\amp \frac{1}{2}\amp \frac{1}{5} \\ 1\amp 0\amp 0\amp 0\amp \frac{1}{5} \\ 0\amp 1\amp 0\amp 0\amp \frac{1}{5} \\ 0\amp 0\amp 0\amp 0\amp \frac{1}{5} \\ 0\amp 0\amp 0\amp \frac{1}{2}\amp \frac{1}{5} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">is the transition matrix for this five page internet. (Keep in mind the adjustment we made for dangling pages.)</p></article><article class="task exercise-like" id="task-538"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1684">Start with different initial state vectors <span class="process-math">\(\vx_0\)</span> and determine if there is a limit to the Markov chain. Explain. You may use the GeoGebra applet at <a class="external" href="https://www.geogebra.org/m/b3dybnux" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/b3dybnux</code></a>.</p></article></article><p id="p-1685"><a href="" class="xref" data-knowl="./knowl/Q_no_limit.html" title="Project Activity 9.9">Project Activity 9.9</a> shows that it is possible to construct an internet so that the corresponding Markov chain does not have a limit, even after adjusting for dangling pages. This is a significant problem if we want to provide a relative ranking of all web pages regardless of where a surfer starts. To fix this problem we need to make one final adjustment to arrive at a type of transition matrix that always provides a limit for our Markov chain.</p>
<article class="definition definition-like" id="definition-26"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">9.8</span><span class="period">.</span>
</h4>
<p id="p-1686">A stochastic matrix is <dfn class="terminology">regular</dfn> if its transition matrix <span class="process-math">\(T\)</span> has the property that for some power <span class="process-math">\(k\text{,}\)</span> all the entries of <span class="process-math">\(T^k\)</span> are positive.</p></article><p id="p-1687">Note that the transition matrix from <a href="" class="xref" data-knowl="./knowl/Q_no_limit.html" title="Project Activity 9.9">Project Activity 9.9</a> is not regular. Regular matrices have some especially nice properties, as the following theorem describes. We will not prove this theorem, but use it in the remainder of this project. The theorem shows that if we have a regular transition matrix, then there will a limit of the state vectors <span class="process-math">\(\vx_n\text{,}\)</span> and that this limit has a very interesting property.</p>
<article class="theorem theorem-like" id="thm_Google_1"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">9.9</span><span class="period">.</span>
</h4>
<p id="p-1688">Assume <span class="process-math">\(n \geq 2\)</span> and that <span class="process-math">\(T\)</span> is a regular <span class="process-math">\(n \times n\)</span> stochastic matrix.</p>
<ol class="decimal">
<li id="li-288"><p id="p-1689"><span class="process-math">\(\ds \lim_{k \to \infty} T^k\)</span> exists and is a stochastic matrix.</p></li>
<li id="li-289">
<p id="p-1690">For any vector <span class="process-math">\(\vx\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\lim_{k \to \infty} T^k \vx = \vc
\end{equation*}
</div>
<p class="continuation">for the same vector <span class="process-math">\(\vc\text{.}\)</span></p>
</li>
<li id="li-290"><p id="p-1691">The columns of <span class="process-math">\(\ds \lim_{k \to \infty} T^k\)</span> are the same vector <span class="process-math">\(\vc\text{.}\)</span></p></li>
<li id="li-291"><p id="p-1692">The vector <span class="process-math">\(\vc\)</span> is the unique eigenvector of <span class="process-math">\(T\)</span> whose entries sum to 1.</p></li>
<li id="li-292"><p id="p-1693">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(T\)</span> not equal to 1, then <span class="process-math">\(|\lambda| \lt 1\text{.}\)</span></p></li>
</ol></article><p id="p-1694">Having a regular transition matrix <span class="process-math">\(T\)</span> ensures that there is always the same limit <span class="process-math">\(\vv\)</span> to the sequence <span class="process-math">\(T^k \vx_0\)</span> for any starting vector <span class="process-math">\(\vx_0\text{.}\)</span> As mentioned before, the entries in <span class="process-math">\(\vv = \ds \lim_{n \to \infty} T^n \vx_0\)</span> can be interpreted as telling us what fraction of the random surfer's time was spent at each webpage. If we interpret the amount of time a surfer spends at a page as a measure of the page's importance, then this steady-state vector <span class="process-math">\(\vv\)</span> provides a ranking of the relative importance of each page in the web. This is the essence of Google's PageRank.</p>
<p id="p-1695">To make our final adjustment in the transition matrix to be sure that we obtain a regular matrix, we need to deal with the problems of “loops” in our internet. Loops, as illustrated in <a href="" class="xref" data-knowl="./knowl/Q_no_limit.html" title="Project Activity 9.9">Project Activity 9.9</a>, can act as sinks just like the dangling pages we saw earlier and condemn a user that enters such a loop to spend his/her time only on those pages in the loop. Quite boring! To account for this problem, we make a second adjustment.</p>
<p id="p-1696">Let <span class="process-math">\(p\)</span> be a number between 0 and 1 (Google supposedly uses <span class="process-math">\(p=0.85\)</span>). Suppose a surfer is on page <span class="process-math">\(i\text{.}\)</span> We assume with probability <span class="process-math">\(p\)</span> that the surfer will chose any link on page <span class="process-math">\(i\)</span> with equal probability. We make the additional assumption with probability <span class="process-math">\(1-p\)</span> that the surfer will select with equal probability any page on the web.</p>
<p id="p-1697">If <span class="process-math">\(T\)</span> is a transition matrix, incorporating the method we used to deal with dangling pages, then the adjusted transition matrix <span class="process-math">\(G\)</span> (the Google matrix) is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
G = pT + (1-p)Q\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(Q\)</span> is the matrix all of whose entries are <span class="process-math">\(\frac{1}{n}\text{,}\)</span> where <span class="process-math">\(n\)</span> is the number of pages in the internet (<span class="process-math">\(n=7\)</span> in our seven page example). Since all of the entries of <span class="process-math">\(G\)</span> are positive, <span class="process-math">\(G\)</span> is a regular stochastic matrix.</p>
<article class="project project-like" id="project-30"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">9.10</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-151"><p id="p-1698">Return to the seven page internet in <a href="" class="xref" data-knowl="./knowl/F_seven_page.html" title="Figure 9.5">Figure 9.5</a>.</p></div>
<article class="task exercise-like" id="task-539"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1699">Find the Google matrix <span class="process-math">\(G\)</span> for this internet.</p></article><article class="task exercise-like" id="task-540"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1700">Approximate, to four decimal places, the steady-state vector for this internet.</p></article><article class="task exercise-like" id="task-541"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1701">What is the relative rank of each page in this internet, and approximately what percentage of time does a random user spend on each page.</p></article></article><p id="p-1702">We conclude with two observations. Consider the role of the parameter <span class="process-math">\(p\)</span> in our final adjustment. Notice that if <span class="process-math">\(p=1\text{,}\)</span> then <span class="process-math">\(G = T\)</span> and we have the original hyperlink structure of the web. However, if <span class="process-math">\(p=0\text{,}\)</span> then <span class="process-math">\(G = \frac{1}{n} I_n\text{,}\)</span> where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix with <span class="process-math">\(n\)</span> as the number of pages in the web. In this case, every page is linked to every other page and a random surfer spends equal time on any page. Here we have lost all of the character of the linked structure of the web. Choosing <span class="process-math">\(p\)</span> close to 1 retains much of the original hyperlink structure of the web.</p>
<p id="p-1703">Finally, the matrices that model the web are HUGE, and so the methods we used in this project to approximate the steady-state vectors are not practical. There are many methods for approximating eigenvectors that are often used in these situations, some of which we discuss in a later section.</p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-13"><div class="fn">A differential equation is an equation that involves one or more derivatives of a function.</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-14"><div class="fn">Information for this project was taken from the websites <a class="external" href="http://www.ams.org/samplings/feature-column/fcarc-pagerank" target="_blank"><code class="code-inline tex2jax_ignore">ams.org/samplings/feature-column/fcarc-pagerank</code></a> and <a class="external" href="http://faculty.winthrop.edu/polaskit/spring11/math550/chapter.pdf" target="_blank"><code class="code-inline tex2jax_ignore">faculty.winthrop.edu/polaskit/spring11/math550/chapter.pdf</code></a>.</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-15"><div class="fn"><a class="external" href="http://web.archive.org/web/20111104131332/http://www.google.com/competition/howgooglesearchworks.html" target="_blank"><code class="code-inline tex2jax_ignore">web.archive.org/web/20111104131332/http://www.google.com/competition/howgooglesearchworks.html</code></a></div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-16"><div class="fn">The Internet is very large and has upwards of 25 billion pages. This would leave us with an enormous transition matrix, even though most of its entries are 0. In fact, studies show that web pages have an average of about 10 links, so on average all but 10 entries of each column are 0. Working with such a large matrix is beyond what we want to do in this project, so we will just amuse ourselves with small examples that illustrate the general points.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
