<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-05-25T08:17:58-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Linear Dependence and Independence</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_matrix_vector.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-systems.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_matrix_transformations.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_matrix_vector.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-systems.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_matrix_transformations.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Sqaures Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_independence"><h2 class="heading">
<span class="type">Chapter</span> <span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span>
</h2>
<section class="introduction" id="introduction-79"><article class="objectives goal-like" id="objectives-6"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-80"><p id="p-946">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-183"><p id="p-947">What are two ways to describe what it means for a set of vectors in <span class="process-math">\(\R^n\)</span> to be linearly independent?</p></li>
<li id="li-184"><p id="p-948">What are two ways to describe what it means for a set of vectors in <span class="process-math">\(\R^n\)</span> to be linearly dependent?</p></li>
<li id="li-185"><p id="p-949">If <span class="process-math">\(S\)</span> is a set of vectors, what do we mean by a basis for <span class="process-math">\(\Span \ S\text{?}\)</span></p></li>
<li id="li-186"><p id="p-950">Given a nonzero set <span class="process-math">\(S\)</span> of vectors, how can we find a linearly independent subset of <span class="process-math">\(S\)</span> that has the same span as <span class="process-math">\(S\text{?}\)</span></p></li>
<li id="li-187"><p id="p-951">How do we recognize if the columns of a matrix <span class="process-math">\(A\)</span> are linearly independent?</p></li>
<li id="li-188"><p id="p-952">How can we use a matrix to determine if a set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors is linearly independent?</p></li>
<li id="li-189"><p id="p-953">How can we use a matrix to find a minimal spanning set for a set <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \ldots, \vv_k\}\)</span> of vectors in <span class="process-math">\(\R^n\text{?}\)</span></p></li>
</ul></article></section><section class="section" id="sec_appl_bezier"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Application: Bézier Curves</span>
</h3>
<p id="p-954">Bézier curves are simple curves that were first developed in 1959 by French mathematician Paul de Casteljau, who was working at the French automaker Citroën. The curves were made public in 1962 by Pierre Bézier who used them in his work designing automobiles at the French car maker Renault. In addition to automobile design, Bézier curves have many other uses. Two of the most common applications of Bézier curves are font design and drawing tools. As an example, the letter “S” in Palatino font is shown using Bézier curves in <a href="" class="xref" data-knowl="./knowl/F_Letter_S.html" title="Figure 6.1">Figure 6.1</a>. If you've used Adobe Illustrator, Photoshop, Macromedia Freehand, Fontographer, or any other of a number of drawing programs, then you've used Bézier curves. At the end of this section we will see how Bézier curves can be defined using linearly independent vectors and linear combinations of vectors.</p>
<figure class="figure figure-like" id="F_Letter_S"><div class="image-box" style="width: 40%; margin-left: 30%; margin-right: 30%;"><img src="external/letter.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">6.1<span class="period">.</span></span><span class="space"> </span>A letter <span class="process-math">\(S\text{.}\)</span></figcaption></figure></section><section class="section" id="sec_indep_intro"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-955">In <a href="chap_vector_representation.html" class="internal" title="Chapter 4: Vector Representation">Chapter 4</a> we saw how to represent water-benzene-acetic acid chemical solutions with vectors, where the components represent the water, benzene and acid percentages. We then considered a problem of determining if a given chemical solution could be made by mixing other chemical solutions. Suppose we now have three different water-benzene-acetic acid chemical solutions, one with 40% water, 50% benzene and 10% acetic acid, the second with 52% water, 42% benzene and 6% acid, and a third with 46% water, 46% benzene and 8% acid. We represent the first chemical solution with the vector <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 40\\50\\10 \end{array}  \right]\text{,}\)</span> the second with the vector <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 52\\42\\6 \end{array}  \right]\text{,}\)</span> and the third with the vector <span class="process-math">\(\vv_3 = \left[ \begin{array}{c} 46\\46\\8 \end{array}  \right]\text{.}\)</span> By combining these three chemical solutions we can make a chemical solution with 43% water, 48% benzene and 9% acid as follows</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/chap_vector_representation.html">
\begin{equation*}
\frac{7}{12}\vv_1 + \frac{1}{12} \vv_2 + \frac{1}{3}\vv_3 = \left[ \begin{array}{c} 43\\48\\9 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-956">However, if we had noticed that the third chemical solution can actually be made from the first two, that is,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{1}{2}\vv_1 + \frac{1}{2} \vv_2 = \vv_3\text{,}
\end{equation*}
</div>
<p class="continuation">we might have realized that we don't need the third chemical solution to make the 43% water, 48% benzene and 9% acid chemical solution. In fact,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{3}{4}\vv_1 + \frac{1}{4} \vv_2 = \left[ \begin{array}{c} 43\\48\\9 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-957">(See <a href="" class="xref" data-knowl="./knowl/ex_1_d_acid.html" title="Exercise 5">Exercise 5</a> of <a href="chap_vector_representation.html" class="internal" title="Chapter 4: Vector Representation">Chapter 4</a>.) Using the third chemical solution (represented by <span class="process-math">\(\vv_3\)</span>) uses more information than we actually need to make the desired 43% water, 48% benzene and 9% acid chemical solution because the vector <span class="process-math">\(\vv_3\)</span> is redundant — all of the material we need to make <span class="process-math">\(\vv_3\)</span> is contained in <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span> This is the basic idea behind linear independence — representing information in the most efficient way.</p>
<p id="p-958">Information is often contained in and conveyed through vectors — especially linear combinations of vectors. In this section we will investigate the concepts of linear dependence and independence of a set of vectors. Our goal is to be able to efficiently determine when a given set of vectors forms a <dfn class="terminology">minimal spanning set</dfn>. A minimal spanning set is a spanning set that contains the smallest number of vectors to obtain all of the vectors in the span. An important aspect of a minimal spanning set is that every vector in the span can be written in one and only one way as a linear combination of the vectors in the minimal spanning set. This will allow us to define the important notion of the dimension of a vector space.</p>
<section class="paragraphs" id="paragraphs-16"><h4 class="heading"><span class="title">Review of useful information.</span></h4>
<p id="p-959">Recall that a linear combination of vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> in <span class="process-math">\(\R^n\)</span> is a sum of scalar multiples of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\text{.}\)</span> That is, a linear combination of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> is a vector of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
c_1\vv_1 + c_2\vv_2 + \cdots + c_k\vv_k\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(c_k\)</span> are scalars.</p>
<p id="p-960">Recall also that the collection of all linear combinations of a set <span class="process-math">\(\{\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is called the span of the set of vectors. That is, the span <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of the set <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{c_1\vv_1 + c_2\vv_2 + \cdots + c_k\vv_k : \text{ where }  c_1, c_2, \ldots, c_k \text{ are scalars } \}\text{.}
\end{equation*}
</div>
<p id="p-961">For example, a linear combination of vectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 1\\1\\2 \end{array}  \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} 0\\-2\\1 \end{array}  \right]\)</span> is <span class="process-math">\(2 \vv_1-3\vv_2 = \left[ \begin{array}{c} 2\\8\\1 \end{array}  \right]\text{.}\)</span> All linear combinations of these two vectors can be expressed as the collection of vectors of the form <span class="process-math">\(\left[ \begin{array}{c} c_1\\c_1-2c_2\\2c_1+c_2 \end{array}  \right]\)</span> where <span class="process-math">\(c_1, c_2\)</span> are scalars. Suppose we want to determine whether <span class="process-math">\(\vw=\left[ \begin{array}{c} 1\\2\\3 \end{array}  \right]\)</span> is in the span, in other words if <span class="process-math">\(\vw\)</span> is a linear combination of <span class="process-math">\(\vv_1, \vv_2\text{.}\)</span> This means we are looking for <span class="process-math">\(c_1, c_2\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{c} c_1\\c_1-2c_2\\2c_1+c_2 \end{array}  \right] = \left[ \begin{array}{c} 1\\2\\3 \end{array}  \right] \,\text{.}
\end{equation*}
</div>
<p class="continuation">we solve for the system represented with the augmented matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[\begin{array}{crc|c} 1\amp 0\amp \amp 1\\ 1\amp -2\amp \amp 2 \\ 2\amp 1\amp \amp 3 \end{array}  \right] \,\text{.}
\end{equation*}
</div>
<p id="p-962">By reducing this matrix, we find that there are no solutions of the system, which implies that <span class="process-math">\(\vw\)</span> is not a linear combination of <span class="process-math">\(\vv_1, \vv_2\text{.}\)</span> Note that we can use any names we please for the scalars, say <span class="process-math">\(x_1, x_2\text{,}\)</span> if we prefer.</p></section><article class="exploration project-like" id="pa_1_f"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">6.1</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-81"><p id="p-963">Let <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} 2\\1\\-3 \end{array}  \right]\text{,}\)</span> <span class="process-math">\(\vv_2 =  \left[ \begin{array}{c} 1\\1\\0 \end{array}  \right]\text{,}\)</span> and <span class="process-math">\(\vv_3 = \left[ \begin{array}{r} 1\\-1\\-6 \end{array}  \right]\text{,}\)</span> and let <span class="process-math">\(\vb = \left[ \begin{array}{c} 0 \\ 1 \\ 3 \end{array}  \right]\text{.}\)</span> If <span class="process-math">\(\vb\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\text{,}\)</span> we are interested in the most efficient way to represent <span class="process-math">\(\vb\)</span> as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span></p></div>
<article class="task exercise-like" id="act_PA1_f_1"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-82">
<p id="p-964">The vector <span class="process-math">\(\vb\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\)</span> if there exist <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> and <span class="process-math">\(x_3\)</span> so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + x_3 \vv_3 = \vb\text{.}
\end{equation*}
</div>
<p class="continuation">(Recall that we can use any letters we want for the scalars. They are simply unknown scalars we want to solve for.)</p>
</div>
<article class="task exercise-like" id="task-286"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-965">Explain why <span class="process-math">\(\vb\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-4" id="hint-4"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-4"><div class="hint solution-like"><p id="p-966">What is the matrix we need to reduce?</p></div></div>
</div></article><article class="task exercise-like" id="task-287"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-967">Write <span class="process-math">\(\vb\)</span> as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> In how many ways can <span class="process-math">\(\vb\)</span> be written as a linear combination of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{?}\)</span> Explain.</p></article></article><article class="task exercise-like" id="act_PA1_f_2"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-83"><p id="p-968">In <a href="" class="xref" data-knowl="./knowl/act_PA1_f_1.html" title="Task 6.1.a">Task 6.1.a</a> we saw that the vector <span class="process-math">\(\vb\)</span> could be written in infinitely many different ways as linear combinations of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> We now ask the question if we really need all of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> to make <span class="process-math">\(\vb\)</span> as a linear combination in a unique way.</p></div>
<article class="task exercise-like" id="task-289"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-969">Can the vector <span class="process-math">\(\vb\)</span> be written as a linear combination of the vectors <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{?}\)</span> If not, why not? If so, in how many ways can <span class="process-math">\(\vb\)</span> be written as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-290"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-970">If possible, write <span class="process-math">\(\vb\)</span> as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span></p></article></article><article class="task exercise-like" id="task-291"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-84"><p id="p-971">In <a href="" class="xref" data-knowl="./knowl/act_PA1_f_1.html" title="Task 6.1.a">Task 6.1.a</a> we saw that <span class="process-math">\(\vb\)</span> could be written in infinitely many different ways as a linear combination of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> However, the vector <span class="process-math">\(\vb\)</span> could only be written in one way as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span> So <span class="process-math">\(\vb\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\)</span> and <span class="process-math">\(\vb\)</span> is also in <span class="process-math">\(\Span \{\vv_1, \vv_2\}\text{.}\)</span> This raises a question — is <em class="emphasis">any</em> vector in <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\)</span> also in <span class="process-math">\(\Span\{\vv_1, \vv_2\}\text{.}\)</span> If so, then the vector <span class="process-math">\(\vv_3\)</span> is redundant in terms of forming the span of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> For the sake of efficiency, we want to recognize and eliminate this redundancy.</p></div>
<article class="task exercise-like" id="task-292"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-972">Can <span class="process-math">\(\vv_3\)</span> be written as a linear combination of the vectors <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{?}\)</span> If not, why not? If so, write <span class="process-math">\(\vv_3\)</span> as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-293"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-973">Use the result of part (a) to decide if <em class="emphasis">any</em> vector in <span class="process-math">\(\Span\{\vv_1, \vv_2, \vv_3\}\)</span> is also in <span class="process-math">\(\Span\{\vv_1, \vv_2\}\text{.}\)</span></p></article></article></article></section><section class="section" id="lin_indep_intro_new"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Linear Independence</span>
</h3>
<p id="p-974">In this section we will investigate the concepts of linear independence of a set of vectors. Our goal is to be able to efficiently determine when a given set of vectors forms a <dfn class="terminology">minimal spanning set</dfn>. This will involve the concepts of span and linear independence. Minimal spanning sets are important in that they provide the most efficient way to represent vectors in a space, and will later allow us to define the dimension of a vector space.</p>
<p id="p-975">In <a href="" class="xref" data-knowl="./knowl/pa_1_f.html" title="Preview Activity 6.1">Preview Activity 6.1</a> we considered the case where we had a set <span class="process-math">\(\{ \vv_1, \vv_2, \vv_3 \}\)</span> of three vectors, and the vector <span class="process-math">\(\vv_3\)</span> was in the span of <span class="process-math">\(\{ \vv_1, \vv_2 \}\text{.}\)</span> So the vector <span class="process-math">\(\vv_3\)</span> did not add anything to the span of <span class="process-math">\(\{ \vv_1, \vv_2 \}\text{.}\)</span> In other words, the set <span class="process-math">\(\{ \vv_1, \vv_2, \vv_3 \}\)</span> was larger than it needed to be in order to generate the vectors in its span — that is, <span class="process-math">\(\Span \{ \vv_1, \vv_2, \vv_3 \} = \Span \{ \vv_1, \vv_2 \}\text{.}\)</span> However, neither of the vectors in the set <span class="process-math">\(\{ \vv_1, \vv_2 \}\)</span> could be removed without changing its span. In this case, the set <span class="process-math">\(\{ \vv_1, \vv_2 \}\)</span> is what we will call a <dfn class="terminology">minimal spanning set</dfn> or <dfn class="terminology">basis</dfn> for <span class="process-math">\(\Span S\text{.}\)</span> There are two important properties that make <span class="process-math">\(\{ \vv_1, \vv_2 \}\)</span> a basis for <span class="process-math">\(\Span S\text{.}\)</span> The first is that every vector in <span class="process-math">\(\Span S\)</span> can be written as linear combinations of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> (we also use the terminology that the vectors <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> span <span class="process-math">\(\Span S\)</span>), and the second is that every vector in <span class="process-math">\(\Span S\)</span> can be written in exactly one way as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{.}\)</span> This second property is the property of linear independence, and it is the property that makes the spanning set <dfn class="terminology">minimal</dfn>.</p>
<p id="p-976">To make a spanning set minimal, we want to be able to write every vector in the span in a unique way in terms of the spanning vectors. Notice that the zero vector can always be written as a linear combination of any set of vectors using 0 for all of the weights. So to have a <dfn class="terminology">minimal</dfn> or <dfn class="terminology">linearly independent</dfn> spanning set, that is, to have a unique representation for each vector in the span, it will need to be the case that the <dfn class="terminology">only</dfn> way we can write the zero vector as a linear combination of a set of vectors is if all of the weights are 0. This leads us to the definition of a linearly independent set of vectors.</p>
<article class="definition definition-like" id="def_linear_independence_Rn"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">6.2</span><span class="period">.</span>
</h4>
<p id="p-977">A set <span class="process-math">\(\{ \vv_1, \vv_2, \cdots, \vv_k \}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is <dfn class="terminology">linearly independent</dfn> if the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero
\end{equation*}
</div>
<p class="continuation">for the scalars <span class="process-math">\(x_1, x_2, \cdots, x_k\)</span> has only the trivial solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 = x_2 = x_3 = \cdots x_k = 0\text{.}
\end{equation*}
</div>
<p class="continuation">If a set is not linearly independent, then the set is <dfn class="terminology">linearly dependent</dfn>.</p></article><p id="p-978">Alternatively, we say that the vectors <span class="process-math">\(\vv_1, \vv_2, \cdots, \vv_k\)</span> are linearly independent (or dependent) if the set <span class="process-math">\(\{ \vv_1, \vv_2, \cdots, \vv_k \}\)</span> is linearly independent (or dependent).</p>
<p id="p-979">Note that the definition tells us that a set <span class="process-math">\(\{ \vv_1, \vv_2, \cdots, \vv_k \}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is linearly dependent if there are scalars <span class="process-math">\(x_1, x_2, \cdots, x_n\text{,}\)</span> not all of which are 0 so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_s + \cdots + x_k \vv_k = \vzero\text{.}
\end{equation*}
</div>
<article class="activity project-like" id="act_1_f_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-85"><p id="p-980">Which of the following sets in <span class="process-math">\(\R^2\)</span> or <span class="process-math">\(\R^3\)</span> is linearly independent and which is linearly dependent? Why? For the linearly dependent sets, write one of the vectors as a linear combination of the others, if possible.</p></div>
<article class="task exercise-like" id="act_1_f_1a"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-981"><span class="process-math">\(S_1 = \left\{\left[\begin{array}{c} 2 \\ 0 \\ 1 \end{array}\right], \left[\begin{array}{r} -2 \\ 8 \\ 1 \end{array}\right], \left[\begin{array}{r} -4 \\ 8 \\ 0 \end{array}\right]\right\}\)</span></p></article><article class="task exercise-like" id="task-295"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-982"><span class="process-math">\(S_2 = \left\{\left[\begin{array}{c} 1 \\ 2 \\ 1 \end{array}\right], \left[\begin{array}{c} 0 \\ 2 \\ 3 \end{array}\right]\right\}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-5" id="hint-5"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-5"><div class="hint solution-like"><p id="p-983">What relationship must exist between two vectors if they are linearly dependent?</p></div></div>
</div></article><article class="task exercise-like" id="act_1_f_1c"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-984">The vectors <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\text{,}\)</span> and <span class="process-math">\(\vw\)</span> as shown in <a href="" class="xref" data-knowl="./knowl/F_1_f_1.html" title="Figure 6.3">Figure 6.3</a>.</p>
<figure class="figure figure-like" id="F_1_f_1"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/1_f_lin_dependence.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">6.3<span class="period">.</span></span><span class="space"> </span>Vectors <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\text{,}\)</span> and <span class="process-math">\(\vw\text{.}\)</span></figcaption></figure></article></article><p id="p-985"><a href="" class="xref" data-knowl="./knowl/act_1_f_1a.html" title="Task 6.2.a">Task 6.2.a</a> and <a href="" class="xref" data-knowl="./knowl/act_1_f_1c.html" title="Task 6.2.c">Task 6.2.c</a> illustrate how we can write one of the vectors in a linearly dependent set as a linear combination of the others. This would allow us to write at least one of the vectors in the span of the set in more than one way as a linear combination of vectors in this set. We prove this result in general in the following theorem.</p>
<article class="theorem theorem-like" id="thm_dependence"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">6.4</span><span class="period">.</span>
</h4>
<p id="p-986">A set <span class="process-math">\(\{ \vv_1, \vv_2, \cdots, \vv_k \}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is linearly dependent if and only if at least one of the vectors in the set can be written as a linear combination of the remaining vectors in the set.</p></article><p id="p-987">The next activity is intended to help set the stage for the proof of <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a>.</p>
<article class="activity project-like" id="act_1_f_1b"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-86"><p id="p-988">The statement of <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a> is a bi-conditional statement (an if and only if statement). To prove this statement about the set <span class="process-math">\(S\)</span> we need to show two things about <span class="process-math">\(S\text{.}\)</span> One: we must demonstrate that if <span class="process-math">\(S\)</span> is a linearly dependent set, then at least one vector in <span class="process-math">\(S\)</span> is a linear combination of the other vectors (this is the “only if” part ofthe biconditional statement) and Two: if at least one vector in <span class="process-math">\(S\)</span> is a linear combination of the others, then <span class="process-math">\(S\)</span> is linearly dependent (this is the “if” part of the biconditional statement). We illustrate the main idea of the proof using a three vector set <span class="process-math">\(S = \{ \vv_1, \vv_2, \vv_3 \}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-297"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-989">First let us assume that <span class="process-math">\(S\)</span> is a linearly dependent set and show that at least one vector in <span class="process-math">\(S\)</span> is a linear combination of the other vectors. Since <span class="process-math">\(S\)</span> is linearly dependent we can write the zero vector as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> with at least one nonzero weight. For example, suppose</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_1_f_dependence_thm_1.html" id="eq_1_f_dependence_thm_1">
\begin{equation}
2 \vv_1 + 3 \vv_2 + 4 \vv_3 = \vzero\tag{6.1}
\end{equation}
</div>
<p class="continuation">Solve Equation <a href="" class="xref" data-knowl="./knowl/eq_1_f_dependence_thm_1.html" title="Equation 6.1">(6.1)</a> for the vector <span class="process-math">\(\vv_2\)</span> to show that <span class="process-math">\(\vv_2\)</span> can be written as a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> Conclude that <span class="process-math">\(\vv_2\)</span> is a linear combination of the other vectors in the set <span class="process-math">\(S\text{.}\)</span></p></article><article class="task exercise-like" id="task-298"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-990">Now we assume that at least one of the vectors in <span class="process-math">\(S\)</span> is a linear combination of the others. For example, suppose that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_1_f_dependence_thm_2.html" id="eq_1_f_dependence_thm_2">
\begin{equation}
\vv_3 = \vv_1 + 5 \vv_2\text{.}\tag{6.2}
\end{equation}
</div>
<p class="continuation">Use vector algebra to rewrite Equation <a href="" class="xref" data-knowl="./knowl/eq_1_f_dependence_thm_2.html" title="Equation 6.2">(6.2)</a> so that <span class="process-math">\(\vzero\)</span> is expressed as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> such that the weight on <span class="process-math">\(\vv_3\)</span> is not zero. Conclude that the set <span class="process-math">\(S\)</span> is linearly dependent.</p></article></article><p id="p-991">Now we provide a formal prof of <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a>, using the ideas from <a href="" class="xref" data-knowl="./knowl/act_1_f_1b.html" title="Activity 6.3">Activity 6.3</a>.</p>
<article class="proof" id="proof-1"><h4 class="heading"><span class="title">Proof of Theorem 6.4.</span></h4>
<p id="p-992">Let <span class="process-math">\(s = \{ \vv_1, \vv_2, \cdots, \vv_k \}\)</span> be a set of vectors in <span class="process-math">\(\R^n\text{.}\)</span> We will begin by verifying the first statement.</p>
<p id="p-993">We assume that <span class="process-math">\(S\)</span> is a linearly dependent set and show that at least one vector in <span class="process-math">\(S\)</span> is a linear combination of the others. Since <span class="process-math">\(S\)</span> is linearly dependent, there are scalarc <span class="process-math">\(x_1, x_2, \cdots, x_n\text{,}\)</span> not all of which are 0, so that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_1_f_dependence_1.html" id="eq_1_f_dependence_1">
\begin{equation}
x_1\vv_1 + x_2\vv_2 + \cdots +  x_{k}\vv_{k} = \vzero\text{.}\tag{6.3}
\end{equation}
</div>
<p class="continuation">We don't know which scalar(s) are not zero, but there is at least one. So let us assume that <span class="process-math">\(x_i\)</span> is not zero for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{.}\)</span> we can then subtract <span class="process-math">\(x_i \vv_i\)</span> from both sides of Equation <a href="" class="xref" data-knowl="./knowl/eq_1_f_dependence_1.html" title="Equation 6.3">(6.3)</a> and divide by <span class="process-math">\(x_i\)</span> to obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_1_f_dependence_1.html">
\begin{equation*}
\vv_i = \frac{x_1}{x_i}\vv_1 + \frac{x_2}{x_i}\vv_2 + \cdots + \frac{x_{i-1}}{x_i}\vv_{i-1} +  \frac{x_{i+1}}{x_i}\vv_{i+1} + \frac{x_{i+2}}{x_i}\vv_{i+2} + \cdots + \frac{x_{k}}{x_i}\vv_{k}\text{.}
\end{equation*}
</div>
<p class="continuation">Thus, the vector <span class="process-math">\(\vv_i\)</span> is a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(\vv_{i-1}\text{,}\)</span> <span class="process-math">\(\vv_{i+1}\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(\vv_k\text{,}\)</span> and at least one of the vectors in <span class="process-math">\(S\)</span>is a linear combination of the other vectors in <span class="process-math">\(S\text{.}\)</span></p>
<p id="p-994">To verify the second statement, we assume that at least one of the vectors in <span class="process-math">\(S\)</span> can be written as a linear combination of the others and show that <span class="process-math">\(S\)</span> is then a linearly dependent set. We don't know which vector(s) in <span class="process-math">\(S\)</span> can be written as a linear combination of the others, but there is at least one. Let us suppose that <span class="process-math">\(\vv_i\)</span> is a linear combination of the others, but there is at least one. Let us suppose that <span class="process-math">\(\vv_i\)</span> is a linear combination of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(\vv_{i-1}\text{,}\)</span> <span class="process-math">\(\vv_{i+1}\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(\vv_k\text{,}\)</span> for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{.}\)</span> Then there exist scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(x_{i-1}\text{,}\)</span> <span class="process-math">\(x_{i+1}\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(x_n\)</span> so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_i = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1}\vv_{i-1} +  x_{i+1}\vv_{i+1} + x_{i+2}\vv_{i+2} + \cdots + x_{k}\vv_{k}\text{.}
\end{equation*}
</div>
<p class="continuation">It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vzero = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1}\vv_{i-1} +  (-1)\vv_i + x_{i+1}\vv_{i+1} + x_{i+2}\vv_{i+2} + \cdots + x_{k}\vv_{k}\text{.}
\end{equation*}
</div>
<p class="continuation">So there are scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(x_n\)</span> (with <span class="process-math">\(x_i = -1\)</span>), not all of which are 0, so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1\vv_1 + x_2\vv_2 + \cdots +  x_{k}\vv_{k} = \vzero\text{.}
\end{equation*}
</div>
<p class="continuation">This makes <span class="process-math">\(S\)</span> a linearly dependent set.</p></article><p id="p-995">With a linearly dependent set, at least one of the vectors in the set is a linear combination of the others. With a linearly independent set, this cannot happen — no vector in the set can be written as a linear combination of the others. This result is given in the next theorem. You may be able to see how <a href="" class="xref" data-knowl="./knowl/thm_dependence.html" title="Theorem 6.4">Theorem 6.4</a> and <a href="" class="xref" data-knowl="./knowl/thm_Independence.html" title="Theorem 6.5">Theorem 6.5</a> are logically equivalent.</p>
<article class="theorem theorem-like" id="thm_Independence"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">6.5</span><span class="period">.</span>
</h4>
<p id="p-996">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is linearly independent if and only if no vector in the set can be written as a linear combination of the remaining vectors in the set.</p></article><article class="activity project-like" id="act_1_f_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-87">
<p id="p-997">As was hinted at in <a href="" class="xref" data-knowl="./knowl/pa_1_f.html" title="Preview Activity 6.1">Preview Activity 6.1</a>, an important consequence of a linearly independent set is that every vector in the span of the set can be written in one and only one way as a linear combination of vectors in the set. It is this uniqueness that makes linearly independent sets so useful. We explore this idea in this activity for a linearly independent set of three vectors. Let <span class="process-math">\(S = \{ \vv_1, \vv_2, \vv_3 \}\)</span> be a linearly independent set of vectors in <span class="process-math">\(\R^n\)</span> for some <span class="process-math">\(n\text{,}\)</span> and let <span class="process-math">\(\vb\)</span> be a vector in <span class="process-math">\(\Span S\text{.}\)</span> To show that <span class="process-math">\(\vb\)</span> can be written in exactly one way as a linear combination of vectors in <span class="process-math">\(S\text{,}\)</span> we assume that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_1_f.html">
\begin{equation*}
\vb = x_1 \vv_1 + x_2 \vv_2 + x_3 \vv_3 \ \ \text{ and } \ \ \vb = y_1\vv_1 + y_2 \vv_2 + y_3 \vv_3
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(x_3\text{,}\)</span> <span class="process-math">\(y_1\text{,}\)</span> <span class="process-math">\(y_2\text{,}\)</span> and <span class="process-math">\(y_3\text{.}\)</span> We need to demonstrate that <span class="process-math">\(x_1 = y_1\text{,}\)</span> <span class="process-math">\(x_2 = y_2\text{,}\)</span> and <span class="process-math">\(x_3 = y_3\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-299"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-998">use the two different ways of writing <span class="process-math">\(\vb\)</span> as a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> to come up with a linear combination expressing <span class="process-math">\(\vzero\)</span> as a linear combination of these vectors.</p></article><article class="task exercise-like" id="task-300"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-999">Use the linear independence of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\)</span> to explain why <span class="process-math">\(x_1 = y_1\text{,}\)</span> <span class="process-math">\(x_2 = y_2\text{,}\)</span> and <span class="process-math">\(x_3 = y_3\text{.}\)</span></p></article></article><p id="p-1000"><a href="" class="xref" data-knowl="./knowl/act_1_f_2.html" title="Activity 6.4">Activity 6.4</a> contains the general ideas to show that any vector in the span of a linearly independent set can be written in one and only one way as a linear combination of the vectors in the set. The weights of such a linear combination provide us a <dfn class="terminology">coordinate system</dfn> for the vectors in terms of the basis. Two familiar concepts of coordinate systems are the Cartesian coordinates and <span class="process-math">\(xy\)</span>-plane, and <span class="process-math">\(xyz\)</span>-space. We will revisit the coordinate system idea in a later chapter.</p>
<p id="p-1001">In the next theorem we state and prove the general case of any number of linearly independent vectors productin unique representations as linear combinations.</p>
<article class="theorem theorem-like" id="thm_1_f_unique_representation"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">6.6</span><span class="period">.</span>
</h4>
<p id="p-1002">Let <span class="process-math">\(S = \{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> be a linearly independent set of vectors in <span class="process-math">\(\R^n\text{.}\)</span> Any vector in <span class="process-math">\(\Span S\)</span> can be written in one and only one way as as linear combination of the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span></p></article><article class="proof" id="proof-2"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-1003">Let <span class="process-math">\(S = \{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> be a linearly independent set of vectors in <span class="process-math">\(\R^n\)</span> and let <span class="process-math">\(\vb\)</span> be a vector in <span class="process-math">\(\Span S\text{.}\)</span> By definition, it follows that <span class="process-math">\(\vb\)</span> can be written as a linear combination of the vectors in <span class="process-math">\(S\text{.}\)</span> It remains for us to show that this representation is unique. So assume that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_1_f_1">
\begin{equation}
\vb = x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k \ \ \text{ and } \ \ \vb = y_1\vv_1 + y_2 \vv_2 + \cdots + y_k \vv_k\tag{6.4}
\end{equation}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(x_k\)</span> and <span class="process-math">\(y_1\text{,}\)</span> <span class="process-math">\(y_2\text{,}\)</span> <span class="process-math">\(\cdots\text{,}\)</span> <span class="process-math">\(y_k\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = y_1\vv_1 + y_2 \vv_2 + \cdots + y_k \vv_k\text{.}
\end{equation*}
</div>
<p class="continuation">Subtracting all terms from the right side and using a little vector algebra gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(x_1-y_1) \vv_1 + (x_2-y_2) \vv_2 + \cdots + (x_k-y_k) \vv_k = \vzero\text{.}
\end{equation*}
</div>
<p class="continuation">The fact that <span class="process-math">\(S\)</span> is a linearly independent set implies that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1-y_1=0, \ x_2-y_2 = 0, \ \ldots, \ x_k-y_k=0\text{,}
\end{equation*}
</div>
<p class="continuation">showing that <span class="process-math">\(x_i = y_i\)</span> for every <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{.}\)</span> We conclude that the representation of <span class="process-math">\(\vb\)</span> as a linear combination of the linearly independent vectors in <span class="process-math">\(S\)</span> is unique.</p></article></section><section class="section" id="sec_determ_lin_ind"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Determining Linear Independence</span>
</h3>
<p id="p-1004">The definition and our previous work give us a straightforward method for determining when a set of vectors in <span class="process-math">\(\R^n\)</span> is linearly independent or dependent.</p>
<article class="activity project-like" id="act_1_f_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-88">
<p id="p-1005">In this activity we learn how to use a matrix to determine in general if a set of vectors in <span class="process-math">\(\R^n\)</span> is linearly independent or dependent. Suppose we have <span class="process-math">\(k\)</span> vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> in <span class="process-math">\(\R^n\text{.}\)</span> To see if these vectors are linearly independent, we need to find the solutions to the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_lin_indep">
\begin{equation}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero\text{.}\tag{6.5}
\end{equation}
</div>
<p id="p-1006">If we let <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \vv_3 \ \cdots \ \vv_k]\)</span> and <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_k \end{array} \right]\text{,}\)</span> then we can write the vector equation <a href="" class="xref" data-knowl="./knowl/eq_lin_indep.html" title="Equation 6.5">(6.5)</a> in matrix form <span class="process-math">\(A \vx = \vzero\text{.}\)</span> Let <span class="process-math">\(B\)</span> be the reduced row echelon form of <span class="process-math">\(A\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-301"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1007">What can we say about the pivots of <span class="process-math">\(B\)</span> in order for <span class="process-math">\(A \vx = \vzero\)</span> to have exactly one solution? Under these conditions, are the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> linearly independent or dependent?</p></article><article class="task exercise-like" id="task-302"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1008">What can we say about the rows or columns of <span class="process-math">\(B\)</span> in order for <span class="process-math">\(A \vx = \vzero\)</span> to have infinitely many solutions? Under these conditions, are the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\)</span> linearly independent or dependent?</p></article><article class="task exercise-like" id="task-303"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1009">Use the result of parts (a) and (b) to determine if the vectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} 1 \\ -1 \\ 2 \\ 0 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 1 \\ 0 \\ 2 \\ 3 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vv_3 = \left[ \begin{array}{c} 0 \\ 0 \\ 2 \\ 1 \end{array} \right]\)</span> in <span class="process-math">\(\R^4\)</span> are linearly independent or dependent. If dependent, write one of the vectors as a linear combination of the others. You may use the fact that the matrix <span class="process-math">\(\left[ \begin{array}{rcc} 1\amp 1\amp 0 \\ -1\amp 0\amp 0 \\ 2\amp 2\amp 2 \\ 0\amp 3\amp 1 \end{array} \right]\)</span> is row equivalent to <span class="process-math">\(\left[ \begin{array}{rcc} 1\amp 0\amp 0 \\ 0\amp 1\amp 0 \\ 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \end{array} \right]\text{.}\)</span></p></article></article></section><section class="section" id="sec_min_span_set"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Minimal Spanning Sets</span>
</h3>
<p id="p-1010">It is important to note the differences and connections between linear independence, span, and minimal spanning set.</p>
<ul class="disc">
<li id="li-190"><p id="p-1011">The set <span class="process-math">\(S = \left\{ \left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right], \left[ \begin{array}{c} 0 \\ 1 \\ 0 \end{array} \right] \right\}\)</span> is not a minimal spanning set for <span class="process-math">\(\R^3\)</span> even though <span class="process-math">\(S\)</span> is a linearly independent set. Note that <span class="process-math">\(S\)</span> does not span <span class="process-math">\(\R^3\)</span> since the vector <span class="process-math">\(\left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array} \right]\)</span> is not in <span class="process-math">\(\Span \ S\text{.}\)</span></p></li>
<li id="li-191">
<p id="p-1012">The set <span class="process-math">\(T = \left\{ \left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array}  \right], \left[ \begin{array}{c} 0 \\ 1 \\ 0 \end{array}  \right] , \left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array}  \right] , \left[ \begin{array}{c} 1 \\ 1 \\ 1 \end{array}  \right] \right\}\)</span> is not a minimal spanning set for <span class="process-math">\(\R^3\)</span> even though <span class="process-math">\(\Span \ T = \R^3\text{.}\)</span> Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{c} 1 \\ 1 \\ 1 \end{array}  \right] = \left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array}  \right] + \left[ \begin{array}{c} 0 \\ 1 \\ 0 \end{array}  \right] + \left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(T\)</span> is not a linearly independent set.</p>
</li>
<li id="li-192"><p id="p-1013">The set <span class="process-math">\(U = \left\{ \left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right], \left[ \begin{array}{c} 0 \\ 1 \\ 0 \end{array} \right] , \left[ \begin{array}{c} 0 \\ 0 \\ 1 \end{array} \right] \right\}\)</span> is a minimal spanning set for <span class="process-math">\(\R^3\)</span> since it satisfies both characteristics of a minimal spanning set: <span class="process-math">\(\Span \ U = \R^3\)</span> AND <span class="process-math">\(U\)</span> is linearly independent.</p></li>
</ul>
<p id="p-1014">The three concepts — linear independence, span, and minimal spanning set — are different. The important point to note is that minimal spanning set must be both linearly independent and span the space.</p>
<p id="p-1015">To find a minimal spanning set we will often need to find a smallest subset of a given set of vectors that has the same span as the original set of vectors. In this section we determine a method for doing so.</p>
<article class="activity project-like" id="act_1_f_4"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-89"><p id="p-1016">Let <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -1 \\ 0 \\ 2 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} 2 \\ 0 \\ -4 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_3 = \left[ \begin{array}{c} 0 \\ 1 \\ 3 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vv_4 = \left[ \begin{array}{r} -3 \\ 4 \\ 18 \end{array} \right]\)</span> in <span class="process-math">\(\R^3\text{.}\)</span> Assume that the reduced row echelon form of the matrix <span class="process-math">\(A = \left[ \begin{array}{rrcr} -1\amp 2\amp 0\amp -3 \\ 0\amp 0\amp 1\amp 4 \\ 2\amp -4\amp 3\amp 18 \end{array} \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{crcc} 1\amp -2\amp 0\amp 3 \\ 0\amp 0\amp 1\amp 4 \\ 0\amp 0\amp 0\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-304"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1017">Write the general solution to the homogeneous system <span class="process-math">\(A \vx = \vzero\text{,}\)</span> where <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \\ x_4 \end{array} \right]\text{.}\)</span> Write all linear combinations of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\vv_3\text{,}\)</span> and <span class="process-math">\(\vv_4\)</span> that are equal to <span class="process-math">\(\vzero\text{,}\)</span> using weights that only involve <span class="process-math">\(x_2\)</span> and <span class="process-math">\(x_4\text{.}\)</span></p></article><article class="task exercise-like" id="task-305"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1018">Explain how we can conveniently choose the weights in the general solution to <span class="process-math">\(A \vx = \vzero\)</span> to show that the vector <span class="process-math">\(\vv_4\)</span> is a linear combination of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> What does this tell us about <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3\}\)</span> and <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3, \vv_4\}\text{?}\)</span></p></article><article class="task exercise-like" id="task-306"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1019">Explain how we can conveniently choose the weights in the general solution to <span class="process-math">\(A \vx = \vzero\)</span> to show why the vector <span class="process-math">\(\vv_2\)</span> is a linear combination of <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span> What does this tell us about <span class="process-math">\(\Span \{\vv_1, \vv_3\}\)</span> and <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3 \}\text{?}\)</span></p></article><article class="task exercise-like" id="task-307"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1020">Is <span class="process-math">\(\{\vv_1, \vv_3\}\)</span> a minimal spanning set for <span class="process-math">\(\Span \{\vv_1, \vv_2, \vv_3, \vv_4\}\text{?}\)</span> Explain your response.</p></article></article><p id="p-1021"><a href="" class="xref" data-knowl="./knowl/act_1_f_4.html" title="Activity 6.6">Activity 6.6</a> illustrates how we can use a matrix to determine a minimal spanning set for a given set of vectors <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> in <span class="process-math">\(\R^n\text{.}\)</span></p>
<ul class="disc">
<li id="li-193"><p id="p-1022">Form the matrix <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \cdots \ \vv_k]\text{.}\)</span></p></li>
<li id="li-194"><p id="p-1023">Find the reduced row echelon form <span class="process-math">\([B \ | \ \vzero]\)</span> of <span class="process-math">\([A \ | \ \vzero]\text{.}\)</span> If <span class="process-math">\(B\)</span> contains non-pivot columns, say for example that the <span class="process-math">\(i\)</span>th column is a non-pivot column, then we can choose the weight <span class="process-math">\(x_i\)</span> corresponding to the <span class="process-math">\(i\)</span>th column to be 1 and all weights corresponding to the other non-pivot columns to be 0 to make a linear combination of the columns of <span class="process-math">\(A\)</span> that is equal to <span class="process-math">\(\vzero\text{.}\)</span> This allows us to write <span class="process-math">\(\vv_i\)</span> as a linear combination of the vectors corresponding to the pivot columns of <span class="process-math">\(A\)</span> as we did in the proof of <a href="" class="xref" data-knowl="./knowl/thm_Independence.html" title="Theorem 6.5">Theorem 6.5</a>. So every vector corresponding to a non-pivot column is in the span of the set of vectors corresponding to the pivot columns. The vectors corresponding to the pivot columns are linearly independent, since the matrix with those columns has every column as a pivot column. Thus, the set of vectors corresponding to the pivot columns of <span class="process-math">\(A\)</span> forms a minimal spanning set for <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\text{.}\)</span></p></li>
</ul>
<section class="paragraphs" id="paragraphs-17"><h4 class="heading"><span class="title">IMPORTANT NOTE.</span></h4>
<p id="p-1024">The set of pivot columns of the reduced row echelon form of <span class="process-math">\(A\)</span> will normally not have the same span as the set of columns of <span class="process-math">\(A\text{,}\)</span> so it is critical that we use columns of <span class="process-math">\(A\text{,}\)</span> <em class="alert">not</em> <span class="process-math">\(B\)</span> in our minimal spanning set.</p></section><article class="activity project-like" id="act_1_f_5"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">6.7</span><span class="period">.</span>
</h4>
<p id="p-1025">Find a minimal spanning set for the span of the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ \begin{array}{c} 1 \\ 1 \\ 0 \\ 0 \end{array}  \right], \left[ \begin{array}{c} 2 \\ 3 \\ 0 \\ 0 \end{array}  \right], \left[ \begin{array}{c} 0 \\ 1 \\ 2 \\ 0 \end{array}  \right], \left[ \begin{array}{c} 4 \\ 1 \\ 0 \\ 0 \end{array}  \right] \right\}\text{.}
\end{equation*}
</div></article><p id="p-1026"><a href="" class="xref" data-knowl="./knowl/act_1_f_4.html" title="Activity 6.6">Activity 6.6</a> also illustrates a general process by which we can find a minimal spanning set — that is the smallest subset of vectors that has the same span. This process will be useful later when we consider vectors in arbitrary vector spaces. The idea is that if we can write one of the vectors in a set <span class="process-math">\(S\)</span> as a linear combination of the remaining vectors, then we can remove that vector from the set and maintain the same span. In other words, begin with the span of a set <span class="process-math">\(S\)</span> and follow these steps:</p>
<dl class="description-list">
<dt id="li-195">Step 1</dt>
<dd><p id="p-1027">If <span class="process-math">\(S\)</span> is a linearly independent set, we already have a minimal spanning set.</p></dd>
<dt id="li-196">Step 2</dt>
<dd><p id="p-1028">If <span class="process-math">\(S\)</span> is not a linearly independent set, then one of the vectors in <span class="process-math">\(S\)</span> is a linear combination of the others. Remove that vector from <span class="process-math">\(S\)</span> to obtain a new set <span class="process-math">\(T\text{.}\)</span> It will be the case that <span class="process-math">\(\Span \ T = \Span \ S\text{.}\)</span></p></dd>
<dt id="li-197">Step 3</dt>
<dd><p id="p-1029">If <span class="process-math">\(T\)</span> is a linearly independent set, then <span class="process-math">\(T\)</span> is a minimal spanning set. If not, repeat steps 2 and 3 for the set <span class="process-math">\(T\)</span> until you arrive at a linearly independent set.</p></dd>
</dl>
<p id="p-1030">This process is guaranteed to stop as long as the set contains at least one nonzero vector. A verification of the statement in Step 2 that <span class="process-math">\(\Span \ T = \Span \ S\)</span> is given in the next theorem.</p>
<article class="theorem theorem-like" id="thm_minimal_spanning_set"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">6.7</span><span class="period">.</span>
</h4>
<p id="p-1031">Let <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> be a set of vectors in <span class="process-math">\(\R^n\)</span> so that for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{,}\)</span> <span class="process-math">\(\vv_i\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span \{\vv_1, \vv_2, \ldots, \vv_k\} = \Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{.}
\end{equation*}
</div></article><article class="proof" id="proof-3"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-1032">Let <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> be a set of vectors in <span class="process-math">\(\R^n\)</span> so that <span class="process-math">\(\vv_i\)</span> is in the span of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_{i-1}\text{,}\)</span> <span class="process-math">\(\vv_{i+1}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> and <span class="process-math">\(\vv_k\)</span> for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{.}\)</span> To show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span \{\vv_1, \vv_2, \ldots, \vv_k\} = \Span \{\vv_1,  \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{,}
\end{equation*}
</div>
<p class="continuation">we need to show that</p>
<ol class="decimal">
<li id="li-198"><p id="p-1033">every vector in <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> is in <span class="process-math">\(\Span\{\vv_1, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{,}\)</span> and</p></li>
<li id="li-199"><p id="p-1034">every vector in <span class="process-math">\(\Span \{\vv_1, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\)</span> is in <span class="process-math">\(\Span \{\vv_1, \ldots, \vv_k\}\text{.}\)</span></p></li>
</ol>
<p id="p-1035">Let us consider the second containment. Let <span class="process-math">\(\vx\)</span> be a vector in the span of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_{i-1}\text{,}\)</span> <span class="process-math">\(\vv_{i+1}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> and <span class="process-math">\(\vv_k\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1}\vv_{i-1} + x_{i+1}\vv_{i+1} + \cdots + x_k\vv_k
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_{i-1}\text{,}\)</span> <span class="process-math">\(x_{i+1}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_k\text{.}\)</span> Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1}\vv_{i-1} + (0)\vv_i + x_{i+1}\vv_{i+1} + \cdots + x_k\vv_k
\end{equation*}
</div>
<p class="continuation">as well, so <span class="process-math">\(\vx\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_k\}\text{.}\)</span> Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\} \subseteq  \Span \{\vv_1, \vv_2, \ldots, \vv_k\}\text{.}
\end{equation*}
</div>
<p id="p-1036">(This same argument shows a more general statement that if <span class="process-math">\(S\)</span> is a subset of <span class="process-math">\(T\text{,}\)</span> then <span class="process-math">\(\Span \ S \subseteq \Span \ T\text{.}\)</span>)</p>
<p id="p-1037">Now we demonstrate the first containment. Here we need the assumption that <span class="process-math">\(\vv_i\)</span> is in <span class="process-math">\(\Span \{\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_{i-1}\text{,}\)</span> <span class="process-math">\(\vv_{i+1}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\}\)</span> for some <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(k\text{.}\)</span> That assumption gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_lin_depend_containment.html" id="eq_lin_depend_containment">
\begin{equation}
\vv_i = c_1 \vv_1 + c_2\vv_2 + \cdots + c_{i-1}\vv_{i-1} + c_{i+1}\vv_{i+1} + \cdots + c_k\vv_k\tag{6.6}
\end{equation}
</div>
<p class="continuation">for some scalars <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(c_{i-1}\text{,}\)</span> <span class="process-math">\(c_{i+1}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(c_k\text{.}\)</span> Now let <span class="process-math">\(\vx\)</span> be a vector in the span of <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_k\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_lin_depend_containment.html">
\begin{equation*}
\vx = x_1\vv_1 + x_2\vv_2 + \cdots + x_k\vv_k
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_k\text{.}\)</span> Substituting from <a href="" class="xref" data-knowl="./knowl/eq_lin_depend_containment.html" title="Equation 6.6">(6.6)</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_lin_depend_containment.html" id="md-78">
\begin{align*}
\vx \amp = x_1\vv_1 + x_2\vv_2 + \cdots + x_k\vv_k\\
\amp = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1} \vv_{i-1} + x_i \vv_i + x_{i+1}\vv_{i+1} + \cdots + x_k\vv_k\\
\amp = x_1\vv_1 + x_2\vv_2 + \cdots + x_{i-1} \vv_{i-1}\\
\amp \qquad + x_i[c_1 \vv_1 + c_2\vv_2 + \cdots + c_{i-1}\vv_{i-1} + c_{i+1}\vv_{i+1} + \cdots + c_k\vv_k]\\
\amp \qquad + x_{i+1}\vv_{i+1} + \cdots + x_k\vv_k\\
\amp = (x_1+x_ic_1)\vv_1 + (x_2+x_ic_2)\vv_2 + \cdots + (x_{i-1}+x_ic_{i-1}) \vv_{i-1}\\
\amp \qquad + (x_{i+1}+x_ic_{i+1}) \vv_{i+1} \cdots + (x_k+x_ic_k)\vv_k\text{.}
\end{align*}
</div>
<p id="p-1038">So <span class="process-math">\(\vx\)</span> is in <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span \{\vv_1, \vv_2, \ldots, \vv_k\} \subseteq \Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{.}
\end{equation*}
</div>
<p id="p-1039">Since the two sets are subsets of each other, they must be equal sets. We conclude that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Span \{\vv_1, \vv_2, \ldots, \vv_k\} = \Span \{\vv_1, \vv_2, \ldots, \vv_{i-1}, \vv_{i+1}, \ldots, \vv_k\}\text{.}
\end{equation*}
</div></article><p id="p-1040">The result of <a href="" class="xref" data-knowl="./knowl/thm_minimal_spanning_set.html" title="Theorem 6.7">Theorem 6.7</a> is that if we have a finite set <span class="process-math">\(S\)</span> of vectors in <span class="process-math">\(\R^n\text{,}\)</span> we can eliminate those vectors that are linear combinations of others until we obtain a smallest set of vectors that still has the same span. As mentioned earlier, we call such a minimal spanning set a basis.</p>
<article class="definition definition-like" id="def_1_f_basis"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">6.8</span><span class="period">.</span>
</h4>
<p id="p-1041">Let <span class="process-math">\(S\)</span> be a set of vectors in <span class="process-math">\(\R^n\text{.}\)</span> A subset <span class="process-math">\(B\)</span> of <span class="process-math">\(S\)</span> is a <dfn class="terminology">basis</dfn> for <span class="process-math">\(\Span \ S\)</span> if <span class="process-math">\(B\)</span> is linearly independent and <span class="process-math">\(\Span \ B = \Span \ S\text{.}\)</span></p></article><section class="paragraphs" id="paragraphs-18"><h4 class="heading"><span class="title">IMPORTANT NOTE.</span></h4>
<p id="p-1042">A basis is defined by two characteristics. A basis must span the space in question and a basis must be a linearly independent set. It is the linear independence that makes a basis a <em class="emphasis">minimal</em> spanning set.</p></section><p id="p-1043">We have worked with a familiar basis in <span class="process-math">\(\R^2\)</span> throughout our mathematical careers. A vector <span class="process-math">\(\left[ \begin{array}{c} a \\ b \end{array}  \right]\)</span> in <span class="process-math">\(\R^2\)</span> can be written as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{c} a \\ b \end{array}  \right] = a\left[ \begin{array}{c} 1 \\ 0 \end{array}  \right] + b\left[ \begin{array}{c} 0 \\ 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1044">So the set <span class="process-math">\(\{\ve_1, \ve_2\}\text{,}\)</span> where <span class="process-math">\(\ve_1 = \left[ \begin{array}{c} 1 \\ 0 \end{array} \right]\)</span> and <span class="process-math">\(\ve_2 = \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]\)</span> spans <span class="process-math">\(\R^2\text{.}\)</span> Since the columns of <span class="process-math">\([\ve_1 \ \ve_2]\)</span> are linearly independent, so is the set <span class="process-math">\(\{\ve_1, \ve_2\}\text{.}\)</span> Therefore, the set <span class="process-math">\(\{\ve_1, \ve_2\}\)</span> is a basis for <span class="process-math">\(\R^2\text{.}\)</span> The vector <span class="process-math">\(\ve_1\)</span> is in the direction of the positive <span class="process-math">\(x\)</span>-axis and the vector <span class="process-math">\(\ve_2\)</span> is in the direction of the positive <span class="process-math">\(y\)</span>-axis, so decomposing a vector <span class="process-math">\(\left[ \begin{array}{c} a \\ b \end{array} \right]\)</span> as a linear combination of <span class="process-math">\(\ve_1\)</span> and <span class="process-math">\(\ve_2\)</span> is akin to identifying the vector with the point <span class="process-math">\((a,b)\)</span> as we discussed earlier. The set <span class="process-math">\(\{\ve_1, \ve_2\}\)</span> is called the <dfn class="terminology">standard basis</dfn> for <span class="process-math">\(\R^2\text{.}\)</span></p>
<p id="p-1045"> This idea is not restricted to <span class="process-math">\(\R^2\text{.}\)</span> Consider the vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\ve_1 = \left[ \begin{array}{c} 1\\0\\0 \\ \vdots \\ 0 \\ 0 \end{array}  \right], \ \ve_2 = \left[ \begin{array}{c} 0\\1\\0 \\ \vdots \\ 0 \\ 0 \end{array}  \right], \ \cdots, \ \ve_n = \left[ \begin{array}{c} 0\\0\\0 \\ \vdots \\ 0 \\ 1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">in <span class="process-math">\(\R^n\text{.}\)</span> That is, the vector <span class="process-math">\(\ve_i\)</span> is the vector with a 1 in the <span class="process-math">\(i\)</span>th position and 0s everywhere else. Since the matrix <span class="process-math">\([\ve_1 \ \ve_2 \ \cdots \ \ve_n]\)</span> has a pivot in each row and column, the set <span class="process-math">\(\{\ve_1, \ve_2, \ldots, \ve_n\}\)</span> is a basis for <span class="process-math">\(\R^n\text{.}\)</span> The set <span class="process-math">\(\{\ve_1, \ve_2, \ldots, \ve_n\}\)</span> is called the <dfn class="terminology">standard basis</dfn> for <span class="process-math">\(\R^n\text{.}\)</span></p>
<p id="p-1046">As we will see later, bases<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-9" id="fn-9"><sup> 9 </sup></a> are of fundamental importance in linear algebra in that bases will allow us to define the dimension of a vector space and will provide us with coordinate systems.</p>
<p id="p-1047">We conclude this section with an important theorem that is similar to <a href="" class="xref" data-knowl="./knowl/thm_IMT_1_e.html" title="Theorem 5.3">Theorem 5.3</a>.</p>
<article class="theorem theorem-like" id="thm_IMT_1_f"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">6.9</span><span class="period">.</span>
</h4>
<p id="p-1048">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix. The following statements are equivalent.</p>
<ol class="decimal">
<li id="li-200"><p id="p-1049">The matrix equation <span class="process-math">\(A \vx = \vb\)</span> has a unique solution for every vector <span class="process-math">\(\vb\)</span> in the span of the columns of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-201"><p id="p-1050">The matrix equation <span class="process-math">\(A \vx = \vzero\)</span> has the unique solution <span class="process-math">\(\vx = \vzero\text{.}\)</span></p></li>
<li id="li-202"><p id="p-1051">The columns of <span class="process-math">\(A\)</span> are linearly independent.</p></li>
<li id="li-203"><p id="p-1052">The matrix <span class="process-math">\(A\)</span> has a pivot position in each column.</p></li>
</ol></article></section><section class="section" id="sec_indep_exam"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-1053">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-11"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">6.10</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-90"><p id="p-1054">Let <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 1\\2\\0\\1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} 0\\6\\-1\\5 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_3 = \left[ \begin{array}{r} 3\\-6\\2\\-7 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vv_4 = \left[ \begin{array}{r} 5\\-2\\2\\-5 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-308"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1055">Is the set <span class="process-math">\(S = \{\vv_1, \vv_2, \vv_3, \vv_4\}\)</span> linearly independent or dependent. If independent, explain why. If dependent, write one of the vectors in <span class="process-math">\(S\)</span> as a linear combination of the other vectors in <span class="process-math">\(S\text{.}\)</span></p>
<div class="solution solution-like" id="solution-32">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1056">We need to know the solutions to the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + x_3 \vv_3 + x_4 \vv_4 = \vzero\text{.}
\end{equation*}
</div>
<p class="continuation">If the equation has as its only solution <span class="process-math">\(x_1 = x_2 = x_3 = x_4 = 0\)</span> (the trivial solution), then the set <span class="process-math">\(S\)</span> is linearly independent. Otherwise the set <span class="process-math">\(S\)</span> is linearly dependent. To find the solutions to this system, we row reduce the augmented matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{crrr|c} 1\amp 0\amp 3\amp 5\amp 0 \\ 2\amp 6\amp -6\amp -2\amp 0 \\ 0\amp -1\amp 2\amp 2\amp 0 \\ 1\amp 5\amp -7\amp -5\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">(Note that we really don't need the augmented column of zeros — row operations won't change that column at all. We just need to know that the column of zeros is there.) Technology shows that the reduced row echelon form of this augmented matrix is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccr|c} 1\amp 0\amp 3\amp 5\amp 0 \\ 0\amp 1\amp -2\amp -2\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">The reduced row echelon form tells us that the vector equation is consistent, and the fact that there is no pivot in the fourth column shows that the system has a free variable and more than just the trivial solution. We conclude that <span class="process-math">\(S\)</span> is linearly dependent. Moreover, the general solution to our vector equation is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-79">
\begin{align*}
x_1 \amp = -3x_3 - 5x_4\\
x_2 \amp = 2x_3 + 2x_4\\
x_3 \amp \text{ is free }\\
x_4 \amp \text{ is free } \text{.}
\end{align*}
</div>
<p class="continuation">Letting <span class="process-math">\(x_4 = 0\)</span> and <span class="process-math">\(x_3 = 1\)</span> shows that one non-trivial solution to our vector equation is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 = -3, \ x_2 = 2, \ x_3 = 1, \ \text{ and }  \ x_4 = 0\text{.}
\end{equation*}
</div>
<p class="continuation">Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-3\vv_1 + 2\vv_2 + \vv_3 = \vzero\text{,}
\end{equation*}
</div>
<p class="continuation">or</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_3 = 3\vv_1 - 2\vv_2
\end{equation*}
</div>
<p class="continuation">and we have written one vector in <span class="process-math">\(S\)</span> as a linear combination of the other vectors in <span class="process-math">\(S\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-309"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1057">Find a subset <span class="process-math">\(B\)</span> of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(\Span \ S\text{.}\)</span> Explain how you know you have a basis.</p>
<div class="solution solution-like" id="solution-33">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1058">We have seen that the pivot columns in a matrix <span class="process-math">\(A\)</span> form a minimal spanning set (or basis) for the span of the columns of <span class="process-math">\(A\text{.}\)</span> From part (a) we see that the pivot columns in the reduced row echelon form of <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \vv_3 \ \vv_4]\)</span> are the first and second columns. So a basis for the span of the columns of <span class="process-math">\(A\)</span> is <span class="process-math">\(\{\vv_1, \vv_2\}\text{.}\)</span> Since the elements of <span class="process-math">\(S\)</span> are the columns of <span class="process-math">\(A\text{,}\)</span> we conclude that the set <span class="process-math">\(B = \{\vv_1, \vv_2\}\)</span> is a subset of <span class="process-math">\(S\)</span> that is a basis for <span class="process-math">\(\Span \ S\text{.}\)</span></p>
</div></article></article><article class="example example-like" id="example-12"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">6.11</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-91"><p id="p-1059">Let <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} 1 \\ 1 \\ 0 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} 3 \\ -7 \\ 2 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vv_3 = \left[ \begin{array}{r} -5 \\ 6 \\ 10 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-310"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1060">Is the set <span class="process-math">\(S = \left\{\vv_1, \vv_2, \vv_3\right\}\)</span> a basis for <span class="process-math">\(\R^3\text{?}\)</span> Explain.</p>
<div class="solution solution-like" id="solution-34">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1061">We need to know if the vectors in <span class="process-math">\(S\)</span> are linearly independent and span <span class="process-math">\(\R^3\text{.}\)</span> Technology shows that the reduced row echelon form of</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\left[ \begin{array}{crr} 1\amp 3\amp -5 \\ 1\amp -7\amp 6 \\ 0\amp 2\amp 10 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccc} 1\amp 0\amp 0 \\ 0\amp 1\amp 0 \\ 0\amp 0\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Since every column of <span class="process-math">\([\vv_1 \ \vv_2 \ \vv_3]\)</span> is a pivot column, the set <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> is linearly independent. The fact that there is a pivot in every row of the matrix <span class="process-math">\(A\)</span> means that the equation <span class="process-math">\(A \vx = \vb\)</span> is consistent for every <span class="process-math">\(\vb\)</span> in <span class="process-math">\(\R^3\text{.}\)</span> Since <span class="process-math">\(A \vx\)</span> is a linear combination of the columns of <span class="process-math">\(A\)</span> with weights from <span class="process-math">\(\vx\text{,}\)</span> tt follows that the columns of <span class="process-math">\(A\)</span> span <span class="process-math">\(\R^3\text{.}\)</span> We conclude that the set <span class="process-math">\(S\)</span> is a basis for <span class="process-math">\(\R^3\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-311"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1062">Let <span class="process-math">\(\vv_4 = \left[ \begin{array}{r} -5 \\ 6 \\ h \end{array} \right]\text{,}\)</span> where <span class="process-math">\(h\)</span> is a scalar. Are there any values of <span class="process-math">\(h\)</span> for which the set <span class="process-math">\(S' = \{\vv_1, \vv_2, \vv_4\}\)</span> is not a basis for <span class="process-math">\(\R^3\text{?}\)</span> If so, find all such values of <span class="process-math">\(h\)</span> and explain why <span class="process-math">\(S'\)</span> is not a basis for <span class="process-math">\(\R^3\)</span> for those values of <span class="process-math">\(h\text{.}\)</span></p>
<div class="solution solution-like" id="solution-35">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1063">Technology shows that a row echelon form of <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \vv_4]\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[  \begin{array}{crc} 1\amp 0\amp 0 \\ 0\amp -10\amp 11 \\ 0\amp 0\amp h+\frac{11}{5} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">The columns of <span class="process-math">\(A\)</span> are all pivot columns (hence linearly independent) as long as <span class="process-math">\(h \neq -\frac{11}{5}\text{,}\)</span> and are linearly dependent when <span class="process-math">\(h = -\frac{11}{5}\text{.}\)</span> So the only value of <span class="process-math">\(h\)</span> for which <span class="process-math">\(S'\)</span> is not a basis for <span class="process-math">\(\R^3\)</span> is <span class="process-math">\(h = -\frac{11}{5}\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_indep_summ"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-204">
<p id="p-1064">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is linearly independent if the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero
\end{equation*}
</div>
<p class="continuation">for scalars <span class="process-math">\(x_1, x_2, \ldots,
x_k\)</span> has only the trivial solution</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 = x_2 = x_3 = \cdots = x_k = 0\text{.}
\end{equation*}
</div>
<p class="continuation">Another way to think about this is that a set of vectors is linearly independent if no vector in the set can be written as a linear combination of the other vectors in the set.</p>
</li>
<li id="li-205">
<p id="p-1065">A set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> of vectors in <span class="process-math">\(\R^n\)</span> is linearly dependent if the vector equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero
\end{equation*}
</div>
<p class="continuation">has a nontrivial solution. That is, we can find scalars <span class="process-math">\(x_1, x_2, \ldots,
x_k\)</span> that are not all 0 so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_1 \vv_1 + x_2 \vv_2 + \cdots + x_k \vv_k = \vzero\text{.}
\end{equation*}
</div>
<p class="continuation">Another way to think about this is that a set of vectors is linearly dependent if at least one vector in the set can be written as a linear combination of the other vectors in the set.</p>
</li>
<li id="li-206"><p id="p-1066">If <span class="process-math">\(S\)</span> is a set of vectors, a subset <span class="process-math">\(B\)</span> of <span class="process-math">\(S\)</span> is a basis for <span class="process-math">\(\Span \ S\)</span> if <span class="process-math">\(B\)</span> is a linearly independent set and <span class="process-math">\(\Span \ B = \Span \ S\text{.}\)</span></p></li>
<li id="li-207"><p id="p-1067">Given a nonzero set <span class="process-math">\(S\)</span> of vectors, we can remove vectors from <span class="process-math">\(S\)</span> that are linear combinations of remaining vectors in <span class="process-math">\(S\)</span> to obtain a linearly independent subset of <span class="process-math">\(S\)</span> that has the same span as <span class="process-math">\(S\text{.}\)</span></p></li>
<li id="li-208"><p id="p-1068">The columns of a matrix <span class="process-math">\(A\)</span> are linearly independent if the equation <span class="process-math">\(A \vx = \vzero\)</span> has only the trivial solution <span class="process-math">\(\vx = \vzero\text{.}\)</span></p></li>
<li id="li-209"><p id="p-1069">The set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_k\}\)</span> is linearly independent if and only if every column of the matrix <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \vv_3 \ \cdots \ \vv_k]\text{,}\)</span> is a pivot column.</p></li>
<li id="li-210"><p id="p-1070">If <span class="process-math">\(A = [\vv_1 \ \vv_2 \ \vv_3 \ \cdots \ \vv_k]\text{,}\)</span> then the vectors in the pivot columns of <span class="process-math">\(A\)</span> form a minimal spanning set for <span class="process-math">\(\Span \{\vv_1, \vv_2, \ldots, \vv_k\}\text{.}\)</span></p></li>
</ul></section><section class="exercises" id="sec_indep_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-55"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<p id="p-1071">Consider the following vectors in <span class="process-math">\(\R^3\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_1 = \left[ \begin{array}{c} 1 \\ 1\\ 1 \end{array}  \right]\; , \; \vv_2 = \left[ \begin{array}{c} 1 \\ 2\\ 1 \end{array}  \right] \; , \; \vv_3= \left[ \begin{array}{c} 1 \\ 3\\ 1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">Is the set consisting of these vectors linearly independent? If so, explain why. If not, make a single change in one of the vectors so that the set is linearly independent.</p></article><article class="exercise exercise-like" id="exercise-56"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-1073">Consider the following vectors in <span class="process-math">\(\R^3\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_1 = \left[ \begin{array}{c} 1 \\ 2\\ 1 \end{array}  \right]\; , \; \vv_2 = \left[ \begin{array}{r} 1 \\ -1\\ 2 \end{array}  \right] \; , \; \vv_3= \left[ \begin{array}{c} 1 \\ 1\\ c \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">For which values of <span class="process-math">\(c\)</span> is the set consisting of these vectors linearly independent?</p></article><article class="exercise exercise-like" id="exercise-57"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-1074">In a lab, there are three different water-benzene-acetic acid solutions: The first one with 36% water, 50% benzene and 14% acetic acid; the second one with 44% water, 46% benzene and 10% acetic acid; and the last one with 38% water, 49% benzene and 13% acid. Since the lab needs space, the lab coordinator wants to determine whether all solutions are needed, or if it is possible to create one of the solutions using the other two. Can you help the lab coordinator?</p></article><article class="exercise exercise-like" id="exercise-58"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-1076">Given vectors <span class="process-math">\(\vv_1= \left[ \begin{array}{c} 1 \\ 2\\ 3 \end{array} \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 0 \\ 2\\ 1 \end{array} \right]\text{,}\)</span> find a vector <span class="process-math">\(\vv_3\)</span> in <span class="process-math">\(\R^3\)</span> so that the set consisting of <span class="process-math">\(\vv_1, \vv_2\)</span> and <span class="process-math">\(\vv_3\)</span> is linearly independent.</p></article><article class="exercise exercise-like" id="exercise-59"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-92">
<p id="p-1077">Consider the span of <span class="process-math">\(S=\{\vv_1, \vv_2, \vv_3, \vv_4\}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_1= \left[ \begin{array}{c} 1\\ 1\\ 1\\ 4 \end{array}  \right]\, ,\, \vv_2 = \left[ \begin{array}{c} 2\\1\\0\\3 \end{array}  \right]\, ,\, \vv_3 = \left[ \begin{array}{r} 3\\2\\-1\\1 \end{array}  \right]\, ,\, \vv_4 = \left[ \begin{array}{c} 3\\3\\1\\6 \end{array}  \right]\,\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-312"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1078">Is the set <span class="process-math">\(S\)</span> a minimal spanning set of <span class="process-math">\(\Span \ S\text{?}\)</span> If not, determine a minimal spanning set, i.e. a basis, of <span class="process-math">\(\Span\ S\text{.}\)</span></p></article><article class="task exercise-like" id="task-313"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1080">Check that the vector <span class="process-math">\(\vu=\left[ \begin{array}{r} 6\\5\\-2\\1 \end{array} \right]\)</span> is in <span class="process-math">\(\Span \ S\text{.}\)</span> Find the unique representation of <span class="process-math">\(\vu\)</span> in terms of the basis vectors.</p></article></article><article class="exercise exercise-like" id="exercise-60"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-1082">Come up with a <span class="process-math">\(4\times 3\)</span> matrix with linearly independent columns, if possible. If not, explain why not.</p></article><article class="exercise exercise-like" id="exercise-61"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-1083">Come up with a <span class="process-math">\(3\times 4\)</span> matrix with linearly independent columns, if possible. If not, explain why not.</p></article><article class="exercise exercise-like" id="exercise-62"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<p id="p-1085">Give an example of vectors <span class="process-math">\(\vv_1, \vv_2, \vv_3\)</span> such that a minimal spanning set for <span class="process-math">\(\Span\{\vv_1, \vv_2, \vv_3\}\)</span> is equal to that of <span class="process-math">\(\Span\{\vv_1, \vv_2\}\text{;}\)</span> and an example of three vectors <span class="process-math">\(\vv_1, \vv_2, \vv_3\)</span> such that a minimal spanning set for <span class="process-math">\(\Span\{\vv_1, \vv_2, \vv_3\}\)</span> is equal to that of <span class="process-math">\(\Span\{\vv_1, \vv_3\}\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-63"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-93"><p id="p-1086">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-314"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1087">If <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\)</span> and <span class="process-math">\(\vv_3\)</span> are three vectors none of which is a multiple of another, then these vectors form a linearly independent set.</p></article><article class="task exercise-like" id="task-315"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1089">If <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\)</span> and <span class="process-math">\(\vv_3\)</span> in <span class="process-math">\(\R^n\)</span> are linearly independent vectors, then so are <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\vv_3\)</span> and <span class="process-math">\(\vv_4\)</span> for any <span class="process-math">\(\vv_4\)</span> in <span class="process-math">\(\R^n\text{.}\)</span></p></article><article class="task exercise-like" id="task-316"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1090">If <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\vv_3\)</span> and <span class="process-math">\(\vv_4\)</span> in <span class="process-math">\(\R^n\)</span> are linearly independent vectors, then so are <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\)</span> and <span class="process-math">\(\vv_3\text{.}\)</span></p></article><article class="task exercise-like" id="task-317"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1092">A <span class="process-math">\(3\times 4\)</span> matrix cannot have linearly independent columns.</p></article><article class="task exercise-like" id="task-318"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1093">If two vectors span <span class="process-math">\(\R^2\text{,}\)</span> then they are linearly independent.</p></article><article class="task exercise-like" id="task-319"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1095">The space <span class="process-math">\(\R^3\)</span> cannot contain four linearly independent vectors.</p></article><article class="task exercise-like" id="task-320"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1096">If two vectors are linearly dependent, then one is a scalar multiple of the other.</p></article><article class="task exercise-like" id="task-321"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1098">If a set of vectors in <span class="process-math">\(\R^n\)</span> is linearly dependent, then the set contains more than <span class="process-math">\(n\)</span> vectors.</p></article><article class="task exercise-like" id="task-322"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1099">The columns of a matrix <span class="process-math">\(A\)</span> are linearly independent if the equation <span class="process-math">\(A\vx=\vzero\)</span> has only the trivial solution.</p></article><article class="task exercise-like" id="task-323"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1101">Let <span class="process-math">\(W = \Span\{\vv_1, \vv_2, \vv_3, \vv_4\}\text{.}\)</span> If <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> is a minimal spanning set for <span class="process-math">\(W\text{,}\)</span> then <span class="process-math">\(\{\vv_1, \vv_2, \vv_4\}\)</span> cannot also be a minimal spanning set for <span class="process-math">\(W\text{.}\)</span></p></article><article class="task exercise-like" id="task-324"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1102">Let <span class="process-math">\(W = \Span\{\vv_1, \vv_2, \vv_3, \vv_4\}\text{.}\)</span> If <span class="process-math">\(\{\vv_1, \vv_2, \vv_3\}\)</span> is a minimal spanning set for <span class="process-math">\(W\text{,}\)</span> then <span class="process-math">\(\{\vv_1, \vv_2\}\)</span> cannot also be a minimal spanning set for <span class="process-math">\(W\text{.}\)</span></p></article><article class="task exercise-like" id="task-325"><h5 class="heading">
<span class="codenumber">(l)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1104">If <span class="process-math">\(\vv_3=2\vv_1-3\vv_2\text{,}\)</span> then <span class="process-math">\(\{\vv_1, \vv_2\}\)</span> is a minimal spanning set for <span class="process-math">\(\Span\{\vv_1, \vv_2, \vv_3\}\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_bezier"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Project: Generating Bézier Curves</span>
</h3>
<p id="p-1105">Bézier curves can be created as linear combinations of vectors. In this section we will investigate how cubic Bézier curves (the ones used for fonts) can be realized through linear and quadratic Bézier curves. We begin with linear Bézier curves.</p>
<article class="project project-like" id="act_1_d_linear_Bezier"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">6.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-94">
<p id="p-1106">Start with two vectors <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\text{.}\)</span> Linear Bézier curves are linear combinations</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vq = (1-t)\vp_0 + t\vp_1
\end{equation*}
</div>
<p class="continuation">of the vectors <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\)</span> for scalars <span class="process-math">\(t\)</span> between 0 and 1. (You can visualize these linear combinations using the GeoGebra file <code class="code-inline tex2jax_ignore">Linear Bezier</code> at <a class="external" href="https://www.geogebra.org/m/HvrPhh86" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/HvrPhh86</code></a>. With this file you can draw the vectors <span class="process-math">\(\vq\)</span> for varying values of <span class="process-math">\(t\text{.}\)</span> You can move the points <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\)</span> in the GeoGebra file, and the slider controls the values of <span class="process-math">\(t\text{.}\)</span> The point identified with <span class="process-math">\(\vq\)</span> is traced as <span class="process-math">\(t\)</span> is changed.) For this activity, we will see what the curve <span class="process-math">\(\vq\)</span> corresponds to by evaluating certain points on the curve in a specific example. Let <span class="process-math">\(\vp_0 = \left[ \begin{array}{c} 2 \\ 1 \end{array}  \right]\)</span> and <span class="process-math">\(\vp_1 = \left[ \begin{array}{c} 6 \\ 3 \end{array}  \right]\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-326"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1107">What are the components of the vector <span class="process-math">\((1-t)\vp_0 + t\vp_1\)</span> if <span class="process-math">\(t = \frac{1}{2}\text{?}\)</span> Where is this vector in relation to <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-327"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1108">What are the components of the vector <span class="process-math">\((1-t)\vp_0 + t\vp_1\)</span> if <span class="process-math">\(t = \frac{1}{3}\text{?}\)</span> Where is this vector in relation to <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-328"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1109">What are the components of the vector <span class="process-math">\((1-t)\vp_0 + t\vp_1\)</span> for an arbitrary <span class="process-math">\(t\text{?}\)</span> Where is this vector in relation to <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\text{?}\)</span> Explain.</p></article></article><p id="p-1110">For each value of <span class="process-math">\(t\text{,}\)</span> the vector <span class="process-math">\(\vq = (1-t)\vp_0 + t\vp_1\)</span> is a linear combination of the vectors <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\text{.}\)</span> Note that when <span class="process-math">\(t=0\text{,}\)</span> we have <span class="process-math">\(\vq = \vp_0\)</span> and when <span class="process-math">\(t=1\)</span> we have <span class="process-math">\(\vq = \vp_1\text{,}\)</span> and for <span class="process-math">\(0 \leq t \leq 1\)</span> <a href="" class="xref" data-knowl="./knowl/act_1_d_linear_Bezier.html" title="Project Activity 6.8">Project Activity 6.8</a> shows that the vectors <span class="process-math">\(\vq\)</span> trace out the line segment from <span class="process-math">\(\vp_0\)</span> to <span class="process-math">\(\vp_1\text{.}\)</span> The span <span class="process-math">\(\{(1-t)\vp_0 + t\vp_1\}\)</span> of the vectors <span class="process-math">\(\vp_0\)</span> and <span class="process-math">\(\vp_1\)</span> for <span class="process-math">\(0 \leq t \leq 1\)</span> is a linear Bézier curve. Once we have a construction like this, it is natural in mathematics to extend it and see what happens. We do that in the next activity to construct quadratic Bézier curves.</p>
<article class="project project-like" id="act_1_d_quadratic_Bezier"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">6.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-95">
<p id="p-1111">Let <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\)</span> be vectors in the plane. We can then let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_1_d_linear_Bezier.html">
\begin{equation*}
\vq_0 = (1-t)\vp_0 + t\vp_1 \ \ \text{ and }  \ \  \vq_1 = (1-t)\vp_1 + t\vp_2
\end{equation*}
</div>
<p class="continuation">be the linear Bézier curves as defined in <a href="" class="xref" data-knowl="./knowl/act_1_d_linear_Bezier.html" title="Project Activity 6.8">Project Activity 6.8</a>. Since <span class="process-math">\(\vq_0\)</span> and <span class="process-math">\(\vq_1\)</span> are vectors, we can define <span class="process-math">\(\vr\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_1_d_linear_Bezier.html">
\begin{equation*}
\vr = (1-t)\vq_0 + t\vq_1\text{.}
\end{equation*}
</div>
<p id="p-1112">(You can visualize these linear combinations using the GeoGebra file <code class="code-inline tex2jax_ignore">Quadraric Bezier</code> at <a class="external" href="https://www.geogebra.org/m/VWCZZBXz" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/VWCZZBXz</code></a>. With this file you can draw the vectors <span class="process-math">\(\vr\)</span> for varying values of <span class="process-math">\(t\text{.}\)</span> You can move the points <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\)</span> in the GeoGebra file, and the slider controls the values of <span class="process-math">\(t\text{.}\)</span> The point identified with <span class="process-math">\(\vr\)</span> is traced as <span class="process-math">\(t\)</span> is changed.) In this activity we investigate how the vectors <span class="process-math">\(\vr\)</span> change as <span class="process-math">\(t\)</span> changes. For the remainder of this activity, let <span class="process-math">\(\vp_0 = \left[ \begin{array}{c} 2 \\ 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vp_1 = \left[ \begin{array}{c} 8 \\ 4 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vp_2 = \left[ \begin{array}{r} 6 \\ -3 \end{array} \right]\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-329"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1113">At what point (in terms of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\)</span>) is the vector <span class="process-math">\(\vr = (1-t)\vq_0 + t\vq_1\)</span> when <span class="process-math">\(t=0\text{?}\)</span> Explain using the definition of <span class="process-math">\(\vr\text{.}\)</span></p></article><article class="task exercise-like" id="task-330"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1114">At what point (in terms of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\)</span>) is the vector <span class="process-math">\(\vr = (1-t)\vq_0 + t\vq_1\)</span> when <span class="process-math">\(t=1\text{?}\)</span> Explain using the definition of <span class="process-math">\(\vr\text{.}\)</span></p></article><article class="task exercise-like" id="task-331"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1115">Find by hand the components of the vector <span class="process-math">\((1-t)\vq_0 + t\vq_1\)</span> with <span class="process-math">\(t = \frac{1}{4}\text{.}\)</span> Compare with the result of the GeoGebra file.</p></article></article><p id="p-1116">The span <span class="process-math">\(\{(1-t)\vq_0 + t \vq_1\}\)</span> of the vectors <span class="process-math">\(\vq_0\)</span> and <span class="process-math">\(\vq_1\text{,}\)</span> or the set of points traced out by the vectors <span class="process-math">\(\vr\)</span> for <span class="process-math">\(0 \leq t \leq 1\text{,}\)</span> is a quadratic Bézier curve. To understand why this curve is called quadratic, we examine the situation in a general context in the following activity.</p>
<article class="project project-like" id="act_1_d_quadratic_Bezier_general"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">6.10</span><span class="period">.</span>
</h4>
<p id="p-1117">Let <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\)</span> be arbitrary vectors in the plane. Write <span class="process-math">\(\vr = (1-t)\vq_0 + t\vq_1\)</span> as a linear combination of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> and <span class="process-math">\(\vp_2\text{.}\)</span> That is, write <span class="process-math">\(\vr\)</span> in the form <span class="process-math">\(a_0 \vp_0 + a_1 \vp_1 + a_2 \vp_2\)</span> for some scalars (that may depend on <span class="process-math">\(t\)</span>) <span class="process-math">\(a_0\text{,}\)</span> <span class="process-math">\(a_1\text{,}\)</span> and <span class="process-math">\(a_2\text{.}\)</span> Explain why the result leads us to call these vectors <dfn class="terminology">quadratic</dfn> Bézier curves.</p></article><p id="p-1118">Notice that if any one of the <span class="process-math">\(\vp_i\)</span> lies on the line determined by the other two vectors, then the quadratic Bézier curve is just a line segment. So to obtain something non-linear we need to choose our vectors so that that doesn't happen.</p>
<p id="p-1119">Quadratic Bézier curves are limited, because their graphs are parabolas. For applications we need higher order Bézier curves. In the next activity we consider cubic Bézier curves.</p>
<article class="project project-like" id="act_1_d_cubic_Bezier"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">6.11</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-96">
<p id="p-1120">Start with four vectors <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> <span class="process-math">\(\vp_3\)</span> — the points defined by these vectors are called <em class="emphasis">control points</em> for the curve. As with the linear and quadratic Bézier curves, we let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vq_0 = (1-t)\vp_0 + t\vp_1, \ \ \vq_1 = (1-t)\vp_1+t\vp_2,  \ \ \text{ and }  \ \  \vq_2 = (1-t)\vp_2 + t\vp_3\text{.}
\end{equation*}
</div>
<p id="p-1121">Then let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vr_0 = (1-t)\vq_0 + t\vq_1 \ \ \text{ and }  \ \ \vr_1 = (1-t)\vq_1 + t\vq_2\text{.}
\end{equation*}
</div>
<p id="p-1122">We take this one step further to generate the cubic Bézier curves by letting</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vs = (1-t)\vr_0 + t\vr_1\text{.}
\end{equation*}
</div>
<p id="p-1123">(You can visualize these linear combinations using the GeoGebra file <code class="code-inline tex2jax_ignore">Cubic Bezier</code> at <a class="external" href="https://www.geogebra.org/m/EDAhudy9" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/EDAhudy9</code></a>. With this file you can draw the vectors <span class="process-math">\(\vs\)</span> for varying values of <span class="process-math">\(t\text{.}\)</span> You can move the points <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\)</span> in the GeoGebra file, and the slider controls the values of <span class="process-math">\(t\text{.}\)</span> The point identified with <span class="process-math">\(\vs\)</span> is traced as <span class="process-math">\(t\)</span> is changed.) In this activity we investigate how the vectors <span class="process-math">\(\vs\)</span> change as <span class="process-math">\(t\)</span> changes. For the remainder of this activity, let <span class="process-math">\(\vp_0 = \left[ \begin{array}{c} 1 \\ 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vp_1 = \left[ \begin{array}{c} 4 \\ 5 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vp_2 = \left[ \begin{array}{r} 9 \\ -3 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vp_3 = \left[ \begin{array}{c} 2 \\ 0 \end{array} \right]\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-332"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1124">At what point (in terms of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\)</span>) is the vector <span class="process-math">\(\vs = (1-t)\vr_0 + t\vr_1\)</span> when <span class="process-math">\(t=0\text{?}\)</span> Explain using the definition of <span class="process-math">\(\vs\text{.}\)</span></p></article><article class="task exercise-like" id="task-333"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1125">At what point (in terms of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\)</span>) is the vector <span class="process-math">\(\vs = (1-t)\vr_0 + t\vr_1\)</span> when <span class="process-math">\(t=1\text{?}\)</span> Explain using the definition of <span class="process-math">\(\vs\text{.}\)</span></p></article><article class="task exercise-like" id="task-334"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1126">Find by hand the components of the vector <span class="process-math">\((1-t)\vr_0 + t\vr_1\)</span> with <span class="process-math">\(t = \frac{3}{4}\text{.}\)</span> Compare with the result of the GeoGebra file.</p></article></article><p id="p-1127">The span <span class="process-math">\(\{(1-t)\vr_0 + t \vr_1\}\)</span> of the vectors <span class="process-math">\(\vr_0\)</span> and <span class="process-math">\(\vr_1\text{,}\)</span> or the set of points traced out by the vectors <span class="process-math">\(\vs\)</span> for <span class="process-math">\(0 \leq t \leq 1\text{,}\)</span> is a cubic Bézier curve. To understand why this curve is called cubic, we examine the situation in a general context in the following activity.</p>
<article class="project project-like" id="act_1_d_cubic_Bezier_general"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">6.12</span><span class="period">.</span>
</h4>
<p id="p-1128">Let <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\)</span> be arbitrary vectors in the plane. Write <span class="process-math">\(\vs = (1-t)\vr_0 + t\vr_1\)</span> as a linear combination of <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\text{.}\)</span> That is, write <span class="process-math">\(\vs\)</span> in the form <span class="process-math">\(b_0 \vp_0 + b_1 \vp_1 + b_2 \vp_2 + b_3 \vp_3\)</span> for some scalars (that may depend on <span class="process-math">\(t\)</span>) <span class="process-math">\(b_0\text{,}\)</span> <span class="process-math">\(b_1\text{,}\)</span> <span class="process-math">\(b_2\text{,}\)</span> and <span class="process-math">\(b_3\text{.}\)</span> Explain why the result leads us to call these vectors <dfn class="terminology">cubic</dfn> Bézier curves.</p></article><p id="p-1129">Just as with the quadratic case, we need certain subsets of the set of control vectors to be linearly independent so that the cubic Bézier curve does not degenerate to a quadratic or linear Bézier curve.</p>
<p id="p-1130">More complicated and realistic shapes can be represented by piecing together two or more Bézier curves as illustrated with the letter “S” in <a href="" class="xref" data-knowl="./knowl/F_Letter_S.html" title="Figure 6.1">Figure 6.1</a>. Suppose we have two cubic Bézier curves, the first with control points <span class="process-math">\(\vp_0\text{,}\)</span> <span class="process-math">\(\vp_1\text{,}\)</span> <span class="process-math">\(\vp_2\text{,}\)</span> and <span class="process-math">\(\vp_3\)</span> and the second with control points <span class="process-math">\(\vp_0'\text{,}\)</span> <span class="process-math">\(\vp_1'\text{,}\)</span> <span class="process-math">\(\vp_2'\text{,}\)</span> and <span class="process-math">\(\vp_3'\text{.}\)</span> You may have noticed that <span class="process-math">\(\vp_1\)</span> lies on the tangent line to the first Bézier curve at <span class="process-math">\(\vp_0\)</span> and that <span class="process-math">\(\vp_2\)</span> lies on the tangent line to the first Bézier curve at <span class="process-math">\(\vp_3\text{.}\)</span> (Play around with the program <code class="code-inline tex2jax_ignore">Cubic Bezier</code> to convince yourself of these statements. This can be proved in a straightforward manner using vector calculus.) So if we want to make a smooth curve from these two Bézier curves, the curves will need to join together smoothly at <span class="process-math">\(\vp_3\)</span> and <span class="process-math">\(\vp_0'\text{.}\)</span> This will force <span class="process-math">\(\vp_3 = \vp_0'\)</span> and the tangents at <span class="process-math">\(\vp_3 = \vp_0'\)</span> will have to match. This implies that <span class="process-math">\(\vp_2\text{,}\)</span> <span class="process-math">\(\vp_3\text{,}\)</span> and <span class="process-math">\(\vp_1'\)</span> all have to lie on this common tangent line. Keeping this idea in mind, use the GeoGebra file <code class="code-inline tex2jax_ignore">Cubic Bezier Pair</code> at <a class="external" href="https://www.geogebra.org/m/UwxQ6RPk" target="_blank"><code class="code-inline tex2jax_ignore">geogebra.org/m/UwxQ6RPk</code></a> to find control points for the pair of Bézier curves that create your own letter S.</p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-9"><div class="fn">The plural of basis is bases.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
