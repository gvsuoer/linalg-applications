<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-05-25T08:23:03-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The Singular Value Decomposition</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_principal_axis_theorem.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-app-orthog.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_pseudoinverses.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_principal_axis_theorem.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-app-orthog.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_pseudoinverses.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Sqaures Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_SVD"><h2 class="heading">
<span class="type">Chapter</span> <span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span>
</h2>
<section class="introduction" id="introduction-480"><article class="objectives goal-like" id="objectives-29"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-481"><p id="p-4892">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-750"><p id="p-4893">What is the operator norm of a matrix and what does it tell us about the matrix?</p></li>
<li id="li-751"><p id="p-4894">What is a singular value decomposition of a matrix? Why is a singular value decomposition important?</p></li>
<li id="li-752"><p id="p-4895">How does a singular value decomposition relate fundamental subspaces connected to a matrix?</p></li>
<li id="li-753"><p id="p-4896">What is an outer product decomposition of a matrix and how is it useful?</p></li>
</ul></article></section><section class="section" id="sec_appl_search_engn"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Application: Search Engines and Semantics</span>
</h3>
<p id="p-4897">Effective search engines search for more than just words. Language is complex and search engines must deal with the fact that there are often many ways to express a given concept (this is called <dfn class="terminology">synonymy</dfn>, that multiple words can have the same meaning), and that a single word can have multiple meanings (<dfn class="terminology">polysemy</dfn>). As a consequence, a search on a word may provide irrelevant matches (e.g., searching for <em class="emphasis">derivative</em> could provide pages on mathematics or financial securities) or you might search for articles on <em class="emphasis">cats</em> but the paper you really want uses the word <em class="emphasis">felines</em>. A better search engine will not necessarily try to match terms, but instead retrieve information based on concept or intent. Latent Semantic Indexing (LSI) (or <dfn class="terminology">Latent Semantic Analysis</dfn>), developed in the late 1980s, helps search engines determine concept and intent in order to provide more accurate and relevant results. LSI essentially works by providing underlying (latent) relationships between words (semantics) that search engines need to provide context and understanding (indexing). LSI provides a mapping of both words and documents into a lower dimensional “concept” space, and makes the search in this new space. The mapping is provided by the singular value decomposition.</p></section><section class="section" id="sec_svd_intro"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-4898">The singular value decomposition (SVD) of a matrix is an important and useful matrix decomposition. Unlike other matrix decompositions, <em class="emphasis">every</em> matrix has a singular value decomposition. The SVD is used in a variety of applications including scientific computing, digital signal processing, image compression, principal component analysis, web searching through latent semantic indexing, and seismology. Recall that the eigenvector decomposition of an <span class="process-math">\(n \times n\)</span> diagonalizable matrix <span class="process-math">\(M\)</span> has the form <span class="process-math">\(P^{-1}MP\text{,}\)</span> where the columns of the matrix <span class="process-math">\(P\)</span> are <span class="process-math">\(n\)</span> linearly independent eigenvectors of <span class="process-math">\(M\)</span> and the diagonal entries of the diagonal matrix <span class="process-math">\(P^{-1}MP\)</span> are the eigenvalues of <span class="process-math">\(M\text{.}\)</span> The singular value decomposition does something similar for any matrix of any size. One of the keys to the SVD is that the matrix <span class="process-math">\(A^{\tr}A\)</span> is symmetric for any matrix <span class="process-math">\(A\text{.}\)</span></p></section><section class="section" id="sec_mtx_op_norm"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">The Operator Norm of a Matrix</span>
</h3>
<p id="p-4899">Before we introduce the Singular Value Decomposition, let us work through some preliminaries to motivate the idea. The first is to provide an answer to the question “How ‘big’ is a matrix?” There are many ways to interpret and answer this question, but a substantial (and useful) answer should involve more than just the dimensions of the matrix. A good measure of the size of a matrix, which we will refer to as the norm of the matrix, should take into account the action of the linear transformation defined by the matrix on vectors. This then will lead to questions about how difficult or easy is it to solve a matrix equation <span class="process-math">\(A \vx = \vb\text{.}\)</span></p>
<p id="p-4900">If we want to incorporate the action of a matrix <span class="process-math">\(A\)</span> into a calculation of the norm of <span class="process-math">\(A\text{,}\)</span> we might think of measuring how much <span class="process-math">\(A\)</span> can change a vector <span class="process-math">\(\vx\text{.}\)</span> This could lead us to using <span class="process-math">\(||A\vx||\)</span> as some sort of measure of a norm of <span class="process-math">\(A\text{.}\)</span> However, since <span class="process-math">\(||A (c\vx)|| = |c| \ ||A\vx||\)</span> for any scalar <span class="process-math">\(c\text{,}\)</span> scaling <span class="process-math">\(\vx\)</span> by a large scalar will produce a large norm, so this is not a viable definition of a norm. We could instead measure the <dfn class="terminology">relative</dfn> effect that <span class="process-math">\(A\)</span> has on a vector <span class="process-math">\(\vx\)</span> as <span class="process-math">\(\ds \frac{||A\vx||}{||\vx||}\text{,}\)</span> since this ratio does not change when <span class="process-math">\(\vx\)</span> is multiplied by a scalar. The largest of all of these ratios would provide a good sense of how much <span class="process-math">\(A\)</span> can change vectors. Thus, we define the operator norm of a matrix <span class="process-math">\(A\)</span> as follows.</p>
<article class="definition definition-like" id="definition-65"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">29.1</span><span class="period">.</span>
</h4>
<p id="p-4901">The <dfn class="terminology">operator norm</dfn> <a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-48" id="fn-48"><sup> 48 </sup></a> of a matrix <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||A|| = \max_{||\vx|| \neq 0} \left\{\frac{||A\vx||}{||\vx||} \right\}\text{.}
\end{equation*}
</div></article><p id="p-4902">Due to the linearity of matrix multiplication, we can restrict ourselves to unit vectors for an equivalent definition of the operator norm of the matrix <span class="process-math">\(A\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||A|| = \ds \max_{||\vx|| = 1}\{||A\vx||\}\text{.}
\end{equation*}
</div>
<article class="exploration project-like" id="pa_7_c_1"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">29.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1641"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4903">Determine <span class="process-math">\(||A||\)</span> if <span class="process-math">\(A\)</span> is the zero matrix.</p></article><article class="task exercise-like" id="task-1642"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4904">Determine <span class="process-math">\(||I_n||\text{,}\)</span> where <span class="process-math">\(I_n\)</span> is the <span class="process-math">\(n \times n\)</span> identity matrix.</p></article><article class="task exercise-like" id="task-1643"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4905">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 0\\0\amp 2 \end{array} \right]\text{.}\)</span> Find <span class="process-math">\(||A||\text{.}\)</span> Justify your answer. (Hint: <span class="process-math">\(x_1^2+4x_2^2 \leq 4(x_1^2 + x_2^2)\text{.}\)</span>)</p></article><article class="task exercise-like" id="task-1644"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4906">If <span class="process-math">\(P\)</span> is an orthogonal matrix, what is <span class="process-math">\(||P||\text{?}\)</span> Why?</p></article></article><p id="p-4907">The operator norm of a matrix tells us that how big the action of an <span class="process-math">\(m \times n\)</span> matrix is can be determined by its action on the unit sphere in <span class="process-math">\(\R^n\)</span> (the unit sphere is the set of terminal point of unit vectors). Let us consider two examples.</p>
<article class="example example-like" id="example-58"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">29.2</span><span class="period">.</span>
</h4>
<p id="p-4908">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 1 \\ 2\amp 5 \end{array} \right]\text{.}\)</span> We can draw a graph to see the action of <span class="process-math">\(A\)</span> on the unit circle. A picture of the set <span class="process-math">\(\{A\vx \ : \ ||\vx|| = 1\}\)</span> is shown in <a href="" class="xref" data-knowl="./knowl/F_7_c_Mat_norm1.html" title="Figure 29.3">Figure 29.3</a>.</p>
<figure class="figure figure-like" id="F_7_c_Mat_norm1"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/7_c_Mat_norm_a.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">29.3<span class="period">.</span></span><span class="space"> </span>The image of the unit circle under the action of <span class="process-math">\(A\text{.}\)</span></figcaption></figure><p id="p-4909">It appears that <span class="process-math">\(A\)</span> transforms the unit circle into an ellipse. To find <span class="process-math">\(||A||\)</span> we want to maximize <span class="process-math">\(||A\vx||\)</span> for <span class="process-math">\(\vx\)</span> on the unit circle. This is the same as maximizing</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||A\vx||^2 = (A\vx)^{\tr}(A\vx) = \vx^{\tr}A^{\tr}A\vx\text{.}
\end{equation*}
</div>
<p id="p-4910">Now <span class="process-math">\(A^{\tr}A = \left[ \begin{array}{cc} 8\amp 12 \\ 12\amp 26 \end{array}  \right]\)</span> is a symmetric matrix, so we can orthogonally diagonalize <span class="process-math">\(A^{\tr}A\text{.}\)</span> The eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are 32 and 2. Let <span class="process-math">\(P = [\vu_1 \ \vu_2]\text{,}\)</span> where <span class="process-math">\(\vu_1=\left[ \frac{\sqrt{5}}{5} \ \frac{2\sqrt{5}}{5} \right]^{\tr}\)</span> is a unit eigenvector of <span class="process-math">\(A^{\tr}A\)</span> with eigenvalue 32 and <span class="process-math">\(\vu_2=\left[ -\frac{2\sqrt{5}}{5} \ \frac{\sqrt{5}}{5} \right]^{\tr}\)</span> is a unit eigenvector of <span class="process-math">\(A^{\tr}A\)</span> with eigenvalue 2. Then <span class="process-math">\(P\)</span> is an orthogonal matrix such that <span class="process-math">\(P^{\tr}(A^{\tr}A)P = \left[ \begin{array}{cc} 32\amp 0 \\ 0\amp 2 \end{array}  \right] = D\text{.}\)</span> It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx^{\tr} (A^{\tr}A)  \vx = \vx^{\tr} PDP^{\tr} \vx = (P^{\tr}\vx)^{\tr} D (P^{\tr}\vx)\text{.}
\end{equation*}
</div>
<p id="p-4911">Now <span class="process-math">\(P^{\tr}\)</span> is orthogonal, so <span class="process-math">\(||P^{\tr}\vx|| = ||\vx||\)</span> and <span class="process-math">\(P^{\tr}\)</span> maps the unit circle to the unit circle. Moreover, if <span class="process-math">\(\vx\)</span> is on the unit circle, then <span class="process-math">\(\vy = P\vx\)</span> is also on the unit circle and <span class="process-math">\(P^{\tr}\vy = P^{\tr}P\vx = \vx\text{.}\)</span> So every point <span class="process-math">\(\vx\)</span> on the unit circle corresponds to a point <span class="process-math">\(P\vx\)</span> on the unit circle. Thus, the forms <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\)</span> and <span class="process-math">\((P^{\tr}\vx)^{\tr} D (P^{\tr}\vx)\)</span> take on exactly the same values over all points on the unit circle. Now we just need to find the maximum value of <span class="process-math">\((P^{\tr}\vx)^{\tr} D (P^{\tr}\vx)\text{.}\)</span> This turns out to be relatively easy since <span class="process-math">\(D\)</span> is a diagonal matrix.</p>
<p id="p-4912">Let's simplify the notation. Let <span class="process-math">\(\vy = P^{\tr}\vx\text{.}\)</span> Then our job is to maximize <span class="process-math">\(\vy^{\tr}D\vy\text{.}\)</span> If <span class="process-math">\(\vy = [y_1 \ y_2]^{\tr}\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vy^{\tr} D  \vy = 32y_1^2 + 2y_2^2\text{.}
\end{equation*}
</div>
<p id="p-4913">We want to find the maximum value of this expression for <span class="process-math">\(\vy\)</span> on the unit circle. Note that <span class="process-math">\(2y_2^2 \leq 32y_2^2\)</span> and so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
32y_1^2 + 2y_2^2 \leq 32y_1^2 + 32y_2^2 = 32(y_1^2+y_2^2) = 32||\vy||^2 = 32\text{.}
\end{equation*}
</div>
<p id="p-4914">Since <span class="process-math">\([1 \ 0]^{\tr}\)</span> is on the unit circle, the expression <span class="process-math">\(32y_1^2 + 2y_2^2\)</span> attains the value 32 at some point on the unit circle, so 32 is the maximum value of <span class="process-math">\(\vy^{\tr} D \vy\)</span> over all <span class="process-math">\(\vy\)</span> on the unit circle. While we are at it, we can similarly find the minimum value of <span class="process-math">\(\vy^{\tr} D  \vy\)</span> for <span class="process-math">\(\vy\)</span> on the unit circle. Since <span class="process-math">\(2y_1^2 \leq 32y_1^2\)</span> we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
32y_1^2 + 2y_2^2 \geq 2y_1^2 + 2y_2^2 = 2(y_1^2+y_2^2) = 2||\vy||^2 = 2\text{.}
\end{equation*}
</div>
<p id="p-4915">Since the expression <span class="process-math">\(\vy^{\tr} D \vy\)</span> attains the value 2 at <span class="process-math">\([0 \ 1]^{\tr}\)</span> on the unit circle, we can see that <span class="process-math">\(\vy^{\tr} D \vy\)</span> attains the minimum value of 2 on the unit circle.</p>
<p id="p-4916">Now we can return to the expression <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\text{.}\)</span> Since <span class="process-math">\(\vy^{\tr} D \vy\)</span> assumes the same values as <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\text{,}\)</span> we can say that the maximum value of <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\)</span> for <span class="process-math">\(\vx\)</span> on the unit circle is 32 (and the minimum value is 2). Moreover, the quadratic form <span class="process-math">\((P^{\tr}\vx)^{\tr} D (P^{\tr}\vx)\)</span> assumes its maximum value when <span class="process-math">\(P^{\tr}\vx = [1 \ 0]^{\tr}\)</span> or <span class="process-math">\([-1 \ 0]^{\tr}\text{.}\)</span> Thus, the form <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\)</span> assumes its maximum value at the vector <span class="process-math">\(\vx = P[1 \ 0 ]^{\tr} = \vu_1\)</span> or <span class="process-math">\(-\vu_1\text{.}\)</span> Similarly, the quadratic form <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\)</span> attains its minimum value at <span class="process-math">\(P[0 \ 1]^{\tr} = \vu_2\)</span> or <span class="process-math">\(-\vu_2\text{.}\)</span> We conclude that <span class="process-math">\(||A|| = \sqrt{32}\text{.}\)</span></p>
<p id="p-4917"><a href="" class="xref" data-knowl="./knowl/F_7_c_Mat_norm1_b.html" title="Figure 29.4">Figure 29.4</a> shows the image of the unit circle under the action of <span class="process-math">\(A\)</span> and the images of <span class="process-math">\(A\vu_1\)</span> and <span class="process-math">\(A\vu_2\)</span> where <span class="process-math">\(\vu_1, \vu_2\)</span> are the two unit eigenvectors of <span class="process-math">\(A^{\tr}A\text{.}\)</span> The image also supports that <span class="process-math">\(A\vx\)</span> assumes its maximum and minimum values for points on the unit circle at <span class="process-math">\(\vu_1\)</span> and <span class="process-math">\(\vu_2\text{.}\)</span></p>
<figure class="figure figure-like" id="F_7_c_Mat_norm1_b"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/7_c_Mat_norm_b.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">29.4<span class="period">.</span></span><span class="space"> </span>The image of the unit circle under the action of <span class="process-math">\(A\text{,}\)</span> and the vectors <span class="process-math">\(A\vu_1\)</span> and <span class="process-math">\(A\vu_2\)</span></figcaption></figure></article><section class="paragraphs" id="paragraphs-29"><h4 class="heading"><span class="title">IMPORTANTE NOTE 1.</span></h4>
<p id="p-4918">What we have just argued is that the maximum value of <span class="process-math">\(||A\vx||\)</span> for <span class="process-math">\(\vx\)</span> on the unit sphere in <span class="process-math">\(\R^n\)</span> is the square root of the largest eigenvalue of <span class="process-math">\(A^{\tr}A\)</span> and occurs at a corresponding unit eigenvector.</p></section><article class="example example-like" id="example-59"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">29.5</span><span class="period">.</span>
</h4>
<p id="p-4919">This same process works for matrices other than <span class="process-math">\(2 \times 2\)</span> ones. For example, consider <span class="process-math">\(A = \left[ \begin{array}{rrr} -2\amp 8\amp 20 \\ 14\amp 19\amp 10 \end{array} \right]\text{.}\)</span> In this case <span class="process-math">\(A\)</span> maps <span class="process-math">\(\R^3\)</span> to <span class="process-math">\(\R^2\text{.}\)</span> The image of the unit sphere <span class="process-math">\(\{\vx \in \R^3 : ||\vx|| = 1\}\)</span> under left multiplication by <span class="process-math">\(A\)</span> is a filled ellipse as shown in <a href="" class="xref" data-knowl="./knowl/F_7_c_Mat_norm_2.html" title="Figure 29.6">Figure 29.6</a>.</p>
<figure class="figure figure-like" id="F_7_c_Mat_norm_2"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/7_c_Mat_norm_2.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">29.6<span class="period">.</span></span><span class="space"> </span>The image of the unit circle under the action of <span class="process-math">\(A\text{,}\)</span> and the vectors <span class="process-math">\(A\vu_1\)</span> and <span class="process-math">\(A\vu_2\)</span></figcaption></figure><p id="p-4920">As with the previous example, the norm of <span class="process-math">\(A\)</span> is the square root of the maximum value of <span class="process-math">\(\vx^{\tr} (A^{\tr}A) \vx\)</span> and this maximum value is the dominant eigenvalue of <span class="process-math">\(A^{\tr}A = \left[ \begin{array}{ccc} 200\amp 250\amp 100\\ 250\amp 425\amp 350\\ 100\amp 350\amp 500 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(\lambda_1 = 900\text{,}\)</span> <span class="process-math">\(\lambda_2 = 225\text{,}\)</span> and <span class="process-math">\(\lambda_3 = 0\)</span> with corresponding unit eigenvectors <span class="process-math">\(\vu_1=\left[ \frac{1}{3} \ \frac{2}{3} \ \frac{2}{3} \right]^{\tr}\text{,}\)</span> <span class="process-math">\(\vu_1=\left[ -\frac{2}{3} \ -\frac{1}{3} \ \frac{2}{3} \right]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vu_3=\left[ \frac{2}{3} \ -\frac{2}{3} \ \frac{1}{3} \right]^{\tr}\text{.}\)</span> So in this case we have <span class="process-math">\(||A|| = \sqrt{900} = 30\text{.}\)</span> The transformation defined by matrix multiplication by <span class="process-math">\(A\)</span> from <span class="process-math">\(\R^3\)</span> to <span class="process-math">\(\R^2\)</span> has a one-dimensional kernel which is spanned by the eigenvector corresponding to <span class="process-math">\(\lambda_3\text{.}\)</span> The image of the transformation is 2-dimensional and the image of the unit circle is an ellipse where <span class="process-math">\(A\vu_1\)</span> gives the major axis of the ellipse and <span class="process-math">\(A\vu_2\)</span> gives the minor axis. Essentially, the square roots of the eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> tell us how <span class="process-math">\(A\)</span> stretches the image space in each direction.</p></article><section class="paragraphs" id="paragraphs-30"><h4 class="heading"><span class="title">IMPORTANT NOTE 2.</span></h4>
<p id="p-4921">We have just argued that the image of the unit <span class="process-math">\(n\)</span>-sphere under the action of an <span class="process-math">\(m \times n\)</span> matrix is an ellipsoid in <span class="process-math">\(\R^m\)</span> stretched the greatest amount, <span class="process-math">\(\sqrt{\lambda_1}\text{,}\)</span> in the direction of an eigenvector for the largest eigenvalue (<span class="process-math">\(\lambda_1\)</span>) of <span class="process-math">\(A^{\tr}A\text{;}\)</span> the next greatest amount, <span class="process-math">\(\sqrt{\lambda_2}\text{,}\)</span> in the direction of a unit vector for the second largest eigenvalue (<span class="process-math">\(\lambda_2\)</span>) of <span class="process-math">\(A^{\tr}A\text{;}\)</span> and so on.</p></section><article class="activity project-like" id="activity-110"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">29.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-482"><p id="p-4922">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 0\amp 5\\ 4\amp 3 \\ -2\amp 1 \end{array} \right]\text{.}\)</span> Then <span class="process-math">\(A^{\tr}A = \left[ \begin{array}{cc} 20\amp 10\\ 10\amp 35 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are <span class="process-math">\(\lambda_1 = 40\)</span> and <span class="process-math">\(\lambda_2 = 15\)</span> with respective eigenvectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{c} \frac{1}{2} \\ 1 \end{array} \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} -2 \\ 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1645"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4923">Find <span class="process-math">\(||A||\text{.}\)</span></p></article><article class="task exercise-like" id="task-1646"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4924">Find a unit vector <span class="process-math">\(\vx\)</span> at which <span class="process-math">\(||A\vx||\)</span> assumes its maximum value.</p></article></article></section><section class="section" id="sec_svd"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">The SVD</span>
</h3>
<p id="p-4925">The Singular Value Decomposition (SVD) is essentially a concise statement of what we saw in the previous section that works for <em class="emphasis">any</em> matrix. We will uncover the SVD in this section.</p>
<article class="exploration project-like" id="pa_7_c_2"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">29.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-483">
<p id="p-4926">Let <span class="process-math">\(A = \left[ \begin{array}{ccc} 1\amp 1\amp 0\\ 0\amp 1\amp 1 \end{array}  \right]\text{.}\)</span> Since <span class="process-math">\(A\)</span> is not square, we cannot diagonalize <span class="process-math">\(A\text{.}\)</span> However, the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A^{\tr}A = \left[ \begin{array}{ccc} 1\amp 1\amp 0 \\ 1\amp 2\amp 1 \\ 0\amp 1\amp 1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">is a symmetric matrix and can be orthogonally diagonalized. The eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are 3, 1, and 0 with corresponding eigenvectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{c} 1\\2\\1 \end{array}  \right], \ \left[ \begin{array}{r} -1\\0\\1 \end{array}  \right], \ \text{ and }  \ \left[ \begin{array}{r} 1\\-1\\1 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">respectively. Use appropriate technology to do the following.</p>
</div>
<article class="task exercise-like" id="task-1647"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4927">Find an orthogonal matrix <span class="process-math">\(V = [\vv_1 \ \vv_2 \ \vv_3]\)</span> that orthogonally diagonalizes <span class="process-math">\(A^{\tr}A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V^{\tr}\left(A^{\tr}A\right)V = \left[ \begin{array}{ccc} 3\amp 0\amp 0\\0\amp 1\amp 0\\0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1648"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4928">For <span class="process-math">\(i=1,2\text{,}\)</span> let <span class="process-math">\(\vu_i = \frac{A \vv_i}{||A \vv_i||}\text{.}\)</span> Find each <span class="process-math">\(\vu_i\text{.}\)</span> Why don't we define <span class="process-math">\(\vu_3\)</span> in this way?</p></article><article class="task exercise-like" id="task-1649"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4929">Let <span class="process-math">\(U = [\vu_1 \ \vu_2]\text{.}\)</span> What kind of matrix is <span class="process-math">\(U\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-1650"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4930">Calculate the matrix product <span class="process-math">\(U^{\tr}AV\text{.}\)</span> What do you notice? How is this similar to the eigenvector decomposition of a matrix?</p></article></article><p id="p-4931"><a href="" class="xref" data-knowl="./knowl/pa_7_c_2.html" title="Preview Activity 29.3">Preview Activity 29.3</a> contains the basic ideas behind the Singular Value Decomposition. Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix with real entries. Note that <span class="process-math">\(A^{\tr}A\)</span> is a symmetric <span class="process-math">\(n \times n\)</span> matrix and, hence, it can be orthogonally diagonalized. Let <span class="process-math">\(V = [\vv_1 \ \vv_2 \ \vv_3 \  \cdots \  \vv_n ]\)</span> be an <span class="process-math">\(n \times n\)</span> orthogonal matrix whose columns form an orthonormal set of eigenvectors for <span class="process-math">\(A^{\tr}A\text{.}\)</span> For each <span class="process-math">\(i\text{,}\)</span> let <span class="process-math">\((A^{\tr}A)\vv_i = \lambda_i \vv_i\text{.}\)</span> We know</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_7_c_2.html">
\begin{equation*}
V^{\tr} (A^{\tr}A) V = \left[ \begin{array}{ccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0 \\ 0\amp  \lambda_2\amp 0\amp \cdots\amp 0 \\ \vdots \amp  \vdots \amp  \vdots \amp  \amp  \vdots  \\ 0\amp 0\amp 0\amp \cdots\amp  \lambda_n \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4932">Now notice that for each <span class="process-math">\(i\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_7_c_sing_vals1">
\begin{equation}
|| A \vv_i ||^2 = (A\vv_i)^{\tr}(A\vv_i) = \vv_i^{\tr}(A^{\tr}A) \vv_i = \vv_i^{\tr} \lambda_i \vv_i = \lambda_i ||\vv_i||^2 = \lambda_i\text{,}\tag{29.1}
\end{equation}
</div>
<p class="continuation">so <span class="process-math">\(\lambda_i \geq 0\text{.}\)</span> Thus, the matrix <span class="process-math">\(A^{\tr}A\)</span> has no negative eigenvalues. We can always arrange the eigenvectors and eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0\text{.}
\end{equation*}
</div>
<p id="p-4933">Also note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(A\vv_i) \cdot (A\vv_j) = (A\vv_i)^{\tr} (A\vv_j) = \vv_i^{\tr} (A^{\tr}A) \vv_j = \vv_i^{\tr} \lambda_j\ \vv_j = \lambda_j \vv_i \cdot \vv_j = 0
\end{equation*}
</div>
<p class="continuation">if <span class="process-math">\(i \neq j\text{.}\)</span> So the set <span class="process-math">\(\{A\vv_1, A\vv_2, \ldots, A\vv_n\}\)</span> is an orthogonal set in <span class="process-math">\(\R^m\text{.}\)</span> Each of the vectors <span class="process-math">\(A\vv_i\)</span> is in <span class="process-math">\(\Col A\text{,}\)</span> and so <span class="process-math">\(\{A\vv_1, A\vv_2, \ldots, A\vv_n\}\)</span> is an orthogonal subset of <span class="process-math">\(\Col A\text{.}\)</span> It is possible that <span class="process-math">\(A\vv_i = \vzero\)</span> for some of the <span class="process-math">\(\vv_i\)</span> (if <span class="process-math">\(A^{\tr}A\)</span> has 0 as an eigenvalue). Let <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_r\)</span> be the eigenvectors corresponding to the nonzero eigenvalues. Then the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\CB=\{A\vv_1, A\vv_2, \ldots, A\vv_r\}
\end{equation*}
</div>
<p class="continuation">is a linearly independent set of nonzero orthogonal vectors in <span class="process-math">\(\Col A\text{.}\)</span> Now we will show that <span class="process-math">\(\CB\)</span> is a basis for <span class="process-math">\(\Col A\text{.}\)</span> Let <span class="process-math">\(\vy\)</span> be a vector in <span class="process-math">\(\Col A\text{.}\)</span> Then <span class="process-math">\(\vy = A\vx\)</span> for some vector <span class="process-math">\(\vx\)</span> in <span class="process-math">\(\R^n\text{.}\)</span> Recall that the vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> form an orthonormal basis of <span class="process-math">\(\R^n\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx = x_1 \vv_1 + x_2 \vv_2 + \cdots + x_n \vv_n
\end{equation*}
</div>
<p class="continuation">for some scalars <span class="process-math">\(x_1\text{,}\)</span> <span class="process-math">\(x_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(x_n\text{.}\)</span> Since <span class="process-math">\(A\vv_j = \vzero\)</span> for <span class="process-math">\(r+1 \leq j \leq n\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-193">
\begin{align*}
\vy \amp = A\vx\\
\amp = A(x_1 \vv_1 + x_2 \vv_2 + \cdots + x_n \vv_n)\\
\amp = x_1 A\vv_1 + x_2 A\vv_2 + \cdots + x_r A\vv_r + x_{r+1} A \vv_{r+1} + \cdots + x_n A\vv_n\\
\amp = x_1 A\vv_1 + x_2 A\vv_2 + \cdots + x_r A\vv_r\text{.}
\end{align*}
</div>
<p id="p-4934">So <span class="process-math">\(\Span \ \CB = \Col A\)</span> and <span class="process-math">\(\CB\)</span> is an orthogonal basis for <span class="process-math">\(\Col A\text{.}\)</span></p>
<p id="p-4935">Now we are ready to find the Singular Value Decomposition of <span class="process-math">\(A\text{.}\)</span> First we create an orthonormal basis <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r\}\)</span> for <span class="process-math">\(\Col A\)</span> by normalizing the vectors <span class="process-math">\(A\vv_i\text{.}\)</span> So we let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu_i = \frac{A\vv_i}{||A\vv_i||}
\end{equation*}
</div>
<p class="continuation">for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{.}\)</span></p>
<p id="p-4936">Remember from <a href="" class="xref" data-knowl="./knowl/eq_7_c_sing_vals1.html" title="Equation 29.1">(29.1)</a> that <span class="process-math">\(||A\vv_i||^2 = \lambda_i\text{,}\)</span> so if we let <span class="process-math">\(\sigma_i = \sqrt{\lambda_i}\text{,}\)</span> then we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_7_c_sing_vals1.html">
\begin{equation*}
\vu_i = \frac{A\vv_i}{\sigma_i} \text{ and }  A \vv_i = \sigma_i \vu_i\text{.}
\end{equation*}
</div>
<p id="p-4937">We ordered the <span class="process-math">\(\lambda_i\)</span> so that <span class="process-math">\(\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n\text{,}\)</span> so we also have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r &gt; 0\text{.}
\end{equation*}
</div>
<p id="p-4938">The scalars <span class="process-math">\(\sigma_1\text{,}\)</span> <span class="process-math">\(\sigma_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\sigma_n\)</span> are called the <em class="emphasis">singular values</em> of <span class="process-math">\(A\text{.}\)</span></p>
<article class="definition definition-like" id="definition-66"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">29.7</span><span class="period">.</span>
</h4>
<p id="p-4939">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix. The <dfn class="terminology">singular values</dfn> of <span class="process-math">\(A\)</span> are the square roots of the eigenvalues of <span class="process-math">\(A^{\tr}A\text{.}\)</span></p></article><p id="p-4940">The vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\)</span> are <span class="process-math">\(r\)</span> orthonormal vectors in <span class="process-math">\(\R^m\text{.}\)</span> We can extend the set <span class="process-math">\(\{\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\}\)</span> to an orthonormal basis <span class="process-math">\(\CC = \{\vu_1, \vu_2, \ldots, \vu_r, \vu_{r+1} \vu_{r+2}, \ldots, \vu_m\}\)</span> of <span class="process-math">\(\R^m\text{.}\)</span> Recall that <span class="process-math">\(A \vv_i = \sigma_i \vu_i\)</span> for <span class="process-math">\(1 \leq i \leq r\)</span> and <span class="process-math">\(A \vv_j = \vzero\)</span> for <span class="process-math">\(r+1 \leq j \leq n\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-194">
\begin{align*}
AV \amp = A [\vv_1 \  \vv_2  \ \cdots  \ \vv_n]\\
\amp = [A\vv_1  \ A\vv_2  \ \cdots  \ A\vv_n]\\
\amp = [\sigma_1 \vu_1  \ \sigma_2 \vu_2  \ \cdots  \ \sigma_r \vu_r  \ \vzero  \ \vzero  \ \cdots  \ \vzero]\text{.}
\end{align*}
</div>
<p id="p-4941">We can write the matrix <span class="process-math">\([\sigma_1 \vv_1  \ \sigma_2 \vv_2  \ \cdots  \ \sigma_r \vv_r  \ \vzero  \ \vzero  \ \cdots  \ \vzero]\)</span> in another way. Let <span class="process-math">\(\Sigma\)</span> be the <span class="process-math">\(m\times n\)</span> matrix defined as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Sigma = \left[ \begin{array}{ccccc|c} \sigma_1\amp \amp \amp \amp 0\amp  \\ \amp  \sigma_2\amp \amp \amp \amp 0 \\ \amp \amp  \sigma_3\amp \amp \amp  \\ \amp   \amp  \amp  \ddots \amp  \amp  \\ 0\amp \amp \amp \amp  \sigma_r \\ \hline \amp \amp 0\amp \amp \amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4942">Now</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[\vu_1  \ \vu_2  \ \cdots  \ \vu_m] \Sigma = [\sigma_1\vu_1  \ \sigma_1\vu_2  \ \cdots  \ \sigma_r\vu_r \ \vzero \ \vzero \ \cdots \ \vzero] = AV\text{.}
\end{equation*}
</div>
<p id="p-4943">So if <span class="process-math">\(U = [\vu_1 \ \vu_2 \ \cdots \ \vu_m]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U\Sigma = AV\text{.}
\end{equation*}
</div>
<p id="p-4944">Since <span class="process-math">\(V\)</span> is an orthogonal matrix, we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U \Sigma V^{\tr} = AV V^{\tr} = A\text{.}
\end{equation*}
</div>
<p class="continuation">This is the Singular Value Decomposition of <span class="process-math">\(A\text{.}\)</span></p>
<article class="theorem theorem-like" id="theorem-72"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">29.8</span><span class="period">.</span><span class="space"> </span><span class="title">The Singular Value Decomposition.</span>
</h4>
<p id="p-4945">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix of rank <span class="process-math">\(r\text{.}\)</span> There exist an <span class="process-math">\(m \times m\)</span> orthogonal matrix <span class="process-math">\(U\text{,}\)</span> an <span class="process-math">\(n \times n\)</span> orthogonal matrix <span class="process-math">\(V\text{,}\)</span> and an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(\Sigma\)</span> whose first <span class="process-math">\(r\)</span> diagonal entries are the singular values <span class="process-math">\(\sigma_1\text{,}\)</span> <span class="process-math">\(\sigma_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\sigma_r\)</span> and whose other entries are 0, such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = U \Sigma V^{\tr}\text{.}
\end{equation*}
</div></article><section class="paragraphs" id="paragraphs-31"><h4 class="heading"><span class="title">SVD Summary.</span></h4>
<p id="p-4946">A Singular Value Decomposition of an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> of rank <span class="process-math">\(r\)</span> can be found as follows.</p>
<ol class="decimal">
<li id="li-754"><p id="p-4947">Find an orthonormal basis <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \ldots, \vv_n\}\)</span> of eigenvectors of <span class="process-math">\(A^{\tr}A\)</span> such that <span class="process-math">\((A^{\tr}A) \vv_i = \lambda_i \vv_i\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(n\)</span> with <span class="process-math">\(\lambda_1 \geq \lambda_{2} \geq \cdots \geq \lambda_n \geq 0\)</span> with the first <span class="process-math">\(r\)</span> eigenvalues being positive. The vectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\vv_3\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> are the <dfn class="terminology">right singular vectors</dfn> of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-755">
<p id="p-4948">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V= [\vv_1 \  \vv_2 \  \vv_3 \  \cdots \  \vv_n ]\text{.}
\end{equation*}
</div>
<p class="continuation">Then <span class="process-math">\(V\)</span> orthogonally diagonalizes <span class="process-math">\(A^{\tr}A\text{.}\)</span></p>
</li>
<li id="li-756">
<p id="p-4949">The singular values of <span class="process-math">\(A\)</span> are the numbers <span class="process-math">\(\sigma_i\text{,}\)</span> where <span class="process-math">\(\sigma_i = \sqrt{\lambda_i} &gt; 0\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{.}\)</span> Let <span class="process-math">\(\Sigma\)</span> be the <span class="process-math">\(m \times n\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Sigma = \left[ \begin{array}{ccccc|c} \sigma_1\amp \amp \amp \amp 0\amp  \\ \amp  \sigma_2\amp \amp \amp \amp 0 \\ \amp \amp  \sigma_3\amp \amp \amp  \\ \amp   \amp  \amp  \ddots \amp  \amp  \\ 0\amp \amp \amp \amp  \sigma_r \\ \hline \amp \amp 0\amp \amp \amp 0 \end{array}  \right]
\end{equation*}
</div>
</li>
<li id="li-757"><p id="p-4950">For <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{,}\)</span> let <span class="process-math">\(\vu_i = \frac{A\vv_i}{||A\vv_i||}\text{.}\)</span> Then the set <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r\}\)</span> forms an orthonormal basis of <span class="process-math">\(\Col A\text{.}\)</span></p></li>
<li id="li-758">
<p id="p-4951">Extend the set <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r\}\)</span> to an orthonormal basis</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{\vu_1, \vu_2, \ldots, \vu_r, \vu_{r+1} \vu_{r+2}, \ldots, \vu_m\}
\end{equation*}
</div>
<p class="continuation">of <span class="process-math">\(\R^m\text{.}\)</span> Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = [\vu_1 \ \vu_2 \ \cdots \ \vu_m]\text{.}
\end{equation*}
</div>
<p class="continuation">The vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_m\)</span> are the <dfn class="terminology">left singular vectors</dfn> of <span class="process-math">\(A\text{.}\)</span></p>
</li>
<li id="li-759"><p id="p-4952">Then <span class="process-math">\(A = U \Sigma V^{\tr}\)</span> is a singular value decomposition of <span class="process-math">\(A\text{.}\)</span></p></li>
</ol></section><article class="activity project-like" id="ex_7_c_SVD"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">29.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-484"><p id="p-4953">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 0\amp 5\\ 4\amp 3 \\ -2\amp 1 \end{array}  \right]\text{.}\)</span> Then <span class="process-math">\(A^{\tr}A = \left[ \begin{array}{cc} 20\amp 10\\ 10\amp 35 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are <span class="process-math">\(\lambda_1 = 40\)</span> and <span class="process-math">\(\lambda_2 = 15\)</span> with respective eigenvectors <span class="process-math">\(\vw_1 = \left[ \begin{array}{c} 1 \\ 2 \end{array}  \right]\)</span> and <span class="process-math">\(\vw_2 = \left[ \begin{array}{r} -2 \\ 1 \end{array}  \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1651"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4954">Find an orthonormal basis <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \ldots, \vv_n\}\)</span> of eigenvectors of <span class="process-math">\(A^{\tr}A\text{.}\)</span> What is <span class="process-math">\(n\text{?}\)</span> Find the matrix <span class="process-math">\(V\)</span> in a SVD for <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1652"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4955">Find the singular values of <span class="process-math">\(A\text{.}\)</span> What is the rank <span class="process-math">\(r\)</span> of <span class="process-math">\(A\text{?}\)</span> Why?</p></article><article class="task exercise-like" id="task-1653"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4956">What are the dimensions of the matrix <span class="process-math">\(\Sigma\)</span> in a SVD of <span class="process-math">\(A\text{?}\)</span> Find <span class="process-math">\(\Sigma\text{.}\)</span></p></article><article class="task exercise-like" id="task-1654"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4957">Find the vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\text{.}\)</span> If necessary, extend this set to an orthonormal basis</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{\vu_1, \vu_2, \ldots, \vu_r, \vu_{r+1} \vu_{r+2}, \ldots, \vu_m\}
\end{equation*}
</div>
<p class="continuation">of <span class="process-math">\(\R^m\text{.}\)</span></p></article><article class="task exercise-like" id="task-1655"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-4958">Find the matrix <span class="process-math">\(U\)</span> so that <span class="process-math">\(A = U \Sigma V^{\tr}\)</span> is a SVD for <span class="process-math">\(A\text{.}\)</span></p></article></article><p id="p-4959">There is another way we can write this SVD of <span class="process-math">\(A\text{.}\)</span> Let the <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> have a singular value decomposition <span class="process-math">\(U \Sigma V^{\tr}\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-195">
\begin{align*}
U \amp = [\vu_1 \ \vu_2 \ \cdots \ \vu_m],\\
\Sigma \amp = \left[ \begin{array}{ccccc|c} \sigma_1\amp \amp \amp \amp 0\amp\\
\amp  \sigma_2\amp \amp \amp \amp 0\\
\amp \amp  \sigma_3\amp \amp \amp\\
\amp   \amp  \amp  \ddots \amp  \amp\\
0\amp \amp \amp \amp  \sigma_r\\
\hline \amp \amp 0\amp \amp \amp 0 \end{array} \right],  \text{ and }\\
V \amp = [\vv_1 \ \vv_2 \ \vv_3 \   \cdots \  \vv_n ]\text{.}
\end{align*}
</div>
<p id="p-4960">Since <span class="process-math">\(A = U \Sigma V^{\tr}\)</span> we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-23">
\begin{align}
A \amp = [ \vu_1 \ \vu_2 \ \vu_3 \ \cdots \ \vu_m] \left[ \begin{array}{ccccc|c} \sigma_1\amp \amp \amp \amp 0\amp\notag\\
\amp  \sigma_2\amp \amp \amp \amp 0\notag\\
\amp \amp  \sigma_3\amp \amp \amp\notag\\
\amp   \amp  \amp  \ddots \amp  \amp\notag\\
0\amp \amp \amp \amp  \sigma_r\notag\\
\hline \amp \amp 0\amp \amp \amp 0 \end{array} \right] \left[  \begin{array}{c} \vv_1^{\tr}\notag\\
\vv_2^{\tr}\notag\\
\vv_3^{\tr}\notag\\
\vdots\notag\\
\vv_n^{\tr} \end{array} \right]\notag\\
\amp = [ \sigma_1\vu_1 \ \sigma_2\vu_2 \ \sigma_3\vu_3 \ \cdots \ \sigma_r\vu_r \ \vzero \ \cdots \ \vzero] \left[  \begin{array}{c} \vv_1^{\tr}\notag\\
\vv_2^{\tr}\notag\\
\vv_3^{\tr}\notag\\
\vdots\notag\\
\vv_n^{\tr} \end{array} \right]\notag\\
\amp = \sigma_1 \vu_1\vv_1^{\tr} + \sigma_2 \vu_2\vv_2^{\tr} + \sigma_3 \vu_3\vv_3^{\tr} + \cdots + \sigma_r \vu_r\vv_r^{\tr}\text{.}\tag{29.2}
\end{align}
</div>
<p id="p-4961"> This is called an <dfn class="terminology">outer product decomposition</dfn> of <span class="process-math">\(A\)</span> and tells us everything we learned above about the action of the matrix <span class="process-math">\(A\)</span> as a linear transformation. Each of the products <span class="process-math">\(\vu_i\vv_i^{\tr}\)</span> is a rank 1 matrix (see <a href="" class="xref" data-knowl="./knowl/ex_7_c_rank1.html" title="Exercise 9">Exercise 9</a>), and <span class="process-math">\(||A\vv_1|| = \sigma_1\)</span> is the largest value <span class="process-math">\(A\)</span> takes on the unit <span class="process-math">\(n\)</span>-sphere, <span class="process-math">\(||A\vv_2|| = \sigma_2\)</span> is the next largest dilation of the unit <span class="process-math">\(n\)</span>-sphere, and so on. An outer product decomposition allows us to approximate <span class="process-math">\(A\)</span> with smaller rank matrices. For example, the matrix <span class="process-math">\(\sigma_1 \vu_1\vv_1^{\tr}\)</span> is the best rank 1 approximation to <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(\sigma_1 \vu_1\vv_1^{\tr} + \sigma_2 \vu_2\vv_2^{\tr}\)</span> is the best rank 2 approximation, and so on. This will be very useful in applications, as we will see in the next section.</p></section><section class="section" id="sec_svd_mtx_spaces"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">SVD and the Null, Column, and Row Spaces of a Matrix</span>
</h3>
<p id="p-4962">We conclude this section with a short discussion of how a singular value decomposition relates fundamental subspaces of a matrix. We have seen that the vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\)</span> in an SVD for an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> form a basis for <span class="process-math">\(\Col A\text{.}\)</span> Recall also that <span class="process-math">\(A \vv_j = \vzero\)</span> for <span class="process-math">\(r+1 \leq j \leq n\text{.}\)</span> Since <span class="process-math">\(\dim(\Nul A) + \dim(\Col A) = n\text{,}\)</span> it follows that the vectors <span class="process-math">\(\vv_{r+1}\text{,}\)</span> <span class="process-math">\(\vv_{r+2}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> form a basis for <span class="process-math">\(\Nul A\text{.}\)</span> As you will show in the exercises, the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_r\}\)</span> is a basis for <span class="process-math">\(\Row A\text{.}\)</span> Thus, an SVD for a matrix <span class="process-math">\(A\)</span> tells us about three fundamental vector spaces related to <span class="process-math">\(A\text{.}\)</span></p></section><section class="section" id="sec_svd_exam"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-4963">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-60"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">29.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-485"><p id="p-4964">Let <span class="process-math">\(A = \left[ \begin{array}{cccc} 2 \amp 0 \amp 0 \amp 0 \\ 0 \amp 2 \amp 1 \amp 0 \\ 0\amp 1 \amp 2 \amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1656"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4965">Find a singular value decomposition for <span class="process-math">\(A\text{.}\)</span> You may use technology to find eigenvalues and eigenvectors of matrices.</p>
<div class="solution solution-like" id="solution-172">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4966">With <span class="process-math">\(A\)</span> as given, we have <span class="process-math">\(A^{\tr}A = \left[ \begin{array}{cccc} 4  \amp   0  \amp   0  \amp   0 \\  0  \amp   5  \amp   4  \amp   0 \\ 0  \amp   4  \amp   5  \amp   0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> Technology shows that the eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are <span class="process-math">\(\lambda_1 = 9\text{,}\)</span> <span class="process-math">\(\lambda_2 = 4\text{,}\)</span> <span class="process-math">\(\lambda_3 = 1\text{,}\)</span> and <span class="process-math">\(\lambda_4 = 0\)</span> with corresponding orthonormal eigenvectors <span class="process-math">\(\vv_1 = \frac{1}{\sqrt{2}}[0 \ 1 \ 1 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_2 = [1 \ 0 \ 0 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_3 = \frac{1}{\sqrt{2}}[0 \ -1 \ 1 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vv_4 = [0 \ 0 \ 0 \ 1]^{\tr}\text{.}\)</span> This makes <span class="process-math">\(V = [\vv_1 \ \vv_2 \ \vv_3 \ \vv_4]\text{.}\)</span> The singular values of <span class="process-math">\(A\)</span> are <span class="process-math">\(\sigma_1 = \sqrt{9} = 3\text{,}\)</span> <span class="process-math">\(\sigma_2 = \sqrt{4}= 2\text{,}\)</span> <span class="process-math">\(\sigma_3 = \sqrt{1} = 1\text{,}\)</span> and <span class="process-math">\(\sigma_4 = 0\text{,}\)</span> so <span class="process-math">\(\Sigma\)</span> is the <span class="process-math">\(3 \times 4\)</span> matrix with the nonzero singular values along the diagonal and zeros everywhere else. Finally, we define the vectors <span class="process-math">\(\vu_i\)</span> as <span class="process-math">\(\vu_i = \frac{1}{||A \vv_i||} A\vv_i\text{.}\)</span> Again, technology gives us <span class="process-math">\(\vu_1 = \frac{1}{\sqrt{2}}[0 \ 1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vu_2 = [1 \ 0 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vu_3 = \frac{1}{\sqrt{2}}[0 \ -1 \ 1]^{\tr}\text{.}\)</span> Thus, a singular value decomposition of <span class="process-math">\(A\)</span> is <span class="process-math">\(U \Sigma V^{\tr}\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-196">
\begin{align*}
U \amp = \left[ \begin{array}{ccr} 0\amp 1\amp 0\\
\frac{1}{\sqrt{2}}\amp 0\amp -\frac{1}{\sqrt{2}}\\
\frac{1}{\sqrt{2}}\amp 0\amp \frac{1}{\sqrt{2}} \end{array} \right],\\
\Sigma \amp = \left[ \begin{array}{cccc} 3\amp 0\amp 0\amp 0\\
0\amp 2\amp 0\amp 0\\
0\amp 0\amp 1\amp 0 \end{array} \right], \ \text{ and }\\
V \amp = \left[ \begin{array}{ccrc} 0\amp 1\amp 0\amp 0\\
\frac{1}{\sqrt{2}}\amp 0\amp -\frac{1}{\sqrt{2}}\amp 0\\
\frac{1}{\sqrt{2}}\amp 0\amp \frac{1}{\sqrt{2}}\amp 0\\
0\amp 0\amp 0\amp 1 \end{array} \right]\text{.}
\end{align*}
</div>
</div></article><article class="task exercise-like" id="task-1657"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4967">Use the singular value decomposition to find a basis for <span class="process-math">\(\Col A\text{,}\)</span> <span class="process-math">\(\Row A\text{,}\)</span> and <span class="process-math">\(\Nul A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-173">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4968">Recall that the right singular vectors of an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> of rank <span class="process-math">\(r\)</span> form an orthonormal basis <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \ldots, \vv_n\}\)</span> of eigenvectors of <span class="process-math">\(A^{\tr}A\)</span> such that <span class="process-math">\((A^{\tr}A) \vv_i = \lambda_i \vv_i\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(n\)</span> with <span class="process-math">\(\lambda_1 \geq \lambda_{2} \geq \cdots \geq \lambda_n \geq 0\text{.}\)</span> These vectors are the columns of the matrix <span class="process-math">\(V = [\vv_1 \ \vv_2 \ \cdots \ \vv_n]\)</span> in a singular value decomposition of <span class="process-math">\(A\text{.}\)</span> For <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{,}\)</span> we let <span class="process-math">\(\vu_i = \frac{A\vv_i}{||A\vv_i||}\text{.}\)</span> Then the set <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r\}\)</span> forms an orthonormal basis of <span class="process-math">\(\Col A\text{.}\)</span> We extend this set <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r\}\)</span> to an orthonormal basis <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r, \vu_{r+1} \vu_{r+2}, \ldots, \vu_m\}\)</span> of <span class="process-math">\(\R^m\text{.}\)</span> Recall also that <span class="process-math">\(A \vv_j = \vzero\)</span> for <span class="process-math">\(r+1 \leq j \leq n\text{.}\)</span> Since <span class="process-math">\(\dim(\Nul A) + \dim(\Col A) = n\text{,}\)</span> it follows that the vectors <span class="process-math">\(\vv_{r+1}\text{,}\)</span> <span class="process-math">\(\vv_{r+2}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> form a basis for <span class="process-math">\(\Nul A\text{.}\)</span> Finally, the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_r\}\)</span> is a basis for <span class="process-math">\(\Row A\text{.}\)</span> So in our example, we have <span class="process-math">\(m = 3\text{,}\)</span> <span class="process-math">\(n = 4\text{,}\)</span> <span class="process-math">\(\vv_1 = \frac{1}{\sqrt{2}}[0 \ 1 \ 1 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_2 = [1 \ 0 \ 0 \ 0]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv_3 = \frac{1}{\sqrt{2}}[0 \ -1 \ 1 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vv_4 = [0 \ 0 \ 0 \ 1]^{\tr}\text{.}\)</span> Since the singular values of <span class="process-math">\(A\)</span> are <span class="process-math">\(3\text{,}\)</span> <span class="process-math">\(2\text{,}\)</span> <span class="process-math">\(1\text{,}\)</span> and <span class="process-math">\(0\text{,}\)</span> it follows that <span class="process-math">\(r = \rank(A) = 3\text{.}\)</span> We also have <span class="process-math">\(\vu_1 = \frac{1}{\sqrt{2}}[0 \ 1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vu_2 = [1 \ 0 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vu_3 = \frac{1}{\sqrt{2}}[ 0 \ -1 \ 1]^{\tr}\text{.}\)</span> So</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{\frac{1}{\sqrt{2}}[0 \ 1 \ 1 \ 0]^{\tr}, [1 \ 0 \ 0 \ 0]^{\tr}, \frac{1}{\sqrt{2}}[0 \ -1 \ 1 \ 0]^{\tr}\right\}
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\Row A\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{[0 \ 0 \ 0 \ 1]^{\tr}\}
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\Nul A\text{.}\)</span> Finally, the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \frac{1}{\sqrt{2}}[0 \ 1 \ 1]^{\tr}, [1 \ 0 \ 0]^{\tr}, \frac{1}{\sqrt{2}}[[ 0 \ -1 \ 1]^{\tr}\right\}
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\Col A\text{.}\)</span></p>
</div></article></article><article class="example example-like" id="example-61"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">29.10</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-486">
<p id="p-4969">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{ccc} 2\amp 5\amp 4\\6\amp 3\amp 0\\6\amp 3\amp 0\\2\amp 5\amp 4 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4970">The eigenvalues of <span class="process-math">\(A^{\tr}A\)</span> are <span class="process-math">\(\lambda_1 = 144\text{,}\)</span> <span class="process-math">\(\lambda_2 = 36\text{,}\)</span> and <span class="process-math">\(\lambda_3=0\)</span> with corresponding eigenvectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vw_1 = \left[ \begin{array}{c} 2\\2\\1 \end{array}  \right], \ \vw_1 = \left[ \begin{array}{r} -2\\1\\2 \end{array}  \right], \ \text{ and }  \ \vw_1 = \left[ \begin{array}{r} 1\\-2\\2 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4971">In addition,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \vw_1 = \left[ \begin{array}{c} 18\\18\\18\\18 \end{array}  \right] \ \text{ and }  A \vw_2 = \left[ \begin{array}{r} 9\\-9\\-9\\9 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-1658"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4972">Find orthogonal matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\text{,}\)</span> and the matrix <span class="process-math">\(\Sigma\text{,}\)</span> so that <span class="process-math">\(U \Sigma V^{\tr}\)</span> is a singular value decomposition of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-174">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4973">Normalizing the eigenvectors <span class="process-math">\(\vw_1\text{,}\)</span> <span class="process-math">\(\vw_2\text{,}\)</span> and <span class="process-math">\(\vw_3\)</span> to normal eigenvectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> and <span class="process-math">\(\vv_3\text{,}\)</span> respectively, gives us an orthogonal matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \left[  \begin{array}{crr} \frac{2}{3}\amp -\frac{2}{3}\amp \frac{1}{3}\\ \frac{2}{3}\amp \frac{1}{3}\amp - \frac{2}{3}\\  \frac{1}{3}\amp \frac{2}{3}\amp \frac{2}{3} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now <span class="process-math">\(A \vv_i = A \frac{\vw_i}{||\vw_i||} = \frac{1}{|| \vw_i ||} A \vw_i\text{,}\)</span> so normalizing the vectors <span class="process-math">\(A \vv_1\)</span> and <span class="process-math">\(A \vv_2\)</span> gives us vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vu_1 = \frac{1}{2} \left[ \begin{array}{c} 1\\1\\1\\1 \end{array}  \right] \ \text{ and }  \ \vu_2 = \frac{1}{2} \left[ \begin{array}{r} 1\\-1\\-1\\1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">that are the first two columns of our matrix <span class="process-math">\(U\text{.}\)</span> Given that <span class="process-math">\(U\)</span> is a <span class="process-math">\(4 \times 4\)</span> matrix, we need to find two other vectors orthogonal to <span class="process-math">\(\vu_1\)</span> and <span class="process-math">\(\vu_2\)</span> that will combine with <span class="process-math">\(\vu_1\)</span> and <span class="process-math">\(\vu_2\)</span> to form an orthogonal basis for <span class="process-math">\(\R^4\text{.}\)</span> Letting <span class="process-math">\(\vz_1 = [1 \ 1 \ 1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vz_2 = [1 \ -1 \ -1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vz_3 = [1 \ 0 \ 0 \ 0]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vz_4 = [0 \ 1 \ 0 \ 1]^{\tr}\text{,}\)</span> a computer algebra system shows that the reduced row echelon form of the matrix <span class="process-math">\([\vz_1 \ \vz_2 \ \vz_3 \ \vz_4]\)</span> is <span class="process-math">\(I_4\text{,}\)</span> so that vectors <span class="process-math">\(\vz_1\text{,}\)</span> <span class="process-math">\(\vz_2\text{,}\)</span> <span class="process-math">\(\vz_3\text{,}\)</span> <span class="process-math">\(\vz_4\)</span> are linearly independent. Letting <span class="process-math">\(\vw_1 = \vz_1\)</span> and <span class="process-math">\(\vw_2 = \vz_2\text{,}\)</span> the Gram-Schmidt process shows that the set <span class="process-math">\(\{\vw_1, \vw_2, \vw_3, \vw_4\}\)</span> is an orthogonal basis for <span class="process-math">\(\R^4\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-197">
\begin{align*}
\vw_3 \amp = [1 \ 0 \ 0 \ 0]^{\tr} - \frac{[1 \ 0 \ 0 \ 0]^{\tr} \cdot [1 \ 1 \ 1 \ 1]^{\tr}}{[1 \ 1 \ 1 \ 1]^{\tr} \cdot [1 \ 1 \ 1 \ 1]^{\tr}} [1 \ 1 \ 1 \ 1]^{\tr}\\
\amp \qquad - \frac{[1 \ 0 \ 0 \ 0]^{\tr} \cdot [1 \ -1 \ -1 \ 1]^{\tr}}{[1 \ -1 \ -1 \ 1]^{\tr} \cdot [1 \ -1 \ -1 \ 1]^{\tr}} [1 \ -1 \ -1 \ 1]^{\tr}\\
\amp = [1 \ 0 \ 0 \ 0]^{\tr} - \frac{1}{4}[1 \ 1 \ 1 \ 1]^{\tr} - \frac{1}{4} [1 \ -1 \ -1 \ 1]^{\tr}\\
\amp = \frac{1}{4} [2 \ 0 \ 0 \ -2]^{\tr}
\end{align*}
</div>
<p class="continuation">and (using <span class="process-math">\([1 \ 0 \ 0 \ -1]^{\tr}\)</span> for <span class="process-math">\(\vw_3\)</span>)</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-198">
\begin{align*}
\vw_4 \amp = [0 \ 1 \ 0 \ 0]^{\tr} - \frac{[0 \ 1 \ 0 \ 0]^{\tr} \cdot [1 \ 1 \ 1 \ 1]^{\tr}}{[1 \ 1 \ 1 \ 1]^{\tr} \cdot [1 \ 1 \ 1 \ 1]^{\tr}} [1 \ 1 \ 1 \ 1]^{\tr}\\
\amp \qquad - \frac{[0 \ 1 \ 0 \ 0]^{\tr} \cdot [1 \ -1 \ -1 \ 1]^{\tr}}{[1 \ -1 \ -1 \ 1]^{\tr} \cdot [1 \ -1 \ -1 \ 1]^{\tr}} [1 \ -1 \ -1 \ 1]^{\tr}\\
\amp \qquad - \frac{[0 \ 1 \ 0 \ 0]^{\tr} \cdot [1 \ 0 \ 0 \ -1]^{\tr}}{[1 \ 0 \ 0 \ -1]^{\tr} \cdot [1 \ 0 \ 0 \ -1]^{\tr}} [1 \ 0 \ 0 \ -1]^{\tr}\\
\amp = [0 \ 1 \ 0 \ 0]^{\tr} - \frac{1}{4}[1 \ 1 \ 1 \ 1]^{\tr} + \frac{1}{4} [1 \ -1 \ -1 \ 1]^{\tr} - \vzero\\
\amp = \frac{1}{4} [0 \ 2 \ -2 \ 0]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">The set <span class="process-math">\(\{\vu_1, \vu_2, \vu_3, \vu_4\}\)</span> where <span class="process-math">\(\vu_1 = \frac{1}{2}[1 \ 1 \ 1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vu_2 = \frac{1}{2}[1 \ -1 \ -1 \ 1]^{\tr}\text{,}\)</span> <span class="process-math">\(\vu_3 = \frac{1}{\sqrt{2}}[1 \ 0 \ 0 \ -1]^{\tr}\)</span> and <span class="process-math">\(\vu_4 = \frac{1}{\sqrt{2}}[0 \ 1 \ -1 \ 0]^{\tr}\)</span> is an orthonormal basis for <span class="process-math">\(\R^4\)</span> and we can let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \left[  \begin{array}{crrr} \frac{1}{2} \amp  \frac{1}{2} \amp  \frac{1}{\sqrt{2}} \amp  0 \\ \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  \frac{1}{\sqrt{2}} \\  \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  -\frac{1}{\sqrt{2}} \\ \frac{1}{2} \amp  \frac{1}{2} \amp  -\frac{1}{\sqrt{2}} \amp  0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">The singular values of <span class="process-math">\(A\)</span> are <span class="process-math">\(\sigma_1 = \sqrt{\lambda_1} = 12\)</span> and <span class="process-math">\(\sigma_2 = \sqrt{\lambda_2} = 6\text{,}\)</span> and so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Sigma = \begin{bmatrix}12\amp 0\amp 0 \\ 0\amp 6\amp 0 \\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{bmatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, a singular value decomposition of <span class="process-math">\(A\)</span> is <span class="process-math">\(U \Sigma V^{\tr}\)</span> of</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{crrr} \frac{1}{2} \amp  \frac{1}{2} \amp  \frac{1}{\sqrt{2}} \amp  0 \\ \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  \frac{1}{\sqrt{2}} \\  \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  -\frac{1}{\sqrt{2}} \\ \frac{1}{2} \amp  \frac{1}{2} \amp  -\frac{1}{\sqrt{2}} \amp  0 \end{array}  \right] \begin{bmatrix}12\amp 0\amp 0 \\ 0\amp 6\amp 0 \\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{bmatrix}  \left[ \begin{array}{rrc} \frac{2}{3}\amp \frac{2}{3}\amp \frac{1}{3}\\ -\frac{2}{3}\amp \frac{1}{3}\amp \frac{2}{3}\\  \frac{1}{3}\amp -\frac{2}{3}\amp \frac{2}{3} \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1659"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4974">Determine the best rank 1 approximation to <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-175">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4975">Determine the best rank 1 approximation to <span class="process-math">\(A\text{.}\)</span> The outer product decomposition of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \sigma_1 \vu_1 \vv_1^{\tr} + \sigma_2 \vu_2 \vv_2^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">So the rank one approximation to <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\sigma_1 \vu_1 \vv_1^{\tr} = 12 \left(\frac{1}{2}\right) \left[ \begin{array}{c} 1\\1\\1\\1 \end{array}  \right] \left[ \begin{array}{ccc} \frac{2}{3} \amp  \frac{2}{3} \amp  \frac{1}{3} \end{array}  \right] = \left[ \begin{array}{ccc} 4\amp 4\amp 2\\ 4\amp 4\amp 2 \\ 4\amp 4\amp 2\\ 4\amp 4\amp 2 \end{array}   \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Note that the rows in this rank one approximation are the averages of the two distinct rows in the matrix <span class="process-math">\(A\text{,}\)</span> which makes sense considering that this is the closest rank one matrix to <span class="process-math">\(A\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_svd_summ"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<p id="p-4976">We learned about the singular value decomposition of a matrix.</p>
<ul class="disc">
<li id="li-760">
<p id="p-4977">The operator norm of an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
||A|| = \max_{||\vx|| \neq 0} \frac{||A\vx||}{||\vx||} = \max_{||\vx||=1} ||A\vx||\text{.}
\end{equation*}
</div>
<p class="continuation">The operator norm of a matrix tells us that how big the action of an <span class="process-math">\(m \times n\)</span> matrix is can be determined by its action on the unit sphere in <span class="process-math">\(\R^n\text{.}\)</span></p>
</li>
<li id="li-761">
<p id="p-4978">A singular value decomposition of an <span class="process-math">\(m \times n\)</span> matrix is of the form <span class="process-math">\(A = U \Sigma V^{\tr}\text{,}\)</span> where</p>
<ul class="circle">
<li id="li-762"><p id="p-4979"><span class="process-math">\(V= [\vv_1 \ \vv_2 \ \vv_3 \ \cdots \ \vv_n ]\)</span> where <span class="process-math">\(\{\vv_1, \vv_2, \vv_3, \ldots, \vv_n\}\)</span> is an orthonormal basis of eigenvectors of <span class="process-math">\(A^{\tr}A\)</span> such that <span class="process-math">\((A^{\tr}A) \vv_i = \lambda_i \vv_i\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(n\)</span> with <span class="process-math">\(\lambda_1 \geq \lambda_{2} \geq \cdots \geq \lambda_n \geq 0\text{,}\)</span></p></li>
<li id="li-763"><p id="p-4980"><span class="process-math">\(U = [\vu_1 \ \vu_2 \ \cdots \ \vu_m]\)</span> where <span class="process-math">\(\vu_i = \frac{A\vv_i}{||A\vv_i||}\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{,}\)</span> and this orthonormal basis of <span class="process-math">\(\Col A\)</span> is extended to an orthonormal basis <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_r, \vu_{r+1} \vu_{r+2}, \ldots, \vu_m\}\)</span> of <span class="process-math">\(\R^m\text{,}\)</span></p></li>
<li id="li-764">
<p id="p-4981"><span class="process-math">\(\Sigma = \left[ \begin{array}{ccccc|c} \sigma_1\amp \amp \amp \amp 0\amp \\ \amp \sigma_2\amp \amp \amp \amp 0 \\ \amp \amp \sigma_3\amp \amp \amp \\ \amp \amp \amp \ddots \amp \amp \\ 0\amp \amp \amp \amp \sigma_r \\ \hline \amp \amp 0\amp \amp \amp 0 \end{array} \right]\text{,}\)</span> where <span class="process-math">\(\sigma_i = \sqrt{\lambda_i} &gt; 0\)</span> for <span class="process-math">\(i\)</span> from 1 to <span class="process-math">\(r\text{.}\)</span></p>
<p id="p-4982">A singular value decomposition is important in that every matrix has a singular value decomposition, and a singular value decomposition has a variety of applications including scientific computing and digital signal processing, image compression, principal component analysis, web searching through latent semantic indexing, and seismology.</p>
</li>
</ul>
</li>
<li id="li-765"><p id="p-4983">The vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\)</span> in an SVD for an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A\)</span> form a basis for <span class="process-math">\(\Col A\)</span> while the vectors <span class="process-math">\(\vv_{r+1}\text{,}\)</span> <span class="process-math">\(\vv_{r+2}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> form a basis for <span class="process-math">\(\Nul A\text{.}\)</span> Also, the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_r\}\)</span> is a basis for <span class="process-math">\(\Row A\text{.}\)</span></p></li>
<li id="li-766">
<p id="p-4984">Let <span class="process-math">\(A\)</span> have an SVD as in the second bullet. Decomposing <span class="process-math">\(A\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A =\sigma_1 \vu_1\vv_1^{\tr} + \sigma_2 \vu_2\vv_2^{\tr} + \sigma_3 \vu_3\vv_3^{\tr} + \cdots + \sigma_r \vu_r\vv_r^{\tr}
\end{equation*}
</div>
<p class="continuation">is an outer product decomposition of <span class="process-math">\(A\text{.}\)</span> An outer product decomposition allows us to approximate <span class="process-math">\(A\)</span> with smaller rank matrices. For example, the matrix <span class="process-math">\(\sigma_1 \vu_1\vv_1^{\tr}\)</span> is the best rank 1 approximation to <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(\sigma_1 \vu_1\vv_1^{\tr} + \sigma_2 \vu_2\vv_2^{\tr}\)</span> is the best rank 2 approximation, and so on.</p>
</li>
</ul></section><section class="exercises" id="sec_svd_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-288"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-487"><p id="p-4985">Find a singular value decomposition of the following matrices.</p></div>
<article class="task exercise-like" id="task-1660"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4986"><span class="process-math">\(\left[ \begin{array}{cc} 1\amp 1\\0\amp 0 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1661"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4988"><span class="process-math">\(\left[ \begin{array}{c} 1\\0\\1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1662"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4990"><span class="process-math">\(\left[ \begin{array}{ccc} 1\amp 1\amp 0\\1\amp 0\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1663"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4992"><span class="process-math">\(\left[ \begin{array}{cc} 1\amp 2\\2\amp 1\\3\amp 1\\1\amp 3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1664"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-4994"><span class="process-math">\(\left[ \begin{array}{cccc} 2\amp 0\amp 0\amp 0\\0\amp 2\amp 1\amp 0\\0\amp 1\amp 2\amp 0 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-289"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-488"><p id="p-4996">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m \times n\)</span> matrix of rank <span class="process-math">\(r\)</span> with singular value decomposition <span class="process-math">\(U \Sigma V^{\tr}\text{,}\)</span> where <span class="process-math">\(U = [ \vu_1 \ \vu_2 \ \cdots \ \vu_m ]\)</span> and <span class="process-math">\(V = [\vv_1 \ \vv_2 \ \cdots \ \vv_n]\text{.}\)</span> We have seen that the set <span class="process-math">\(\{ \vu_1, \vu_2, \ldots, \vu_r\}\)</span> is a basis for <span class="process-math">\(\Col A\text{,}\)</span> and the vectors <span class="process-math">\(\vv_{r+1}\text{,}\)</span> <span class="process-math">\(\vv_{r+2}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> form a basis for <span class="process-math">\(\Nul A\text{.}\)</span> In this exercise we examine the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_r\}\)</span> and determine what this set tells us about <span class="process-math">\(\Row A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1665"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4997">Find a singular value decomposition for <span class="process-math">\(A^{\tr}\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-69" id="hint-69"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-69"><div class="hint solution-like"><p id="p-4998">Use the singular value decomposition <span class="process-math">\(U \Sigma V^{\tr}\)</span> for <span class="process-math">\(A\text{.}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-1666"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4999">Explain why the result of (a) shows that the set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_r\}\)</span> is a basis for <span class="process-math">\(\Row A\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-290"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-489"><p id="p-5000">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 2\amp 2 \\ 3\amp 3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1667"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5001">Find the singular values of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1668"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5003">Find a singular value decomposition of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1669"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-490"><p id="p-5005">Use a singular value decomposition to find orthonormal bases for the following:</p></div>
<article class="task exercise-like" id="task-1670"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-5006"><span class="process-math">\(\Nul A\)</span></p></article><article class="task exercise-like" id="task-1671"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-5008"><span class="process-math">\(\Col A\)</span></p></article><article class="task exercise-like" id="task-1672"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-5010"><span class="process-math">\(\Row A\)</span></p></article></article></article><article class="exercise exercise-like" id="exercise-291"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-491"><p id="p-5012">Let <span class="process-math">\(A\)</span> have the singular value decomposition as in <a href="" class="xref" data-knowl="./knowl/eq_7_c_SVD.html" title="Equation 29.2">(29.2)</a>.</p></div>
<article class="task exercise-like" id="task-1673"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5013">Show, using <a href="" class="xref" data-knowl="./knowl/eq_7_c_SVD.html" title="Equation 29.2">(29.2)</a>, that <span class="process-math">\(||A\vv_j|| = \sigma_j\text{.}\)</span></p></article><article class="task exercise-like" id="task-1674"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5014">Explain why <span class="process-math">\(||A|| = \sigma_1\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-70" id="hint-70"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-70"><div class="hint solution-like"><p id="p-5015">The set <span class="process-math">\(\{\vv_1, \vv_2, \ldots, \vv_n\}\)</span> is an orthonormal basis of <span class="process-math">\(\R^n\text{.}\)</span> Use this to show that <span class="process-math">\(||A \vx||^2 \leq \sigma_1^2\)</span> for any unit vector <span class="process-math">\(\vx\)</span> in <span class="process-math">\(\R^n\text{.}\)</span></p></div></div>
</div></article></article><article class="exercise exercise-like" id="exercise-292"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-5016">Show that <span class="process-math">\(A\)</span> and <span class="process-math">\(A^{\tr}\)</span> have the same nonzero singular values. How are their singular value decompositions related?</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-71" id="hint-71"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-71"><div class="hint solution-like"><p id="p-5017">Find the transpose of an SVD for <span class="process-math">\(A\text{.}\)</span></p></div></div>
</div></article><article class="exercise exercise-like" id="ex_7_c_AAT"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-492"><p id="p-5018">The vectors <span class="process-math">\(\vv_i\)</span> that form the columns of the matrix <span class="process-math">\(V\)</span> in a singular value decomposition of a matrix <span class="process-math">\(A\)</span> are eigenvectors of <span class="process-math">\(A^{\tr}A\text{.}\)</span> In this exercise we investigate the vectors <span class="process-math">\(\vu_i\)</span> that make up the columns of the matrix <span class="process-math">\(U\)</span> in a singular value decomposition of a matrix <span class="process-math">\(A\)</span> for each <span class="process-math">\(i\)</span> between 1 and the rank of <span class="process-math">\(A\text{,}\)</span> and their connection to the matrix <span class="process-math">\(AA^{\tr}\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1675"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-493">&gt; <p id="p-5019">Let <span class="process-math">\(A = \left[ \begin{array}{ccr} 1\amp 1\amp 0 \\ 0\amp 1\amp -1 \end{array}  \right]\text{.}\)</span> A singular value decomposition of <span class="process-math">\(A\)</span> is <span class="process-math">\(U \Sigma V^{\tr}\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-199">
\begin{align*}
U \amp = \frac{1}{\sqrt{2}}\left[ \begin{array}{rr} -1\amp 1\\
-1\amp -1 \end{array} \right],\\
\Sigma \amp = \left[ \begin{array}{ccc} \sqrt{3}\amp 0\amp 0\\
0\amp 1\amp 0 \end{array} \right],\\
V \amp = \left[ \begin{array}{rcc} -\frac{1}{\sqrt{6}}\amp -\frac{1}{3\sqrt{6}}\amp \frac{1}{\sqrt{6}}\\
\frac{1}{\sqrt{2}}\amp 0\amp \frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{3}} \amp  \frac{1}{\sqrt{3}} \amp  \frac{1}{\sqrt{3}}\end{array} \right]\text{.}
\end{align*}
</div>
</div>
<article class="task exercise-like" id="task-1676"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-5020">Determine the rank <span class="process-math">\(r\)</span> of <span class="process-math">\(A^{\tr}A\)</span> and identify the vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\text{.}\)</span></p></article><article class="task exercise-like" id="task-1677"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-5021">Calculate <span class="process-math">\(AA^{\tr} \vu_i\)</span> for each <span class="process-math">\(i\)</span> between 1 and <span class="process-math">\(r\text{.}\)</span> How is <span class="process-math">\(AA^{\tr} \vu_i\)</span> related to <span class="process-math">\(\vu_i\text{?}\)</span></p></article></article><article class="task exercise-like" id="task-1678"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5022">Now we examine the result of part (a) in general. Let <span class="process-math">\(A\)</span> be an arbitrary matrix. Calculate <span class="process-math">\(AA^{\tr} \vu_i\)</span> for <span class="process-math">\(1 \leq i \leq \rank(A)\)</span> and determine specifically how <span class="process-math">\(AA^{\tr} \vu_i\)</span> is related to <span class="process-math">\(\vu_i\text{.}\)</span> What does this tell us about the vectors <span class="process-math">\(\vu_i\)</span> and the matrix <span class="process-math">\(AA^{\tr}\text{?}\)</span></p></article><article class="task exercise-like" id="task-1679"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5023">Now show in general that the columns of <span class="process-math">\(U\)</span> are orthonormal eigenvectors for <span class="process-math">\(AA^{\tr}\text{.}\)</span> (That is, what can we say about the vectors <span class="process-math">\(\vu_i\)</span> if <span class="process-math">\(i &gt; \rank(A)\text{?}\)</span>)</p></article></article><article class="exercise exercise-like" id="exercise-294"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-5024">If <span class="process-math">\(A\)</span> is a symmetric matrix with eigenvalues <span class="process-math">\(\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0\text{,}\)</span> what is <span class="process-math">\(||A||\text{?}\)</span> Justify your answer.</p></article><article class="exercise exercise-like" id="ex_7_c_Symmetric_SVD"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-494"><p id="p-5026">Let <span class="process-math">\(A\)</span> be a <span class="process-math">\(n \times n\)</span> symmetric matrix.</p></div>
<article class="task exercise-like" id="task-1680"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-5027">Show that if <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> then <span class="process-math">\(\vv\)</span> is an eigenvector for <span class="process-math">\(A^{\tr}A\text{.}\)</span> What is the corresponding eigenvalue?</p></article><article class="task exercise-like" id="task-1681"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-5028">Show that if <span class="process-math">\(\vv\)</span> is an eigenvector of <span class="process-math">\(A^{\tr}A\)</span> with non-negative eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> then <span class="process-math">\(A\vv\)</span> is an eigenvector of <span class="process-math">\(A^{\tr}A\text{.}\)</span> What is the corresponding eigenvalue?</p></article><article class="task exercise-like" id="task-1682"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-5029">Suppose <span class="process-math">\(U \Sigma V^{\tr}\)</span> is a singular value decomposition of <span class="process-math">\(A\text{.}\)</span> Explain why <span class="process-math">\(V \Sigma V^{\tr}\)</span> is also a singular value decomposition of <span class="process-math">\(A\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="ex_7_c_rank1"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-5030">Let <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_r\)</span> and <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_r\)</span> be the vectors found in a singular value decomposition of a matrix <span class="process-math">\(A\text{,}\)</span> where <span class="process-math">\(r\)</span> is the rank of <span class="process-math">\(A\text{.}\)</span> Show that <span class="process-math">\(\vu_i\vv_i^{\tr}\)</span> is a rank 1 matrix for each <span class="process-math">\(i\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-72" id="hint-72"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-72"><div class="hint solution-like"><p id="p-5031">Mimic <a href="" class="xref" data-knowl="./knowl/ex_7_a_spectral_decomposition.html" title="Exercise 5">Exercise 5</a> in <a href="chap_orthogonal_diagonalization.html" class="internal" title="Chapter 27: Orthogonal Diagonalization">Chapter 27</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-297"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-5032">Is it possible for a matrix <span class="process-math">\(A\)</span> to have a singular value decomposition <span class="process-math">\(U \Sigma V^{\tr}\)</span> in which <span class="process-math">\(U = V\text{?}\)</span> If no, explain why. If yes, determine for which matrices we can have <span class="process-math">\(U = V\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-298"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-495"><p id="p-5033">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1683"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5034">If <span class="process-math">\(\sigma\)</span> is a singular value of a matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\sigma\)</span> is an eigenvalue of <span class="process-math">\(A^{\tr}A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1684"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5036">A set of right singular vectors of a matrix <span class="process-math">\(A\)</span> is also a set of left singular vectors of <span class="process-math">\(A^{\tr}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1685"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5037">The transpose of a singular value decomposition of a matrix <span class="process-math">\(A\)</span> is a singular value decomposition for <span class="process-math">\(A^{\tr}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1686"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5039">Similar matrices have the same singular values.</p></article><article class="task exercise-like" id="task-1687"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5040">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, then the singular values of <span class="process-math">\(A^2\)</span> are the squares of the singular values of <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1688"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5042">The <span class="process-math">\(\Sigma\)</span> matrix in an SVD of <span class="process-math">\(A\)</span> is unique.</p></article><article class="task exercise-like" id="task-1689"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5043">The matrices <span class="process-math">\(U, V\)</span> in an SVD of <span class="process-math">\(A\)</span> are unique.</p></article><article class="task exercise-like" id="task-1690"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-5045">If <span class="process-math">\(A\)</span> is a positive definite matrix, then an orthogonal diagonalization of <span class="process-math">\(A\)</span> is an SVD of <span class="process-math">\(A\text{.}\)</span></p></article></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-48"><div class="fn">Technically this definition should be in terms of a supremum, but because the equivalent definition restricts the <span class="process-math">\(\vx\)</span>'s to a compact subset, the sup is achieved and we can use max.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
