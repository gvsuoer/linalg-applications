<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-03-22T13:06:29-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h3 class="heading"><span class="type">Paragraph</span></h3>
<p>Of course, it is unlikely that the <span class="process-math">\(m\)</span> data points already lie on a polynomial of degree <span class="process-math">\(n\text{,}\)</span> so the system will usually have no solution. So instead of attempting to find coefficients <span class="process-math">\(a_0\text{,}\)</span> <span class="process-math">\(a_1\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(a_n\)</span> that give a solution to this system, which may be impossible, we instead look for a vector that is ``close" to a solution. As we have seen, the vector <span class="process-math">\(\proj_{W} \vy\text{,}\)</span> where <span class="process-math">\(W\)</span> is the span of the columns of <span class="process-math">\(M\text{,}\)</span> minimizes the sum of the squares of the differences of the components. That is, our desired approximation to a solution to <span class="process-math">\(M \vx = \vy\)</span> is the projection of <span class="process-math">\(\vy\)</span> onto <span class="process-math">\(\Col M\text{.}\)</span> Now <span class="process-math">\(\proj_W \vy\)</span> is a linear combination of the columns of <span class="process-math">\(M\text{,}\)</span> so <span class="process-math">\(\proj_W \vy = M \va^*\)</span> for some vector <span class="process-math">\(\va^*\text{.}\)</span> This vector <span class="process-math">\(\va^*\)</span> then minimizes <span class="process-math">\(|| \proj_{\perp W} \vy|| = ||\vy - M \va ||\text{.}\)</span> That is, if we let <span class="process-math">\((M\va)^{\tr} = [b_1 \ b_2 \ b_3 \ \cdots \ b_m]\text{,}\)</span> we are minimizing</p>
<div class="displaymath process-math">
\begin{equation}
||\vy - M\va||^2 = (y_1-b_1)^2 + (t_2-b_2)^2 + \cdots + (y_m-b_m)^2\text{.}\tag{26.7}
\end{equation}
</div>
<p class="continuation">The expression <span class="process-math">\(||\vy - M\va||^2\)</span> measures the error in our approximation.</p>
<span class="incontext"><a href="sec_ls_approx.html#p-4398">in-context</a></span>
</body>
</html>
