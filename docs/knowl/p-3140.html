<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-05-25T11:23:49-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<p>This example is an example of a Markov process (see <a href="" class="xref" data-knowl="./knowl/def_Markov.html" title="Definition 9.4">DefinitionÂ 9.4</a>). There are several questions we can ask about this model. For example, what is the long-term behavior of this system, and how does this model relate to entropy? That is, given an initial probability distribution vector <span class="process-math">\(\vx_0\text{,}\)</span> the system will have probability distribution vectors <span class="process-math">\(\vx_1\text{,}\)</span> <span class="process-math">\(\vx_2\text{,}\)</span> <span class="process-math">\(\ldots\)</span> after subsequent moves. What happens to the vectors <span class="process-math">\(\vx_k\)</span> as <span class="process-math">\(k\)</span> goes to infinity, and what does this tell us about entropy? To answer these questions, we will first explore the sequence <span class="process-math">\(\{\vx_k\}\)</span> numerically, and then use the eigenvalues and eigenvectors of <span class="process-math">\(T\)</span> to analyze the sequence <span class="process-math">\(\{\vx_k\}\text{.}\)</span></p>
<span class="incontext"><a href="chap_characteristic_equation.html#p-3140" class="internal">in-context</a></span>
</body>
</html>
