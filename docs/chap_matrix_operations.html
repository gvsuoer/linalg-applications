<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-05-23T12:12:40-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Matrix Operations</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\newcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="part-matrices.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-matrices.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_intro_eigenvals_eigenvects.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="part-matrices.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-matrices.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_intro_eigenvals_eigenvects.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link active">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Sqaures Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_matrix_operations"><h2 class="heading">
<span class="type">Chapter</span> <span class="codenumber">8</span> <span class="title">Matrix Operations</span>
</h2>
<section class="introduction" id="introduction-112"><article class="objectives goal-like" id="objectives-8"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-113"><p id="p-1285">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-235"><p id="p-1286">Under what conditions can we add two matrices and how is the matrix sum defined?</p></li>
<li id="li-236"><p id="p-1287">Under what conditions can we multiply a matrix by a scalar and how is a scalar multiple of a matrix defined?</p></li>
<li id="li-237"><p id="p-1288">Under what conditions can we multiply two matrices and how is the matrix product defined?</p></li>
<li id="li-238"><p id="p-1289">What properties do matrix addition, scalar multiplication of matrices and matrix multiplication satisfy? Are these properties similar to properties that are satisfied by vector operations?</p></li>
<li id="li-239"><p id="p-1290">What are two properties that make matrix multiplication fundamentally different than our standard product of real numbers?</p></li>
<li id="li-240"><p id="p-1291">What is the interpretation of matrix multiplication from the perspective of linear transformations?</p></li>
<li id="li-241"><p id="p-1292">How is the transpose of a matrix defined?</p></li>
</ul></article></section><section class="section" id="sec_appl_mtx_mult"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Application: Algorithms for Matrix Multiplication</span>
</h3>
<p id="p-1293">Matrix multiplication is widely used in applications ranging from scientific computing and pattern recognition to counting paths in graphs. As a consequence, much work is being done in developing efficient algorithms for matrix multiplication.</p>
<p id="p-1294">We will see that a matrix product can be calculated through the row-column method. Recall that the product of two <span class="process-math">\(2 \times 2\)</span> matrices <span class="process-math">\(A = \left[ \begin{array}{cc} a_{11}\amp a_{12}\\a_{21}\amp a_{22} \end{array}  \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cc} b_{11}\amp b_{12}\\b_{21}\amp b_{22} \end{array}  \right]\)</span> is given by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = \left[ \begin{array}{cc} a_{11}b_{11}+a_{12}b_{21} \amp  a_{11}b_{12}+a_{12}b_{22} \\ a_{21}b_{11}+a_{22}b_{21} \amp  a_{21}b_{12}+a_{22}b_{22} \end{array}  \right]\text{,}
\end{equation*}
</div>
<p id="p-1295">This product involves eight scalar multiplications and some scalar additions. As we will see, multiplication is more computationally expensive than addition, so we will focus on multiplication. In 1969, a German mathematician named Volker Strassen showed<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-10" id="fn-10"><sup> 10 </sup></a> that the product of two <span class="process-math">\(2 \times 2\)</span> matrices can be calculated using only seven multiplications. While this is not much of an improvement, the Strassen algorithm can be applied to larger matrices, using matrix partitions (which allow for parallel computation), and its publication led to additional research on faster algorithms for matrix multiplication. More details are provided later in this section.</p></section><section class="section" id="sec_mtx_ops_intro"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-1296">A vector is a list of numbers in a specified order and a matrix is an ordered array of objects. In fact, a vector can be thought of as a matrix of size <span class="process-math">\(n \times 1\text{.}\)</span> Vectors and matrices are so alike in this way that it would seem natural that we can define operations on matrices just as we did with vectors.</p>
<p id="p-1297">Recall that a matrix is made of rows and columns — the entries reading from left to right form the <em class="emphasis">rows</em> of the matrix and the entries reading from top to bottom form the <dfn class="terminology">columns</dfn>. The number of rows and columns of a matrix is called the <dfn class="terminology">size</dfn> of the matrix, so an <span class="process-math">\(m \times n\)</span> matrix has <span class="process-math">\(m\)</span> rows and <span class="process-math">\(n\)</span> columns. If we label the entry in the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of a matrix <span class="process-math">\(A\)</span> as <span class="process-math">\(a_{ij}\text{,}\)</span> then we write <span class="process-math">\(A = [a_{ij}]\text{.}\)</span></p>
<p id="p-1298">We can generalize the operations of addition and scalar multiplication on vectors to matrices similarly. Given two matrices <span class="process-math">\(A=[a_{ij}]\)</span> and <span class="process-math">\(B=[b_{ij}]\)</span> of the same size, we define the sum <span class="process-math">\(A+B\)</span> by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A+B= [ a_{ij}+b_{ij} ]
\end{equation*}
</div>
<p class="continuation">when the sizes of the matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> match. In other words, for matrices of the same size the matrix addition is defined by adding corresponding entries in the matrices. For example,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{rc} 1 \amp  2 \\ -2 \amp  3 \end{array}  \right] + \left[ \begin{array}{cc} 1 \amp  3 \\ 2 \amp  4 \end{array}  \right] = \left[ \begin{array}{cc} 2 \amp  5 \\ 0 \amp  7 \end{array}  \right]  \,\text{.}
\end{equation*}
</div>
<p id="p-1299"> We define the scalar multiple of a matrix <span class="process-math">\(A=[a_{ij}]\)</span> by scalar <span class="process-math">\(c\)</span> to be the matrix <span class="process-math">\(cA\)</span> defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
cA= [ ca_{ij}]\text{,}
\end{equation*}
</div>
<p id="p-1300">This means that we multiply each entry of the matrix <span class="process-math">\(A\)</span> by the scalar <span class="process-math">\(c\text{.}\)</span> As an example,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
3 \left[ \begin{array}{rc} 1 \amp  2 \\ -2 \amp  3 \end{array}  \right] = \left[ \begin{array}{rc} 3 \amp  6 \\ -6 \amp  9 \end{array}  \right] \,\text{.}
\end{equation*}
</div>
<p id="p-1301">Even though we did not have a multiplication operation on vectors, we had a matrix-vector product, which is a special case of a matrix-matrix product since a vector is a matrix with one column. However, generalizing the matrix-vector product to a matrix-matrix product is not immediate as it is not immediately clear what we can do with the other columns. We will consider this question in this section.</p>
<p id="p-1302">Note that all of the matrix operations can be performed on a calculator. After entering each matrix in the calculator, just use <span class="process-math">\(+\text{,}\)</span> <span class="process-math">\(-\)</span> and <span class="times-sign">×</span> operations to find the result of the matrix operation. (Just for fun, try using <span class="process-math">\(\div\)</span> with matrices to see if it will work.)</p>
<article class="exploration project-like" id="pa_2_a"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">8.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-387"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-114"><p id="p-1303">Pick three different varying sizes of pairs of <span class="process-math">\(A, B\)</span> matrices which can be added. For each pair:</p></div>
<article class="task exercise-like" id="task-388"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1304">Find the matrices <span class="process-math">\(A+B\)</span> and <span class="process-math">\(B+A\text{.}\)</span></p></article><article class="task exercise-like" id="task-389"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1305">How are the two matrices <span class="process-math">\(A+B\)</span> and <span class="process-math">\(B+A\)</span> related? What does this tell us about matrix addition?</p></article></article><article class="task exercise-like" id="task-390"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1306">Let <span class="process-math">\(A = \left[ \begin{array}{rc} 1 \amp 0 \\ -2 \amp 8 \end{array} \right]\text{,}\)</span> <span class="process-math">\(B = \left[ \begin{array}{cc} 1 \amp 1 \\ 3 \amp 4 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(C = \left[ \begin{array}{cr} 0 \amp -5 \\ 1 \amp 6 \end{array} \right]\text{.}\)</span> Determine the entries of the matrix <span class="process-math">\(A + 2B - 7C\text{.}\)</span></p></article><article class="task exercise-like" id="p_matrix_multiplication"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-115"><p id="p-1307">Now we turn to multiplication of matrices. Our first goal is to find out what conditions we need on the sizes of matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> if the matrix-matrix product <span class="process-math">\(AB\)</span> is defined and what the size of the resulting product matrix is. We know the condition and the size of the result in the special case of <span class="process-math">\(B\)</span> being a vector, i.e., a matrix with one column. So our conjectures for the general case should match what we know in the special case. In each part of this problem, use any appropriate tool (e.g., your calculator, Maple, Mathematica, Wolfram<span class="process-math">\(|\)</span>Alpha) to determine the matrix product <span class="process-math">\(AB\text{,}\)</span> if it exists. If you obtain a product, write it down and explain how its size is related to the sizes of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{.}\)</span> If you receive an error, write down the error and guess why the error occurred and/or what it means.</p></div>
<article class="task exercise-like" id="task-392"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1308"><span class="process-math">\(A = \left[ \begin{array}{ccc} 1\amp 2\amp 0 \\ 0\amp 1\amp 1 \end{array} \right] \ \ \ \text{ and } \ \ \ B = \left[ \begin{array}{crc} 3\amp 5\amp 0\\0\amp -2\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-393"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1309"><span class="process-math">\(A = \left[ \begin{array}{ccc} 1\amp 2\amp 0 \\ 0\amp 1\amp 1 \end{array} \right] \ \ \ \text{ and } \ \ \ B = \left[ \begin{array}{crc} 3\amp 0\\5\amp -2 \\ 0\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-394"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1310"><span class="process-math">\(A = \left[ \begin{array}{cc} 1 \amp 2 \\ 3 \amp 4 \end{array} \right] \ \ \ \text{ and } \ \ \ B = \left[ \begin{array}{ccc} 1 \amp 1 \amp 1 \\1 \amp 0 \amp 1 \\ 0 \amp 2 \amp 0 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-395"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-1311"><span class="process-math">\(A = \left[ \begin{array}{cc} 1 \amp 2 \\ 3 \amp 4 \\ 5 \amp 6 \\ 7 \amp 8 \end{array} \right] \ \ \ \text{ and } \ \ \ B = \left[ \begin{array}{rcc} 1 \amp 2 \amp 3 \\ -1 \amp 1 \amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-396"><h6 class="heading"><span class="codenumber">(v)</span></h6>
<p id="p-1312">Make a guess for the condition on the sizes of two matrices <span class="process-math">\(A, B\)</span> for which the product <span class="process-math">\(AB\)</span> is defined. How is the size of the product matrix related to the sizes of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{?}\)</span></p></article></article><article class="task exercise-like" id="task-397"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<div class="introduction" id="introduction-116"><p id="p-1313">The final matrix products, when defined, in <a href="" class="xref" data-knowl="./knowl/p_matrix_multiplication.html" title="Task 8.1.c">problem 8.1.c</a> might seem unrelated to the individual matrices at first. In this problem, we will uncover this relationship using our knowledge of the matrix-vector product. Let <span class="process-math">\(A = \left[ \begin{array}{rr} 3 \amp -1 \\ -2 \amp 3 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{ccc} 0 \amp 2 \amp 1 \\ 1 \amp 3 \amp 2 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-398"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1314">Calculate <span class="process-math">\(AB\)</span> using any tool.</p></article><article class="task exercise-like" id="task-399"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1315">Using the matrix-vector product, calculate <span class="process-math">\(A \vx\)</span> where <span class="process-math">\(\vx\)</span> is the first column (i.e., calculate <span class="process-math">\(A\begin{bmatrix}0 \\ 1 \end{bmatrix}\)</span>), and then the second column of <span class="process-math">\(B\)</span> (i.e., calculate <span class="process-math">\(A\begin{bmatrix}2 \\ 3 \end{bmatrix}\)</span>), and then the third column of <span class="process-math">\(B\)</span> (i.e., calculate <span class="process-math">\(A\begin{bmatrix}1 \\ 2 \end{bmatrix}\)</span>). Do you notice these output vectors within <span class="process-math">\(AB\text{?}\)</span></p></article><article class="task exercise-like" id="task-400"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1316">Describe as best you can a definition of <span class="process-math">\(AB\)</span> using the matrix-vector product.</p></article></article></article></section><section class="section" id="sec_mtx_add_smult"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Properties of Matrix Addition and Multiplication by Scalars</span>
</h3>
<p id="p-1317">Just as we were able to define an algebra of vectors with addition and multiplication by scalars, we can define an algebra of matrices. We will see that the properties of these operations on matrices are immediate generalizations of the properties of the operations on vectors. We will then see how the matrix product arises through the connection of matrices to linear transformations. Finally, we define the transpose of a matrix. The transpose of a matrix will be useful in applications such as graph theory and least-squares fitting of curves, as well as in advanced topics such as inner product spaces and the dual space of a vector space.</p>
<p id="p-1318"> We learned in <a href="" class="xref" data-knowl="./knowl/pa_2_a.html" title="Preview Activity 8.1">Preview Activity 8.1</a> that we can add two matrices of the same size together by adding corresponding entries and we can multiply any matrix by a scalar by multiplying each entry of the matrix by that scalar. More generally, if <span class="process-math">\(A = [a_{ij}]\)</span> and <span class="process-math">\(B = [b_{ij}]\)</span> are <span class="process-math">\(m \times n\)</span> matrices and <span class="process-math">\(c\)</span> is any scalar, then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_2_a.html">
\begin{equation*}
A + B = [a_{ij}+b_{ij}] \ \ \text{ and }  \ \ cA = [ca_{ij}]\text{.}
\end{equation*}
</div>
<p id="p-1319">As we have done each time we have introduced a new operation, we ask what properties the operation has. For example, you determined in <a href="" class="xref" data-knowl="./knowl/pa_2_a.html" title="Preview Activity 8.1">Preview Activity 8.1</a> that addition of matrices is a commutative operation. More specifically, for every two <span class="process-math">\(m\times n\)</span> matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{,}\)</span> <span class="process-math">\(A+B=B+A\text{.}\)</span> We can use similar arguments to verify the following properties of matrix addition and multiplication by scalars. Notice that these properties are very similar to the properties of addition and scalar multiplication of vectors we discussed earlier. This should come as no surprise since the <span class="process-math">\(n\)</span>-dimensional vectors are <span class="process-math">\(n\times 1\)</span> matrices. In a strange twist, we will see that matrices themselves can be considered as vectors when we discuss vector spaces in a later section.</p>
<article class="theorem theorem-like" id="thm_matrix_sum_properties"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">8.1</span><span class="period">.</span>
</h4>
<p id="p-1320">Let <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(B\text{,}\)</span> and <span class="process-math">\(C\)</span> be <span class="process-math">\(m \times n\)</span> matrices and let <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> be scalars. Then</p>
<ol class="decimal">
<li id="li-242"><p id="p-1321"><span class="process-math">\(A+B = B+A\)</span> (this property tells us that matrix addition is <dfn class="terminology">commutative</dfn>)</p></li>
<li id="li-243"><p id="p-1322"><span class="process-math">\((A+B) + C = A + (B+C)\)</span> (this property tells us that matrix addition is <dfn class="terminology">associative</dfn>)</p></li>
<li id="li-244"><p id="p-1323">The <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(0\)</span> whose entries are all 0 has the property that <span class="process-math">\(A + 0 = A\text{.}\)</span> The matrix <span class="process-math">\(0\)</span> is called the <dfn class="terminology">zero matrix</dfn> (It is generally clear from the context what the size of the 0 matrix is.).</p></li>
<li id="li-245"><p id="p-1324">The scalar multiple <span class="process-math">\((-1)A\)</span> of the matrix <span class="process-math">\(A\)</span> has the property that <span class="process-math">\((-1)A + A = 0\text{.}\)</span> The matrix <span class="process-math">\((-1)A = -A\)</span> is called the <dfn class="terminology">additive inverse</dfn> of the matrix <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-246"><p id="p-1325"><span class="process-math">\((a+b) A = aA + bA\)</span> (this property tells us that <em class="emphasis">scalar multiplication of matrices distributes over scalar addition</em>)</p></li>
<li id="li-247"><p id="p-1326"><span class="process-math">\(a(A+B) = aA + aB\)</span> (this property tells us that <em class="emphasis">scalar multiplication of matrices distributes over matrix addition</em>)</p></li>
<li id="li-248"><p id="p-1327"><span class="process-math">\(\displaystyle (ab) A = a(bA)\)</span></p></li>
<li id="li-249"><p id="p-1328"><span class="process-math">\(1A=A\text{.}\)</span></p></li>
</ol></article><p id="p-1329">Later on, we will see that these properties define the set of all <span class="process-math">\(m \times n\)</span> matrices as a <dfn class="terminology">vector space</dfn>. These properties just say that, regarding addition and multiplication by scalars, we can manipulate matrices just as we do real numbers. Note, however, we have not yet defined an operation of multiplication on matrices. That is the topic for the next section.</p></section><section class="section" id="sec_mtx_prod"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">A Matrix Product</span>
</h3>
<section class="introduction" id="introduction-117"><p id="p-1330">As we saw in <a href="" class="xref" data-knowl="./knowl/pa_2_a.html" title="Preview Activity 8.1">Preview Activity 8.1</a>, a matrix-matrix product can be found in a way which makes use of and also generalizes the matrix-vector product.</p>
<article class="definition definition-like" id="definition-19"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">8.2</span><span class="period">.</span>
</h4>
<p id="p-1331">The <dfn class="terminology">matrix product</dfn> of a <span class="process-math">\(k \times m\)</span> matrix <span class="process-math">\(A\)</span> and an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B = [\vb_1 \ \vb_2 \ \cdots \ \vb_n]\)</span> with columns <span class="process-math">\(\vb_1\text{,}\)</span> <span class="process-math">\(\vb_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vb_n\)</span> is the <span class="process-math">\(k \times n\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[A\vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{.}
\end{equation*}
</div></article><p id="p-1332">We now consider the motivation behind this definition by thinking about the matrix transformations corresponding to each of the matrices <span class="process-math">\(A, B\)</span> and <span class="process-math">\(AB\text{.}\)</span> Recall that left multiplication by an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B\)</span> defines a transformation <span class="process-math">\(T\)</span> from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span> by <span class="process-math">\(T(\vx)=B\vx\text{.}\)</span> The domain of <span class="process-math">\(T\)</span> is <span class="process-math">\(\R^n\)</span> because the number of components of <span class="process-math">\(\vx\)</span> have to match the number of entries in each of row of <span class="process-math">\(B\)</span> in order for the matrix-vector product <span class="process-math">\(B\vx\)</span> to be defined. Similarly, a <span class="process-math">\(k \times m\)</span> matrix <span class="process-math">\(A\)</span> defines a transformation <span class="process-math">\(A\)</span> from <span class="process-math">\(\R^m\)</span> to <span class="process-math">\(\R^k\text{.}\)</span> Since transformations are functions, we can compose them as long as the output vectors of the inside transformation lie in the domain of the outside transformation. Therefore if <span class="process-math">\(T\)</span> is the inside transformation and <span class="process-math">\(S\)</span> is the outside transformation, the composition <span class="process-math">\(S\circ T\)</span> is defined. So a natural question to ask is if we are given</p>
<ul class="disc">
<li id="li-250"><p id="p-1333">a transformation <span class="process-math">\(T\)</span> from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span> where <span class="process-math">\(T(\vx) = B \vx\)</span> for an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B\)</span> and</p></li>
<li id="li-251"><p id="p-1334">a transformation <span class="process-math">\(S\)</span> from <span class="process-math">\(\R^m\)</span> to <span class="process-math">\(\R^k\)</span> with <span class="process-math">\(S(\vy) = A \vy\)</span> for some <span class="process-math">\(k \times m\)</span> matrix <span class="process-math">\(A\text{,}\)</span></p></li>
</ul>
<p class="continuation">is there a matrix that represents the transformation <span class="process-math">\(S \circ T\)</span> defined by <span class="process-math">\((S\circ T)(\vx)=S(T(\vx))\text{?}\)</span> We investigate this question in the next activity in the special case of a <span class="process-math">\(2\times 3\)</span> matrix <span class="process-math">\(A\)</span> and a <span class="process-math">\(3\times 2\)</span> matrix <span class="process-math">\(B\text{.}\)</span></p>
<article class="activity project-like" id="act_A2_1_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">8.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-118">
<p id="p-1335">In this activity, we look for the meaning of the matrix product from a transformation perspective. Let <span class="process-math">\(S\)</span> and <span class="process-math">\(T\)</span> be matrix transformations defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
S(\vy) = A \vy \ \ \ \text{ and }  \ \ \ T(\vx) = B \vx\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{ccc} 1\amp 2\amp 0 \\ 0\amp 1\amp 1 \end{array}  \right]  \ \ \ \text{ and }  \ \ \ B = \left[ \begin{array}{cr} 3\amp 0\\5\amp -2 \\ 0\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div>
<article class="task exercise-like" id="task-401"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1336">What are the domains and codomains of <span class="process-math">\(S\)</span> and <span class="process-math">\(T\text{?}\)</span> Why is the composite transformation <span class="process-math">\(S \circ T\)</span> defined? What is the domain of <span class="process-math">\(S\circ T\text{?}\)</span> What is the codomain of <span class="process-math">\(S\circ T\text{?}\)</span> (Recall that <span class="process-math">\(S \circ T\)</span> is defined by <span class="process-math">\((S \circ T)(\vx) = S(T(\vx))\text{,}\)</span> i.e., we substitute the output <span class="process-math">\(T(\vx)\)</span> as the input into the transformation <span class="process-math">\(S\text{.}\)</span>)</p></article><article class="task exercise-like" id="task-402"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1337">Let <span class="process-math">\(\vx = \left[ \begin{array}{c} x \\ y \end{array} \right]\text{.}\)</span> Determine the components of <span class="process-math">\(T(\vx)\text{.}\)</span></p></article><article class="task exercise-like" id="task-403"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1338">Find the components of <span class="process-math">\(S\circ T(\vx)=S(T(\vx))\text{.}\)</span></p></article><article class="task exercise-like" id="task-404"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1339">Find a matrix <span class="process-math">\(C\)</span> so that <span class="process-math">\(S(T(\vx)) = C\vx\text{.}\)</span></p></article><article class="task exercise-like" id="task-405"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-1340">Use the definition of composition of transformations and the definitions of the <span class="process-math">\(S\)</span> and <span class="process-math">\(T\)</span> transformations to explain why it is reasonable to define <span class="process-math">\(AB\)</span> to be the matrix <span class="process-math">\(C\text{.}\)</span> Does the matrix <span class="process-math">\(C\)</span> agree with the</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_2_a.html">
\begin{equation*}
AB = \left[ \begin{array}{cr} 13 \amp  -4 \\ 5 \amp  -1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">you found in <a href="" class="xref" data-knowl="./knowl/pa_2_a.html" title="Preview Activity 8.1">Preview Activity 8.1</a> using technology?</p></article></article><p id="p-1341">We now consider this result in the general case of a <span class="process-math">\(k\times m\)</span> matrix <span class="process-math">\(A\)</span> and an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B\text{,}\)</span> where <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> define matrix transformations <span class="process-math">\(S\)</span> and <span class="process-math">\(T\text{,}\)</span> respectively. In other words, <span class="process-math">\(S\)</span> and <span class="process-math">\(T\)</span> are matrix transformations defined by <span class="process-math">\(S(\vx) = A\vx\)</span> and <span class="process-math">\(T(\vx) = B\vx\text{.}\)</span> The domain of <span class="process-math">\(S\)</span> is <span class="process-math">\(\R^m\)</span> and the codomain is <span class="process-math">\(\R^k\text{.}\)</span> The domain of <span class="process-math">\(T\)</span> is <span class="process-math">\(\R^n\)</span> and the codomain is <span class="process-math">\(\R^m\text{.}\)</span> The composition <span class="process-math">\(S\circ T\)</span> is defined because the output vectors of <span class="process-math">\(T\)</span> are in <span class="process-math">\(\R^m\)</span> and they lie in the domain of <span class="process-math">\(S\text{.}\)</span> The domain of <span class="process-math">\(S\circ T\)</span> is the same as the domain of <span class="process-math">\(T\)</span> since the input vectors first go through the <span class="process-math">\(T\)</span> transformation. The codomain of <span class="process-math">\(S\circ T\)</span> is the same as the codomain of <span class="process-math">\(S\)</span> since the final output vectors are produced by applying the <span class="process-math">\(S\)</span> transformation.</p>
<p id="p-1342">Let us see how we can obtain the matrix corresponding to the transformation <span class="process-math">\(S\circ T\text{.}\)</span> Let <span class="process-math">\(B = \left[ \vb_1 \ \vb_2  \  \cdots \ \vb_n  \right]\text{,}\)</span> where <span class="process-math">\(\vb_j\)</span> is the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(B\text{,}\)</span> and let <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_n \end{array}  \right]\text{.}\)</span> Recall that the matrix vector product <span class="process-math">\(B\vx\)</span> is the linear combination of the columns of <span class="process-math">\(B\)</span> with the corresponding weights from <span class="process-math">\(\vx\text{.}\)</span> So</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(\vx) = B\vx = x_1 \vb_1 + x_2 \vb_2 + \cdots + x_n \vb_n\text{.}
\end{equation*}
</div>
<p id="p-1343">Note that each of the <span class="process-math">\(\vb_j\)</span> vectors are in <span class="process-math">\(\R^m\)</span> since <span class="process-math">\(B\)</span> is an <span class="process-math">\(m\times n\)</span> matrix. Therefore, each of these vectors can be multiplied by matrix <span class="process-math">\(A\)</span> and we can evaluate <span class="process-math">\(S(B\vx)\text{.}\)</span> Therefore, <span class="process-math">\(S\circ T\)</span> is defined and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_2_a_1">
\begin{equation}
(S \circ T)(\vx) = S(T(\vx))= A(B\vx) = A\left( x_1 \vb_1 + x_2 \vb_2 + \cdots + x_n \vb_n\right)\text{.}\tag{8.1}
\end{equation}
</div>
<p id="p-1344">The properties of matrix-vector products show that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_2_a_2">
\begin{equation}
A\left( x_1 \vb_1 + x_2 \vb_2 + \cdots + x_n \vb_n\right) = x_1 A\vb_1 + x_2 A\vb_2 + \cdots + x_n A\vb_n\text{.}\tag{8.2}
\end{equation}
</div>
<p id="p-1345">This expression is a linear combination of <span class="process-math">\(A\vb_i\)</span>'s with <span class="process-math">\(x_i\)</span>'s being the weights. Therefore, if we let <span class="process-math">\(C\)</span> be the matrix with columns <span class="process-math">\(A \vb_1\text{,}\)</span> <span class="process-math">\(A\vb_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(A\vb_n\text{,}\)</span> that is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_2_a_1.html ./knowl/eq_2_a_2.html ./knowl/eq_2_a_3.html">
\begin{equation*}
C = [A \vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_2_a_1.html ./knowl/eq_2_a_2.html ./knowl/eq_2_a_3.html" id="eq_2_a_3">
\begin{equation}
x_1 A\vb_1 + x_2 A\vb_2 + \cdots + x_n A\vb_n = C \vx\tag{8.3}
\end{equation}
</div>
<p class="continuation">by definition of the matrix-vector product. Combining equations <a href="" class="xref" data-knowl="./knowl/eq_2_a_1.html" title="Equation 8.1">(8.1)</a>, <a href="" class="xref" data-knowl="./knowl/eq_2_a_2.html" title="Equation 8.2">(8.2)</a>, and <a href="" class="xref" data-knowl="./knowl/eq_2_a_3.html" title="Equation 8.3">(8.3)</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_2_a_1.html ./knowl/eq_2_a_2.html ./knowl/eq_2_a_3.html">
\begin{equation*}
(S \circ T)(\vx) = C \vx
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(C = [A \vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{.}\)</span></p>
<p id="p-1346">Also note that since <span class="process-math">\(T(\vx)=B\vx\)</span> and <span class="process-math">\(S(\vy)=A\vy\text{,}\)</span> we find</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_2_a_4">
\begin{equation}
(S\circ T)(\vx)= S(T(\vx))= S(B\vx)=A(B(\vx)) \,\text{.}\tag{8.4}
\end{equation}
</div>
<p id="p-1347">Since the matrix representing the transformation <span class="process-math">\(S\circ T\)</span> is the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_2_a_4.html">
\begin{equation*}
[A \vb_1 \ A\vb_2 \ \cdots \ A\vb_n]
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\vb_1\text{,}\)</span> <span class="process-math">\(\vb_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vb_n\)</span> are the columns of the matrix <span class="process-math">\(B\text{,}\)</span> it is natural to define <span class="process-math">\(AB\)</span> to be this matrix in light of equation <a href="" class="xref" data-knowl="./knowl/eq_2_a_4.html" title="Equation 8.4">(8.4)</a>.</p>
<p id="p-1348">Matrix multiplication has some properties that are unfamiliar to us as the next activity illustrates.</p>
<article class="activity project-like" id="act_A2_1_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">8.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-119"><p id="p-1349">Let <span class="process-math">\(A~=~\left[ \begin{array}{rr} 3 \amp -1 \\ -2 \amp 6 \end{array} \right]\text{,}\)</span> <span class="process-math">\(B~=~\left[ \begin{array}{cc} 0 \amp 2 \\ 1 \amp 3 \end{array} \right]\text{,}\)</span> <span class="process-math">\(C~=~\left[ \begin{array}{cc} 1 \amp 1 \\ 1 \amp 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(D~=~\left[ \begin{array}{rr} 3 \amp -3 \\ -3 \amp 3 \end{array} \right]\)</span> and <span class="process-math">\(E~=~\left[ \begin{array}{cc} 1 \amp 0 \\ 0 \amp 1 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-406"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1350">Find the indicated products (by hand or using a calculator).</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB \qquad BA \qquad DC \qquad AC \qquad BC \qquad AE \qquad EB
\end{equation*}
</div></article><article class="task exercise-like" id="task-407"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1351">Is matrix multiplication commutative? Explain.</p></article><article class="task exercise-like" id="task-408"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1352">Is there an identity element for matrix multiplication? In other words, is there a matrix <span class="process-math">\(I\)</span> for which <span class="process-math">\(AI=IA=A\)</span> for any matrix <span class="process-math">\(A\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-409"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1353">If <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> are real numbers with <span class="process-math">\(ab=0\text{,}\)</span> then we know that either <span class="process-math">\(a=0\)</span> or <span class="process-math">\(b=0\text{.}\)</span> Is this same property true with matrix multiplication? Explain.</p></article><article class="task exercise-like" id="task-410"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-1354">If <span class="process-math">\(a\text{,}\)</span> <span class="process-math">\(b\text{,}\)</span> and <span class="process-math">\(c\)</span> are real numbers with <span class="process-math">\(c \neq 0\)</span> and <span class="process-math">\(ac = bc\text{,}\)</span> we know that <span class="process-math">\(a=b\text{.}\)</span> Is this same property true with matrix multiplication? Explain.</p></article></article><p id="p-1355">As we saw in <a href="" class="xref" data-knowl="./knowl/act_A2_1_2.html" title="Activity 8.3">Activity 8.3</a>, there are matrices <span class="process-math">\(A, B\)</span> for which <span class="process-math">\(AB\neq BA\text{.}\)</span> On the other hand, there are matrices for which <span class="process-math">\(AB=BA\text{.}\)</span> For example, this equality will always hold for a square matrix <span class="process-math">\(A\)</span> and if <span class="process-math">\(B\)</span> is the identity matrix of the same size. It also holds if <span class="process-math">\(A=B\text{.}\)</span> If the equality <span class="process-math">\(AB=BA\)</span> holds, we say that matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> <dfn class="terminology">commute</dfn>. So the identity matrix commutes with all square matrices of the same size and every matrix <span class="process-math">\(A\)</span> commutes with <span class="process-math">\(A^k\)</span> for any power <span class="process-math">\(k\text{.}\)</span></p>
<p id="p-1356">There is an alternative method of calculating a matrix product that we will often use that we illustrate in the next activity. This alternate version depends on the product of a row matrix with a vector. Suppose <span class="process-math">\(A = [a_1 \ a_2 \ \cdots \ a_n]\)</span> is a <span class="process-math">\(1 \times n\)</span> matrix and <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_n \end{array}  \right]\)</span> is an <span class="process-math">\(n \times 1\)</span> vector. Then the product <span class="process-math">\(A \vx\)</span> is the <span class="process-math">\(1 \times 1\)</span> vector</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[a_1 \ a_2 \ \cdots \ a_n]\left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_n \end{array}  \right] = [a_1x_1+a_2x_2 + \cdots + a_nx_n]\text{.}
\end{equation*}
</div>
<p id="p-1357">In this situation, we usually identify the <span class="process-math">\(1 \times 1\)</span> matrix with its scalar entry and write</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_2_a_5">
\begin{equation}
[a_1 \ a_2 \ \cdots \ a_n] \cdot \left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_n \end{array}  \right] = a_1x_1+a_2x_2 + \cdots + a_nx_n\text{.}\tag{8.5}
\end{equation}
</div>
<p id="p-1358"> The product <span class="process-math">\(\cdot\)</span> in <a href="" class="xref" data-knowl="./knowl/eq_2_a_5.html" title="Equation 8.5">(8.5)</a> is called the <dfn class="terminology">scalar</dfn> or <dfn class="terminology">dot</dfn> product of <span class="process-math">\([a_1 \ a_2 \ \cdots \ a_n]\)</span> with <span class="process-math">\(\left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_n \end{array} \right]\text{.}\)</span></p>
<article class="activity project-like" id="act_A2_1_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">8.4</span><span class="period">.</span>
</h4>
<p id="p-1359">Let <span class="process-math">\(A = \left[ \begin{array}{crr} 1\amp -1\amp 2 \\ 3\amp 0\amp -4 \\ 2\amp -5\amp 1 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cr} 4\amp -2 \\ 6\amp 0 \\ 1\amp 3 \end{array} \right]\text{.}\)</span></p>
<p id="p-1360">Let <span class="process-math">\(\va_i\)</span> be the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(A\)</span> and <span class="process-math">\(\vb_j\)</span> the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(B\text{.}\)</span> For example, <span class="process-math">\(\va_1=[ \, 1 \; -1 \; 2 \, ]\)</span> and <span class="process-math">\(\vb_2 = \left[ \begin{array}{r} -2 \\ 0 \\ 3 \end{array} \right]\text{.}\)</span></p>
<p id="p-1361">Calculate the entries of the matrix <span class="process-math">\(C\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_1_e_scalar_product.html ./knowl/chap_matrix_vector.html">
\begin{equation*}
C = \left[ \begin{array}{cc} \va_1 \cdot \vb_1 \amp  \va_1 \cdot \vb_2 \\ \va_2 \cdot \vb_1 \amp  \va_2 \cdot \vb_2 \\ \va_3 \cdot \vb_1 \amp  \va_3 \cdot \vb_2 \end{array}  \right]\,\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\va_i \cdot \vb_j\)</span> refers to the scalar product of row <span class="process-math">\(i\)</span> of <span class="process-math">\(A\)</span> with column <span class="process-math">\(j\)</span> of <span class="process-math">\(B\text{.}\)</span><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-11" id="fn-11"><sup> 11 </sup></a> Compare your result with the result of <span class="process-math">\(AB\)</span> calculated via the product of <span class="process-math">\(A\)</span> with the columns of <span class="process-math">\(B\text{.}\)</span></p></article><p id="p-1362"><a href="" class="xref" data-knowl="./knowl/act_A2_1_3.html" title="Activity 8.4">Activity 8.4</a> shows that these is an alternate way to calculate a matrix product. To see how this works in general, let <span class="process-math">\(A = [a_{ij}]\)</span> be a <span class="process-math">\(k \times m\)</span> matrix and <span class="process-math">\(B = [\vb_1 \ \vb_2 \ \cdots \ \vb_n]\)</span> an <span class="process-math">\(m \times n\)</span> matrix. We know that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_A2_1_3.html">
\begin{equation*}
AB = [A\vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{.}
\end{equation*}
</div>
<p id="p-1363">Now let <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vr_k\)</span> be the rows of <span class="process-math">\(A\)</span> so that <span class="process-math">\(A = \left[ \begin{array}{c} \vr_1 \\ \vr_2 \\ \vdots \\ \vr_k \end{array}  \right]\text{.}\)</span> First we argue that if <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ \vdots \\ x_m \end{array}  \right]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \vx = \left[ \begin{array}{c} \vr_1 \cdot \vx \\ \vr_2 \cdot \vx \\ \vdots \\ \vr_k \cdot \vx \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1364">This is the <dfn class="terminology">scalar product</dfn> (or <dfn class="terminology">dot product</dfn>) definition of the matrix-vector product.</p>
<p id="p-1365">To show that this definition gives the same result as the linear combination definition of matrix-vector product, we first let <span class="process-math">\(A = [\vc_1 \ \vc_2 \ \cdots \ \vc_m]\text{,}\)</span> where <span class="process-math">\(\vc_1\text{,}\)</span> <span class="process-math">\(\vc_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vc_m\)</span> are the columns of <span class="process-math">\(A\text{.}\)</span> By our linear combination definition of the matrix-vector product, we obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-83">
\begin{align*}
A \vx \amp = x_1\vc_1 + x_2 \vc_2 + \cdots + x_m \vc_m\\
\amp = x_1 \left[ \begin{array}{c} a_{11}\\
a_{21}\\
\vdots\\
a_{k1} \end{array} \right] + x_2 \left[ \begin{array}{c} a_{12}\\
a_{22}\\
\vdots\\
a_{k2} \end{array} \right] + \cdots + x_m \left[ \begin{array}{c} a_{1m}\\
a_{2m}\\
\vdots\\
a_{km} \end{array} \right]\\
\amp = \left[ \begin{array}{c} a_{11}x_1+a_{12}x_2+ \cdots + a_{1m}x_m\\
a_{21}x_1+a_{22}x_2+ \cdots + a_{2m}x_m\\
\vdots\\
a_{k1}x_1+a_{k2}x_2+ \cdots + a_{km}x_m \end{array} \right]\\
\amp = \left[ \begin{array}{c} \vr_1 \cdot \vx\\
\vr_2 \cdot \vx\\
\vdots\\
\vr_k \cdot \vx \end{array} \right]\text{.}
\end{align*}
</div>
<p id="p-1366">Therefore, the above work shows that both linear combination and scalar product definitions give the same matrix-vector product.</p>
<p id="p-1367">Applying this to the matrix product <span class="process-math">\(AB\)</span> defined in terms of the matrix-vector product, we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \vb_j = \left[ \begin{array}{c} \vr_1 \cdot \vb_j \\ \vr_2 \cdot \vb_j \\ \vdots \\ \vr_k \cdot \vb_j \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1368">So the <span class="process-math">\(i,j\)</span>th entry of the matrix product <span class="process-math">\(AB\)</span> is found by taking the scalar product of the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(A\)</span> with the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(B\text{.}\)</span> In other words,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(AB)_{ij} = \vr_i \cdot \vb_j
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\vr_i\)</span> is the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(A\)</span> and <span class="process-math">\(\vb_j\)</span> is the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(B\text{.}\)</span></p></section><section class="subsection" id="subsection-2"><h4 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Properties of Matrix Multiplication</span>
</h4>
<p id="p-1369"><a href="" class="xref" data-knowl="./knowl/act_A2_1_2.html" title="Activity 8.3">Activity 8.3</a> shows that we must be very careful not to assume that matrix multiplication behaves like multiplication of real numbers. However, matrix multiplication does satisfy some familiar properties. For example, we now have an addition and multiplication of matrices under certain conditions, so we might ask if matrix multiplication distributes over matrix addition. To answer this question we take two <dfn class="terminology">arbitrary</dfn> <span class="process-math">\(k \times m\)</span> matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> and an <dfn class="terminology">arbitrary</dfn> <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(C =  [\vc_1 \ \vc_2 \ \cdots \ \vc_n]\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_A2_1_2.html" id="md-84">
\begin{align*}
(A+B)C \amp = [(A+B)\vc_1 \ (A+B)\vc_2 \ \cdots \ (A+B)\vc_n]\\
\amp = [A\vc_1+B\vc_1 \ A\vc_2+B\vc_2 \ \cdots \ A\vc_n+B\vc_n]\\
\amp = [A\vc_1 \ A\vc_2 \ \cdots \ A\vc_n] + [B\vc_1 \ B\vc_2 \ \cdots \ B\vc_n]\\
\amp = AC + BC\text{.}
\end{align*}
</div>
<p id="p-1370">Similar arguments can be used to show the following properties of matrix multiplication.</p>
<article class="theorem theorem-like" id="thm_matrix_product_properties"><h5 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">8.3</span><span class="period">.</span>
</h5>
<p id="p-1371">Let <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(B\text{,}\)</span> and <span class="process-math">\(C\)</span> be matrices of the appropriate sizes for all sums and products to be defined and let <span class="process-math">\(a\)</span> be a scalar. Then</p>
<ol class="decimal">
<li id="li-252"><p id="p-1372"><span class="process-math">\((AB)C = A(BC)\)</span> (this property tells us that matrix multiplication is <dfn class="terminology">associative</dfn>)</p></li>
<li id="li-253"><p id="p-1373"><span class="process-math">\((A+B)C = AC + BC\)</span> (this property tells us that matrix multiplication on the right <dfn class="terminology">distributes over matrix addition</dfn>)</p></li>
<li id="li-254"><p id="p-1374"><span class="process-math">\(A(B+C) = AB + AC\)</span> (this property tells us that matrix multiplication on the left <dfn class="terminology">distributes over matrix addition</dfn>)</p></li>
<li id="li-255"><p id="p-1375">There is a square matrix <span class="process-math">\(I_n\)</span> with the property that <span class="process-math">\(AI_n = A\)</span> or <span class="process-math">\(I_nA = A\)</span> for whichever product is defined.</p></li>
<li id="li-256"><p id="p-1376"><span class="process-math">\(\displaystyle a(AB) = (aA)B = A(aB)\)</span></p></li>
</ol></article><p id="p-1377">We verified the second part of this theorem and will assume that all of the properties of this theorem hold. The matrix <span class="process-math">\(I_n\)</span> introduced in <a href="" class="xref" data-knowl="./knowl/thm_matrix_product_properties.html" title="Theorem 8.3">Theorem 8.3</a> is called the <dfn class="terminology">(multiplicative) identity matrix</dfn>. We usually omit the word multiplicative and refer to the <span class="process-math">\(I_n\)</span> simply as the identity matrix. This does not cause any confusion since we refer to the additive identity matrix as simply the zero matrix.</p>
<article class="definition definition-like" id="definition-20"><h5 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">8.4</span><span class="period">.</span>
</h5>
<p id="p-1378">Let <span class="process-math">\(n\)</span> be a positive integer. The <span class="process-math">\(n \times n\)</span> <dfn class="terminology">identity matrix</dfn> <span class="process-math">\(I_n\)</span> is the matrix <span class="process-math">\(I_n = [a_{ij}]\text{,}\)</span> where <span class="process-math">\(a_{ii} = 1\)</span> for each <span class="process-math">\(i\)</span> and <span class="process-math">\(a_{ij} = 0\)</span> if <span class="process-math">\(i \neq j\text{.}\)</span></p></article><p id="p-1379">We also write the matrix <span class="process-math">\(I_n\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
I_n = \left[ \begin{array}{ccccccc} 1 \amp  0 \amp  0 \amp  0 \amp  \cdots \amp  0 \amp  0 \\ 0 \amp  1 \amp  0 \amp  0 \amp  \cdots \amp  0 \amp  0 \\ 0 \amp  0 \amp  1 \amp  0 \amp  \cdots \amp  0 \amp  0 \\ \vdots \amp  \amp  \amp  \amp  \ddots \amp  \amp  \vdots \\ 0 \amp  0 \amp  0 \amp  0 \amp  \cdots \amp  1 \amp  0 \\ 0 \amp  0\amp  0 \amp  0 \amp  \cdots \amp  0 \amp  1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1380">The matrix <span class="process-math">\(I_n\)</span> has the property that for any <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AI_n = I_n A = A\,\text{.}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(I_n\)</span> is a multiplicative identity in the set of all <span class="process-math">\(n \times n\)</span> matrices. More generally, for an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AI_n = I_mA = A \,\text{.}
\end{equation*}
</div></section></section><section class="section" id="sec_mtx_transpose"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">The Transpose of a Matrix</span>
</h3>
<p id="p-1381">One additional operation on matrices is the transpose. The transpose of a matrix occurs in many useful formulas in linear algebra and in applications of linear algebra.</p>
<article class="definition definition-like" id="definition-21"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">8.5</span><span class="period">.</span>
</h4>
<p id="p-1382">The <dfn class="terminology">transpose</dfn> of an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A = [a_{ij}]\)</span> is the <span class="process-math">\(n \times m\)</span> matrix <span class="process-math">\(A^{\tr}\)</span> whose <span class="process-math">\(i,j\)</span>th entry is <span class="process-math">\(a_{ji}\text{.}\)</span></p></article><p id="p-1383">Written out, the transpose of the <span class="process-math">\(m \times n\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{ccccc} a_{11} \amp  a_{12} \amp  \cdots    \amp  a_{1n-1} \amp  a_{1n} \\ a_{21} \amp  a_{22} \amp  \cdots    \amp  a_{2n-1} \amp  a_{2n} \\ \vdots \amp        \amp  \ddots    \amp            \amp \vdots \\ a_{m1} \amp  a_{m2} \amp  \cdots    \amp  a_{mn-1} \amp  a_{mn} \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">is the <span class="process-math">\(n \times m\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A^{\tr} = \left[ \begin{array}{ccccc} a_{11} \amp  a_{21} \amp  \cdots \amp  a_{m-11} \amp  a_{m1} \\ a_{12} \amp  a_{22} \amp  \cdots \amp  a_{m-12} \amp  a_{m2} \\ \vdots \amp        \amp  \ddots \amp           \amp \vdots \\ a_{1n} \amp  a_{2n} \amp  \cdots \amp  a_{m-1n} \amp  a_{mn} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1384"> In other words, the transpose of a matrix <span class="process-math">\(A\)</span> is the matrix <span class="process-math">\(A^{\tr}\)</span> whose rows are the columns of <span class="process-math">\(A\text{.}\)</span> Alternatively, the transpose of <span class="process-math">\(A\)</span> is the matrix <span class="process-math">\(A^{\tr}\)</span> whose columns are the rows of <span class="process-math">\(A\text{.}\)</span> We can also view the transpose of <span class="process-math">\(A\)</span> as the reflection of <span class="process-math">\(A\)</span> across its main diagonal, where the <dfn class="terminology">diagonal</dfn> of a matrix <span class="process-math">\(A = [a_{ij}]\)</span> consists of the entries of the form <span class="process-math">\([a_{ii}]\text{.}\)</span></p>
<article class="activity project-like" id="act_A2_1_4"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">8.5</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-411"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1385">Find the transpose of each of the indicated matrices.</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccc} 1 \amp 2 \amp 3 \amp 4 \\ 5 \amp 6 \amp 7 \amp 8 \end{array} \right] \qquad
\left[ \begin{array}{r} 1 \\ -1 \\ 0 \end{array} \right] \qquad \left[ \begin{array}{cr} 1 \amp 2 \\ 4 \amp -3 \\ 0 \amp -1 \end{array} \right]
\end{equation*}
</div></article><article class="task exercise-like" id="task-412"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1386">Find the transpose of the new matrix for each part above. What can you conjecture based on your results? There are certain special types of matrices that are given names.</p></article><article class="task exercise-like" id="task-413"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-120">
<p id="p-1387">There are certain special types of matrices that are given names.</p>
<article class="definition definition-like" id="def_special_matrices"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">8.6</span><span class="period">.</span>
</h6>
<p id="p-1388">Let <span class="process-math">\(A\)</span> be a square matrix whose <span class="process-math">\(ij\)</span>th entry is <span class="process-math">\(a_{ij}\text{.}\)</span></p>
<ol class="decimal">
<li id="li-257"><p id="p-1389">The matrix <span class="process-math">\(A\)</span> is a <em class="emphasis">diagonal matrix</em>  if <span class="process-math">\(a_{ij} = 0\)</span> whenever <span class="process-math">\(i \neq j\text{.}\)</span></p></li>
<li id="li-258"><p id="p-1390">The matrix <span class="process-math">\(A\)</span> is a <em class="emphasis">symmetric</em>  matrix if <span class="process-math">\(A^{\tr} = A\text{.}\)</span></p></li>
<li id="li-259"><p id="p-1391">The matrix <span class="process-math">\(A\)</span> is an <em class="emphasis">upper triangular</em>  if <span class="process-math">\(a_{ij} = 0\)</span> whenever <span class="process-math">\(i &gt; j\text{.}\)</span></p></li>
<li id="li-260"><p id="p-1392">The matrix <span class="process-math">\(A\)</span> is a <em class="emphasis">lower triangular</em>  if <span class="process-math">\(a_{ij} = 0\)</span> whenever <span class="process-math">\(i \lt j\text{.}\)</span></p></li>
</ol></article>
</div>
<article class="task exercise-like" id="task-414"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1393">Find an example of a diagonal matrix <span class="process-math">\(A\text{.}\)</span> What can you say about <span class="process-math">\(A^{\tr}\text{?}\)</span></p></article><article class="task exercise-like" id="task-415"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1394">Find an example of a non-diagonal symmetric matrix <span class="process-math">\(B\text{.}\)</span> If <span class="process-math">\(B^{\tr} = B\text{,}\)</span> must <span class="process-math">\(B\)</span> be a square matrix?</p></article><article class="task exercise-like" id="task-416"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-1395">Find an example of an upper triangular matrix <span class="process-math">\(C\text{.}\)</span> What kind of a matrix is <span class="process-math">\(C^{\tr}\text{?}\)</span></p></article></article></article><p id="p-1396">We will see later that diagonal matrices are important in that their powers are easy to calculate. Symmetric matrices arise frequently in applications such as in graph theory as adjacency matrices and in quantum mechanics as observables, and have many useful properties including being diagonalizable and having real eigenvalues, as we will also see later.</p></section><section class="section" id="sec_mtx_transpose_prop"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Properties of the Matrix Transpose</span>
</h3>
<p id="p-1397">As with every other operation, we want to understand what properties the matrix transpose has. Properties of transposes are shown in the following theorem.</p>
<article class="theorem theorem-like" id="thm_transpose_props"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">8.7</span><span class="period">.</span>
</h4>
<p id="p-1398">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be matrices of the appropriate sizes and let <span class="process-math">\(a\)</span> be a scalar. Then</p>
<ol class="decimal">
<li id="li-261"><p id="p-1399"><span class="process-math">\(\displaystyle \left(A^{\tr}\right)^{\tr} = A\)</span></p></li>
<li id="li-262"><p id="p-1400"><span class="process-math">\(\displaystyle (A+B)^{\tr} = A^{\tr} + B^{\tr}\)</span></p></li>
<li id="li-263"><p id="p-1401"><span class="process-math">\(\displaystyle (AB)^{\tr} = B^{\tr}A^{\tr}\)</span></p></li>
<li id="li-264"><p id="p-1402"><span class="process-math">\(\displaystyle (aA)^{\tr} = aA^{\tr}\)</span></p></li>
</ol></article><p id="p-1403">The one property that might seem strange is the third one. To understand this property, suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(m \times n\)</span> matrix and <span class="process-math">\(B\)</span> an <span class="process-math">\(n \times k\)</span> matrix so that the product <span class="process-math">\(AB\)</span> is defined. We will argue that <span class="process-math">\((AB)^{\tr} = B^{\tr}A^{\tr}\)</span> by comparing the <span class="process-math">\(i,j\)</span>th entry of each side.</p>
<ul class="disc">
<li id="li-265"><p id="p-1404">First notice that the <span class="process-math">\(i,j\)</span>th entry of <span class="process-math">\((AB)^{\tr}\)</span> is the <span class="process-math">\(j,i\)</span>th entry of <span class="process-math">\(AB\text{.}\)</span> The <span class="process-math">\(j,i\)</span>th entry of <span class="process-math">\(AB\)</span> is found by taking the scalar product of the <span class="process-math">\(j\)</span>th row of <span class="process-math">\(A\)</span> with the <span class="process-math">\(i\)</span>th column of <span class="process-math">\(B\text{.}\)</span> Thus, the <span class="process-math">\(i,j\)</span>th entry of <span class="process-math">\((AB)^{\tr}\)</span> is the scalar product of the <span class="process-math">\(j\)</span>th row of <span class="process-math">\(A\)</span> with the <span class="process-math">\(i\)</span>th column of <span class="process-math">\(B\text{.}\)</span></p></li>
<li id="li-266"><p id="p-1405">The <span class="process-math">\(i,j\)</span>th entry of <span class="process-math">\(B^{\tr}A^{\tr}\)</span> is the scalar product of the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(B^{\tr}\)</span> with the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A^{\tr}\text{.}\)</span> But the <span class="process-math">\(i\)</span>th row of <span class="process-math">\(B^{\tr}\)</span> is the <span class="process-math">\(i\)</span>th column of <span class="process-math">\(B\)</span> and the <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A^{\tr}\)</span> is the <span class="process-math">\(j\)</span>th row of <span class="process-math">\(A\text{.}\)</span> So the <span class="process-math">\(i,j\)</span>th entry of <span class="process-math">\(B^{\tr}A^{\tr}\)</span> is the scalar product of the <span class="process-math">\(j\)</span>th row of <span class="process-math">\(A\)</span> with the <span class="process-math">\(i\)</span>th column of <span class="process-math">\(B\text{.}\)</span></p></li>
</ul>
<p id="p-1406">Since the two matrices <span class="process-math">\((AB)^{\tr}\)</span> and <span class="process-math">\(B^{\tr}A^{\tr}\)</span> have the same size and same corresponding entries, they are the same matrix.</p></section><section class="section" id="sec_mtx_ops_exam"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-1407">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-15"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">8.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-121">
<p id="p-1408">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{array}{ccc} A = \left[ \begin{array}{ccrc} 1\amp 2\amp 0\amp 1\\3\amp 0\amp -4\amp 5\\7\amp 6\amp -1\amp 0 \end{array}  \right] \amp \amp   B = \left[ \begin{array}{rcr} -2\amp 4\amp -3\\5\amp 1\amp 9\\1\amp 1\amp -2 \end{array}  \right] \\ \amp \amp  \\ C = \left[ \begin{array}{crc} 0\amp -1\amp 6\\3\amp -2\amp 5\\1\amp 0\amp 4 \end{array}  \right] 
\amp \amp  D = \left[ \begin{array}{cr} 10\amp -4\\5\amp 2\\8\amp -1 \end{array}  \right] \\ \amp \amp  \\ E = \left[ \begin{array}{cr} 1\amp 0\\4\amp -3\\5\amp -1 \end{array}  \right] \amp \text{ and }   \amp  F = \left[ \begin{array}{rcr} -2\amp 1\amp 5\\6\amp 3\amp -8\\1\amp 0\amp -1\\ 7\amp 0\amp -5 \end{array}  \right]. \end{array}\text{.}
\end{equation*}
</div>
<p id="p-1409">Determine the results of the following operations, if defined. If not defined, explain why.</p>
</div>
<article class="task exercise-like" id="task-417"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1410"><span class="process-math">\(AF\)</span></p>
<div class="solution solution-like" id="solution-41">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1411">Since <span class="process-math">\(A\)</span> is a <span class="process-math">\(3 \times 4\)</span> matrix and <span class="process-math">\(F\)</span> is a <span class="process-math">\(4 \times 3\)</span> matrix, the number of columns of <span class="process-math">\(A\)</span> equals the number of rows of <span class="process-math">\(F\)</span> and the matrix produce <span class="process-math">\(AF\)</span> is defined. Recall that if <span class="process-math">\(F = [\vf_1 \ \vf_2 \ \vf_3]\text{,}\)</span> where <span class="process-math">\(\vf_1\text{,}\)</span> <span class="process-math">\(\vf_2\text{,}\)</span> <span class="process-math">\(\vf_3\)</span> are the columns of <span class="process-math">\(F\text{,}\)</span> then <span class="process-math">\(AF = [A\vf_1 \ A\vf_2 \ A\vf_3]\text{.}\)</span> Recall also that <span class="process-math">\(A \vf_1\)</span> is the linear combination of the columns of <span class="process-math">\(A\)</span> with weights from <span class="process-math">\(\vf_1\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-85">
\begin{align*}
A\vf_1 \amp = \left[ \begin{array}{ccrc} 1\amp 2\amp 0\amp 1\\
3\amp 0\amp -4\amp 5\\
7\amp 6\amp -1\amp 0 \end{array} \right] \left[ \begin{array}{r} -2\\
6\\
1\\
7 \end{array} \right]\\
\amp = (-2) \left[ \begin{array}{c} 1\\
3\\
7 \end{array} \right]  + (6)  \left[ \begin{array}{c} 2\\
0\\
6 \end{array} \right]  + (1)  \left[ \begin{array}{r} 0\\
-4\\
-1 \end{array} \right] + (7)  \left[ \begin{array}{c} 1\\
5\\
0 \end{array} \right]\\
\amp =  \left[ \begin{array}{c} -2+12+0+7\\
-6+0-4+35\\
-14+36-1+0\end{array} \right]\\
\amp =  \left[ \begin{array}{c} 17\\
25\\
21 \end{array} \right]\text{,}
\end{align*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-86">
\begin{align*}
A\vf_2 \amp = \left[ \begin{array}{ccrc} 1\amp 2\amp 0\amp 1\\
3\amp 0\amp -4\amp 5\\
7\amp 6\amp -1\amp 0 \end{array} \right] \left[ \begin{array}{c} 1\\
3\\
0\\
0 \end{array} \right]\\
\amp = (1) \left[ \begin{array}{c} 1\\
3\\
7 \end{array} \right]  + (3)  \left[ \begin{array}{c} 2\\
0\\
6 \end{array} \right]  + (0)  \left[ \begin{array}{r} 0\\
-4\\
-1 \end{array} \right] + (0)  \left[ \begin{array}{c} 1\\
5\\
0 \end{array} \right]\\
\amp =  \left[ \begin{array}{c} 1+6+0+0\\
3+0+0+0\\
7+18+0+0\end{array} \right]\\
\amp =  \left[ \begin{array}{c} 7\\
3\\
25 \end{array} \right]\text{,}
\end{align*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-87">
\begin{align*}
A\vf_3 \amp = \left[ \begin{array}{ccrc} 1\amp 2\amp 0\amp 1\\
3\amp 0\amp -4\amp 5\\
7\amp 6\amp -1\amp 0 \end{array} \right] \left[ \begin{array}{r} 5\\
-8\\
-1\\
-5 \end{array} \right]\\
\amp = (5) \left[ \begin{array}{c} 1\\
3\\
7 \end{array} \right]  - (8)  \left[ \begin{array}{c} 2\\
0\\
6 \end{array} \right]  - (1)  \left[ \begin{array}{r} 0\\
-4\\
-1 \end{array} \right] - (5)  \left[ \begin{array}{c} 1\\
5\\
0 \end{array} \right]\\
\amp =  \left[ \begin{array}{c} 5-16-0-5\\
15-0+4-25\\
35-48+1-0\end{array} \right]\\
\amp =  \left[ \begin{array}{r} -16\\
-6\\
-12 \end{array} \right]\text{.}
\end{align*}
</div>
<p class="continuation">So <span class="process-math">\(AF = \left[ \begin{array}{ccr} 17\amp 7\amp -16\\25\amp 3\amp -6\\21\amp 25\amp -12 \end{array}  \right]\text{.}\)</span> Alternatively, if <span class="process-math">\(A = \left[ \begin{array}{c} \va_1\\ \va_2 \\ \va_3 \\ \va_4 \end{array} \right]\text{,}\)</span> then the matrix product <span class="process-math">\(AF\)</span> is the matrix whose <span class="process-math">\(ij\)</span> entry is <span class="process-math">\(\va_i \cdot \vf_j\text{.}\)</span> Using this method we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AF = \left[ \begin{array}{ccc} \va_1 \cdot \vf_1\amp \va_1 \cdot \vf_2 \amp  \va_1 \cdot \vf_3 \\ \va_2 \cdot \vf_1\amp \va_2 \cdot \vf_2 \amp  \va_2 \cdot \vf_3 \\ \va_3 \cdot \vf_1\amp \va_3 \cdot \vf_2 \amp  \va_3 \cdot \vf_3 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-88">
\begin{align*}
\va_1 \cdot \vf_1 \amp = (1)(-2)+(2)(6)+(0)(1)+(1)(7) = 17\\
\va_1 \cdot \vf_2 \amp = (1)(1)+(2)(3)+(0)(0)+(1)(0) = 7\\
\va_1 \cdot \vf_3 \amp = (1)(5)+(2)(-8)+(0)(-1)+(1)(-5) = -16\\
\va_2 \cdot \vf_1 \amp = (3)(-2)+(0)(6)+(-4)(1)+(5)(7) = 25\\
\va_2 \cdot \vf_2 \amp = (3)(1)+(0)(3)+(-4)(0)+(5)(0) = 3\\
\va_2 \cdot \vf_3 \amp = (3)(5)+(0)(-8)+(-4)(-1)+(5)(-5) = -6\\
\va_3 \cdot \vf_1 \amp = (7)(-2)+(6)(6)+(-1)(1)+(0)(7) = 21\\
\va_3 \cdot \vf_2 \amp = (7)(1)+(6)(3)+(-1)(0)+(0)(0) = 25\\
\va_3 \cdot \vf_3 \amp =(7)(5)+(6)(-8)+(-1)(-1)+(0)(-5) = -12\text{,}
\end{align*}
</div>
<p class="continuation">so <span class="process-math">\(AF = \left[ \begin{array}{ccr} 17\amp 7\amp -16\\25\amp 3\amp -6\\21\amp 25\amp -12 \end{array}  \right]\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-418"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1412"><span class="process-math">\(A(BC)\)</span></p>
<div class="solution solution-like" id="solution-42">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1413">Since <span class="process-math">\(BC\)</span> is a <span class="process-math">\(3 \times 3\)</span> matrix but <span class="process-math">\(A\)</span> is <span class="process-math">\(3 \times 4\text{,}\)</span> the number of columns of <span class="process-math">\(A\)</span> is not equal to the number of rows of <span class="process-math">\(BC\text{.}\)</span> We conclude that <span class="process-math">\(A(BC)\)</span> is not defined.</p>
</div></article><article class="task exercise-like" id="task-419"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1414"><span class="process-math">\((BC)A\)</span></p>
<div class="solution solution-like" id="solution-43">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1415">Since <span class="process-math">\(BC\)</span> is a <span class="process-math">\(3 \times 3\)</span> matrix and <span class="process-math">\(A\)</span> is <span class="process-math">\(3 \times 4\text{,}\)</span> the number of columns of <span class="process-math">\(BC\)</span> is equal to the number of rows of <span class="process-math">\(A\text{.}\)</span> Thus, the quantity <span class="process-math">\((BC)A\)</span> is defined. First we calculate <span class="process-math">\(BC\)</span> using the dot product of the rows of <span class="process-math">\(B\)</span> with the columns of <span class="process-math">\(C\text{.}\)</span> Letting <span class="process-math">\(B = \left[ \begin{array}{c} \vb_1 \\ \vb_2 \\ \vb_3 \end{array}  \right]\)</span> and <span class="process-math">\(C = [\vc_1 \ \vc_2 \ \vc_3]\text{,}\)</span> where <span class="process-math">\(\vb_1\text{,}\)</span> <span class="process-math">\(\vb_2\text{,}\)</span> and <span class="process-math">\(\vb_3\)</span> are the rows of <span class="process-math">\(B\)</span> and <span class="process-math">\(\vc_1\text{,}\)</span> <span class="process-math">\(\vc_2\text{,}\)</span> and <span class="process-math">\(\vc_3\)</span> are the columns of <span class="process-math">\(C\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
BC = \left[ \begin{array}{ccc} \vb_1 \cdot \vc_1 \amp  \vb_1 \cdot \vc_2 \amp  \vb_1 \cdot \vc_3 \\ \vb_2 \cdot \vc_1 \amp  \vb_2 \cdot \vc_2 \amp  \vb_2 \cdot \vc_3 \\ \vb_3 \cdot \vc_1 \amp  \vb_3 \cdot \vc_2 \amp  \vb_3 \cdot \vc_3 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-89">
\begin{align*}
\vb_1 \cdot \vc_1 \amp = (-2)(0)+(4)(3)+(-3)(1) = 9\\
\vb_1 \cdot \vc_1 \amp = (-2)(-1)+(4)(-2)+(-3)(0) = -6\\
\vb_1 \cdot \vc_1 \amp = (-2)(6)+(4)(5)+(-3)(4) = -4\\
\vb_1 \cdot \vc_1 \amp = (5)(0)+(1)(3)+(9)(1) = 12\\
\vb_1 \cdot \vc_1 \amp = (5)(-1)+(1)(-2)+(9)(0) = -7\\
\vb_1 \cdot \vc_1 \amp = (5)(6)+(1)(5)+(9)(4) = 71\\
\vb_1 \cdot \vc_1 \amp =(1)(0)+(1)(3)+(-2)(1) = 1\\
\vb_1 \cdot \vc_1 \amp = (1)(-1)+(1)(-2)+(-2)(0) = -3\\
\vb_1 \cdot \vc_1 \amp = (1)(6)+(1)(5)+(-2)(4) = 3\text{,}
\end{align*}
</div>
<p class="continuation">so <span class="process-math">\(BC = \left[ \begin{array}{crr} 9\amp -6\amp -4 \\ 12\amp -7\amp 71 \\ 1\amp -3\amp 3 \end{array}  \right]\text{.}\)</span> If <span class="process-math">\(BC = \left[ \begin{array}{c} \vr_1 \\  \vr_2 \\ \vr_3 \end{array}  \right]\)</span> and <span class="process-math">\(A = [\vs_1 \ \vs_2 \ \vs_3 \ \vs_4]\text{,}\)</span> where <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\text{,}\)</span> and <span class="process-math">\(\vr_3\)</span> are the rows of <span class="process-math">\(BC\)</span> and <span class="process-math">\(\vs_1\text{,}\)</span> <span class="process-math">\(\vs_2\text{,}\)</span> <span class="process-math">\(\vs_3\text{,}\)</span> and <span class="process-math">\(\vs_4\)</span> are the columns of <span class="process-math">\(A\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(BC)A = \left[ \begin{array}{cccc} \vr_1 \cdot \vs_1 \amp  \vr_1 \cdot \vs_2 \amp  \vr_1 \cdot \vr_3 \amp  \vr_1 \cdot \vs_4 \\ \vr_2 \cdot \vs_1 \amp  \vr_2 \cdot \vs_2 \amp  \vr_2 \cdot \vs_3 \amp  \vr_2 \cdot \vs_4 \\ \vr_3 \cdot \vs_1 \amp  \vr_3 \cdot \vs_2 \amp  \vr_3 \cdot \vs_3 \amp  \vr_3 \cdot \vs_4 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">Now</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-90">
\begin{align*}
\vr_1 \cdot \vs_1 \amp = (9)(1)+(-6)(3)+(-4)(7) = -37\\
\vr_1 \cdot \vs_2 \amp = (9)(2)+(-6)(0)+(-4)(6) = -6\\
\vr_1 \cdot \vs_3 \amp = (9)(0)+(-6)(-4)+(-4)(-1) = 28\\
\vr_1 \cdot \vs_4 \amp = (9)(1)+(-6)(5)+(-4)(0) = -21\\
\vr_2 \cdot \vs_1 \amp = (12)(1)+(-7)(3)+(71)(7) = 488\\
\vr_2 \cdot \vs_2 \amp = (12)(2)+(-7)(0)+(71)(6) = 450\\
\vr_2 \cdot \vs_3 \amp = (12)(0)+(-7)(-4)+(71)(-1) = -43\\
\vr_2 \cdot \vs_4 \amp = (12)(1)+(-7)(5)+(71)(0) = -23\\
\vr_3 \cdot \vs_1 \amp = (1)(1)+(-3)(3)+(3)(7) = 13\\
\vr_3 \cdot \vs_2 \amp = (1)(2)+(-3)(0)+(3)(6) = 20\\
\vr_3 \cdot \vs_3 \amp = (1)(0)+(-3)(-4)+(3)(-1) = 9\\
\vr_3 \cdot \vs_4 \amp = (1)(1)+(-3)(5)+(3)(0) = -14\text{,}
\end{align*}
</div>
<p class="continuation">so <span class="process-math">\((BC)A =  \left[ \begin{array}{rrrr} -37\amp -6\amp 28\amp -21 \\ 488\amp 450\amp -43\amp -23 \\ 13\amp 20\amp 9\amp -14 \end{array}  \right]\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-420"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1416"><span class="process-math">\((B+C)D\)</span></p>
<div class="solution solution-like" id="solution-44">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1417">Since <span class="process-math">\(B\)</span> and <span class="process-math">\(C\)</span> are both <span class="process-math">\(3 \times 3\)</span> matrices, their sum is defined and is a <span class="process-math">\(3 \times 3\)</span> matrix. Because <span class="process-math">\(D\)</span> is <span class="process-math">\(3 \times 2\)</span> matrix, the number of columns of <span class="process-math">\(B+C\)</span> is equal to the number of rows of <span class="process-math">\(D\text{.}\)</span> Thus, the quantity <span class="process-math">\((B+C)D\)</span> is defined and, using the row-column method of matrix multiplication as earlier,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-91">
\begin{align*}
(B+C)D \amp = \left( \left[ \begin{array}{rcr} -2\amp 4\amp -3\\
5\amp 1\amp 9\\
1\amp 1\amp -2 \end{array} \right] +  \left[ \begin{array}{crc} 0\amp -1\amp 6\\
3\amp -2\amp 5\\
1\amp 0\amp 4 \end{array} \right] \right) \left[ \begin{array}{cr} 10\amp -4\\
5\amp 2\\
8\amp -1 \end{array} \right]\\
\amp =  \left[ \begin{array}{ccc} -2+0\amp 4-1\amp -3+6\\
5+3\amp 1-2\amp 9+5\\
1+1\amp 1+0\amp -2+4 \end{array} \right]  \left[ \begin{array}{cr} 10\amp -4\\
5\amp 2\\
8\amp -1 \end{array} \right]\\
\amp = \left[ \begin{array}{rrc} -2\amp 3\amp 3\\
8\amp -1\amp 14\\
2\amp 1\amp 2 \end{array} \right]  \left[ \begin{array}{cr} 10\amp -4\\
5\amp 2\\
8\amp -1 \end{array} \right]\\
\amp =  \left[ \begin{array}{cr} 19\amp 11\\
187\amp -48\\
41\amp -8 \end{array} \right]\text{.}
\end{align*}
</div>
</div></article><article class="task exercise-like" id="task-421"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-1418"><span class="process-math">\(D^{\tr}E\)</span></p>
<div class="solution solution-like" id="solution-45">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1419">Since <span class="process-math">\(D^{\tr}\)</span> is a <span class="process-math">\(2 \times 3\)</span> matrix and <span class="process-math">\(E\)</span> is <span class="process-math">\(3 \times 2\text{,}\)</span> the number of columns of <span class="process-math">\(D^{\tr}\)</span> is equal to the number of rows of <span class="process-math">\(E\text{.}\)</span> Thus, <span class="process-math">\(D^{\tr}E\)</span> is defined and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-92">
\begin{align*}
D^{\tr}E \amp = \left[ \begin{array}{cr} 10\amp -4\\
5\amp 2\\
8\amp -1 \end{array} \right]^{\tr} \left[ \begin{array}{cr} 1\amp 0\\
4\amp -3\\
5\amp -1 \end{array} \right]\\
\amp = \left[ \begin{array}{rcr} 10\amp 5\amp 8\\
-4\amp 2\amp -1 \end{array} \right] \left[ \begin{array}{cr} 1\amp 0\\
4\amp -3\\
5\amp -1 \end{array} \right]\\
\amp = \left[ \begin{array}{rr} 70\amp -23\\
-1\amp -5 \end{array} \right]\text{.}
\end{align*}
</div>
</div></article><article class="task exercise-like" id="task-422"><h5 class="heading"><span class="codenumber">(f)</span></h5>
<p id="p-1420"><span class="process-math">\(\left(A^{\tr}+F\right)^{\tr}\)</span></p>
<div class="solution solution-like" id="solution-46">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1421">The fact that <span class="process-math">\(A\)</span> is a <span class="process-math">\(3 \times 4\)</span> matrix means that <span class="process-math">\(A^{\tr}\)</span> is a <span class="process-math">\(4 \times 3\)</span> matrix. Since <span class="process-math">\(F\)</span> is also a <span class="process-math">\(4 \times 3\)</span> matrix, the sum <span class="process-math">\(A^{\tr}+F\)</span> is defined. The transpose of any matrix is also defined, so <span class="process-math">\(\left(A^{\tr}+F\right)^{\tr}\)</span> is defined and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-93">
\begin{align*}
\left(A^{\tr}+F\right)^{\tr} \amp = \left( \left[ \begin{array}{ccrc} 1\amp 2\amp 0\amp 1\\
3\amp 0\amp -4\amp 5\\
7\amp 6\amp -1\amp 0 \end{array} \right]^{\tr} +  \left[ \begin{array}{rcr} -2\amp 1\amp 5\\
6\amp 3\amp -8\\
1\amp 0\amp -1\\
7\amp 0\amp -5 \end{array} \right] \right)^{\tr}\\
\amp = \left( \left[ \begin{array}{crr} 1\amp 3\amp 7\\
2\amp 0\amp 6\\
0\amp -4\amp -1\\
1\amp 5\amp 0 \end{array} \right] + \left[ \begin{array}{rcr} -2\amp 1\amp 5\\
6\amp 3\amp -8\\
1\amp 0\amp -1\\
7\amp 0\amp -5 \end{array} \right] \right)^{\tr}\\
\amp = \left( \left[ \begin{array}{ccc} 1-2\amp 3+1\amp 7+5\\
2+6\amp 0+3\amp 6-8\\
0+1\amp -4+0\amp -1-1\\
1+7\amp 5+0\amp 0-5 \end{array} \right] \right)^{\tr}\\
\amp = \left( \left[ \begin{array}{rrr} -1\amp 4\amp 12\\
8\amp 3\amp -2\\
1\amp -4\amp -2\\
8\amp 5\amp -5 \end{array} \right] \right)^{\tr}\\
\amp = \left[ \begin{array}{rrrr} -1\amp 8\amp 1\amp 8\\
4\amp 3\amp -4\amp 5\\
12\amp -2\amp -2\amp -5 \end{array} \right]\text{.}
\end{align*}
</div>
</div></article></article><article class="example example-like" id="example-16"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">8.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-122"><p id="p-1422">Let <span class="process-math">\(A = \left[ \begin{array}{cr} 2\amp -1\\7\amp -2 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{rc} 4\amp 6 \\ -3\amp 5 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-423"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1423">Determine the matrix sum <span class="process-math">\(A+B\text{.}\)</span> Then use this sum to calculate <span class="process-math">\((A+B)^2\text{.}\)</span></p>
<div class="solution solution-like" id="solution-47">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1424">Adding corresponding terms shows that <span class="process-math">\(A+B = \left[ \begin{array}{cc} 6\amp 5\\4\amp 3 \end{array} \right]\text{.}\)</span> Squaring this sum yields the result <span class="process-math">\((A+B)^2 = \left[ \begin{array}{cc} 56\amp 45 \\ 36\amp 29 \end{array} \right]\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-424"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1425">Now calculate <span class="process-math">\((A+B)^2\)</span> in a different way. Use the fact that matrix multiplication distributes over matrix addition to expand (like foiling) <span class="process-math">\((A+B)^2\)</span> into a sum of matrix products. The calculate each summand and add to find <span class="process-math">\((A+B)^2\text{.}\)</span> You should obtain the same result as part (a). If not, what could be wrong?</p>
<div class="solution solution-like" id="solution-48">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-1426">Expanding <span class="process-math">\((A+B)^2\)</span> (remember that matrix multiplication is not commutative) gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-94">
\begin{align*}
(A+B)^2 \amp = (A+B)(A+B)\\
\amp = A^2 + AB + BA + B^2\\
\amp = \left[ \begin{array}{rr} -3\amp 0\\
0\amp -3 \end{array} \right] +  \left[ \begin{array}{cc} 11\amp 7\\
34\amp 32 \end{array} \right] +  \left[ \begin{array}{cr} 50\amp -16\\
29\amp -7 \end{array} \right] +  \left[ \begin{array}{rc} -2\amp 54\\
-27\amp 7 \end{array} \right]\\
\amp =  \left[ \begin{array}{cc} 56\amp 45\\
36\amp 29 \end{array} \right]
\end{align*}
</div>
<p class="continuation">just as in part (a). If instead you obtained the matrix <span class="process-math">\(\left[ \begin{array}{cc} 17\amp 68 \\41\amp 68 \end{array}  \right]\)</span> you likely made the mistake of equating <span class="process-math">\((A+B)^2\)</span> with <span class="process-math">\(A^2+2AB+B^2\text{.}\)</span> These two matrices are not equal in general, because we cannot say that <span class="process-math">\(AB\)</span> is equal to <span class="process-math">\(BA\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_mtx_ops_summ"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<p id="p-1427">In this section we defined a matrix sum, scalar multiples of matrices, the matrix product, and the transpose of a matrix.</p>
<ul class="disc">
<li id="li-267"><p id="p-1428">The sum of two <span class="process-math">\(m \times n\)</span> matrices <span class="process-math">\(A = [a_{ij}]\)</span> and <span class="process-math">\(B = [b_{ij}]\)</span> is the <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A+B\)</span> whose <span class="process-math">\(i,j\)</span>th entry is <span class="process-math">\(a_{ij} + b_{ij}\text{.}\)</span></p></li>
<li id="li-268"><p id="p-1429">If <span class="process-math">\(A = [a_{ij}]\)</span> is an <span class="process-math">\(m \times n\)</span> matrix, the scalar multiple <span class="process-math">\(kA\)</span> of <span class="process-math">\(A\)</span> by the scalar <span class="process-math">\(k\)</span> is the <span class="process-math">\(m \times n\)</span> matrix whose <span class="process-math">\(i,j\)</span>th entry is <span class="process-math">\(ka_{ij}\text{.}\)</span></p></li>
<li id="li-269">
<p id="p-1430">If <span class="process-math">\(A\)</span> is a <span class="process-math">\(k \times m\)</span> matrix and <span class="process-math">\(B = [\vb_1 \ \vb_2 \ \cdots \ \vb_n]\)</span> is an <span class="process-math">\(m \times n\)</span> matrix, then the matrix product <span class="process-math">\(AB\)</span> of the matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> is the <span class="process-math">\(k \times n\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[A\vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{.}
\end{equation*}
</div>
<p class="continuation">The matrix product is defined in this way so that the matrix of a composite <span class="process-math">\(S \circ T\)</span> of linear transformations is the product of matrices of <span class="process-math">\(S\)</span> and <span class="process-math">\(T\text{.}\)</span></p>
</li>
<li id="li-270"><p id="p-1431">An alternate way of calculating the product of an <span class="process-math">\(k \times m\)</span> matrix <span class="process-math">\(A\)</span> with rows <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vr_k\)</span> and an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B\)</span> with columns <span class="process-math">\(\vb_1\text{,}\)</span> <span class="process-math">\(\vb_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vb_n\)</span> is that the product <span class="process-math">\(AB\)</span> is the <span class="process-math">\(k \times n\)</span> matrix whose <span class="process-math">\(i,j\)</span>th entry is <span class="process-math">\(\vr_i \cdot \vb_j\text{.}\)</span></p></li>
<li id="li-271"><p id="p-1432">Matrix multiplication does not behave as the standard multiplication on real numbers. For example, we can have a product of two non-zero matrices equal to the zero matrix and there is no cancellation law for matrix multiplication.</p></li>
<li id="li-272"><p id="p-1433">The transpose of an <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(A = [a_{ij}]\)</span> is the <span class="process-math">\(n \times m\)</span> matrix <span class="process-math">\(A^{\tr}\)</span> whose <span class="process-math">\(i,j\)</span>th entry is <span class="process-math">\(a_{ji}\text{.}\)</span></p></li>
</ul></section><section class="exercises" id="sec_mtx_ops_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-76"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-123"><p id="p-1434">Calculate <span class="process-math">\(AB\)</span> for each of the following matrix pairs by hand in two ways.</p></div>
<article class="task exercise-like" id="task-425"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1435"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 0\\0\amp 1\\0\amp 0 \end{array} \right]\text{,}\)</span> <span class="process-math">\(B = \left[ \begin{array}{cc} a\amp b \\ c\amp d \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-426"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1437"><span class="process-math">\(A = \left[ \begin{array}{ccr} 1\amp 0\amp -1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(B = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 3 \\ 3\amp 4 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-77"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-124"><p id="p-1439">For each of the following <span class="process-math">\(A\)</span> matrices, find all <span class="process-math">\(2\times 2\)</span> matrices <span class="process-math">\(B=\left[ \begin{array}{cc} a\amp b\\c\amp d \end{array} \right]\)</span> which commute with the given <span class="process-math">\(A\text{.}\)</span> (Two matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> commute with each other if <span class="process-math">\(AB = BA\text{.}\)</span>)</p></div>
<article class="task exercise-like" id="task-427"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1440"><span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 0 \\ 0 \amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-428"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1441"><span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 0 \\ 0 \amp 3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-429"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1442"><span class="process-math">\(A = \left[ \begin{array}{cc} 0\amp 1 \\ 0 \amp 0 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-78"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-125"><p id="p-1443">Find all possible, if any, <span class="process-math">\(X\)</span> matrices satisfying each of the following matrix equations.</p></div>
<article class="task exercise-like" id="task-430"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1444"><span class="process-math">\(\left[ \begin{array}{cc} 1\amp 2 \\ 0 \amp 2 \end{array} \right] X = \left[ \begin{array}{cc} 0\amp 1 \\ 0 \amp 0 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-431"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1446"><span class="process-math">\(\left[ \begin{array}{rr} 1\amp -2 \\ -2 \amp 4 \end{array} \right] X = \left[ \begin{array}{cc} 0\amp 1 \\ 0 \amp 0 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-432"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1448"><span class="process-math">\(\left[ \begin{array}{rr} 1\amp -2 \\ -2 \amp 4 \end{array} \right] X = \left[ \begin{array}{cc} 0\amp 1 \\ 0 \amp -2 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-79"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-126"><p id="p-1450">For each of the following <span class="process-math">\(A\)</span> matrices, compute <span class="process-math">\(A^2=AA, A^3=AAA, A^4\text{.}\)</span> Use your results to conjecture a formula for <span class="process-math">\(A^m\text{.}\)</span> Interpret your answer geometrically using the transformation interpretation.</p></div>
<article class="task exercise-like" id="task-433"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1451"><span class="process-math">\(A = \left[ \begin{array}{cc} 2\amp 0 \\ 0 \amp 3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-434"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1452"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 0 \amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-435"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1453"><span class="process-math">\(A = \left[ \begin{array}{cr} 0\amp -1 \\ 1 \amp 0 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-80"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-1454">If <span class="process-math">\(A\vv=2\vv\)</span> for unknown <span class="process-math">\(A\)</span> matrix and <span class="process-math">\(\vv\)</span> vector, determine an expression for <span class="process-math">\(A^2 \vv\text{,}\)</span> <span class="process-math">\(A^3\vv\text{,}\)</span> …, <span class="process-math">\(A^m\vv\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-81"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-1456">If <span class="process-math">\(A\vv=2\vv\)</span> and <span class="process-math">\(A\vu=3\vu\text{,}\)</span> find an expression for <span class="process-math">\(A^m(a\vv+b\vu)\)</span> in terms of <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\vu\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-82"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-1457">A matrix <span class="process-math">\(A\)</span> is a <em class="emphasis">nilpotent</em> matrix if <span class="process-math">\(A^m=0\text{,}\)</span> i.e., <span class="process-math">\(A^m\)</span> is the zero matrix, for some positive integer <span class="process-math">\(m\text{.}\)</span> Explain why the matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{cc} 0 \amp  a \\ 0 \amp  0 \end{array}  \right] \, , \, B = \left[ \begin{array}{ccc} 0 \amp  a \amp  b \\ 0 \amp  0\amp  c\\ 0\amp 0\amp 0 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">are nilpotent matrices.</p></article><article class="exercise exercise-like" id="exercise-83"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<p id="p-1459">Suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> matrix for which <span class="process-math">\(A^2=0\text{.}\)</span> Show that there is a matrix <span class="process-math">\(B\)</span> for which <span class="process-math">\((I_n+A)B=I_n\)</span> where <span class="process-math">\(I_n\)</span> is the identity matrix of size <span class="process-math">\(n\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-84"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-127"><p id="p-1460">Let <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(B\text{,}\)</span> and <span class="process-math">\(C\)</span> be <span class="process-math">\(m \times n\)</span> matrices and let <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> be scalars. Verify <a href="" class="xref" data-knowl="./knowl/thm_matrix_sum_properties.html" title="Theorem 8.1">Theorem 8.1</a>. That is, show that</p></div>
<article class="task exercise-like" id="task-436"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1461"><span class="process-math">\(A+B = B+A\)</span></p></article><article class="task exercise-like" id="task-437"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1463"><span class="process-math">\((A+B) + C = A + (B+C)\)</span></p></article><article class="task exercise-like" id="task-438"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1464">The <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(0\)</span> whose entries are all 0 has the property that <span class="process-math">\(A + 0 = A\text{.}\)</span></p></article><article class="task exercise-like" id="task-439"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1466">The scalar multiple <span class="process-math">\((-1)A\)</span> of the matrix <span class="process-math">\(A\)</span> has the property that <span class="process-math">\((-1)A + A = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-440"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-1467"><span class="process-math">\((a+b) A = aA + bA\)</span></p></article><article class="task exercise-like" id="task-441"><h5 class="heading"><span class="codenumber">(f)</span></h5>
<p id="p-1469"><span class="process-math">\(a(A+B) = aA + aB\)</span></p></article><article class="task exercise-like" id="task-442"><h5 class="heading"><span class="codenumber">(g)</span></h5>
<p id="p-1470"><span class="process-math">\((ab) A = a(bA)\)</span></p></article><article class="task exercise-like" id="task-443"><h5 class="heading"><span class="codenumber">(h)</span></h5>
<p id="p-1472"><span class="process-math">\(1A=A\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-85"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-128"><p id="p-1473">Let <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(B\text{,}\)</span> and <span class="process-math">\(C\)</span> be matrices of the appropriate sizes for all sums and products to be defined and let <span class="process-math">\(a\)</span> be a scalar. Verify the remaining parts of <a href="" class="xref" data-knowl="./knowl/thm_matrix_product_properties.html" title="Theorem 8.3">Theorem 8.3</a>. That is, show that</p></div>
<article class="task exercise-like" id="task-444"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1474"><span class="process-math">\((AB)C = A(BC)\)</span></p></article><article class="task exercise-like" id="task-445"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1475"><span class="process-math">\(A(B+C) = AB + AC\)</span></p></article><article class="task exercise-like" id="task-446"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1476">There is a square matrix <span class="process-math">\(I_n\)</span> with the property that <span class="process-math">\(AI_n = A\)</span> or <span class="process-math">\(I_nA = A\)</span> for whichever product is defined.</p></article><article class="task exercise-like" id="task-447"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-1477"><span class="process-math">\(a(AB) = (aA)B = A(aB)\)</span></p></article></article><article class="exercise exercise-like" id="exercise-86"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-129"><p id="p-1478">Let <span class="process-math">\(A = [a_{ij}]\)</span> and <span class="process-math">\(B = [b_{ij}]\)</span> be matrices of the appropriate sizes, and let <span class="process-math">\(a\)</span> be a scalar. Verify the remaining parts of <a href="" class="xref" data-knowl="./knowl/thm_transpose_props.html" title="Theorem 8.7">Theorem 8.7</a>. That is, show that</p></div>
<article class="task exercise-like" id="task-448"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1479"><span class="process-math">\(\left(A^{\tr}\right)^{\tr} = A\)</span></p></article><article class="task exercise-like" id="task-449"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1481"><span class="process-math">\((A+B)^{\tr} = A^{\tr} + B^{\tr}\)</span></p></article><article class="task exercise-like" id="task-450"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1482"><span class="process-math">\((aA)^{\tr} = aA^{\tr}\)</span></p></article></article><article class="exercise exercise-like" id="ex_2_a_matrix_exponential"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-130">
<p id="p-1484">The <dfn class="terminology">matrix exponential</dfn> is an important tool in solving differential equations. Recall from calculus that the Taylor series expansion for <span class="process-math">\(e^x\)</span> centered at <span class="process-math">\(x=0\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots\text{,}
\end{equation*}
</div>
<p class="continuation">and that this Taylor series converges to <span class="process-math">\(e^x\)</span> for every real number <span class="process-math">\(x\text{.}\)</span> We extend this idea to define the matrix exponential <span class="process-math">\(e^A\)</span> for any square matrix <span class="process-math">\(A\)</span> with real entries as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^A = \sum_{n=0}^{\infty} \frac{1}{n!}A^n = I_n + A + \frac{1}{2!}A^2 + \frac{1}{3!}A^3 + \cdots
\end{equation*}
</div>
<p class="continuation">We explore this idea with an example. Let <span class="process-math">\(B = \left[ \begin{array}{cr} 2\amp 0\\0\amp -1 \end{array}  \right]\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-451"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1485">Calculate <span class="process-math">\(B^2\text{,}\)</span> <span class="process-math">\(B^3\text{,}\)</span> <span class="process-math">\(B^4\text{.}\)</span> Explain why <span class="process-math">\(B^n = \left[ \begin{array}{cc} 2^n\amp 0\\0\amp (-1)^n \end{array} \right]\)</span> for any positive integer <span class="process-math">\(n\text{.}\)</span></p></article><article class="task exercise-like" id="task-452"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1486">Show that  <span class="process-math">\(I_2 + B + B^2 + B^3 + B^4\)</span> is equal to</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} 1+2+\frac{2^2}{2} + \frac{2^3}{3!} + \frac{2^4}{4!}\amp 0\\0\amp 1+(-1)+\frac{(-1)^2}{2} + \frac{(-1)^3}{3!} + \frac{(-1)^4}{4!} \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-453"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-1487">Explain why <span class="process-math">\(e^B = \left[ \begin{array}{cc} e^2\amp 0\\0\amp e^{-1} \end{array} \right]\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-88"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<p id="p-1488">Show that if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(2\times 2\)</span> rotation matrices, then <span class="process-math">\(AB\)</span> is also a <span class="process-math">\(2\times 2\)</span> rotation matrix.</p></article><article class="exercise exercise-like" id="exercise-89"><h4 class="heading"><span class="codenumber">14<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-131"><p id="p-1490">Label each of the following statements as True or False. Provide justification for your response. Throughout, assume that matrices are of the appropriate sizes so that any matrix sums or products are defined.</p></div>
<article class="task exercise-like" id="task-454"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1491">For any three matrices <span class="process-math">\(A, B, C\)</span> with <span class="process-math">\(A \neq 0\text{,}\)</span> <span class="process-math">\(AB=AC\)</span> implies <span class="process-math">\(B=C\text{.}\)</span></p></article><article class="task exercise-like" id="task-455"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1493">For any three matrices <span class="process-math">\(A, B, C\)</span> with <span class="process-math">\(A \neq 0\text{,}\)</span> <span class="process-math">\(AB=CA\)</span> implies <span class="process-math">\(B=C\text{.}\)</span></p></article><article class="task exercise-like" id="task-456"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1494">If <span class="process-math">\(A^2\)</span> is the zero matrix, then <span class="process-math">\(A\)</span> itself is the zero matrix.</p></article><article class="task exercise-like" id="task-457"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1496">If <span class="process-math">\(AB=BA\)</span> for every <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(B\text{,}\)</span> then <span class="process-math">\(A\)</span> is the identity matrix <span class="process-math">\(I_n\text{.}\)</span></p></article><article class="task exercise-like" id="task-458"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1497">If matrix products <span class="process-math">\(AB\)</span> and <span class="process-math">\(BA\)</span> are both defined, then <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are both square matrices of the same size.</p></article><article class="task exercise-like" id="task-459"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1499">If <span class="process-math">\(\vx_1\)</span> is a solution for <span class="process-math">\(A\vx=\vb_1\)</span> (i.e., that <span class="process-math">\(A\vx_1 = \vb_1\)</span>) and <span class="process-math">\(\vx_2\)</span> is a solution for <span class="process-math">\(B\vx=\vb_2\text{,}\)</span> then <span class="process-math">\(\vx_1+\vx_2\)</span> is a solution for <span class="process-math">\((A+B)\vx=\vb_1+\vb_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-460"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1500">If <span class="process-math">\(B\)</span> is an <span class="process-math">\(m\times n\)</span> matrix with two equal columns, then the matrix <span class="process-math">\(AB\)</span> has two equal columns for every <span class="process-math">\(k \times m\)</span> matrix.</p></article><article class="task exercise-like" id="task-461"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-1502">If <span class="process-math">\(A^2 = I_2\text{,}\)</span> then <span class="process-math">\(A=-I_2\)</span> or <span class="process-math">\(A=I_2\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_starassen"><h3 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber"></span> <span class="title">Project: Strassen's Algorithm and Partitioned Matrices</span>
</h3>
<p id="p-1503">Strassen's algorithm is an algorithm for matrix multiplication that can be more efficient than the standard row-column method. To understand this method, we begin with the <span class="process-math">\(2 \times 2\)</span> case which will highlight the essential ideas.</p>
<article class="project project-like" id="x_pact_Strassen_1"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">8.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-132"><p id="p-1504">We first work with the <span class="process-math">\(2 \times 2\)</span> case.</p></div>
<article class="task exercise-like" id="task-462"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-133"><p id="p-1505">Let <span class="process-math">\(A = [a_{ij}] = \left[ \begin{array}{cc} 1\amp 2\\3\amp 4 \end{array}  \right]\)</span> and <span class="process-math">\(B =  [b_{ij}] = \left[ \begin{array}{cc} 5\amp 6\\7\amp 8 \end{array}  \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-463"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1506">Calculate the matrix product <span class="process-math">\(AB\text{.}\)</span></p></article><article class="task exercise-like" id="task-464"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1507">Rather than using eight multiplications to calculate <span class="process-math">\(AB\text{,}\)</span> Strassen came up with the idea of using the following seven products:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-95">
\begin{align*}
h_1 \amp = (a_{11}+a_{22})(b_{11}+b_{22})\\
h_2 \amp = (a_{21}+a_{22})b_{11}\\
h_3 \amp = a_{11}(b_{12}-b_{22})\\
h_4 \amp = a_{22}(b_{21}-b_{11})\\
h_5 \amp = (a_{11}+a_{12})b_{22}\\
h_6 \amp =(a_{21}-a_{11})(b_{11}+b_{12})\\
h_7 \amp = (a_{12}-a_{22})(b_{21}+b_{22})\text{.}
\end{align*}
</div>
<p class="continuation">Calculate <span class="process-math">\(h_1\)</span> through <span class="process-math">\(h_7\)</span> for the given matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{.}\)</span> Then calculate the quantities</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
h_1+h_4-h_5+h_7,  \  h_3+h_5, \  h_2+h_4, \ \text{ and }   h_1+h_3-h_2+h_6\text{.}
\end{equation*}
</div>
<p class="continuation">What do you notice?</p></article></article><article class="task exercise-like" id="task-465"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1508">Now we repeat part (a) in general. Suppose we want to calculate the matrix product <span class="process-math">\(AB\)</span> for arbitrary <span class="process-math">\(2 \times 2\)</span> matrices <span class="process-math">\(A = \left[ \begin{array}{cc} a_{11}\amp a_{12}\\a_{21}\amp a_{22} \end{array}  \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cc} b_{11}\amp b_{12}\\b_{21}\amp b_{22} \end{array}  \right]\text{.}\)</span> Let</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-96">
\begin{align*}
h_1 \amp = (a_{11}+a_{22})(b_{11}+b_{22})\\
h_2 \amp = (a_{21}+a_{22})b_{11}\\
h_3 \amp = a_{11}(b_{12}-b_{22})\\
h_4 \amp = a_{22}(b_{21}-b_{11})\\
h_5 \amp = (a_{11}+a_{12})b_{22}\\
h_6 \amp =(a_{21}-a_{11})(b_{11}+b_{12})\\
h_7 \amp = (a_{12}-a_{22})(b_{21}+b_{22})\text{.}
\end{align*}
</div>
<p class="continuation">Show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = \left[ \begin{array}{cc} h_1+h_4-h_5+h_7 \amp  h_3+h_5 \\ h_2+h_4 \amp  h_1+h_3-h_2+h_6 \end{array}  \right]\text{.}
\end{equation*}
</div></article></article><p id="p-1509"> The next step is to understand how Strassen's algorithm can be applied to larger matrices. This involves the idea of partitioned (or block) matrices. Recall that the matrix-matrix product of the <span class="process-math">\(k \times m\)</span> matrix <span class="process-math">\(A\)</span> and the <span class="process-math">\(m \times n\)</span> matrix <span class="process-math">\(B = [\vb_1 \ \vb_2 \ \cdots \ \vb_n]\)</span> is defined as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = [A\vb_1 \ A\vb_2 \ \cdots \ A\vb_n]\text{.}
\end{equation*}
</div>
<p id="p-1510">In this process, we think of <span class="process-math">\(B\)</span> as being partitioned into <span class="process-math">\(n\)</span> columns. We can expand on this idea to partition both <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> when calculating a matrix-matrix product.</p>
<article class="project project-like" id="project-23"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">8.7</span><span class="period">.</span>
</h4>
<p id="p-1511">We illustrate the idea of partitioned matrices with an example. Let <span class="process-math">\(A = \left[ \begin{array}{crcrc} 1\amp -2\amp 3\amp -6\amp 4 \\ 7\amp 5\amp 2\amp -1\amp 0 \\ 3\amp -8\amp 1\amp 0\amp 9 \end{array}  \right]\text{.}\)</span>We can partition <span class="process-math">\(A\)</span> into smaller matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{crc|rc} 1\amp -2\amp 3\amp -6\amp 4 \\ 7\amp 5\amp 2\amp -1\amp 0  \\ \hline 3\amp -8\amp 1\amp 0\amp 9 \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">which are indicated by the vertical and horizontal lines. As a shorthand, we can describe this partition of <span class="process-math">\(A\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{cc} A_{11}\amp A_{12} \\ A_{21}\amp A_{22} \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(A_{11} = \left[ \begin{array}{crc} 1\amp -2\amp 3\\ 7\amp 5\amp 2 \end{array}  \right]\text{,}\)</span> <span class="process-math">\(A_{12} = \left[ \begin{array}{rc} -6\amp 4 \\ -1\amp 0 \end{array}  \right]\text{,}\)</span> <span class="process-math">\(A_{21} = \left[ \begin{array}{crc} 3\amp -8\amp 1 \end{array}  \right]\text{,}\)</span> and <span class="process-math">\(A_{22} =  [0 \ 9 ]\text{.}\)</span> The submatrices <span class="process-math">\(A_{ij}\)</span> are called <em class="emphasis">blocks</em>. If <span class="process-math">\(B\)</span> is a matrix such that <span class="process-math">\(AB\)</span> is defined, then <span class="process-math">\(B\)</span> must have five rows. As an example, <span class="process-math">\(AB\)</span> is defined if <span class="process-math">\(B = \left[ \begin{array}{cc} 1\amp 3\\2\amp 0 \\ 4\amp 1\\6\amp 5\\4\amp 2 \end{array}  \right]\text{.}\)</span> The partition of <span class="process-math">\(A\)</span> breaks <span class="process-math">\(A\)</span> up into blocks with three and two columns, respectively. So if we partition <span class="process-math">\(B\)</span> into blocks with three and two rows, then we can use the blocks to calculate the matrix product <span class="process-math">\(AB\text{.}\)</span> For example, partition <span class="process-math">\(B\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B = \left[ \begin{array}{cc} 1\amp 3\\2\amp 0 \\ 4\amp 1\\ \hline 6\amp 5\\4\amp 2 \end{array}  \right] = \left[ \begin{array}{c} B_{11}\\B_{21} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1512">Show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = \left[ \begin{array}{cc} A_{11}\amp A_{12} \\ A_{21}\amp A_{22} \end{array}  \right] \left[ \begin{array}{c} B_{11}\\B_{21} \end{array}  \right] = \left[ \begin{array}{cc} A_{11}B_{11}+A_{12}B_{21} \\ A_{21}B_{11}+A_{22}B_{21} \end{array}  \right]\text{.}
\end{equation*}
</div></article><p id="p-1513">An advantage to using partitioned matrices is that computations with them can be done in parallel, which lessens the time it takes to do the work. In general, we can multiply partitioned matrices as though the submatrices are scalars. That is,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccc} A_{11}\amp A_{12}\amp \cdots\amp A_{1m} \\ A_{21}\amp A_{22}\amp \cdots\amp A_{2m}\\ \vdots \amp  \vdots \amp \ddots \amp  \vdots \\ A_{i1}\amp A_{i2}\amp \cdots\amp A_{im}  \\ \vdots \amp  \vdots \amp \ddots \amp  \vdots \\ A_{k1}\amp A_{k2}\amp \cdots\amp A_{km} \end{array}  \right] \left[ \begin{array}{cccccc} B_{11}\amp B_{12}\amp \cdots\amp B_{1j} \amp  \cdots \amp B_{1n} \\ B_{21}\amp B_{22}\amp \cdots\amp B_{2j}\amp \cdots \amp B_{2n}\\ \vdots \amp  \vdots \amp \ddots \amp  \vdots\amp \ddots\amp \vdots \\ B_{m1}\amp B_{m2}\amp \cdots\amp B_{mj} \amp \cdots \amp B_{mn} \end{array}  \right] = [P_{ij}]\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_{ij} = A_{i1}B_{1j} + A_{i2}B_{2j} + \cdots + A_{im}B_{mj} = \sum_{t=1}^{m} A_{it}B_{tj}\text{,}
\end{equation*}
</div>
<p class="continuation">provided that all the submatrix products are defined.</p>
<p id="p-1514">Now we can apply Strassen's algorithm to larger matrices using partitions. This method is sometimes referred to as divide and conquer.</p>
<article class="project project-like" id="project-24"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">8.8</span><span class="period">.</span>
</h4>
<p id="p-1515">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be two <span class="process-math">\(r \times r\)</span> matrices. If <span class="process-math">\(r\)</span> is not a power of <span class="process-math">\(2\text{,}\)</span> then pad the rows and columns of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> with zeros to make them of size <span class="process-math">\(2^m \times 2^m\)</span> for some integer <span class="process-math">\(m\text{.}\)</span> (From a practical perspective, we might instead just use unequal block sizes.) Let <span class="process-math">\(n = 2^m\text{.}\)</span> Partition <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/x_pact_Strassen_1.html">
\begin{equation*}
A = \left[ \begin{array}{cc} A_{11}\amp A_{12}\\A_{21}\amp A_{22} \end{array}  \right] \ \text{ and }  \  B = \left[ \begin{array}{cc} B_{11}\amp B_{12}\\B_{21}\amp B_{22} \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where each submatrix is of size <span class="process-math">\(\frac{n}{2} \times \frac{n}{2}\text{.}\)</span> Now we use the Strassen algorithm just as in the <span class="process-math">\(2 \times 2\)</span> case, treating the submatrices as if they were scalars (with the additional constraints of making sure that the dimensions match up so that products are defined, and ensuring we multiply in the correct order). Letting</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/x_pact_Strassen_1.html" id="md-97">
\begin{align*}
M_1 \amp = (A_{11}+A_{22})(B_{11}+B_{22})\\
M_2 \amp = (A_{21}+A_{22})B_{11}\\
M_3 \amp = A_{11}(B_{12}-B_{22})\\
M_4 \amp = A_{22}(B_{21}-B_{11})\\
M_5 \amp = (A_{11}+A_{12})B_{22}\\
M_6 \amp =(A_{21}-A_{11})(B_{11}+B_{12})\\
M_7 \amp = (A_{12}-A_{22})(B_{21}+B_{22})\text{,}
\end{align*}
</div>
<p class="continuation">then the same algebra as in <a href="" class="xref" data-knowl="./knowl/x_pact_Strassen_1.html" title="Project Activity 8.6">Project Activity 8.6</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/x_pact_Strassen_1.html">
\begin{equation*}
AB = \left[ \begin{array}{cc} M_1+M_4-M_5+M_7 \amp  M_3+M_5 \\ M_2+M_4 \amp  M_1+M_3-M_2+M_6 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-1516">Apply Strassen's algorithm to calculate the matrix product <span class="process-math">\(AB\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \left[ \begin{array}{crr} 1\amp 3\amp -1\\2\amp 4\amp 6\\7\amp -2\amp 5 \end{array}  \right] \text{ and }  B = \left[ \begin{array}{crc} 2\amp 5\amp 3\\2\amp -4\amp 1\\1\amp 6\amp 4 \end{array}  \right]\text{.}
\end{equation*}
</div></article><p id="p-1517">While Strassen's algorithm can be more efficient, it does not always speed up the process. We investigate this in the next activity.</p>
<article class="project project-like" id="project-25"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">8.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-134"><p id="p-1518">We introduce a little notation to help us describe the efficiency of our calculations. We won't be formal with this notation, rather work with it in an informal way. Big O (the letter “O” ) notation is used to describe the complexity of an algorithm. Generally speaking, in computer science big O notation can be used to describe the run time of an algorithm, the space used by the algorithm, or the number of computations required. The letter “O” is used because the behavior described is also called the order. Big O measures the asymptotic time of an algorithm, not its exact time. For example, if it takes <span class="process-math">\(6n^2-n+8\)</span> steps to complete an algorithm, then we say that the algorithm grows at the order of <span class="process-math">\(n^2\)</span> (we ignore the constants and the smaller power terms, since they become insignificant as <span class="process-math">\(n\)</span> increases) and we describe its growth as <span class="process-math">\(O{\left(n^2\right)}\text{.}\)</span> To measure the efficiency of an algorithm to determine a matrix product, we will measure the number of operations it takes to calculate the product.</p></div>
<article class="task exercise-like" id="task-466"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-1519">Suppose <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(n \times n\)</span> matrices. Explain why the operation of addition (that is, calculating <span class="process-math">\(A+B\)</span>) is <span class="process-math">\(O{\left(n^2\right)}\text{.}\)</span></p></article><article class="task exercise-like" id="task-467"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-1520">Suppose <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(n \times n\)</span> matrices. How many multiplications are required to calculate the matrix product <span class="process-math">\(AB\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-468"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<div class="introduction" id="introduction-135"><p id="p-1521">The standard algorithm for calculating a matrix product of two <span class="process-math">\(n \times n\)</span> matrices requires <span class="process-math">\(n^3\)</span> multiplications and a number of additions. Since additions are much less costly in terms of operations, the standard matrix product is <span class="process-math">\(O{\left(n^3\right)}\text{.}\)</span> We won't show it here, but using Strassen's algorithm on a product of <span class="process-math">\(2^m \times 2^m\)</span> matrices is <span class="process-math">\(O{\left(n^{\log_2(7)}\right)}\text{,}\)</span> where <span class="process-math">\(n = 2^m\text{.}\)</span> That means that Strassen's algorithm applied to an <span class="process-math">\(n \times n\)</span> matrix (where <span class="process-math">\(n\)</span> is a power of <span class="process-math">\(2\)</span>) requires approximately <span class="process-math">\(n^{\log_2(7)}\)</span> multiplications. We use this to analyze situations to determine when Strassen's algorithm is computationally more efficient than the standard algorithm.</p></div>
<article class="task exercise-like" id="task-469"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-1522">Suppose <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(5 \times 5\)</span> matrices. Determine the number of multiplications required to calculate the matrix product <span class="process-math">\(AB\)</span> using the standard matrix product. Then determine the approximate number of multiplications required to calculate the matrix product <span class="process-math">\(AB\)</span> using Strassen's algorithm. Which is more efficient? (Remember, we can only apply Strassen's algorithm to square matrices whose sizes are powers of <span class="process-math">\(2\text{.}\)</span>)</p></article><article class="task exercise-like" id="task-470"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-1523">Repeat part i. with <span class="process-math">\(125 \times 125\)</span> matrices. Which method is more efficient?</p></article></article></article><p id="p-1524">As a final note, Strassen's algorithm is approximately <span class="process-math">\(O{\left(n^{2.81}\right)}\text{.}\)</span> As of 2018, the best algorithm for matrix multiplication, developed by Virginia Williams at Stanford University, is approximately <span class="process-math">\(O{\left(n^{2.373}\right)}\text{.}\)</span><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-12" id="fn-12"><sup> 12 </sup></a></p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-10"><div class="fn">Strassen, Volker, Gaussian Elimination is not Optimal, Number. Math. 13, p. 354-356, 1969</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-11"><div class="fn">Recall from <a href="" class="xref" data-knowl="./knowl/ex_1_e_scalar_product.html" title="Exercise 5">Exercise 5</a> of <a href="chap_matrix_vector.html" class="internal" title="Chapter 5: The Matrix-Vector Form of a Linear System">Chapter 5</a> that the scalar product <span class="process-math">\(\vu \cdot \vv\)</span> of a <span class="process-math">\(1 \times n\)</span> matrix <span class="process-math">\(\vu = [u_1 \ u_2 \ \ldots \ u_n]\)</span> and an <span class="process-math">\(n \times 1\)</span> vector <span class="process-math">\(\vv=\left[ \begin{array}{c} v_1\\ v_2\\ \vdots \\ v_n \end{array}  \right]\)</span> is <span class="process-math">\(\vu \cdot \vv = u_1v_1 + u_2v_2 + u_3v_3 + \cdots + u_nv_n\text{.}\)</span>
</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-12"><div class="fn">V. V. Williams, Multiplying matrices in <span class="process-math">\(O{\left(n^{2.373}\right)}\)</span> time, Stanford University, (2014).</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
