<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-23T14:59:29-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Diagonalization</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="chap_characteristic_equation.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_approx_eigenvalues.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="chap_characteristic_equation.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_approx_eigenvalues.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link active">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_diagonalization"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">19</span> <span class="title">Diagonalization</span>
</h2>
<section class="introduction" id="introduction-295"><article class="objectives goal-like" id="objectives-19"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-296"><p id="p-3179">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-569"><p id="p-3180">What is a diagonal matrix?</p></li>
<li id="li-570"><p id="p-3181">What does it mean to diagonalize a matrix?</p></li>
<li id="li-571"><p id="p-3182">What does it mean for two matrices to be similar?</p></li>
<li id="li-572"><p id="p-3183">What important properties do similar matrices share?</p></li>
<li id="li-573"><p id="p-3184">Under what conditions is a matrix diagonalizable?</p></li>
<li id="li-574"><p id="p-3185">When a matrix <span class="process-math">\(A\)</span> is diagonalizable, what is the structure of a matrix <span class="process-math">\(P\)</span> that diagonalizes <span class="process-math">\(A\text{?}\)</span></p></li>
<li id="li-575"><p id="p-3186">Why is diagonalization useful?</p></li>
</ul></article></section><section class="section" id="sec_appl_fib_num"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: The Fibonacci Numbers</span>
</h3>
<p id="p-3187">In 1202 Leonardo of Pisa (better known as Fibonacci) published <span class="booktitle">Liber Abaci</span> (roughly translated as <span class="booktitle">The Book of Calculation</span>), in which he constructed a mathematical model of the growth of a rabbit population. The problem Fibonacci considered is that of determining the number of pairs of rabbits produced in a given time period beginning with an initial pair of rabbits. Fibonacci made the assumptions that each pair of rabbits more than one month old produces a new pair of rabbits each month, and that no rabbits die. (We ignore any issues about that might arise concerning the gender of the offspring.) If we let <span class="process-math">\(F_n\)</span> represent the number of rabbits in month <span class="process-math">\(n\text{,}\)</span> Fibonacci produced the model</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Fibonacci">
\begin{equation}
F_{n+2} = F_{n+1} + F_{n}\text{,}\tag{19.1}
\end{equation}
</div>
<p class="continuation">for <span class="process-math">\(n \geq 0\)</span> where <span class="process-math">\(F_0 = 0\)</span> and <span class="process-math">\(F_1 = 1\text{.}\)</span> The resulting sequence</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
1,1,2,3,5,8,13,21, \ldots
\end{equation*}
</div>
<p class="continuation">is a very famous sequence in mathematics and is called the Fibonacci sequence. This sequence is thought to model many natural phenomena such as number of seeds in a sunflower and anything which grows in a spiral form. It is so famous in fact that it has a journal devoted entirely to it. As a note, while Fibonacci's work <span class="booktitle">Liber Abaci</span> introduced this sequence to the western world, it had been described earlier Sanskrit texts going back as early as the sixth century.</p>
<p id="p-3188">By definition, the Fibonacci numbers are calculated by recursion. This is a very ineffective way to determine entries <span class="process-math">\(F_n\)</span> for large <span class="process-math">\(n\text{.}\)</span> Later in this section we will derive a fascinating and unexpected formula for the Fibonacci numbers using the idea of diagonalization.</p></section><section class="section" id="sec_diag_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-3189">As we have seen when studying Markov processes, each state is dependent on the previous state. If <span class="process-math">\(\vx_0\)</span> is the initial state and <span class="process-math">\(A\)</span> is the transition matrix, then the <span class="process-math">\(n\)</span>th state is found by <span class="process-math">\(A^n \vx_0\text{.}\)</span> In these situations, and others, it is valuable to be able to quickly and easily calculate powers of a matrix. We explore a way to do that in this section.</p>
<article class="exploration project-like" id="pa_4_c"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">19.1</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-297">
<p id="p-3190">Consider a very simplified weather forecast. Let us assume there are two possible states for the weather: rainy (<span class="process-math">\(R\)</span>) or sunny(<span class="process-math">\(S\)</span>). Let us also assume that the weather patterns are stable enough that we can reasonably predict the weather tomorrow based on the weather today. If is is sunny today, then there is a 70% chance that it will be sunny tomorrow, and if it is rainy today then there is a 40% chance that it will be rainy tomorrow. If <span class="process-math">\(\vx_0 = \left[ \begin{array}{c} s \\ r \end{array}  \right]\)</span> is a state vector that indicates a probability <span class="process-math">\(s\)</span> that it is sunny and probability <span class="process-math">\(r\)</span> that it is rainy on day <span class="process-math">\(0\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vx_1 = \left[ \begin{array}{cc} 0.70\amp 0.40 \\ 0.30\amp 0.60 \end{array}  \right] \vx_0
\end{equation*}
</div>
<p class="continuation">tells us the likelihood of it being sunny or rainy on day 1. Let <span class="process-math">\(A = \left[ \begin{array}{cc} 0.70\amp 0.40 \\ 0.30\amp 0.60 \end{array}  \right]\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-1046"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3191">Suppose it is sunny today, that is <span class="process-math">\(\vx_0 = \left[ \begin{array}{c} 1 \\ 0 \end{array} \right]\text{.}\)</span> Calculate <span class="process-math">\(\vx_1 = A \vx_0\)</span> and explain how this matrix-vector product tells us the probability that it will be sunny tomorrow.</p></article><article class="task exercise-like" id="task-1047"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3192">Calculate <span class="process-math">\(\vx_2 = A\vx_1\)</span> and interpret the meaning of each component of the product.</p></article><article class="task exercise-like" id="task-1048"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3193">Explain why <span class="process-math">\(\vx_2 = A^2 \vx_0\text{.}\)</span> Then explain in general why <span class="process-math">\(\vx_n = A^n \vx_0\text{.}\)</span></p></article><article class="task exercise-like" id="task-1049"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3194">The previous result demonstrates that to determine the long-term probability of a sunny or rainy day, we want to be able to easily calculate powers of the matrix <span class="process-math">\(A\text{.}\)</span> Use a computer algebra system (e.g., Maple, Mathematica, Wolfram<span class="process-math">\(|\)</span>Alpha) to calculate the entries of <span class="process-math">\(\vx_{10}\text{,}\)</span> <span class="process-math">\(\vx_{20}\text{,}\)</span> and <span class="process-math">\(\vx_{30}\text{.}\)</span> Based on this data, what do you expect the long term probability of any day being a sunny one?</p></article></article></section><section class="section" id="sec_diag"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Diagonalization</span>
</h3>
<p id="p-3195">In <a href="" class="xref" data-knowl="./knowl/pa_4_c.html" title="Preview Activity 19.1">Preview Activity 19.1</a> we saw how if we can powers of a matrix we can make predictions about the long-term behavior of some systems. In general, calculating powers of a matrix can be a very difficult thing, but there are times when the process is straightforward.</p>
<article class="activity project-like" id="act_4_c_0"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">19.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-298"><p id="p-3196">Let <span class="process-math">\(D = \left[ \begin{array}{cc} 2\amp 0 \\ 0\amp 3 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1050"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3197">Show that <span class="process-math">\(D^2 = \left[ \begin{array}{cc} 2^2\amp 0 \\ 0\amp 3^2 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-1051"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3198">Show that <span class="process-math">\(D^3 = \left[ \begin{array}{cc} 2^3\amp 0 \\ 0\amp 3^3 \end{array} \right]\text{.}\)</span> <a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-22" id="hint-22"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-22"><div class="hint solution-like"><p id="p-3199"><span class="process-math">\(D^3 = DD^2\text{.}\)</span></p></div></div></p></article><article class="task exercise-like" id="task-1052"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3200">Explain in general why <span class="process-math">\(D^n = \left[ \begin{array}{cc} 2^n\amp 0 \\ 0\amp 3^n \end{array} \right]\)</span> for any positive integer <span class="process-math">\(n\text{.}\)</span></p></article></article><p id="p-3201"><a href="" class="xref" data-knowl="./knowl/act_4_c_0.html" title="Activity 19.2">Activity 19.2</a> illustrates that calculating powers of square matrices whose only nonzero entries are along the diagonal is rather simple. In general, if</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4_c_0.html ./knowl/def_special_matrices.html">
\begin{equation*}
D = \left[ \begin{array}{cccccc} d_{11}   \amp 0       \amp 0        \amp \cdots      \amp 0    \amp 0 \\ 0       \amp  d_{22}   \amp 0        \amp \cdots      \amp 0    \amp 0 \\ \vdots  \amp  0          \amp 0        \amp \ddots      \amp       \amp \vdots \\ 0       \amp  0       \amp 0          \amp  \cdots    \amp 0    \amp d_{nn} \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_4_c_0.html ./knowl/def_special_matrices.html">
\begin{equation*}
D^k = \left[ \begin{array}{cccccc} d_{11}^k   \amp 0       \amp 0        \amp \cdots      \amp 0    \amp 0 \\ 0       \amp  d_{22}^k   \amp 0        \amp \cdots      \amp 0    \amp 0 \\ \vdots  \amp  0            \amp 0        \amp \ddots      \amp       \amp \vdots \\ 0       \amp  0         \amp 0          \amp  \cdots    \amp 0    \amp d_{nn}^k \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">for any positive integer <span class="process-math">\(k\text{.}\)</span> Recall that a diagonal matrix is a matrix whose only nonzero elements are along the diagonal (see <a href="" class="xref" data-knowl="./knowl/def_special_matrices.html" title="Definition 8.6">Definition 8.6</a>). In this section we will see that matrices that are similar to diagonal matrices have some very nice properties, and that diagonal matrices are useful in calculations of powers of matrices.</p>
<p id="p-3202">We can utilize the method of calculating powers of diagonal matrices to also easily calculate powers of other types of matrices.</p>
<article class="activity project-like" id="act_4_c_0_5"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">19.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-299"><p id="p-3203">Let <span class="process-math">\(D\)</span> be any matrix, <span class="process-math">\(P\)</span> an invertible matrix, and let <span class="process-math">\(A = P^{-1}DP\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1053"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3204">Show that <span class="process-math">\(A^2 = P^{-1}D^2P\text{.}\)</span></p></article><article class="task exercise-like" id="task-1054"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3205">Show that <span class="process-math">\(A^3 = P^{-1}D^3P\text{.}\)</span></p></article><article class="task exercise-like" id="task-1055"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3206">Explain in general why <span class="process-math">\(A^n = P^{-1}D^nP\)</span> for positive integers <span class="process-math">\(n\text{.}\)</span></p></article></article><p id="p-3207">As <a href="" class="xref" data-knowl="./knowl/act_4_c_0_5.html" title="Activity 19.3">Activity 19.3</a> illustrates, to calculate the powers of a matrix of the form <span class="process-math">\(P^{-1}DP\)</span> we only need determine the powers of the matrix <span class="process-math">\(D\text{.}\)</span> If <span class="process-math">\(D\)</span> is a diagonal matrix, this is especially straightforward.</p></section><section class="section" id="sec_mtx_similar"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Similar Matrices</span>
</h3>
<p id="p-3208">Similar matrices play an important role in certain calculations. For example, <a href="" class="xref" data-knowl="./knowl/act_4_c_0_5.html" title="Activity 19.3">Activity 19.3</a> showed that if we can write a square matrix <span class="process-math">\(A\)</span> in the form <span class="process-math">\(A = P^{-1}DP\)</span> for some invertible matrix <span class="process-math">\(P\)</span> and diagonal matrix <span class="process-math">\(D\text{,}\)</span> then finding the powers of <span class="process-math">\(A\)</span> is straightforward. As we will see, the relation <span class="process-math">\(A = P^{-1}DP\)</span> will imply that the matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(D\)</span> share many properties.</p>
<article class="definition definition-like" id="definition-42"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">19.1</span><span class="period">.</span>
</h4>
<p id="p-3209">The <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">similar</dfn> to the <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(B\)</span> if there is an invertible matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(A = P^{-1}BP\text{.}\)</span></p></article><article class="activity project-like" id="act_4_c_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">19.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-300"><p id="p-3210">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1\\2\amp 0 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cr} 2\amp 2\\0\amp -1 \end{array} \right]\text{.}\)</span> Assume that <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(B\)</span> via the matrix <span class="process-math">\(P = \left[ \begin{array}{cc} 2\amp 1\\2\amp 2 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1056"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3211">Calculate <span class="process-math">\(\det(A)\)</span> and <span class="process-math">\(\det(B)\text{.}\)</span> What do you notice?</p></article><article class="task exercise-like" id="task-1057"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3212">Find the characteristic polynomials of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{.}\)</span> What do you notice?</p></article><article class="task exercise-like" id="task-1058"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3213">What can you say about the eigenvalues of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{?}\)</span> Explain.</p></article><article class="task exercise-like" id="task-1059"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3214">Explain why <span class="process-math">\(\vx = \left[ \begin{array}{c} 1\\1 \end{array} \right]\)</span> is an eigenvector for <span class="process-math">\(A\)</span> with eigenvalue 2. Is <span class="process-math">\(\vx\)</span> an eigenvector for <span class="process-math">\(B\)</span> with eigenvalue 2? Why or why not?</p></article></article><p id="p-3215"><a href="" class="xref" data-knowl="./knowl/act_4_c_1.html" title="Activity 19.4">Activity 19.4</a> suggests that similar matrices share some, but not all, properties. Note that if <span class="process-math">\(A = P^{-1}BP\text{,}\)</span> then <span class="process-math">\(B = Q^{-1}AQ\)</span> with <span class="process-math">\(Q = P^{-1}\text{.}\)</span> So if <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(B\text{,}\)</span> then <span class="process-math">\(B\)</span> is similar to <span class="process-math">\(A\text{.}\)</span> Similarly (no pun intended), since <span class="process-math">\(A = I^{-1}AI\)</span> (where <span class="process-math">\(I\)</span> is the identity matrix), then any square matrix is similar to itself. Also, if <span class="process-math">\(A = P^{-1}BP\)</span> and <span class="process-math">\(B = M^{-1}CM\text{,}\)</span> then <span class="process-math">\(A = (MP)^{-1}C(MP)\text{.}\)</span> So if <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(B\)</span> and <span class="process-math">\(B\)</span> is similar to <span class="process-math">\(C\text{,}\)</span> then <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(C\text{.}\)</span> If you have studied relations, these three properties show that similarity is an equivalence relation on the set of all <span class="process-math">\(n \times n\)</span> matrices. This is one reason why similar matrices share many important traits, as the next activity highlights.</p>
<article class="activity project-like" id="act_4_c_2"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">19.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-301"><p id="p-3216">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be similar matrices with <span class="process-math">\(A = P^{-1}BP\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1060"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3217">Use the multiplicative property of the determinant to explain why <span class="process-math">\(\det(A) = \det(B)\text{.}\)</span> So similar matrices have the same determinants.</p></article><article class="task exercise-like" id="task-1061"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3218">Use the fact that <span class="process-math">\(P^{-1}IP = I\)</span> to show that <span class="process-math">\(A-\lambda I\)</span> is similar to <span class="process-math">\(B - \lambda I\text{.}\)</span></p></article><article class="task exercise-like" id="task-1062"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3219">Explain why it follows from (a) and (b) that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A - \lambda I) = \det(B - \lambda I)\text{.}
\end{equation*}
</div>
<p class="continuation">So similar matrices have the same characteristic polynomial, and the same eigenvalues.</p></article></article><p id="p-3220">We summarize some properties of similar matrices in the following theorem.</p>
<article class="theorem theorem-like" id="theorem-42"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">19.2</span><span class="period">.</span>
</h4>
<p id="p-3221">Let <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> be similar <span class="process-math">\(n \times n\)</span> matrices and <span class="process-math">\(I\)</span> the <span class="process-math">\(n \times n\)</span> identity matrix. Then</p>
<ol class="decimal">
<li id="li-576"><p id="p-3222"><span class="process-math">\(\det(A) = \det(B)\text{,}\)</span></p></li>
<li id="li-577"><p id="p-3223"><span class="process-math">\(A-\lambda I\)</span> is similar to <span class="process-math">\(B - \lambda I\text{,}\)</span></p></li>
<li id="li-578"><p id="p-3224"><span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> have the same characteristic polynomial,</p></li>
<li id="li-579"><p id="p-3225"><span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> have the same eigenvalues.</p></li>
</ol></article></section><section class="section" id="sec_sim_mtx_trans"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Similarity and Matrix Transformations</span>
</h3>
<p id="p-3226">When a matrix is similar to a diagonal matrix, we can gain insight into the action of the corresponding matrix transformation. As an example, consider the matrix transformation <span class="process-math">\(T\)</span> from <span class="process-math">\(\R^2\)</span> to <span class="process-math">\(\R^2\)</span> defined by <span class="process-math">\(T(\vx) = A \vx\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_c_1">
\begin{equation}
A = \left[ \begin{array}{cc} 3\amp 1\\1\amp 3 \end{array}  \right]\text{.}\tag{19.2}
\end{equation}
</div>
<p id="p-3227">We are interested in understanding what this matrix transformation does to vectors in <span class="process-math">\(\R^2\text{.}\)</span> First we note that <span class="process-math">\(A\)</span> has eigenvalues <span class="process-math">\(\lambda_1 = 2\)</span> and <span class="process-math">\(\lambda_2 = 4\)</span> with corresponding eigenvectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -1\\1 \end{array}  \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 1\\1 \end{array}  \right]\text{.}\)</span> If we let <span class="process-math">\(P = [\vv_1 \ \vv_2]\text{,}\)</span> then you can check that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = D
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = PDP^{-1}\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = \left[ \begin{array}{cc} 2 \amp  0 \\ 0 \amp  4 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3228">Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(\vx) = PDP^{-1}\vx\text{.}
\end{equation*}
</div>
<p id="p-3229">A simple calculation shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1} = \frac{1}{2}\left[ \begin{array}{rc} -1\amp 1 \\ 1\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3230">Let us apply <span class="process-math">\(T\)</span> to the unit square whose sides are formed by the vectors <span class="process-math">\(\ve_1 = \left[ \begin{array}{c} 1 \\ 0 \end{array} \right]\)</span> and <span class="process-math">\(\ve_2 = \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]\)</span> as shown in the first picture in <a href="" class="xref" data-knowl="./knowl/F_4_c_1.html" title="Figure 19.3">Figure 19.3</a>.</p>
<p id="p-3231">To apply <span class="process-math">\(T\)</span> we first multiply <span class="process-math">\(\ve_1\)</span> and <span class="process-math">\(\ve_2\)</span> by <span class="process-math">\(P^{-1}\text{.}\)</span> This gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}\ve_1 = \frac{1}{2}\left[ \begin{array}{r} -1\\1 \end{array}  \right] \text{ and }  \ P^{-1}\ve_2 = \frac{1}{2}\left[ \begin{array}{c} 1\\1 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3232">So <span class="process-math">\(P^{-1}\)</span> transforms the standard coordinate system into a coordinate system in which columns of <span class="process-math">\(P^{-1}\)</span> determine the axes, as illustrated in the second picture in <a href="" class="xref" data-knowl="./knowl/F_4_c_1.html" title="Figure 19.3">Figure 19.3</a>. Applying <span class="process-math">\(D\)</span> to the output scales by 2 in the first component and by <span class="process-math">\(4\)</span> in the second component as depicted in the third picture in <a href="" class="xref" data-knowl="./knowl/F_4_c_1.html" title="Figure 19.3">Figure 19.3</a>. Finally, we apply <span class="process-math">\(P\)</span> to translate back into the standard <span class="process-math">\(xy\)</span> coordinate system as shown in the last picture in <a href="" class="xref" data-knowl="./knowl/F_4_c_1.html" title="Figure 19.3">Figure 19.3</a>. In this case, we can visualize that when we apply the transformation <span class="process-math">\(T\)</span> to a vector in this system it is just scaled in the <span class="process-math">\(P^{-1}\ve_1-P^{-1}\ve_2\)</span> system by the matrix <span class="process-math">\(D\text{.}\)</span> Then the matrix <span class="process-math">\(P\)</span> translates everything back to the standard <span class="process-math">\(xy\)</span> coordinate system.</p>
<figure class="figure figure-like" id="F_4_c_1"><div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/4_c_Transformation_1.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/4_c_Transformation_2.svg" role="img" class="contained"></div>
</div></div>
<div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/4_c_Transformation_3.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/4_c_Transformation_4.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">19.3<span class="period">.</span></span><span class="space"> </span>The matrix transformation.</figcaption></figure><p id="p-3233">This geometric perspective provides another example of how having a matrix similar to a diagonal matrix informs us about the situation. In what follows we determine the conditions that determine when a matrix is similar to a diagonal matrix.</p></section><section class="section" id="sec_diag_general"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Diagonalization in General</span>
</h3>
<p id="p-3234">In <a href="" class="xref" data-knowl="./knowl/pa_4_c.html" title="Preview Activity 19.1">Preview Activity 19.1</a> and in the matrix transformation example we found that a matrix <span class="process-math">\(A\)</span> was similar to a diagonal matrix whose columns were eigenvectors of <span class="process-math">\(A\text{.}\)</span> This will work for a general <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> as long as we can find an invertible matrix <span class="process-math">\(P\)</span> whose columns are eigenvectors of <span class="process-math">\(A\text{.}\)</span> More specifically, suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix with <span class="process-math">\(n\)</span> linearly independent eigenvectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> with corresponding eigenvalues <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> (not necessarily distinct). Let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/pa_4_c.html">
\begin{equation*}
P = [ \vv_1 \  \vv_2  \ \vv_3  \ \cdots  \ \vv_n]\text{.}
\end{equation*}
</div>
<p id="p-3235">Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-131">
\begin{align*}
AP \amp = [ A\vv_1  \ A\vv_2  \ A\vv_3  \ \cdots  \ A\vv_n]\\
\amp = [ \lambda_1\vv_1  \ \lambda_2\vv_2  \ \lambda_3\vv_3  \ \cdots  \ \lambda_n\vv_n]\\
\amp = [ \vv_1 \  \vv_2  \ \vv_3  \ \cdots  \ \vv_n]\left[ \begin{array}{cccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0\amp 0\\
0\amp \lambda_2\amp 0\amp \cdots\amp 0\amp 0\\
\vdots\amp \vdots\amp \amp  \cdots\amp \vdots\amp \vdots\\
0\amp 0\amp 0\amp \cdots\amp \lambda_{n-1}\amp 0\\
0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda_{n} \end{array} \right]\\
\amp = P D\text{.}
\end{align*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = \left[ \begin{array}{cccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0\amp 0 \\ 0\amp \lambda_2\amp 0\amp \cdots\amp 0\amp 0 \\ \vdots\amp \vdots\amp \amp  \cdots\amp \vdots\amp \vdots \\ 0\amp 0\amp 0\amp \cdots\amp \lambda_{n-1}\amp 0 \\  0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda_{n} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-3236">Since the columns of <span class="process-math">\(P\)</span> are linearly independent, we know <span class="process-math">\(P\)</span> is invertible, and so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = D\text{.}
\end{equation*}
</div>
<article class="definition definition-like" id="definition-43"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">19.4</span><span class="period">.</span>
</h4>
<p id="p-3237">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">diagonalizable</dfn> if there is an invertible <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(P\)</span> so that <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix.</p></article><p id="p-3238">In other words, a matrix <span class="process-math">\(A\)</span> is diagonalizable if <span class="process-math">\(A\)</span> is similar to a diagonal matrix.</p>
<section class="paragraphs" id="paragraphs-25"><h4 class="heading"><span class="title">IMPORTANT NOTE.</span></h4>
<p id="p-3239">The key notion to the process described above is that in order to diagonalize an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we have to find <span class="process-math">\(n\)</span> linearly independent eigenvectors for <span class="process-math">\(A\text{.}\)</span> When <span class="process-math">\(A\)</span> is diagonalizable, a matrix <span class="process-math">\(P\)</span> so that <span class="process-math">\(P^{-1}AP\)</span> is diagonal is said to <dfn class="terminology">diagonalize</dfn> <span class="process-math">\(A\text{.}\)</span></p></section><article class="activity project-like" id="act_4_c_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">19.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-302"><p id="p-3240">Find an invertible matrix <span class="process-math">\(P\)</span> that diagonalizes <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1063"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3241"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 0\amp 2 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1064"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3242"><span class="process-math">\(A = \left[ \begin{array}{ccc} 3\amp 2\amp 4 \\ 2\amp 0\amp 2 \\ 4\amp 2\amp 3 \end{array} \right]\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-23" id="hint-23"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-23"><div class="hint solution-like"><p id="p-3243">The eigenvalues of <span class="process-math">\(A\)</span> are 8 and <span class="process-math">\(-1\text{.}\)</span></p></div></div>
</div></article></article><p id="p-3244">It should be noted that there are square matrices that are not diagonalizable. For example, the matrix <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 0\amp 1 \end{array} \right]\)</span> has 1 as its only eigenvalue and the dimension of the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue is one. Therefore, it will be impossible to find two linearly independent eigenvectors for <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-3245">We showed previously that eigenvectors corresponding to distinct eigenvalue are always linearly independent, so if an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> distinct eigenvalues then <span class="process-math">\(A\)</span> is diagonalizable. <a href="" class="xref" data-knowl="./knowl/act_4_c_3.html" title="Activity 19.6">Activity 19.6</a> (b) shows that it is possible to diagonalize an <span class="process-math">\(n \times n\)</span> matrix even if the matrix does not have <span class="process-math">\(n\)</span> distinct eigenvalues. In general, we can diagonalize a matrix as long as the dimension of each eigenspace is equal to the multiplicity of the corresponding eigenvalue. In other words, a matrix is diagonalizable if the geometric multiplicity is the same is the algebraic multiplicity for each eigenvalue.</p>
<p id="p-3246">At this point we might ask one final question. We argued that if an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors, then <span class="process-math">\(A\)</span> is diagonalizable. It is reasonable to wonder if the converse is true — that is, if <span class="process-math">\(A\)</span> is diagonalizable, must <span class="process-math">\(A\)</span> have <span class="process-math">\(n\)</span> linearly independent eigenvectors? The answer is yes, and you are asked to show this in <a href="" class="xref" data-knowl="./knowl/ex_4_c_diagonal_converse.html" title="Exercise 6">Exercise 6</a>. We summarize the result in the following theorem.</p>
<article class="theorem theorem-like" id="theorem-43"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">19.5</span><span class="period">.</span><span class="space"> </span><span class="title">The Diagonalization Theorem.</span>
</h4>
<p id="p-3247">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors. If <span class="process-math">\(A\)</span> is diagonalizable and has linearly independent eigenvectors <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> with <span class="process-math">\(A\vv_i = \lambda_i \vv_i\)</span> for each <span class="process-math">\(i\text{,}\)</span> then <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(P [ \vv_1 \ \vv_2 \ \cdots \ \vv_n]\)</span> whose columns are linearly independent eigenvectors of <span class="process-math">\(A\)</span> satisfies <span class="process-math">\(P^{-1}AP = D\text{,}\)</span> where <span class="process-math">\(D = [d_{ij}]\)</span> is the diagonal matrix with diagonal entries <span class="process-math">\(d_{ii} = \lambda_i\)</span> for each <span class="process-math">\(i\text{.}\)</span></p></article></section><section class="section" id="sec_diag_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-3248">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-38"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">19.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-303"><p id="p-3249">Let <span class="process-math">\(A = \left[ \begin{array}{crr} 1\amp -2\amp 1 \\ 0\amp 3\amp -1 \\ 0\amp -2\amp 2 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{ccc} 1\amp 2\amp 0 \\ 0\amp 1\amp 0 \\ 0\amp 0\amp 4 \end{array} \right]\text{.}\)</span> You should use appropriate technology to calculate determinants, perform any row reductions, or solve any polynomial equations.</p></div>
<article class="task exercise-like" id="task-1065"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3250">Determine if <span class="process-math">\(A\)</span> is diagonalizable. If diagonalizable, find a matrix <span class="process-math">\(P\)</span> that diagonalizes <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-115">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3251">Technology shows that the characteristic polynomial of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(\lambda) = \det(A - \lambda I_3) = (4-\lambda)(1-\lambda)^2\text{.}
\end{equation*}
</div>
<p class="continuation">The eigenvalues of <span class="process-math">\(A\)</span> are the solutions to the characteristic equation <span class="process-math">\(p(\lambda) = 0\text{.}\)</span> Thus, the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(4\text{.}\)</span> To find a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{,}\)</span> we find the general solution to the homogeneous system <span class="process-math">\((A - I_3)\vx = \vzero\text{.}\)</span> Using technology we see that the reduced row echelon form of <span class="process-math">\(A - I_3 =  \left[ \begin{array}{crr} 0\amp -2\amp 1 \\ 0\amp 2\amp -1 \\ 0\amp -2\amp 1 \end{array}  \right]\)</span> is <span class="process-math">\(\left[  \begin{array}{ccr} 0\amp 1\amp -\frac{1}{2} \\ 0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> So if <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}  \right]\text{,}\)</span> then the general solution to <span class="process-math">\((A-I_3)\vx = \vzero\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-132">
\begin{align*}
\vx \amp = \left[   \begin{array}{c} x_1\\
\frac{1}{2}x_3\\
x_3 \end{array} \right]\\
\amp = x_1 \left[\begin{array}{c}  1\\
0\\
0 \end{array} \right] + x_3 \left[   \begin{array}{c} 0\\
\frac{1}{2}\\
1 \end{array} \right]\text{.}
\end{align*}
</div>
<p class="continuation">So a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(1\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ 1 \ 0 \ 0 \right]^{\tr}, \left[  0 \ 1 \ 2 \right]^{\tr} \right\}\text{.}
\end{equation*}
</div>
<p class="continuation">To find a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(4\text{,}\)</span> we find the general solution to the homogeneous system <span class="process-math">\((A - 4I_3)\vx = \vzero\text{.}\)</span> Using technology we see that the reduced row echelon form of <span class="process-math">\(A - 4I_3 =  \left[ \begin{array}{rrr} -3\amp -2\amp 1 \\ 0\amp -1\amp -1 \\ 0\amp -2\amp -2 \end{array}  \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccr} 0\amp 1\amp -1 \\ 0\amp 1\amp 1 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> So if <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}  \right]\text{,}\)</span> then the general solution to <span class="process-math">\((A-4I_3)\vx = \vzero\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-133">
\begin{align*}
\vx \amp = \left[ x_1 \ x_2 \ x_3 \right]^{\tr}\\
\amp = \left[ x_3 \ -x_3 \ x_3 \right]^{\tr}\\
\amp = x_3 \left[  1\ -1 \ 1 \right]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">So a basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(4\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ 1 \ -1 \ 0 \right]^{\tr}\right\}\text{.}
\end{equation*}
</div>
<p class="continuation">Eigenvectors corresponding to different eigenvalues are linearly independent, so the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ 1 \ 0 \ 0 \right]^{\tr}, \left[  0 \ 1 \ 2  \right]^{\tr},  \left[ 1 \ -1 \ 0 \right]^{\tr} \right\}
\end{equation*}
</div>
<p class="continuation">is a basis for <span class="process-math">\(\R^3\text{.}\)</span> Since we can find a basis for <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{,}\)</span> we conclude that <span class="process-math">\(A\)</span> is diagonalizable. Letting</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P =  \left[ \begin{array}{ccr} 1\amp 0\amp 1 \\ 0\amp 1\amp -1 \\ 0\amp 2\amp 1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">gives us</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = \left[ \begin{array}{ccc} 1\amp 0\amp 0 \\ 0\amp 1\amp 0 \\ 0\amp 0\amp 4 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1066"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3252">Determine if <span class="process-math">\(B\)</span> is diagonalizable. If diagonalizable, find a matrix <span class="process-math">\(Q\)</span> that diagonalizes <span class="process-math">\(B\text{.}\)</span></p>
<div class="solution solution-like" id="solution-116">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3253">Technology shows that the characteristic polynomial of <span class="process-math">\(B\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(\lambda) = \det(B - \lambda I_3) = (4-\lambda)(1-\lambda)^2\text{.}
\end{equation*}
</div>
<p class="continuation">The eigenvalues of <span class="process-math">\(B\)</span> are the solutions to the characteristic equation <span class="process-math">\(p(\lambda) = 0\text{.}\)</span> Thus, the eigenvalues of <span class="process-math">\(B\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(4\text{.}\)</span> To find a basis for the eigenspace of <span class="process-math">\(B\)</span> corresponding to the eigenvalue <span class="process-math">\(1\text{,}\)</span> we find the general solution to the homogeneous system <span class="process-math">\((B - I_3)\vx = \vzero\text{.}\)</span> Using technology we see that the reduced row echelon form of <span class="process-math">\(B - I_3 =  \left[ \begin{array}{ccc} 0\amp 2\amp 0 \\ 0\amp 0\amp 0 \\ 0\amp 0\amp 3 \end{array}  \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccc} 0\amp 1\amp 0 \\ 0\amp 0\amp 1 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> So if <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}  \right]\text{,}\)</span> then the general solution to <span class="process-math">\((B-I_3)\vx = \vzero\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-134">
\begin{align*}
\vx \amp = \left[ x_1 \ x_2 \ x_3\right]^{\tr}\\
\amp = \left[  x_1 \ 0 \ 0  \right]^{\tr}\\
\amp = x_1 \left[ 1 \ 0 \ 0 \right]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">So a basis for the eigenspace of <span class="process-math">\(B\)</span> corresponding to the eigenvalue <span class="process-math">\(1\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ 1 \ 0 \ 0 \right]^{\tr}\right\}\text{.}
\end{equation*}
</div>
<p class="continuation">To find a basis for the eigenspace of <span class="process-math">\(B\)</span> corresponding to the eigenvalue <span class="process-math">\(4\text{,}\)</span> we find the general solution to the homogeneous system <span class="process-math">\((B - 4I_3)\vx = \vzero\text{.}\)</span> Using technology we see that the reduced row echelon form of <span class="process-math">\(B - 4I_3 =  \left[ \begin{array}{rrc} -3\amp 2\amp 0 \\ 0\amp -3\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]\)</span> is <span class="process-math">\(\left[ \begin{array}{ccc} 1\amp 0\amp 0 \\ 0\amp 1\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]\text{.}\)</span> So if <span class="process-math">\(\vx = \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}  \right]\text{,}\)</span> then the general solution to <span class="process-math">\((B-4I_3)\vx = \vzero\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-135">
\begin{align*}
\vx \amp = \left[ x_1 \ x_2 \ x_3  \right]^{\tr}\\
\amp = \left[  0 \ 0 \ x_3  \right]^{\tr}\\
\amp = x_3 \left[  0\ 0 \ 1  \right]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">So a basis for the eigenspace of <span class="process-math">\(B\)</span> corresponding to the eigenvalue <span class="process-math">\(4\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{ \left[ 0 \ 0 \ 1  \right]^{\tr}\right\}\text{.}
\end{equation*}
</div>
<p class="continuation">Since each eigenspace is one-dimensional, we cannot find a basis for <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(B\text{.}\)</span> We conclude that <span class="process-math">\(B\)</span> is not diagonalizable.</p>
</div></article><article class="task exercise-like" id="task-1067"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3254">Is it possible for two matrices <span class="process-math">\(R\)</span> and <span class="process-math">\(S\)</span> to have the same eigenvalues with the same algebraic multiplicities, but one matrix is diagonalizable and the other is not? Explain.</p>
<div class="solution solution-like" id="solution-117">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3255">Yes it is possible for two matrices <span class="process-math">\(R\)</span> and <span class="process-math">\(S\)</span> to have the same eigenvalues with the same multiplicities, but one matrix is diagonalizable and the other is not. An example is given by the matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> in this problem.</p>
</div></article></article><article class="example example-like" id="example-39"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">19.7</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1068"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3256">Is it possible to find diagonalizable matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> such that <span class="process-math">\(AB\)</span> is not diagonalizable? If yes, provide an example. If no, explain why.</p>
<div class="solution solution-like" id="solution-118">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3257">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 2 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cr} 2\amp -2 \\ 0\amp 1 \end{array} \right]\text{.}\)</span> Since <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are both diagonal matrices, their eigenvalues are their diagonal entries. With <span class="process-math">\(2\)</span> distinct eigenvalues, both <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are diagonalizable. In this case we have <span class="process-math">\(AB = \left[ \begin{array}{cr} 2\amp -1\\0\amp 2 \end{array} \right]\text{,}\)</span> whose only eigenvector is <span class="process-math">\(2\text{.}\)</span> The reduced row echelon form of <span class="process-math">\(AB - 2I_2\)</span> is <span class="process-math">\(\left[ \begin{array}{cr} 0\amp 1\\0\amp 0 \end{array} \right]\text{.}\)</span> So a basis for the eigenspace of <span class="process-math">\(AB\)</span> is <span class="process-math">\(\{[1 \ 0]^{\tr}\}\text{.}\)</span> Since there is no basis for <span class="process-math">\(\R^2\)</span> consisting of eigenvectors of <span class="process-math">\(AB\text{,}\)</span> we conclude that <span class="process-math">\(AB\)</span> is not diagonalizable.</p>
</div></article><article class="task exercise-like" id="task-1069"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3258">Is it possible to find diagonalizable matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> such that <span class="process-math">\(A+B\)</span> is not diagonalizable? If yes, provide an example. If no, explain why.</p>
<div class="solution solution-like" id="solution-119">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3259">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 3\\0\amp 2 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{rr} 2\amp 0 \\ 0\amp 1 \end{array} \right]\text{.}\)</span> Since <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are both diagonal matrices, their eigenvalues are their diagonal entries. With <span class="process-math">\(2\)</span> distinct eigenvalues, both <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are diagonalizable. In this case we have <span class="process-math">\(A+B = \left[ \begin{array}{cc} 3\amp 3\\0\amp 3 \end{array} \right]\text{,}\)</span> whose only eigenvector is <span class="process-math">\(3\text{.}\)</span> The reduced row echelon form of <span class="process-math">\((A+B) - 3I_2\)</span> is <span class="process-math">\(\left[ \begin{array}{cc} 0\amp 1\\0\amp 0 \end{array} \right]\text{.}\)</span> So a basis for the eigenspace of <span class="process-math">\(A+B\)</span> is <span class="process-math">\(\{[1 \ 0]^{\tr}\}\text{.}\)</span> Since there is no basis for <span class="process-math">\(\R^2\)</span> consisting of eigenvectors of <span class="process-math">\(A+B\text{,}\)</span> we conclude that <span class="process-math">\(A+B\)</span> is not diagonalizable.</p>
</div></article><article class="task exercise-like" id="task-1070"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3260">Is it possible to find a diagonalizable matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(A^{\tr}\)</span> is not diagonalizable? If yes, provide an example. If no, explain why.</p>
<div class="solution solution-like" id="solution-120">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3261">It is not possible to find a diagonalizable matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(A^{\tr}\)</span> is not diagonalizable. To see why, suppose that matrix <span class="process-math">\(A\)</span> is diagonalizable. That is, there exists a matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}AP = D\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix. Recall that <span class="process-math">\(\left(P^{-1}\right)^{\tr} = \left(P^{\tr}\right)^{-1}\text{.}\)</span> So</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-136">
\begin{align*}
D \amp = D^{\tr}\\
\amp = \left(P^{-1}AP\right)^{\tr}\\
\amp = P^{\tr}A^{\tr}\left(P^{-1}\right)^{\tr}\\
\amp = P^{\tr}A^{\tr}\left(P^{\tr}\right)^{-1}\text{.}
\end{align*}
</div>
<p class="continuation">Letting <span class="process-math">\(A = \left(P^{\tr}\right)^{-1}\text{,}\)</span> we conclude that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
Q^{-1}A^{\tr}Q = D\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, <span class="process-math">\(Q\)</span> diagonalizes <span class="process-math">\(A^{\tr}\text{.}\)</span></p>
</div></article><article class="task exercise-like" id="task-1071"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3262">Is it possible to find an invertible diagonalizable matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(A^{-1}\)</span> is not diagonalizable? If yes, provide an example. If no, explain why.</p>
<div class="solution solution-like" id="solution-121">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-3263">It is not possible to find an invertible diagonalizable matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(A^{-1}\)</span> is not diagonalizable. To see why, suppose that matrix <span class="process-math">\(A\)</span> is diagonalizable. That is, there exists a matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}AP = D\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix. Thus, <span class="process-math">\(A = PDP^{-1}\text{.}\)</span> Since <span class="process-math">\(A\)</span> is invertible, <span class="process-math">\(\det(A) \neq 0\text{.}\)</span> It follows that <span class="process-math">\(\det(D) \neq 0\text{.}\)</span> So none of the diagonal entries of <span class="process-math">\(D\)</span> can be <span class="process-math">\(0\text{.}\)</span> Thus, <span class="process-math">\(D\)</span> is invertible and <span class="process-math">\(D^{-1}\)</span> is a diagonal matrix. Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D^{-1} = \left(P^{-1}AP\right)^{-1} = PA^{-1}P^{-1}
\end{equation*}
</div>
<p class="continuation">and so <span class="process-math">\(P^{-1}\)</span> diagonalizes <span class="process-math">\(A^{-1}\text{.}\)</span></p>
</div></article></article></section><section class="section" id="sec_diag_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-580"><p id="p-3264">A matrix <span class="process-math">\(D = [d_{ij}]\)</span> is a diagonal matrix if <span class="process-math">\(d_{ij} = 0\)</span> whenever <span class="process-math">\(i \neq j\text{.}\)</span></p></li>
<li id="li-581"><p id="p-3265">A matrix <span class="process-math">\(A\)</span> is diagonalizable if there is an invertible matrix <span class="process-math">\(P\)</span> so that <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix.</p></li>
<li id="li-582">
<p id="p-3266">Two matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are similar if there is an invertible matrix <span class="process-math">\(P\)</span> so that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B = P^{-1}AP\text{.}
\end{equation*}
</div>
</li>
<li id="li-583"><p id="p-3267">Similar matrices have the same determinants, same characteristic polynomials, and same eigenvalues. Note that similar matrices do not necessarily have the same eigenvectors corresponding to the same eigenvalues.</p></li>
<li id="li-584"><p id="p-3268">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors.</p></li>
<li id="li-585"><p id="p-3269">When an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable, then <span class="process-math">\(P = [ \vv_1 \ \vv_2 \ \vv_3 \ \cdots \ \vv_n]\)</span> is invertible and <span class="process-math">\(P^{-1}AP\)</span> is diagonal, where <span class="process-math">\(\vv_1\text{,}\)</span> <span class="process-math">\(\vv_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vv_n\)</span> are <span class="process-math">\(n\)</span> linearly independent eigenvectors for <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-586"><p id="p-3270">One use for diagonalization is that once we have diagonalized a matrix <span class="process-math">\(A\)</span> we can quickly and easily compute powers of <span class="process-math">\(A\text{.}\)</span> Diagonalization can also help us understand the actions of matrix transformations.</p></li>
</ul></section><section class="exercises" id="sec_diag_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-175"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-304"><p id="p-3271">Determine if each of the following matrices is diagonalizable or not. For diagonalizable matrices, clearly identify a matrix <span class="process-math">\(P\)</span> which diagonalizes the matrix, and what the resulting diagonal matrix is.</p></div>
<article class="task exercise-like" id="task-1072"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3272"><span class="process-math">\(A=\left[ \begin{array}{cr} 2\amp -1\\ 1\amp 4 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1073"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3274"><span class="process-math">\(A=\left[ \begin{array}{rcr} -1 \amp 4 \amp -2 \\ -3 \amp 4 \amp 0 \\ -3 \amp 1 \amp 3 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-176"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-3276">The <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\)</span> has two eigenvalues <span class="process-math">\(\lambda_1=2\)</span> and <span class="process-math">\(\lambda_2=3\text{.}\)</span> The vectors <span class="process-math">\(\left[ \begin{array}{c} 1\\2\\1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\left[ \begin{array}{r} 1\\-1\\2 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\left[ \begin{array}{c} 2\\4\\2 \end{array} \right]\)</span> are eigenvectors for <span class="process-math">\(\lambda_1=2\text{,}\)</span> while the vectors <span class="process-math">\(\left[ \begin{array}{c} 1\\1\\1 \end{array} \right], \left[ \begin{array}{c} 2\\2\\2 \end{array} \right]\)</span> are eigenvectors for <span class="process-math">\(\lambda_2=3\text{.}\)</span> Find the matrix <span class="process-math">\(A\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-177"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-3277">Find a <span class="process-math">\(2\times 2\)</span> non-diagonal matrix <span class="process-math">\(A\)</span> and two different pairs of <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span> matrices for which <span class="process-math">\(A=PDP^{-1}\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-178"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-3279">Find a <span class="process-math">\(2\times 2\)</span> non-diagonal matrix <span class="process-math">\(A\)</span> and two different <span class="process-math">\(P\)</span> matrices for which <span class="process-math">\(A=PDP^{-1}\)</span> with the same <span class="process-math">\(D\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-179"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-3280">Suppose a <span class="process-math">\(4\times 4\)</span> matrix <span class="process-math">\(A\)</span> has eigenvalues 2, 3 and 5 and the eigenspace for the eigenvalue 3 has dimension 2. Do we have enough information to determine if <span class="process-math">\(A\)</span> is diagonalizable? Explain.</p></article><article class="exercise exercise-like" id="ex_4_c_diagonal_converse"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-3282">Let <span class="process-math">\(A\)</span> be a diagonalizable <span class="process-math">\(n \times n\)</span> matrix. Show that <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors.</p></article><article class="exercise exercise-like" id="exercise-181"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<article class="task exercise-like" id="task-1074"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3283">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 1 \end{array} \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cc} 1\amp 2\\0\amp 1 \end{array} \right]\text{.}\)</span> Find the eigenvalues and eigenvectors of <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{.}\)</span> Conclude that it is possible for two different <span class="process-math">\(n \times n\)</span> matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> to have exactly the same eigenvectors and corresponding eigenvalues.</p></article><article class="task exercise-like" id="task-1075"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3285">A natural question to ask is if there are any conditions under which <span class="process-math">\(n \times n\)</span> matrices that have exactly the same eigenvectors and corresponding eigenvalues must be equal. Determine the answer to this question if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are both diagonalizable.</p></article></article><article class="exercise exercise-like" id="exercise-182"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<article class="task exercise-like" id="task-1076"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3287">Show that if <span class="process-math">\(D\)</span> and <span class="process-math">\(D'\)</span> are <span class="process-math">\(n \times n\)</span> diagonal matrices, then <span class="process-math">\(DD' = D'D\text{.}\)</span></p></article><article class="task exercise-like" id="task-1077"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3288">Show that if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(n \times n\)</span> matrices and <span class="process-math">\(P\)</span> is an invertible <span class="process-math">\(n \times n\)</span> matrix such that <span class="process-math">\(P^{-1}AP = D\)</span> and <span class="process-math">\(P^{-1}BP = D'\)</span> with <span class="process-math">\(D\)</span> and <span class="process-math">\(D'\)</span> diagonal matrices, then <span class="process-math">\(AB = BA\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="ex_trace_eigenvalues"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-305">
<p id="p-3289"><a href="" class="xref" data-knowl="./knowl/ex_determinant_eigenvalues.html" title="Exercise 1">Exercise 1</a> in <a href="chap_characteristic_equation.html" class="internal" title="Section 18: The Characteristic Equation">Section 18</a> shows that the determinant of a matrix is the product of its eigenvalues. In this exercise we show that the trace of a diagonalizable matrix is the sum of its eigenvalues.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-36" id="fn-36"><sup> 36 </sup></a> First we define the trace of a matrix.</p>
<article class="definition definition-like" id="def_trace"><h5 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">19.8</span><span class="period">.</span>
</h5>
<p id="p-3290">The <dfn class="terminology">trace</dfn> of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A = [a_{ij}]\)</span> is the sum of the diagonal entries of <span class="process-math">\(A\text{.}\)</span> That is,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\trace(A) = a_{11} + a_{22} + \cdots + a_{nn} = \sum_{i=1}^n a_{ii}\text{.}
\end{equation*}
</div></article>
</div>
<article class="task exercise-like" id="task-1078"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3291">Show that if <span class="process-math">\(R = [r_{ij}]\)</span> and <span class="process-math">\(S = [s_{ij}]\)</span> are <span class="process-math">\(n \times n\)</span> matrices, then <span class="process-math">\(\trace(RS) = \trace(SR)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1079"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-306"><p id="p-3293">Let <span class="process-math">\(A\)</span> be a diagonalizable <span class="process-math">\(n \times n\)</span> matrix, and let <span class="process-math">\(p(\lambda) = \det(A - \lambda I_n)\)</span> be the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(P\)</span> be an invertible matrix such that <span class="process-math">\(P^{-1}AP = D\text{,}\)</span> where <span class="process-math">\(D\)</span> is the diagonal matrix whose diagonal entries are <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\text{,}\)</span> the eigenvalues of <span class="process-math">\(A\)</span> (note that these eigenvalues may not all be distinct).</p></div>
<article class="task exercise-like" id="task-1080"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3294">Explain why <span class="process-math">\(\trace(A) = \trace(D)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1081"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3296">Show that the trace of an <span class="process-math">\(n \times n\)</span> diagonalizable matrix is the sum of the eigenvalues of the matrix.</p></article></article></article><article class="exercise exercise-like" id="ex_4_c_matrix_exponential"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-307"><p id="p-3298">In this exercise we generalize the result of <a href="" class="xref" data-knowl="./knowl/ex_2_a_matrix_exponential.html" title="Exercise 12">Exercise 12</a> in <a href="chap_matrix_operations.html" class="internal" title="Section 8: Matrix Operations">Section 8</a> to arbitrary diagonalizable matrices.</p></div>
<article class="task exercise-like" id="task-1082"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3299">Show that if</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D=\left[ \begin{array}{ccccc} \lambda_1\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  \lambda_2\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  \lambda_n \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^D =  \left[ \begin{array}{ccccc} e^{\lambda_1}\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  e^{\lambda_2}\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  e^{\lambda_n} \end{array}  \right]\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1083"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3300">Now suppose that an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable, with <span class="process-math">\(P^{-1}AP\)</span> equal to a diagonal matrix <span class="process-math">\(D\text{.}\)</span> Show that <span class="process-math">\(e^A = Pe^DP^{-1}\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="ex_4_c_matrix_exponential_examples"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-308"><p id="p-3301">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 0 \end{array} \right]\)</span> and let <span class="process-math">\(B = \left[ \begin{array}{cr} 0\amp -1 \\ 0\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1084"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3302">Use the result of <a href="" class="xref" data-knowl="./knowl/ex_4_c_matrix_exponential.html" title="Exercise 10">Exercise 10</a> to calculate <span class="process-math">\(e^A\text{.}\)</span></p></article><article class="task exercise-like" id="task-1085"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3304">Calculate <span class="process-math">\(e^B\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-24" id="hint-24"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-24"><div class="hint solution-like"><p id="p-3305">Explain why <span class="process-math">\(B\)</span> is not diagonalizable.</p></div></div>
</div></article><article class="task exercise-like" id="task-1086"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3307">Use the result of <a href="" class="xref" data-knowl="./knowl/ex_4_c_matrix_exponential.html" title="Exercise 10">Exercise 10</a> to calculate <span class="process-math">\(e^{A+B}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1087"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-3309">The real exponential function satisfies some familiar properties. For example, <span class="process-math">\(e^xe^y = e^ye^x\)</span> and <span class="process-math">\(e^{x+y} = e^x e^y\)</span> for any real numbers <span class="process-math">\(x\)</span> and <span class="process-math">\(y\text{.}\)</span> Does the matrix exponential satisfy the corresponding properties. That is, if <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are <span class="process-math">\(n \times n\)</span> matrices, must <span class="process-math">\(e^Xe^Y = e^Ye^X\)</span> and <span class="process-math">\(e^{X+Y} = e^X e^Y\text{?}\)</span> Explain.</p></article></article><article class="exercise exercise-like" id="exercise-186"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-309"><p id="p-3311">In <a href="" class="xref" data-knowl="./knowl/ex_4_c_matrix_exponential_examples.html" title="Exercise 11">Exercise 11</a> we see that we cannot conclude that <span class="process-math">\(e^{X+Y} = e^X e^Y\)</span> for <span class="process-math">\(n \times n\)</span> matrices <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\text{.}\)</span> However, a more limited property is true.</p></div>
<article class="task exercise-like" id="task-1088"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-310">&gt; <p id="p-3312">Follow the steps indicated to show that if <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> matrix and <span class="process-math">\(s\)</span> and <span class="process-math">\(t\)</span> are any scalars, then <span class="process-math">\(e^{As} e^{At} = e^{A(s+t)}\text{.}\)</span> (Although we will not use it, you may assume that the series for <span class="process-math">\(e^A\)</span> converges for any square matrix <span class="process-math">\(A\text{.}\)</span>)</p>
</div>
<article class="task exercise-like" id="task-1089"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3313">Use the definition to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^{As}e^{At} = \sum_{k \geq 0} \sum_{m \geq 0} \frac{s^kt^m}{k!}m! A^{k+m}\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1090"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3314">Relabel and reorder terms with <span class="process-math">\(n = k+m\)</span> to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
e^{As}e^{At} = sum_{n \geq 0} \frac{1}{n!} A^n \sum_{m = 0}^n \frac{n!}{(n-m)!m!} s^{n-m}t^m\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-1091"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-3315">Complete the problem using the Binomial Theorem that says</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(s+t)^n =  \sum_{m = 0}^n \frac{n!} {(n-m)!m!} s^{n-m}t^m\text{.}
\end{equation*}
</div></article></article><article class="task exercise-like" id="task-1092"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3316">Use the result of part (a) to show that <span class="process-math">\(e^A\)</span> is an invertible matrix for any <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{.}\)</span></p></article></article><article class="exercise exercise-like" id="exercise-187"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-311"><p id="p-3317">There is an interesting connection between the determinant of a matrix exponential and the trace of the matrix. Let <span class="process-math">\(A\)</span> be a diagonalizable <span class="process-math">\(n \times n\)</span> matrix with real entries. Let <span class="process-math">\(D = P^{-1}AP\)</span> for some invertible matrix <span class="process-math">\(P\text{,}\)</span> where <span class="process-math">\(D\)</span> is the diagonal matrix with entries <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1093"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3318">Show that <span class="process-math">\(e^A = Pe^DP^{-1}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1094"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3320">Use <a href="" class="xref" data-knowl="./knowl/ex_trace_eigenvalues.html" title="Exercise 9">Exercise 9</a> to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_trace_eigenvalues.html">
\begin{equation*}
\det\left(e^A\right) = e^{\trace(A)}\text{.}
\end{equation*}
</div></article></article><article class="exercise exercise-like" id="ex_Cayley-Hamilton"><h4 class="heading"><span class="codenumber">14<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-312"><p id="p-3322">There is interesting relationship between a matrix and its characteristic equation that we explore in this exercise.</p></div>
<article class="task exercise-like" id="task-1095"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-313"><p id="p-3323">We first illustrate with an example. Let <span class="process-math">\(B = \left[ \begin{array}{cr} 1\amp 2\\ 1\amp -2 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1096"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3324">Show that <span class="process-math">\(\lambda^2 + \lambda - 4\)</span> is the characteristic polynomial for <span class="process-math">\(B\text{.}\)</span></p></article><article class="task exercise-like" id="task-1097"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3325">Calculate <span class="process-math">\(B^2\text{.}\)</span> Then compute <span class="process-math">\(B^2 + B - 4I_2\text{.}\)</span> What do you get?</p></article></article><article class="task exercise-like" id="task-1098"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3326">The first part of this exercise presents an example of a matrix that satisfies its own characteristic equation. Show that if <span class="process-math">\(A\)</span> is an <span class="process-math">\(n \times n\)</span> <em class="emphasis">diagonalizable</em> matrix with characteristic polynomial <span class="process-math">\(p(x)\text{,}\)</span> then <span class="process-math">\(p(A) = 0\text{.}\)</span><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-37" id="fn-37"><sup> 37 </sup></a> That is, if <span class="process-math">\(p(x) = a_nx^n+a_{n-1}x^{n-1} + \cdots + a_1x + a_0\text{,}\)</span> then <span class="process-math">\(p(A) = a_nA^n+a_{n-1}A^{n-1} + \cdots + a_1A + a_0 = 0\text{.}\)</span> (Hint: If <span class="process-math">\(A = PDP^{-1}\)</span> for some diagonal matrix <span class="process-math">\(D\text{,}\)</span> show that <span class="process-math">\(p(A) = Pp(D)P^{-1}\text{.}\)</span> Then determine <span class="process-math">\(p(D)\text{.}\)</span>)</p></article></article><article class="exercise exercise-like" id="exercise-189"><h4 class="heading"><span class="codenumber">15<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-314"><p id="p-3327">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1099"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3328">If matrix <span class="process-math">\(A\)</span> is diagonalizable, then so is <span class="process-math">\(A^T\text{.}\)</span></p></article><article class="task exercise-like" id="task-1100"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3330">If matrix <span class="process-math">\(A\)</span> is diagonalizable, then <span class="process-math">\(A\)</span> is invertible.</p></article><article class="task exercise-like" id="task-1101"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3331">If an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable, then <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> distinct eigenvalues.</p></article><article class="task exercise-like" id="task-1102"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3333">If matrix <span class="process-math">\(A\)</span> is invertible and diagonalizable, then so is <span class="process-math">\(A^{-1}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1103"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3334">If an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(C\)</span> is diagonalizable, then there exists a basis of <span class="process-math">\(\R^n\)</span> consisting of the eigenvectors of <span class="process-math">\(C\text{.}\)</span></p></article><article class="task exercise-like" id="task-1104"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3336">An <span class="process-math">\(n\times n\)</span> matrix with <span class="process-math">\(n\)</span> distinct eigenvalues is diagonalizable.</p></article><article class="task exercise-like" id="task-1105"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3337">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> diagonalizable matrix, then there is a unique diagonal matrix such that <span class="process-math">\(P^{-1}AP = D\)</span> for some invertible matrix <span class="process-math">\(P\text{.}\)</span></p></article><article class="task exercise-like" id="task-1106"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3339">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> matrix with eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> then the dimension of the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\lambda\)</span> is <span class="process-math">\(n - \rank(A - \lambda I_n)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1107"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-3340">If <span class="process-math">\(\lambda\)</span> is an eigenvalue of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(e^\lambda\)</span> is an eigenvalue of <span class="process-math">\(e^A\text{.}\)</span> (See <a href="" class="xref" data-knowl="./knowl/ex_2_a_matrix_exponential.html" title="Exercise 12">Exercise 12</a> in <a href="chap_matrix_operations.html" class="internal" title="Section 8: Matrix Operations">Section 8</a> for information on the matrix exponential.)</p></article></article></section><section class="section" id="sec_proj_binet_fibo"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Binet's Formula for the Fibonacci Numbers</span>
</h3>
<p id="p-3342">We return to the Fibonacci sequence <span class="process-math">\(F_n\)</span> where <span class="process-math">\(F_{n+2} = F_{n+1} + F_{n}\text{,}\)</span> for <span class="process-math">\(n \geq 0\text{,}\)</span> <span class="process-math">\(F_0 = 0\text{,}\)</span> and <span class="process-math">\(F_1=1\text{.}\)</span> Since <span class="process-math">\(F_{n+2}\)</span> is determined by previous values <span class="process-math">\(F_{n+1}\)</span> and <span class="process-math">\(F_n\text{,}\)</span> the relation <span class="process-math">\(F_{n+2} = F_{n+1} + F_{n}\)</span> is called a <dfn class="terminology">recurrence relation</dfn>. The recurrence relation <span class="process-math">\(F_{n+2} = F_{n+1} + F_{n}\)</span> is very time consuming to use to compute <span class="process-math">\(F_n\)</span> for large values of <span class="process-math">\(n\text{.}\)</span> It turns out that there is a fascinating formula that gives the <span class="process-math">\(n\)</span>th term of the Fibonacci sequence directly, without using the relation <span class="process-math">\(F_{n+2} = F_{n+1} + F_{n}\text{.}\)</span></p>
<article class="project project-like" id="project-62"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">19.7</span><span class="period">.</span>
</h4>
<p id="p-3343">The recurrence relation<span class="process-math">\(F_{n+2} = F_{n+1} + F_{n}\)</span> gives the equations</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-16">
\begin{align}
F_{n+1} \amp = F_{n} + F_{n-1}\tag{19.3}\\
F_{n} \amp = F_{n}\text{.}\tag{19.4}
\end{align}
</div>
<p id="p-3344">Let <span class="process-math">\(\vx_{n} = \left[ \begin{array}{c} F_{n+1} \\ F_{n} \end{array}  \right]\)</span> for <span class="process-math">\(n \geq 0\text{.}\)</span> Explain how the equations <a href="" class="xref" data-knowl="./knowl/eq_Fib_1.html" title="Equation 19.3">(19.3)</a> and <a href="" class="xref" data-knowl="./knowl/eq_Fib_1.html" title="Equation 19.3">(19.3)</a> can be described with the matrix equation</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Fib_1.html ./knowl/eq_Fib_1.html" id="eq_Fib_matrix">
\begin{equation}
\vx_n = A \vx_{n-1}\text{,}\tag{19.5}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 1\amp 0 \end{array}  \right]\text{.}\)</span></p></article><p id="p-3345">The matrix equation <a href="" class="xref" data-knowl="./knowl/eq_Fib_matrix.html" title="Equation 19.5">(19.5)</a> shows us how to find the vectors <span class="process-math">\(\vx_n\)</span> using powers of the matrix <span class="process-math">\(A\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Fib_matrix.html" id="md-139">
\begin{align*}
\vx_1 \amp = A\vx_0\\
\vx_2 \amp = A\vx_1 = A(A\vx_0) = A^2\vx_0\\
\vx_3 \amp = A\vx_2 = A(A^2\vx_0) = A^3\vx_0\\
\ \vdots \amp  \qquad \vdots\\
\vx_n \amp = A^n\vx_0\text{.}
\end{align*}
</div>
<p id="p-3346">So if we can somehow easily find the powers of the matrix <span class="process-math">\(A\text{,}\)</span> then we can find a convenient formula for <span class="process-math">\(F_n\text{.}\)</span> As we have seen, we know how to do this if <span class="process-math">\(A\)</span> is diagonalizable</p>
<article class="project project-like" id="project-63"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">19.8</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-315"><p id="p-3347">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 1 \\ 1\amp 0 \end{array} \right]\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1108"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3348">Show that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(\varphi = \frac{1 + \sqrt{5}}{2}\)</span> and <span class="process-math">\(\overline{\varphi} = \frac{1 - \sqrt{5}}{2}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1109"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3349">Find bases for each eigenspace of <span class="process-math">\(A\text{.}\)</span></p></article></article><p id="p-3350">Now that we have the eigenvalues and know corresponding eigenvectors for <span class="process-math">\(A\text{,}\)</span> we can return to the problem of diagonalizing <span class="process-math">\(A\text{.}\)</span></p>
<article class="project project-like" id="project-64"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">19.9</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1110"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3351">Why do we know that <span class="process-math">\(A\)</span> is diagonalizable?</p></article><article class="task exercise-like" id="task-1111"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3352">Find a matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix. What is the diagonal matrix?</p></article></article><p id="p-3353">Now we can find a formula for the <span class="process-math">\(n\)</span>th Fibonacci number.</p>
<article class="project project-like" id="project-65"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">19.10</span><span class="period">.</span>
</h4>
<p id="p-3354">Since <span class="process-math">\(P^{-1}AP = D\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix, we also have <span class="process-math">\(A = PDP^{-1}\text{.}\)</span> Recall that when <span class="process-math">\(A = PDP^{-1}\text{,}\)</span> it follows that <span class="process-math">\(A^n = PD^nP^{-1}\text{.}\)</span> Use the equation <span class="process-math">\(A^n = PD^nP^{-1}\)</span> to show that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Binet">
\begin{equation}
F_n = \frac{\varphi^n - \overline{\varphi}^n}{\sqrt{5}}\text{.}\tag{19.6}
\end{equation}
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-25" id="hint-25"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-25"><div class="hint solution-like"><p id="p-3355">We just need to calculate the second component of <span class="process-math">\(A^n \vx_0\text{.}\)</span></p></div></div>
</div></article><p id="p-3356"> Formula <a href="" class="xref" data-knowl="./knowl/eq_Binet.html" title="Equation 19.6">(19.6)</a> is called <em class="emphasis">Binet's formula</em>. It is a very surprising formula in the fact that the expression on the right hand side of <a href="" class="xref" data-knowl="./knowl/eq_Binet.html" title="Equation 19.6">(19.6)</a> is an integer for each positive integer <span class="process-math">\(n\text{.}\)</span> Note that with Binet's formula we can quickly compute <span class="process-math">\(F_n\)</span> for very large values of <span class="process-math">\(n\text{.}\)</span> For example,</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Binet.html ./knowl/eq_Binet.html">
\begin{equation*}
F_{150} = 9969216677189303386214405760200\text{.}
\end{equation*}
</div>
<p id="p-3357">The number <span class="process-math">\(\varphi = \frac{1+\sqrt{5}}{2}\text{,}\)</span> called the <dfn class="terminology">golden mean</dfn> or <dfn class="terminology">golden ratio</dfn> is intimately related to the Fibonacci sequence. Binet's formula provides a fascinating relationship between the Fibonacci numbers and the golden ratio. The golden ratio also occurs often in other areas of mathematics. It was an important number to the ancient Greek mathematicians who felt that the most aesthetically pleasing rectangles had sides in the ratio of <span class="process-math">\(\varphi:1\text{.}\)</span></p>
<article class="project project-like" id="project-66"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">19.11</span><span class="period">.</span>
</h4>
<p id="p-3358">You might wonder what happens if we use negative integer exponents in Binet's formula. In other words, are there negatively indexed Fibonacci numbers? For any integer <span class="process-math">\(n\text{,}\)</span> including negative integers, let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
F_n = \frac{\varphi^n - \overline{\varphi}^n}{\sqrt{5}}
\end{equation*}
</div>
<p id="p-3359">There is a specific relationship between <span class="process-math">\(F_{-n}\)</span> and <span class="process-math">\(F_n\text{.}\)</span> Find it and verify it.</p></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-36"><div class="fn">This result is true for any matrix, but the argument is more complicated.</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-37"><div class="fn">This result is known as the Cayley-Hamilton Theorem and is one of the fascinating results in linear algebra. This result is true for any square matrix.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
