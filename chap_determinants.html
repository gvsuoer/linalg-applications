<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The Determinant</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
},
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{colortbl}\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="part-eigen.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_characteristic_equation.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="part-eigen.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-eigen.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_characteristic_equation.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link active">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_determinants"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">17</span> <span class="title">The Determinant</span>
</h2>
<section class="introduction" id="introduction-267"><article class="objectives goal-like" id="objectives-17"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-268"><p id="p-2880">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-507"><p id="p-2881">How do we calculate the determinant of an <span class="process-math">\(n \times n\)</span> matrix?</p></li>
<li id="li-508"><p id="p-2882">What is one important fact the determinant tells us about a matrix?</p></li>
</ul></article></section><section class="section" id="sec_appl_area_vol"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: Area and Volume</span>
</h3>
<p id="p-2883">Consider the problem of finding the area of a parallelogram determined by two vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> as illustrated at left in <a href="" class="xref" data-knowl="./knowl/F_det_area.html" title="Figure 17.1">Figure 17.1</a>.</p>
<figure class="figure figure-like" id="F_det_area"><div class="sidebyside"><div class="sbsrow" style="margin-left:0%;margin-right:0%;">
<div class="sbspanel top" style="width:50%;"><img src="external/det_area_2.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:50%;"><img src="external/det_volume_2.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.1<span class="period">.</span></span><span class="space"> </span>A parallelogram and a parallelepiped.</figcaption></figure><p id="p-2884">We could calculate this area, for example, by breaking up the parallelogram into two triangles and a rectangle and finding the area of each. Now consider the problem of calculating the volume of the three-dimensional analog (called a <dfn class="terminology">parallelepiped</dfn>) determined by three vectors <span class="process-math">\(\vu\text{,}\)</span> <span class="process-math">\(\vv\text{,}\)</span> and <span class="process-math">\(\vw\)</span> as illustrated at right in <a href="" class="xref" data-knowl="./knowl/F_det_area.html" title="Figure 17.1">Figure 17.1</a>.</p>
<p id="p-2885">It is quite a bit more difficult to break this parallelepiped into subregions whose volumes are easy to compute. However, all of these computations can be made quickly by using determinants. The details are later in this section.</p></section><section class="section" id="sec_det_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-2886">We know that a non-zero vector <span class="process-math">\(\vx\)</span> is an eigenvector of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> if <span class="process-math">\(A \vx = \lambda \vx\)</span> for some scalar <span class="process-math">\(\lambda\text{.}\)</span> Note that this equation can be written as <span class="process-math">\((A-\lambda I_n)\vx=\vzero\text{.}\)</span> Until now, we were given eigenvalues of matrices and have used the eigenvalues to find the eigenvectors. In this section we will learn an algebraic technique to find the eigenvalues ourselves. We will also be able to justify why an <span class="process-math">\(n\times n\)</span> matrix has at most <span class="process-math">\(n\)</span> eigenvalues.</p>
<p id="p-2887">A scalar <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\)</span> if <span class="process-math">\((A - \lambda I_n)\vx=\vzero\)</span> has a non-trivial solution <span class="process-math">\(\vx\text{,}\)</span> which happens if and only if <span class="process-math">\(A-\lambda I_n\)</span> is not invertible. In this section we will find a scalar whose value will tell us when a matrix is invertible and when it is not, and use this scalar to find the eigenvalues of a matrix.</p>
<article class="exploration project-like" id="pa_4_a"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">17.1</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-269">
<p id="p-2888">In this activity, we will focus on <span class="process-math">\(2\times 2\)</span> matrices. Let <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp b \\ c\amp d \end{array}  \right]\)</span> be a <span class="process-math">\(2\times 2\)</span> matrix. To see if <span class="process-math">\(A\)</span> is invertible, we row reduce <span class="process-math">\(A\)</span> by replacing row 2 with <span class="process-math">\(a\cdot\)</span>(row 2) <span class="process-math">\(- c \cdot\)</span>(row 1):</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cc} a\amp b \\ 0\amp ad-bc \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-2889">So the only way <span class="process-math">\(A\)</span> can be reduced <span class="process-math">\(I_2\)</span> is if <span class="process-math">\(ad - bc \neq 0\text{.}\)</span> We call this quantity <span class="process-math">\(ad-bc\)</span> the <dfn class="terminology">determinant</dfn> of <span class="process-math">\(A\text{,}\)</span> and denote the determinant of <span class="process-math">\(A\)</span> as <span class="process-math">\(\det(A)\)</span> or <span class="process-math">\(|A|\text{.}\)</span> When <span class="process-math">\(\det(A)\neq 0\text{,}\)</span> we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A^{-1} = \frac{1}{ad-bc} \left[ \begin{array}{rr} d\amp -b \\ -c\amp a \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-2890">We now consider how we can use the determinant to find eigenvalues and other information about the invertibility of a matrix.</p>
</div>
<article class="task exercise-like" id="task-957"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-2891">Let <span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 4 \end{array} \right]\text{.}\)</span> Find <span class="process-math">\(\det(A)\)</span> by hand. What does this mean about the matrix <span class="process-math">\(A\text{?}\)</span> Can you confirm this with other methods?</p></article><article class="task exercise-like" id="task-958"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-2892">One of the eigenvalues of <span class="process-math">\(A=\left[ \begin{array}{cc} 1\amp 3 \\ 2\amp 2 \end{array} \right]\)</span> is <span class="process-math">\(\lambda=4\text{.}\)</span> Recall that we can rewrite the matrix equation <span class="process-math">\(A\vx=4\vx\)</span> in the form <span class="process-math">\((A-4I_2) \vx = \vzero\text{.}\)</span> What must be true about <span class="process-math">\(A-4I_2\)</span> in order for 4 to be an eigenvalue of <span class="process-math">\(A\text{?}\)</span> How does this relate to <span class="process-math">\(\det(A-4I_2)\text{?}\)</span></p></article><article class="task exercise-like" id="task-959"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-2893">Another eigenvalue of <span class="process-math">\(A=\left[ \begin{array}{cc} 1\amp 3 \\ 2\amp 2 \end{array} \right]\)</span> is <span class="process-math">\(\lambda=-1\text{.}\)</span> What must be true about <span class="process-math">\(A+I_2\)</span> in order for <span class="process-math">\(-1\)</span> to be an eigenvalue of <span class="process-math">\(A\text{?}\)</span> How does this relate to <span class="process-math">\(\det(A+I_2)\text{?}\)</span></p></article><article class="task exercise-like" id="task-960"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-2894">To find the eigenvalues of the matrix <span class="process-math">\(A=\left[ \begin{array}{cc} 3\amp 2\\2\amp 6 \end{array} \right]\text{,}\)</span> we rewrite the equation <span class="process-math">\(A \vx = \lambda \vx\)</span> as <span class="process-math">\((A - \lambda I_2) \vx = \vzero\text{.}\)</span> The coefficient matrix of this last system has the form <span class="process-math">\(A-\lambda I_2 = \left[ \begin{array}{cc} 3-\lambda \amp 2 \\ 2\amp 6-\lambda \end{array} \right]\text{.}\)</span> The determinant of this matrix is a quadratic expression in <span class="process-math">\(\lambda\text{.}\)</span> Since the eigenvalues will occur when the determinant is 0, we need to solve a quadratic equation. Find the resulting eigenvalues. (Note: One of the eigenvalues is 2.)</p></article><article class="task exercise-like" id="task-961"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-2895">Can you explain why a <span class="process-math">\(2\times 2\)</span> matrix can have at most two eigenvalues?</p></article></article></section><section class="section" id="sec_det_square"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Determinant of a Square Matrix</span>
</h3>
<p id="p-2896">Around 1900 or so determinants were deemed much more important than they are today. In fact, determinants were used even before matrices. According to Tucker<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-33" id="fn-33"><sup> 33 </sup></a> determinants (not matrices) developed out of the study of coefficients of systems of linear equations and were used by Leibniz 150 years before the term matrix was coined by J. J. Sylvester in 1848. Even though determinants are not as important as they once were, the determinant of a matrix is still a useful quantity. We saw in <a href="" class="xref" data-knowl="./knowl/pa_4_a.html" title="Preview Activity 17.1">Preview Activity 17.1</a> that the determinant of a matrix tells us if the matrix is invertible and how it can help us find eigenvalues. In this section, we will see how to find the determinant of any size matrix and how to use this determinant to find the eigenvalues.</p>
<p id="p-2897">The determinant of a <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp b \\ c\amp d \end{array}  \right]\)</span> is <span class="process-math">\(\det(A)=ad-bc\text{.}\)</span> The matrix <span class="process-math">\(A\)</span> is invertible if and only if <span class="process-math">\(\det(A) \neq 0\text{.}\)</span> We will use a recursive approach to find the determinants of larger size matrices building from the <span class="process-math">\(2\times 2\)</span> determinants. We present the result in the <span class="process-math">\(3 \times 3\)</span> case here — a more detailed analysis can be found at the end of this section.</p>
<p id="p-2898">To find the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(A = \left[ \begin{array}{ccc} a_{11}\amp a_{12}\amp a_{13} \\ a_{21}\amp a_{22}\amp a_{23}\\ a_{31}\amp a_{32}\amp a_{33} \end{array}  \right]\text{,}\)</span> we will use the determinants of three <span class="process-math">\(2\times 2\)</span> matrices. More specifically, the determinant of <span class="process-math">\(A\text{,}\)</span> denoted <span class="process-math">\(\det(A)\)</span> is the quantity</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_det_3by3">
\begin{equation}
a_{11} \det\left(\left[ \begin{array}{cc} a_{22}\amp a_{23} \\ a_{32}\amp a_{33} \end{array}  \right] \right)- a_{12} \det \left(\left[ \begin{array}{cc} a_{21}\amp a_{23} \\ a_{31}\amp a_{33} \end{array}  \right] \right) + a_{13} \det \left(\left[ \begin{array}{cc} a_{21}\amp a_{22} \\ a_{31}\amp a_{32} \end{array}  \right] \right)\text{.}\tag{17.1}
\end{equation}
</div>
<p id="p-2899">This sum is called a <dfn class="terminology">cofactor expansion</dfn> of the determinant of <span class="process-math">\(A\text{.}\)</span> The smaller matrices in this expansion are obtained by deleting certain rows and columns of the matrix <span class="process-math">\(A\text{.}\)</span> In general, when finding the determinant of an <span class="process-math">\(n\times n\)</span> matrix, we find determinants of <span class="process-math">\((n-1)\times (n-1)\)</span> matrices, which we can again reduce to smaller matrices to calculate.</p>
<p id="p-2900">We will use the specific matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_det_3by3.html">
\begin{equation*}
A = \left[ \begin{array}{ccc} 1 \amp  2 \amp  0 \\ 1 \amp  4 \amp  3 \\ 2 \amp  2 \amp  1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">as an example in illustrating the cofactor expansion method in general.</p>
<ul class="disc">
<li id="li-509"><p id="p-2901">We first pick a row or column of <span class="process-math">\(A\text{.}\)</span> We will pick the first row of <span class="process-math">\(A\)</span> for this example.</p></li>
<li id="li-510">
<p id="p-2902">For each entry in the row (or column) we choose, in this case the first row, we will calculate the determinant of a smaller matrix obtained by removing the row and the column the entry is in. Let <span class="process-math">\(A_{ij}\)</span> be the smaller matrix found by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A\text{.}\)</span> For entry <span class="process-math">\(a_{11}\text{,}\)</span> we find the matrix <span class="process-math">\(A_{11}\)</span> obtained by removing first row and first column:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A_{11} = \left[ \begin{array}{cc} 4 \amp  3 \\ 2 \amp  1 \end{array}  \right]\,\text{.}
\end{equation*}
</div>
<p class="continuation">For entry <span class="process-math">\(a_{12}\text{,}\)</span> we find</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A_{12} = \left[ \begin{array}{cc} 1 \amp  3 \\ 2 \amp  1 \end{array}  \right]\,\text{.}
\end{equation*}
</div>
<p class="continuation">Finally, for entry <span class="process-math">\(a_{13}\text{,}\)</span> we find</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A_{13} = \left[ \begin{array}{cc} 1 \amp  4 \\ 2 \amp  2 \end{array}  \right] \,\text{.}
\end{equation*}
</div>
</li>
<li id="li-511">
<p id="p-2903">Notice that in the <span class="process-math">\(3 \times 3\)</span> determinant formula in <a href="" class="xref" data-knowl="./knowl/eq_det_3by3.html" title="Equation 17.1">(17.1)</a> above, the middle term had a (-) sign. The signs of the terms in the cofactor expansion alternate within each row and each column. More specifically, the sign of a term in the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column is <span class="process-math">\((-1)^{i+j}\text{.}\)</span> We then obtain the following pattern of the signs within each row and column:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_det_3by3.html">
\begin{equation*}
\left[ \begin{array}{cccc} + \amp  - \amp  + \amp  \cdots \\ - \amp  + \amp  - \amp  \cdots \\ + \amp  - \amp  + \amp  \cdots \\ \vdots \amp  \amp  \amp \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">In particular, the sign factor for <span class="process-math">\(a_{11}\)</span> is <span class="process-math">\((-1)^{1+1}=1\text{,}\)</span> for <span class="process-math">\(a_{12}\)</span> is <span class="process-math">\((-1)^{1+2}=-1\text{,}\)</span> and for <span class="process-math">\(a_{13}\)</span> is <span class="process-math">\((-1)^{1+3}=1\text{.}\)</span></p>
</li>
<li id="li-512">
<p id="p-2904">For each entry <span class="process-math">\(a_{ij}\)</span> in the row (or column) of <span class="process-math">\(A\)</span> we chose, we multiply the entry <span class="process-math">\(a_{ij}\)</span> by the determinant of <span class="process-math">\(A_{ij}\)</span> and the sign <span class="process-math">\((-1)^{i+j}\text{.}\)</span> In this case, we obtain the following numbers</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{11} (-1)^{1+1} \det(A_{11})  = 1 \det \left[ \begin{array}{cc} 4 \amp  3 \\ 2 \amp  1 \end{array}  \right] = 1(4-6)=-2
\end{equation*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{12} (-1)^{1+2} \det(A_{12}) = -2 \det \left[ \begin{array}{cc} 1 \amp  3 \\ 2 \amp  1 \end{array}  \right] = -2(1-6)=10
\end{equation*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{13} (-1)^{1+3} \det(A_{13}) = 0
\end{equation*}
</div>
<p class="continuation">Note that in the last calculation, since <span class="process-math">\(a_{13}=0\text{,}\)</span> we did not have to evaluate the rest of the terms.</p>
</li>
<li id="li-513">
<p id="p-2905">Finally, we find the determinant by adding all these values:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-115">
\begin{align*}
\det(A) \amp = a_{11} (-1)^{1+1} \det(A_{11}) + a_{12} (-1)^{1+2} \det(A_{12})\\
\amp \qquad + a_{13} (-1)^{1+3} \det(A_{13})\\
\amp = 8\text{.}
\end{align*}
</div>
</li>
</ul></section><section class="section" id="sec_cofactors"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Cofactors</span>
</h3>
<p id="p-2906">We will now define the determinant of a general <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> in terms of a cofactor expansion as we did in the <span class="process-math">\(3 \times 3\)</span> case. To do so, we need some notation and terminology.</p>
<ul class="disc">
<li id="li-514"><p id="p-2907">We let <span class="process-math">\(A_{ij}\)</span> be the submatrix of <span class="process-math">\(A = [a_{ij}]\)</span> found by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A\text{.}\)</span> The determinant of <span class="process-math">\(A_{ij}\)</span> is called the <span class="process-math">\(ij\)</span>th <dfn class="terminology">minor</dfn> of <span class="process-math">\(A\)</span> or the minor corresponding to the entry <span class="process-math">\(a_{ij}\text{.}\)</span></p></li>
<li id="li-515">
<p id="p-2908">Notice that in the <span class="process-math">\(3 \times 3\)</span> case, we used the opposite of the 1,2 minor in the sum. It will be the case that the terms in the cofactor expansion will alternate in sign. We can make the signs in the sum alternate by taking <span class="process-math">\(-1\)</span> to an appropriate power. As a result, we define the <span class="process-math">\(ij\)</span>th <dfn class="terminology">cofactor</dfn> <span class="process-math">\(C_{ij}\)</span> of <span class="process-math">\(A\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
C_{ij} = (-1)^{i+j} \det\left(A_{ij}\right)\text{.}
\end{equation*}
</div>
</li>
<li id="li-516"><p id="p-2909">Finally, we define the determinant of <span class="process-math">\(A\text{.}\)</span></p></li>
</ul>
<article class="definition definition-like" id="definition-38"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">17.2</span><span class="period">.</span>
</h4>
<p id="p-2910">If <span class="process-math">\(A=[a_{ij}]\)</span> is an <span class="process-math">\(n \times n\)</span> matrix, the <dfn class="terminology">determinant</dfn> of <span class="process-math">\(A\)</span> is the scalar</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13} + \cdots + a_{1n}C_{1n}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(C_{ij}= (-1)^{i+j} \det(A_{ij})\)</span> is the <span class="process-math">\(ij\)</span>-cofactor of <span class="process-math">\(A\)</span> and <span class="process-math">\(A_{ij}\)</span> is the matrix obtained by removing row <span class="process-math">\(i\)</span> and column <span class="process-math">\(j\)</span> of matrix <span class="process-math">\(A\text{.}\)</span></p></article><p id="p-2911">This method for computing determinants is called the <dfn class="terminology">cofactor expansion</dfn> or <dfn class="terminology">Laplace expansion</dfn> of <span class="process-math">\(A\)</span> along the 1st row. The cofactor expansion reduces the computation of the determinant of an <span class="process-math">\(n \times n\)</span> matrix to <span class="process-math">\(n\)</span> computations of determinants of <span class="process-math">\((n-1) \times (n-1)\)</span> matrices. These smaller matrices can be reduced again using cofactor expansions, so it can be a long and grueling process for large matrices. It turns out that we can actually take this expansion along any row or column of the matrix (a proof of this fact is given in <a href="chap_det_properties.html" class="internal" title="Section 22: Properties of Determinants">Section 22</a>). For example, the cofactor expansion along the 2nd row is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/chap_det_properties.html">
\begin{equation*}
\det(A) = a_{21}C_{21} + a_{22}C_{22} + \cdots + a_{2n}C_{2n}
\end{equation*}
</div>
<p class="continuation">and along the 3rd column the formula is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/chap_det_properties.html">
\begin{equation*}
\det(A) = a_{13}C_{13} + a_{23}C_{23} + \cdots + a_{n3}C_{n3}\text{.}
\end{equation*}
</div>
<p id="p-2912">Note that when finding a cofactor expansion, choosing a row or column with many zeros makes calculations easier.</p>
<article class="activity project-like" id="act_4_a_1"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">17.2</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-962"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-2913">Let <span class="process-math">\(A = \left[ \begin{array}{rcr} 1\amp 2\amp -1 \\ -2\amp 0\amp 4 \\ 6\amp 3\amp 0 \end{array} \right]\text{.}\)</span> Use the cofactor expansion along the first row to calculate the determinant of <span class="process-math">\(A\)</span> by hand.</p></article><article class="task exercise-like" id="task-963"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-2914">Calculate <span class="process-math">\(\det(A)\)</span> by using a cofactor expansion along the second row where <span class="process-math">\(A = \left[ \begin{array}{ccc} 1 \amp 4 \amp 2 \\ 0 \amp 2 \amp 0 \\ 2 \amp 5 \amp 3 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-964"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-2915">Calculate the determinant of <span class="process-math">\(\left[ \begin{array}{crr} 1\amp -2\amp 3 \\ 0\amp 4\amp -3 \\ 0\amp 0\amp 8 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-965"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-2916">Which determinant property can be used to calculate the determinant in part (c)? Explain how. (Determinant properties are included below for easy reference.)</p></article><article class="task exercise-like" id="task-966"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-2917">Consider the matrix <span class="process-math">\(A=\left[ \begin{array}{ccc} 1 \amp 1 \amp 2 \\ 0 \amp 2 \amp 1 \\ 1 \amp 2 \amp 2 \end{array} \right]\text{.}\)</span> Let <span class="process-math">\(B\)</span> be the matrix which results when <span class="process-math">\(c\)</span> times row 1 is added to row 2 of <span class="process-math">\(A\text{.}\)</span> Evaluate the determinant of <span class="process-math">\(B\)</span> by hand to check that it is equal to the determinant of <span class="process-math">\(A\text{,}\)</span> which verifies one other determinant property (in a specific case).</p></article></article><p id="p-2918">As with any new idea, like the determinant, we must ask what properties are satisfied. We state the following theorem without proof for the time being. For the interested reader, the proof of many of these properties is given in <a href="chap_det_properties.html" class="internal" title="Section 22: Properties of Determinants">Section 22</a> and others in the exercises.</p>
<article class="theorem theorem-like" id="thm_determinant_properties"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">17.3</span><span class="period">.</span>
</h4>
<p id="p-2919">Given <span class="process-math">\(n\times n\)</span> matrices <span class="process-math">\(A, B\text{,}\)</span> the following hold:</p>
<ol class="decimal">
<li id="li-517"><p id="p-2920"><span class="process-math">\(\det (AB) = \det (A) \cdot \det (B)\text{,}\)</span> and in particular <span class="process-math">\(\det (A^k) = (\det A)^k\)</span> for any positive integer <span class="process-math">\(k\text{.}\)</span></p></li>
<li id="li-518"><p id="p-2921"><span class="process-math">\(\det (A^{\tr}) = \det (A)\text{.}\)</span></p></li>
<li id="li-519"><p id="p-2922"><span class="process-math">\(A\)</span> is invertible if and only if <span class="process-math">\(\det (A) \neq 0\text{.}\)</span></p></li>
<li id="li-520"><p id="p-2923">If <span class="process-math">\(A\)</span> is invertible, then <span class="process-math">\(\det (A^{-1}) = (\det A)^{-1}\text{.}\)</span></p></li>
<li id="li-521"><p id="p-2924">For a <span class="process-math">\(2\times 2\)</span> matrix <span class="process-math">\(A=\begin{bmatrix}a \amp b \\ c \amp d \end{bmatrix}\text{,}\)</span> <span class="process-math">\(\det (A) = ad-bc\text{.}\)</span></p></li>
<li id="li-522"><p id="p-2925">If <span class="process-math">\(A\)</span> is upper/lower triangular, then <span class="process-math">\(\det (A)\)</span> is the product of the entries on the diagonal.</p></li>
<li id="li-523"><p id="p-2926">The determinant of a matrix is the product of the eigenvalues, with each eigenvalue repeated as many times as its multiplicity.</p></li>
<li id="li-524">
<p id="p-2927">Effect of row operations:</p>
<ul class="disc">
<li id="li-525"><p id="p-2928">Adding a multiple of a row to another does NOT change the determinant of the matrix.</p></li>
<li id="li-526"><p id="p-2929">Multiplying a row by a constant multiplies the determinant by the same constant.</p></li>
<li id="li-527"><p id="p-2930">Row swapping multiplies the determinant by <span class="process-math">\((-1)\text{.}\)</span></p></li>
</ul>
</li>
<li id="li-528"><p id="p-2931">If the row echelon form <span class="process-math">\(U\)</span> of <span class="process-math">\(A\)</span> is obtained by adding multiples of one row to another, and row swapping, then <span class="process-math">\(\det (A)\)</span> is equal to <span class="process-math">\(\det (U)\)</span> multiplied by <span class="process-math">\((-1)^r\)</span> where <span class="process-math">\(r\)</span> is the number of row swappings done during the row reduction.</p></li>
</ol></article><p id="p-2932">Note that if we were to find the determinant of a <span class="process-math">\(4\times 4\)</span> matrix using the cofactor method, we will calculate determinants of 4 matrices of size <span class="process-math">\(3\times 3\text{,}\)</span> each of which will require 3 determinant calculations again. So, we will need a total of 12 calculations of determinants of <span class="process-math">\(2\times 2\)</span> matrices. That is a lot of calculations. There are other, more efficient, methods for calculating determinants. For example, we can row reduce the matrix, keeping track of the effect that each row operation has on the determinant.</p></section><section class="section" id="sec_det_3by3"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</span>
</h3>
<p id="p-2933">Earlier we defined the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix. In this section we endeavor to understand the motivation behind that definition.</p>
<p id="p-2934">We will repeat the process we went through in the <span class="process-math">\(2 \times 2\)</span> case to see how to define the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix. Let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A =  \left[ \begin{array}{ccc} a_{11}\amp a_{12}\amp a_{13} \\ a_{21}\amp a_{22}\amp a_{23}\\ a_{31}\amp a_{32}\amp a_{33} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-2935">To find the inverse of <span class="process-math">\(A\)</span> we augment <span class="process-math">\(A\)</span> by the <span class="process-math">\(3 \times 3\)</span> identity matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[A \ | \ I_3] = \left[ \begin{array}{cccccc} a_{11}\amp a_{12}\amp a_{13}\amp 1\amp 0\amp 0 \\ a_{21}\amp a_{22}\amp a_{23}\amp 0\amp 1\amp 0 \\ a_{31}\amp a_{32}\amp a_{33}\amp 0\amp 0\amp 1 \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">and row reduce the matrix (using appropriate technology) to obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{rrrrrr} 1\amp 0\amp 0\amp \ds \frac{a_{33}a_{22}-a_{32}a_{23}}{d}\amp  \ds -\frac{a_{33}a_{12}-a_{32}a_{13}}{d}\amp  \ds \frac{-a_{13}a_{22}+a_{12}a_{23}}{d} \\ 0\amp 1\amp 0\amp  \ds -\frac{a_{33}a_{21}-a_{31}a_{23}}{d}\amp  \ds \frac{a_{33}a_{11}-a_{31}a_{13}}{d}\amp  \ds -\frac{a_{23}a_{11}-a_{21}a_{13}}{d} \\ 0\amp 0\amp 1\amp  \ds \frac{-a_{31}a_{22}+a_{32}a_{21}}{d}\amp  \ds -\frac{a_{32}a_{11}-a_{31}a_{12}}{d}\amp  \ds \frac{a_{22}a_{11}-a_{21}a_{12}}{d} \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_4_a_3by3_det">
\begin{equation}
\begin{aligned}d = a_{33}a_{11}a_{22}\amp -a_{33}a_{21}a_{12}-a_{31}a_{13}a_{22} \\ \amp -a_{32}a_{11}a_{23}+a_{32}a_{21}a_{13}+a_{31}a_{12}a_{23}. \end{aligned}\tag{17.2}
\end{equation}
</div>
<p id="p-2936">In this case, we can see that the inverse of the <span class="process-math">\(3 \times 3\)</span> matrix <span class="process-math">\(A\)</span> will be defined if and only if <span class="process-math">\(d \neq 0\text{.}\)</span> So, in the <span class="process-math">\(3 \times 3\)</span> case the determinant of <span class="process-math">\(A\)</span> will be given by the value of <span class="process-math">\(d\)</span> in Equation <a href="" class="xref" data-knowl="./knowl/eq_4_a_3by3_det.html" title="Equation 17.2">(17.2)</a>. What remains is for us to see how this is related to determinants of <span class="process-math">\(2 \times 2\)</span> sub-matrices of <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-2937">To start, we collect all terms involving <span class="process-math">\(a_{11}\)</span> in <span class="process-math">\(d\text{.}\)</span> A little algebra shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11} \left( a_{33} a_{22} - a_{32} a_{23} \right) - a_{33} a_{21} a_{12} - a_{31} a_{13} a_{22} + a_{32}a_{21}a_{13} + a_{31} a_{12} a_{23}\text{.}
\end{equation*}
</div>
<p id="p-2938">Now let's collect the remaining terms involving <span class="process-math">\(a_{12}\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11} \left( a_{33} a_{22} - a_{32} a_{23} \right) - a_{12} \left(a_{33} a_{21} - a_{31} a_{23} \right)  - a_{31} a_{13} a_{22} + a_{32}a_{21}a_{13}\text{.}
\end{equation*}
</div>
<p id="p-2939">Finally, we collect the terms involving <span class="process-math">\(a_{13}\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11} \left( a_{33} a_{22} - a_{32} a_{23} \right) - a_{12} \left(a_{33} a_{21} - a_{31} a_{23} \right) + a_{13} \left(a_{32} a_{21} - a_{31} a_{22} \right)\text{.}
\end{equation*}
</div>
<p id="p-2940">Now we can connect the determinant of <span class="process-math">\(A\)</span> to determinants of <span class="process-math">\(2 \times 2\)</span> sub-matrices of <span class="process-math">\(A\text{.}\)</span></p>
<ul class="disc">
<li id="li-529">
<p id="p-2941">Notice that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{33} a_{22} - a_{32} a_{23}
\end{equation*}
</div>
<p class="continuation">is the determinant of the <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(\left[ \begin{array}{cc} a_{22}\amp a_{23} \\ a_{32}\amp a_{33} \end{array}  \right]\)</span> obtained from <span class="process-math">\(A\)</span> by deleting the first row and first column.</p>
</li>
<li id="li-530">
<p id="p-2942">Similarly, the expression</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{33} a_{21} - a_{31} a_{23}
\end{equation*}
</div>
<p class="continuation">is the determinant of the <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(\left[ \begin{array}{cc} a_{21}\amp a_{23} \\ a_{31}\amp a_{33} \end{array}  \right]\)</span> obtained from <span class="process-math">\(A\)</span> by deleting the first row and second column.</p>
</li>
<li id="li-531">
<p id="p-2943">Finally, the expression</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
a_{32} a_{21} - a_{31} a_{22}
\end{equation*}
</div>
<p class="continuation">is the determinant of the <span class="process-math">\(2 \times 2\)</span> matrix <span class="process-math">\(\left[ \begin{array}{cc} a_{21}\amp a_{22} \\ a_{31}\amp a_{32} \end{array}  \right]\)</span> obtained from <span class="process-math">\(A\)</span> by deleting the first row and third column.</p>
</li>
</ul>
<p id="p-2944">Putting this all together gives us formula <a href="" class="xref" data-knowl="./knowl/eq_det_3by3.html" title="Equation 17.1">(17.1)</a> for the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix as we defined earlier.</p></section><section class="section" id="sec_det_remember"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Two Devices for Remembering Determinants</span>
</h3>
<p id="p-2945">There are useful ways to remember how to calculate the formulas for determinants of <span class="process-math">\(2 \times 2\)</span> and <span class="process-math">\(3 \times 3\)</span> matrices. In the <span class="process-math">\(2 \times 2\)</span> case of <span class="process-math">\(A = \left[ \begin{array}{cc} a_{11}\amp a_{12} \\ a_{21}\amp a_{22} \end{array}  \right]\text{,}\)</span> we saw that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
|A| = a_{11}a_{22} - a_{21}a_{22}\text{.}
\end{equation*}
</div>
<p id="p-2946">This makes <span class="process-math">\(|A|\)</span> the product of the diagonal elements <span class="process-math">\(a_{11}\)</span> and <span class="process-math">\(a_{22}\)</span> minus the product of the off-diagonal elements <span class="process-math">\(a_{12}\)</span> and <span class="process-math">\(a_{21}\text{.}\)</span> We can visualize this in an array by drawing arrows across the diagonal and off-diagonal, with a plus sign on the diagonal arrow indicting that we add the product of the diagonal elements and a minus sign on the off-diagonal arrow indicating that we subtract the product of the off-diagonal elements as shown in <a href="" class="xref" data-knowl="./knowl/F_2by2_determinant.html" title="Figure 17.4">Figure 17.4</a>.</p>
<figure class="figure figure-like" id="F_2by2_determinant"><div class="image-box" style="width: 25%; margin-left: 37.5%; margin-right: 37.5%;"><img src="external/det_remem_2by2.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.4<span class="period">.</span></span><span class="space"> </span>A diagram to remember the <span class="process-math">\(2 \times 2\)</span> determinant.</figcaption></figure><p id="p-2947">We can do a similar thing for the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix. In this case, we extend the <span class="process-math">\(3 \times 3\)</span> array to a <span class="process-math">\(3 \times 5\)</span> array by adjoining the first two columns onto the matrix. We then add the products along the diagonals going from left to right and subtract the products along the diagonals going from right to left as indicated in <a href="" class="xref" data-knowl="./knowl/F_3by3_determinant.html" title="Figure 17.5">Figure 17.5</a>.</p>
<figure class="figure figure-like" id="F_3by3_determinant"><div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="external/det_remem_3by3.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.5<span class="period">.</span></span><span class="space"> </span>A diagram to remember the <span class="process-math">\(3 \times 3\)</span> determinant.</figcaption></figure></section><section class="section" id="sec_det_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-2948">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-34"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">17.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-270">
<p id="p-2949">For each of the following</p>
<ul class="disc">
<li id="li-532"><p id="p-2950">Identify the sub-matrices <span class="process-math">\(A_{1,j}\)</span></p></li>
<li id="li-533"><p id="p-2951">Determine the cofactors <span class="process-math">\(C_{1,j}\text{.}\)</span></p></li>
<li id="li-534"><p id="p-2952">Use the cofactor expansion to calculate the determinant.</p></li>
</ul>
</div>
<article class="task exercise-like" id="task-967"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-2953"><span class="process-math">\(A = \left[ \begin{array}{ccr} 3\amp 6\amp 2 \\ 0\amp 4\amp -1 \\ 5\amp 0\amp 1 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-107">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-2954">With a <span class="process-math">\(3 \times 3\)</span> matrix, we will find the sub-matrices <span class="process-math">\(A_{11}\text{,}\)</span> <span class="process-math">\(A_{12}\text{,}\)</span> and <span class="process-math">\(A_{13}\text{.}\)</span> Recall that <span class="process-math">\(A_{ij}\)</span> is the sub-matrix of <span class="process-math">\(A\)</span> obtained by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A\text{.}\)</span> Thus,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A_{11} =  \left[ \begin{array}{cr} 4\amp -1 \\ 0\amp 1 \end{array}  \right] \ A_{12} =  \left[ \begin{array}{cr} 0\amp -1 \\ 5\amp 1 \end{array}  \right] \ \text{ and } A_{13} =  \left[ \begin{array}{cc} 0\amp 4 \\ 5\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p class="continuation">The <span class="process-math">\(ij\)</span>th cofactor is <span class="process-math">\(C_{ij} = (-1)^{i+j}\det(A_{ij})\text{,}\)</span> so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-116">
\begin{align*}
C_{11} \amp = (-1)^2 \left[ \begin{array}{cr} 4\amp -1\\
0\amp 1  \end{array} \right] = 4\\
C_{12} \amp = (-1)^3 \left[ \begin{array}{cr} 0\amp -1\\
5\amp 1  \end{array} \right] = -5\\
C_{13} \amp = (-1)^4 \left[ \begin{array}{cc} 0\amp 4\\
5\amp 0  \end{array} \right] = -20\text{.}
\end{align*}
</div>
<p class="continuation">Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13} = (3)(4) +(6)(-5) +(2)(-20) = -58\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-968"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-2955"><span class="process-math">\(A = \left[ \begin{array}{rrcr} 3\amp 0\amp 1\amp 1 \\ 2\amp 1\amp 2\amp 1 \\ 1\amp -2\amp 2\amp -1 \\ -3\amp 2\amp 3\amp 1 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-108">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-2956">With a <span class="process-math">\(4 \times 4\)</span> matrix, we will find the sub-matrices <span class="process-math">\(A_{11}\text{,}\)</span> <span class="process-math">\(A_{12}\text{,}\)</span> <span class="process-math">\(A_{13}\text{,}\)</span> and <span class="process-math">\(A_{14}\text{.}\)</span> We see that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-117">
\begin{align*}
A_{11} \amp = \left[ \begin{array}{rcr}  1\amp 2\amp 1\\
-2\amp 2\amp -1\\
2\amp 3\amp 1  \end{array} \right]\\
A_{12} \amp = \left[ \begin{array}{rcr}  2\amp 2\amp 1\\
1\amp 2\amp -1\\
-3\amp 3\amp 1  \end{array} \right]\\
A_{13} \amp = \left[ \begin{array}{rrr}  2\amp 1\amp 1\\
1\amp -2\amp -1\\
-3\amp 2\amp 1  \end{array} \right]\\
A_{14} \amp = \left[ \begin{array}{rrc}  2\amp 1\amp 2\\
1\amp -2\amp 2\\
-3\amp 2\amp 3  \end{array} \right]\text{.}
\end{align*}
</div>
<p class="continuation">To calculate the <span class="process-math">\(ij\)</span>th cofactor <span class="process-math">\(C_{ij} = (-1)^{i+j}\det(A_{ij})\text{,}\)</span> we need to calculate the determinants of the <span class="process-math">\(A_{1j}\text{.}\)</span> Using the device for calculating the determinant of a <span class="process-math">\(3 \times 3\)</span> matrix we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-118">
\begin{align*}
\det(A_{11}) \amp =\det\left( \left[ \begin{array}{rrr}  1\amp 2\amp 1\\
-2\amp 2\amp -1\\
2\amp 3\amp 1  \end{array} \right] \right)\\
\amp = (1)(2)(1)+(2)(-1)(2)+(1)(-2)(3)\\
\amp \qquad - (1)(2)(2)-(1)(-1)(3)-(2)(-2)(1)\\
\amp = -5\text{,}
\end{align*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-119">
\begin{align*}
\det(A_{12}) \amp = \det\left(\left[ \begin{array}{rcr}  2\amp 2\amp 1\\
1\amp 2\amp -1\\
-3\amp 3\amp 1  \end{array} \right] \right)\\
\amp = (2)(2)(1)+(2)(-1)(-3)+(1)(1)(3)\\
\amp \qquad - (1)(2)(-3)-(2)(-1)(3)-(2)(1)(1)\\
\amp = 23\text{,}
\end{align*}
</div>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-120">
\begin{align*}
\det(A_{13}) \amp =  \det\left(\left[ \begin{array}{rrr}  2\amp 1\amp 1\\
1\amp -2\amp -1\\
-3\amp 2\amp 1  \end{array} \right] \right)\\
\amp = (2)(-2)(1)+(1)(-1)(-3)+(1)(1)(2)\\
\amp \qquad - (1)(-2)(-3)-(2)(-1)(2)-(1)(1)(1)\\
\amp = -2\text{,}
\end{align*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-121">
\begin{align*}
\det(A_{14}) \amp =  \det\left(\left[ \begin{array}{rrc}  2\amp 1\amp 2\\
1\amp -2\amp 2\\
-3\amp 2\amp 3  \end{array} \right] \right)\\
\amp = (2)(-2)(3)+(1)(2)(-3)+(2)(1)(2)\\
\amp \qquad - (2)(-2)(-3)-(2)(2)(2)-(1)(1)(3)\\
\amp = -37\text{.}
\end{align*}
</div>
<p class="continuation">Then</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-122">
\begin{align*}
C_{11} \amp = (-1)^2 \det(A_{11}) = -5\\
C_{12} \amp = (-1)^3 \det(A_{12})= -23\\
C_{13} \amp = (-1)^4 \det(A_{13}) = -2\\
C_{14} \amp = (-1)^5 \det(A_{13}) = 37
\end{align*}
</div>
<p class="continuation">and so</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-123">
\begin{align*}
\det(B) \amp = b_{11}C_{11} + b_{12}C_{12} + b_{13}C_{13} + b_{14}C_{14}\\
\amp = (3)(-5) +(0)(-23) +(1)(-2)+ (1)(37)\\
\amp = 20\text{.}
\end{align*}
</div>
</div></article></article><article class="example example-like" id="example-35"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">17.7</span><span class="period">.</span>
</h4>
<p id="p-2957">Show that for any <span class="process-math">\(2 \times 2\)</span> matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(AB) = \det(A) \det(B)\text{.}
\end{equation*}
</div>
<div class="solution solution-like" id="solution-109">
<h4 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h4>
<p id="p-2958">Let <span class="process-math">\(A = \left[ \begin{array}{cc} a_{11}\amp a_{12} \\ a_{21}\amp a_{22} \end{array}  \right]\)</span> and <span class="process-math">\(B = \left[ \begin{array}{cc} b_{11}\amp b_{12} \\ b_{21}\amp b_{22} \end{array}  \right]\text{.}\)</span> Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = \left[ \begin{array}{cc} a_{11}b_{11}+a_{12}b_{21}\amp a_{11}b_{12}+a_{12}b_{22} \\ a_{21}b_{11}+a_{22}b_{21}\amp a_{21}b_{12}+a_{22}b_{22} \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-2959">So</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-124">
\begin{align*}
\det(AB) \amp = (a_{11}b_{11}+a_{12}b_{21})(a_{21}b_{12}+a_{22}b_{22})\\
\amp  \qquad   - (a_{11}b_{12}+a_{12}b_{22})(a_{21}b_{11}+a_{22}b_{21})\\
\amp = (a_{11}b_{11}a_{21}b_{12} + a_{11}b_{11}a_{22}b_{22} + a_{12}b_{21}a_{21}b_{12} + a_{12}b_{21}a_{22}b_{22})\\
\amp  \qquad - (a_{11}b_{12}a_{21}b_{11} + a_{11}b_{12}a_{22}b_{21} +  a_{12}b_{22}a_{21}b_{11} + a_{12}b_{22}a_{22}b_{21})\\
\amp = a_{11}b_{11}a_{22}b_{22} + a_{12}b_{21}a_{21}b_{12} - a_{11}b_{12}a_{22}b_{21} - a_{12}b_{22}a_{21}b_{11}\text{.}
\end{align*}
</div>
<p id="p-2960">Also,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-125">
\begin{align*}
\det(A) \det(B) \amp = (a_{11}a_{22}-a_{12}a_{21})(b_{11}b_{22}-b_{12}b_{21})\\
\amp = a_{11}a_{22}b_{11}b_{22} - a_{11}a_{22}b_{12}b_{21} - a_{12}a_{21}b_{11}b_{22} + a_{12}a_{21}b_{12}b_{21}\text{.}
\end{align*}
</div>
<p id="p-2961">We conclude that <span class="process-math">\(\det(AB) = \det(A) \det(B)\)</span> if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(2 \times 2\)</span> matrices.</p>
</div></article></section><section class="section" id="sec_det_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-535">
<p id="p-2962">The determinant of an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A = [a_{ij}]\)</span> is found by taking the cofactor expansion of <span class="process-math">\(A\)</span> along the first row. That is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(A) = a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13} + \cdots + a_{1n}C_{1n}\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<ul class="circle">
<li id="li-536"><p id="p-2963"><span class="process-math">\(A_{ij}\)</span> is the sub-matrix of <span class="process-math">\(A\)</span> found by deleting the <span class="process-math">\(i\)</span>th row and <span class="process-math">\(j\)</span>th column of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-537"><p id="p-2964"><span class="process-math">\(C_{ij} = (-1)^{i+j} \det\left(A_{ij}\right)\)</span> is the <span class="process-math">\(ij\)</span>th <dfn class="terminology">cofactor</dfn> of <span class="process-math">\(A\text{.}\)</span></p></li>
</ul>
</li>
<li id="li-538"><p id="p-2965">The matrix <span class="process-math">\(A\)</span> is invertible if and only if <span class="process-math">\(\det(A) \neq 0\text{.}\)</span></p></li>
</ul></section><section class="exercises" id="sec_det_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-162"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<p id="p-2966">Use the cofactor expansion to explain why multiplying each of the entries of a <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\)</span> by 2 multiplies the determinant of <span class="process-math">\(A\)</span> by 8.</p></article><article class="exercise exercise-like" id="exercise-163"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-2968">Use the determinant criterion to determine for which <span class="process-math">\(c\)</span> the matrix <span class="process-math">\(A=\left[ \begin{array}{crc} 1\amp 1\amp 2\\ 1\amp 0\amp c\\ 2\amp -1\amp 2 \end{array} \right]\)</span> is invertible.</p></article><article class="exercise exercise-like" id="exercise-164"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-271"><p id="p-2969">Let <span class="process-math">\(A\)</span> be a square matrix.</p></div>
<article class="task exercise-like" id="task-969"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-2970">Explain why <span class="process-math">\(\det(A^2) = [\det(A)]^2\)</span></p></article><article class="task exercise-like" id="task-970"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-2972">Expand on the argument from (a) to explain why <span class="process-math">\(\det(A^k) = [\det(A)]^k\)</span> for any positive integer <span class="process-math">\(k\text{.}\)</span></p></article><article class="task exercise-like" id="task-971"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-2974">Suppose that <span class="process-math">\(A\)</span> is an invertible matrix and <span class="process-math">\(k\)</span> is a positive integer. Must <span class="process-math">\(A^k\)</span> be an invertible matrix? Why or why not?</p></article></article><article class="exercise exercise-like" id="exercise-165"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-2976">Let <span class="process-math">\(A\)</span> be an invertible matrix. Explain why <span class="process-math">\(\det(A^{-1})= \dfrac{1}{\det(A)}\)</span> using determinant properties.</p></article><article class="exercise exercise-like" id="exercise-166"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-2977">Simplify the following determinant expression using determinant properties:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det(PA^4P^{-1}A^T(A^{-1})^3)
\end{equation*}
</div></article><article class="exercise exercise-like" id="exercise-167"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-272"><p id="p-2979">Find the eigenvalues of the following matrices. Find a basis for and the dimension of each eigenspace.</p></div>
<article class="task exercise-like" id="task-972"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-2980"><span class="process-math">\(A=\left[ \begin{array}{ccc} 1\amp 1\amp 1\\1\amp 1\amp 1\\1\amp 1\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-973"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-2981"><span class="process-math">\(A=\left[ \begin{array}{ccc} 2\amp 0\amp 3\\0\amp 1\amp 0\\0\amp 1\amp 2 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-168"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-273"><p id="p-2982">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-974"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2983">For any two <span class="process-math">\(n\times n\)</span> matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{,}\)</span> <span class="process-math">\(\det (A+B) = \det A + \det B\text{.}\)</span></p></article><article class="task exercise-like" id="task-975"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2985">For any square matrix <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(\det(-A)= -\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-976"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2986">For any square matrix <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(\det(-A)= \det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-977"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2988">The determinant of a square matrix with all non-zero entries is non-zero.</p></article><article class="task exercise-like" id="task-978"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2989">If the determinant of <span class="process-math">\(A\)</span> is non-zero, then so is the determinant of <span class="process-math">\(A^2\text{.}\)</span></p></article><article class="task exercise-like" id="task-979"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2991">If the determinant of a matrix <span class="process-math">\(A\)</span> is 0, then one of the rows of <span class="process-math">\(A\)</span> is a linear combination of the other rows.</p></article><article class="task exercise-like" id="task-980"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2992">For any square matrix <span class="process-math">\(A\text{,}\)</span> <span class="process-math">\(\det(A^2)&gt;\det(A)\text{.}\)</span></p></article><article class="task exercise-like" id="task-981"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2994">If <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are <span class="process-math">\(n \times n\)</span> matrices and <span class="process-math">\(AB\)</span> is invertible, then <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are invertible.</p></article><article class="task exercise-like" id="task-982"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2995">If <span class="process-math">\(A^2\)</span> is the zero matrix, then the only eigenvalue of <span class="process-math">\(A\)</span> is 0.</p></article><article class="task exercise-like" id="task-983"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2997">If 0 is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> then 0 is an eigenvalue of <span class="process-math">\(AB\)</span> for any <span class="process-math">\(B\)</span> of the same size as <span class="process-math">\(A\text{.}\)</span></p></article><article class="task exercise-like" id="task-984"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-2998">Suppose <span class="process-math">\(A\)</span> is a <span class="process-math">\(3 \times 3\)</span> matrix. Then any three eigenvectors of <span class="process-math">\(A\)</span> will form a basis of <span class="process-math">\(\R^3\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_det_area_vol"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: Area and Volume Using Determinants</span>
</h3>
<p id="p-3000">The approach we will take to connecting area (volume) to the determinant will help shed light on properties of the determinant that we will discuss from an algebraic perspective in a later section. First, we mention some basic properties of area (we focus on area for now, but these same properties are valid for volumes as well). volume). As a shorthand, we denote the area of a region <span class="process-math">\(R\)</span> by <span class="process-math">\(\Area(R)\text{.}\)</span></p>
<ul class="disc">
<li id="li-539"><p id="p-3001">Area cannot be negative.</p></li>
<li id="li-540"><p id="p-3002">If two regions <span class="process-math">\(R_1\)</span> and <span class="process-math">\(R_2\)</span> don't overlap, then the area of the union of the regions is equal to the sum of the areas of the regions. That is, if <span class="process-math">\(R_1 \cap R_2 = \emptyset\text{,}\)</span> then <span class="process-math">\(\Area(R_1 \cup R_2) = \Area(R_1) + \Area(R_2)\text{.}\)</span></p></li>
<li id="li-541">
<p id="p-3003">Area is invariant under translation. That is, if we move a geometric region by the same amount uniformly in a given direction, the area of the original region and the area of the transformed region are the same. A translation of a region is done by just adding a fixed vector to each vector in the region. That is, a translation by a vector <span class="process-math">\(\vv\)</span> is a function <span class="process-math">\(T_{\vv}\)</span> such that the image <span class="process-math">\(T_{\vv}(R)\)</span> of a region <span class="process-math">\(R\)</span> is defined as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T_{\vv}(R) = \{\vr+\vv : \vr \in R\}\text{.}
\end{equation*}
</div>
<p class="continuation">Since area is translation invariant, <span class="process-math">\(\Area(T_{\vv}(R)) = \Area(R)\text{.}\)</span></p>
</li>
<li id="li-542"><p id="p-3004">The area of a one-dimensional object like a line segment is <span class="process-math">\(0\text{.}\)</span></p></li>
</ul>
<p id="p-3005">Now we turn our attention to areas of parallelograms. Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors in <span class="process-math">\(\R^2\text{.}\)</span> The parallelogram <span class="process-math">\(P(\vu,\vv)\)</span> defined by <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> with point <span class="process-math">\(Q\)</span> as basepoint is the set</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P(\vu, \vv) = \{\overrightarrow{OQ}+r \vu + s \vv : 0 \leq r, s \leq 1\}\text{.}
\end{equation*}
</div>
<p id="p-3006">An illustration of such a parallelogram is shown at left in <a href="" class="xref" data-knowl="./knowl/F_parallelograms.html" title="Figure 17.8">Figure 17.8</a>.</p>
<figure class="figure figure-like" id="F_parallelograms"><div class="image-box" style="width: 60%; margin-left: 20%; margin-right: 20%;"><img src="external/4_a_parallelogram_rotated.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.8<span class="period">.</span></span><span class="space"> </span>A parallelogram and a translated, rotated parallelogram.</figcaption></figure><p id="p-3007">If <span class="process-math">\(\vu = [u_1 \ u_2]^{\tr}\)</span> and <span class="process-math">\(\vv = [v_1 \ v_2]^{\tr}\text{,}\)</span> then we will also represent <span class="process-math">\(P(\vu,\vv)\)</span> as <span class="process-math">\(P\left( \left[ \begin{array}{cc}u_1\amp u_2 \\ v_1\amp v_2 \end{array} \right] \right)\text{.}\)</span></p>
<p id="p-3008">Since area is translation and rotation invariant, we can translate our parallelogram by <span class="process-math">\(-\overrightarrow{OQ}\)</span> to place its basepoint at the origin, then rotate by an angle <span class="process-math">\(\theta\)</span> (as shown at left in <a href="" class="xref" data-knowl="./knowl/F_parallelograms.html" title="Figure 17.8">Figure 17.8</a>. This transforms the vector <span class="process-math">\(\vv\)</span> to a vector <span class="process-math">\(\vv'\)</span> and the vector <span class="process-math">\(\vu\)</span> to a vector <span class="process-math">\(\vu'\)</span> as shown at right in <a href="" class="xref" data-knowl="./knowl/F_parallelograms.html" title="Figure 17.8">Figure 17.8</a>. With this in mind we can always assume that our parallelograms have one vertex at the origin, with <span class="process-math">\(\vu\)</span> along the <span class="process-math">\(x\)</span>-axis, and <span class="process-math">\(\vv\)</span> in standard position. Now we can investigate how to calculate the area of a parallelogram.</p>
<article class="project project-like" id="act_parallelogram_area"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">17.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-274">
<p id="p-3009">There are two situations to consider when we want to find the area of a parallelogram determined by vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{,}\)</span> both shown in <a href="" class="xref" data-knowl="./knowl/F_parallelogram_area.html" title="Figure 17.9">Figure 17.9</a>. The parallelogram will be determined by the lengths of these vectors.</p>
<figure class="figure figure-like" id="F_parallelogram_area"><div class="image-box" style="width: 60%; margin-left: 20%; margin-right: 20%;"><img src="external/4_a_parallelogram_area.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.9<span class="period">.</span></span><span class="space"> </span>Parallelograms formed by <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span></figcaption></figure>
</div>
<article class="task exercise-like" id="task-985"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3010">In the situation depicted at left in <a href="" class="xref" data-knowl="./knowl/F_parallelogram_area.html" title="Figure 17.9">Figure 17.9</a>, use geometry to explain why <span class="process-math">\(\Area(P(\vu,\vv)) = h |\vu|\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-20" id="hint-20"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-20"><div class="hint solution-like"><p id="p-3011">What can we say about the triangles <span class="process-math">\(ODB\)</span> and <span class="process-math">\(EAC\text{?}\)</span></p></div></div>
</div></article><article class="task exercise-like" id="task-986"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3012">In the situation depicted at right in <a href="" class="xref" data-knowl="./knowl/F_parallelogram_area.html" title="Figure 17.9">Figure 17.9</a>, use geometry to again explain why <span class="process-math">\(\Area(P(\vu,\vv)) = h |\vu|\text{.}\)</span> (Hint: What can we say about <span class="process-math">\(\Area(AEC)\)</span> and <span class="process-math">\(\Area(ODB)\text{?}\)</span>)</p></article></article><p id="p-3013">The result of <a href="" class="xref" data-knowl="./knowl/act_parallelogram_area.html" title="Project Activity 17.3">Project Activity 17.3</a> is that the area of <span class="process-math">\(P(\vu,\vv)\)</span> is given by <span class="process-math">\(h |\vu|\text{,}\)</span> where <span class="process-math">\(h\)</span> is the height of the parallelogram determined by dropping a perpendicular from the terminal point of <span class="process-math">\(\vv\)</span> to the line determined by the vector <span class="process-math">\(\vu\text{.}\)</span></p>
<p id="p-3014">Now we turn to the question of how the determinant is related to area of a parallelogram. Our approach will use some properties of the area of <span class="process-math">\(P(\vu, \vv)\text{.}\)</span></p>
<article class="project project-like" id="act_P_area_properties"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">17.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-275">
<p id="p-3015">Let <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> be vectors that determine a parallelogram in <span class="process-math">\(\R^2\text{.}\)</span></p>
<figure class="figure figure-like" id="F_area_propertities"><div class="image-box" style="width: 60%; margin-left: 20%; margin-right: 20%;"><img src="external/4_a_parallelogram_shear.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">17.10<span class="period">.</span></span><span class="space"> </span>Parallelograms formed by <span class="process-math">\(k\vu\)</span> and <span class="process-math">\(\vv\)</span> and by <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv+k\vu\text{.}\)</span></figcaption></figure>
</div>
<article class="task exercise-like" id="task-987"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3016">Explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_P_area_properties_1">
\begin{equation}
\Area(P(\vu,\vv)) = \Area(P(\vv,\vu))\tag{17.3}
\end{equation}
</div></article><article class="task exercise-like" id="task-988"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3017">If <span class="process-math">\(k\)</span> is any scalar, then <span class="process-math">\(k\vu\)</span> either stretches or compresses <span class="process-math">\(\vu\text{.}\)</span> Use this idea, and the result of <a href="" class="xref" data-knowl="./knowl/act_parallelogram_area.html" title="Project Activity 17.3">Project Activity 17.3</a>, to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_parallelogram_area.html ./knowl/F_parallelogram_area.html" id="eq_P_area_properties_2">
\begin{equation}
\Area(P(k\vu,\vv)) = \Area(P(\vu,k\vv)) = |k| \Area(P(\vu,\vv))\tag{17.4}
\end{equation}
</div>
<p class="continuation">for any real number <span class="process-math">\(k\text{.}\)</span> A representative picture of this situation is shown at left in <a href="" class="xref" data-knowl="./knowl/F_parallelogram_area.html" title="Figure 17.9">Figure 17.9</a> for a value of <span class="process-math">\(k &gt; 1\text{.}\)</span> You will also need to consider what happens when <span class="process-math">\(k \lt  0\text{.}\)</span></p></article><article class="task exercise-like" id="task-989"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3018">Finally, use the result of <a href="" class="xref" data-knowl="./knowl/act_parallelogram_area.html" title="Project Activity 17.3">Project Activity 17.3</a> to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/act_parallelogram_area.html ./knowl/F_area_propertities.html" id="eq_P_area_properties_3">
\begin{equation}
\Area(P(\vu+k\vv,\vv)) = \Area(P(\vu,\vv+k\vu)) = \Area(P(\vu,\vv))\tag{17.5}
\end{equation}
</div>
<p class="continuation">for any real number <span class="process-math">\(k\text{.}\)</span> A representative picture is shown at right in <a href="" class="xref" data-knowl="./knowl/F_area_propertities.html" title="Figure 17.10">Figure 17.10</a>.</p></article></article><p id="p-3019">Properties <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_2.html" title="Equation 17.4">(17.4)</a> and <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_3.html" title="Equation 17.5">(17.5)</a> will allow us to calculate the area of the parallelogram determined by vectors <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\text{.}\)</span></p>
<article class="project project-like" id="act_det_area"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">17.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-276">
<p id="p-3020">Let <span class="process-math">\(\vu = [u_1 \ u_2]^{\tr}\)</span> and <span class="process-math">\(\vv = [v_1 \ v_2]^{\tr}\text{.}\)</span> We will now demonstrate that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Area(P(\vu,\vv)) = \left|\det\left(\left| \begin{array}{cc} u_1\amp u_2\\v_1\amp v_2 \end{array}  \right] \right)\right|\text{.}
\end{equation*}
</div>
<p id="p-3021">Before we begin, note that if both <span class="process-math">\(u_1\)</span> and <span class="process-math">\(v_1\)</span> are <span class="process-math">\(0\text{,}\)</span> then <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are parallel. This makes <span class="process-math">\(P(\vu, \vv)\)</span> a line segment and so <span class="process-math">\(\Area(P(\vu,\vv)) = 0\text{.}\)</span> But if <span class="process-math">\(u_1 = v_1 = 0\text{,}\)</span> it is also the case that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\det\left(\left| \begin{array}{cc} u_1\amp u_2\\v_1\amp v_2 \end{array}  \right] \right) = u_1v_2-u_2v_1 = 0
\end{equation*}
</div>
<p class="continuation">as well. So we can assume that at least one of <span class="process-math">\(u_1\text{,}\)</span> <span class="process-math">\(v_1\)</span> is not <span class="process-math">\(0\text{.}\)</span> Since <span class="process-math">\(P(\vu, \vv) = P(\vv, \vu)\text{,}\)</span> we can assume without loss of generality that <span class="process-math">\(u_1 \neq 0\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-990"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3022">Explain using properties <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_2.html" title="Equation 17.4">(17.4)</a> and  <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_3.html" title="Equation 17.5">(17.5)</a> as appropriate why</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_P_area_properties_2.html ./knowl/eq_P_area_properties_3.html">
\begin{equation*}
\Area(P(\vu,\vv)) =\Area\left(P\left(\vu, \left[0 \ v_2-\frac{v_1}{u_1}u_2\right] \right) \right)\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-991"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-277">
<p id="p-3023">Let <span class="process-math">\(\vv_1 = \left[0 \ v_2-\frac{v_1}{u_1}u_2\right]^{\tr}\text{.}\)</span> Recall that our alternate representation of <span class="process-math">\(P(\vu,\vv))\)</span> allows us to write</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Area(P(\vu, \vv_1)) = \Area\left( P\left(  \left[ \begin{array}{cc} u_1\amp u_2 \\ 0\amp v_2-\frac{v_1}{u_1}u_2 \end{array}  \right] \right) \right)\text{.}
\end{equation*}
</div>
<p class="continuation">This should seem very suggestive. We are essentially applying the process of Gaussian elimination to our parallelogram matrix to reduce it to a diagonal matrix. From there, we can calculate the area. The matrix form should indicate the next step —  applying an operation to eliminate the entry in the first row and second column. To do this, we need to consider what happens if <span class="process-math">\(v_2-\frac{v_1}{u_1}u_2 = 0\)</span> and if <span class="process-math">\(v_2-\frac{v_1}{u_1}u_2 \neq 0\text{.}\)</span></p>
</div>
<article class="task exercise-like" id="task-992"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-3024">Assume that <span class="process-math">\(v_2-\frac{v_1}{u_1}u_2 = 0\text{.}\)</span> Explain why <span class="process-math">\(\Area(P(\vu,\vv)) = 0\text{.}\)</span> Then explain why <span class="process-math">\(\Area(P(\vu,\vv)) = 0 = \det\left(\left[ \begin{array}{cc} u_1\amp u_2\\v_1\amp v_2 \end{array} \right]\right)\text{.}\)</span></p></article><article class="task exercise-like" id="task-993"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-3025">Now we consider the case when <span class="process-math">\(v_2-\frac{v_1}{u_1}u_2 \neq 0\text{.}\)</span> Complete the process as in part (a), using properties <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_2.html" title="Equation 17.4">(17.4)</a> and  <a href="" class="xref" data-knowl="./knowl/eq_P_area_properties_3.html" title="Equation 17.5">(17.5)</a> (compare to Gaussian elimination) to continue to reduce the problem of calculating <span class="process-math">\(\Area(P(\vu,\vv))\)</span> to one of calculating <span class="process-math">\(\Area(P(\ve_1, \ve_2))\text{.}\)</span> Use this process to conclude that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_P_area_properties_2.html ./knowl/eq_P_area_properties_3.html">
\begin{equation*}
\Area(P(\vu,\vv)) = \left| \det\left(\left[ \begin{array}{cc} u_1\amp u_2\\v_1\amp v_2 \end{array}  \right]\right)\right|\text{.}
\end{equation*}
</div></article></article></article><p id="p-3026">We can apply the same arguments as above using rotations, translations, shearings, and scalings to show that the properties of area given above work in any dimension. Given vectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_n\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> we let</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P(\vu_1, \vu_2, \ldots, \vu_n) = \{\overrightarrow{OQ}+x_1 \vu_1 + x_2 \vu_2 + \cdots + x_n \vu_n : 0 \leq x_i \leq 1 \text{ for each }  i\}\text{.}
\end{equation*}
</div>
<p id="p-3027">If <span class="process-math">\(n = 2\text{,}\)</span> then <span class="process-math">\(P(\vu_1,\vu_2)\)</span> is the parallelogram determined by <span class="process-math">\(\vu_1\)</span> and <span class="process-math">\(\vu_2\)</span> with basepoint <span class="process-math">\(Q\text{.}\)</span> If <span class="process-math">\(n = 3\text{,}\)</span> then <span class="process-math">\(P(\vu_1, \vu_2, \vu_3)\)</span> is the parallelepiped with basepoint <span class="process-math">\(Q\)</span> determined by <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> and <span class="process-math">\(\vu_3\text{.}\)</span> In higher dimensions the sets <span class="process-math">\(P(\vu_1, \vu_2, \ldots,\vu_n)\)</span> are called parallelotopes, and we use the notation <span class="process-math">\(\Vol(P(\vu_1, \vu_2, \ldots,\vu_n))\)</span> for their volume. The <span class="process-math">\(n\)</span>-dimensional volumes of these paralleotopes satisfy the following properties:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-14">
\begin{align}
\Vol\amp (P(\vu_1, \vu_2, \ldots, \vu_{i-1}, \vu_i, \vu_{i+1}, \ldots, \vu_{j-1}, \vu_j, \vu_{j+1}, \ldots,\vu_n))\notag\\
\amp = \Vol(P(\vu_1, \vu_2, \ldots, \vu_{i-1}, \vu_j, \vu_{i+1}, \ldots, \vu_{j-1}, \vu_i, \vu_{j+1}, \ldots,\vu_n))\tag{17.6}
\end{align}
</div>
<p class="continuation">for any <span class="process-math">\(i\)</span> and <span class="process-math">\(j\text{.}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_vol_property_2">
\begin{equation}
\Vol(P(\vu_1,\vu_2, \ldots, \vu_{i-1}, k\vu_i, \vu_{i+1}, \ldots, \vu_n)) = |k| \Vol(P(\vu_1,\vu_2, \ldots, \vu_n))\tag{17.7}
\end{equation}
</div>
<p class="continuation">for any real number <span class="process-math">\(k\)</span> and any <span class="process-math">\(i\text{.}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_vol_property_3">
\begin{equation}
\Vol(P(\vu_1,\vu_2, \ldots, \vu_{i-1}, \vu_{i}+k\vu_j, \vu_{i+1}, \ldots, \vu_n)) = \Vol(P(\vu_1,\vu_2, \ldots, \vu_n))\tag{17.8}
\end{equation}
</div>
<p class="continuation">for any real number <span class="process-math">\(k\)</span> and any distinct <span class="process-math">\(i\)</span> and <span class="process-math">\(j\text{.}\)</span></p>
<article class="project project-like" id="act_det_vol"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">17.6</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-278"><p id="p-3028">We now show that <span class="process-math">\(\Vol(P(\vu_1, \vu_2, \vu_3))\)</span> is the absolute value of the determinant of <span class="process-math">\(\left[ \begin{array}{c} \vu_1 \\ \vu_2 \\ \vu_3 \end{array}  \right]\text{.}\)</span> For easier notation, let <span class="process-math">\(\vu = [u_1 \ u_2 \ u_3]^{\tr}\text{,}\)</span> <span class="process-math">\(\vv = [v_1 \ v_2 \ v_3]^{\tr}\text{,}\)</span> and <span class="process-math">\(\vw = [w_1 \ w_2 \ w_3]^{\tr}\text{.}\)</span> As we argued in the 2-dimensional case, we can assume that all terms that we need to be nonzero are nonzero, and we can do so without verification.</p></div>
<article class="task exercise-like" id="task-994"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-3029">Explain how property <a href="" class="xref" data-knowl="./knowl/eq_vol_property_2.html" title="Equation 17.7">(17.7)</a> shows that <span class="process-math">\(\Vol(P(\vu, \vv, \vw))\)</span> is equal to</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_vol_property_2.html">
\begin{equation*}
\Vol\left(P\left( \left[ \begin{array}{ccc} u_{1}\amp u_{2}\amp u_{3} \\ 0\amp \frac{1}{u_1}(v_{2}u_1-v_{1}u_{2})\amp \frac{1}{u_1}(v_{3}u_1-v_{1}u_{3})\\ 0\amp \frac{1}{u_1}(w_{2}u_1-w_{1}u_{2})\amp \frac{1}{u_1}(w_{3}u_1-w_{1}u_{3}) \end{array}  \right] \right)\right)\text{.}
\end{equation*}
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-21" id="hint-21"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-21"><div class="hint solution-like"><p id="p-3030">Think about how these properties are related to row operations.</p></div></div>
</div></article><article class="task exercise-like" id="task-995"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-3031">Now let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_vol_property_2.html">
\begin{equation*}
\vv_1 = \left[ 0 \ \frac{1}{u_1}(v_{2}u_1-v_{1}u_{2}) \ \frac{1}{u_1}(v_{3}u_1-v_{1}u_{3})\right]^{\tr}
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_vol_property_2.html">
\begin{equation*}
\vw_1 = \left[ 0 \ \frac{1}{u_1}(w_{2}u_1-w_{1}u_{2}) \ \frac{1}{u_1}(w_{3}u_1-w_{1}u_{3})\right]^{\tr}\text{.}
\end{equation*}
</div>
<p class="continuation">Explain how property <a href="" class="xref" data-knowl="./knowl/eq_vol_property_2.html" title="Equation 17.7">(17.7)</a> shows that <span class="process-math">\(\Vol(P(\vu, \vv, \vw))\)</span> is equal to</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_vol_property_2.html">
\begin{equation*}
\Vol\left(P\left( \left[ \begin{array}{ccc} u_{1}\amp u_{2}\amp u_{3} \\ 0\amp \frac{1}{u_1}(v_{2}u_1-v_{1}u_{2})\amp \frac{1}{u_1}(v_{3}u_1-v_{1}u_{3})\\ 0\amp 0\amp d \end{array}  \right] \right)\right)\text{,}
\end{equation*}
</div>
<p class="continuation">where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_vol_property_2.html">
\begin{equation*}
d = \frac{1}{u_1v_2-u_2v_1}(u_1(v_2w_3-v_3w_2)-u_2(v_1w_3-v_{3}w_1)+u_3(v_1w_2-v_2w_1))\text{.}
\end{equation*}
</div></article><article class="task exercise-like" id="task-996"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-3032">Just as we saw in the 2-dimensional case, we can proceed to use the diagonal entries to eliminate the entries above the diagonal without changing the volume to see that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Vol(P(\vu, \vv, \vw)) = \Vol\left(P\left( \left[ \begin{array}{ccc} u_{1}\amp 0\amp 0 \\ 0\amp \frac{1}{u_1}(v_{2}u_1-v_{1}u_{2})\amp 0\\ 0\amp 0\amp d \end{array}  \right] \right)\right)\text{.}
\end{equation*}
</div>
<p class="continuation">Complete the process, applying appropriate properties to explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Vol(P(\vu, \vv, \vw)) = x \Vol(P(\ve_1, \ve_2, \ve_3))
\end{equation*}
</div>
<p class="continuation">for some constant <span class="process-math">\(x\text{.}\)</span> Find the constant and, as a result, find a specific expression for <span class="process-math">\(\Vol(P(\vu, \vv, \vw))\)</span> involving a determinant.</p></article></article><p id="p-3033">Properties <a href="" class="xref" data-knowl="./knowl/eq_vol_property_1.html" title="Equation 17.6">(17.6)</a>, <a href="" class="xref" data-knowl="./knowl/eq_vol_property_2.html" title="Equation 17.7">(17.7)</a>, and <a href="" class="xref" data-knowl="./knowl/eq_vol_property_3.html" title="Equation 17.8">(17.8)</a> involve the analogs of row operations on matrices, and we will prove algebraically that the determinant exhibits the same properties. In fact, the determinant can be uniquely defined by these properties. So in a sense, the determinant is an area or volume function.</p></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-33"><div class="fn">Tucker, Alan. (1993). The Growing Importance of Linear Algebra in Undergraduate Mathematics. <span class="booktitle">The College Mathematics Journal</span>, 1, 3-9.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
