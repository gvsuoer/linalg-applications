<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-23T14:59:53-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Orthogonal Diagonalization</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="An Inquiry-Based Introduction to Linear Algebra and Applications">
<meta property="book:author" content="Feryal Alayont">
<meta property="book:author" content="Steven Schlicker">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script async="" src="https://cse.google.com/cse.js?cx=a16e70a6cb1434676"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="external/custom_style.css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\usepackage{amsmath}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\ch}{char}
\newcommand{\N}{\mathbb{N}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\NE}{\mathcal{E}}
\newcommand{\Mn}[1]{\mathcal{M}_{#1 \times #1}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Rn}{\R^n}
\newcommand{\Mat}{\mathbf}
\newcommand{\Seq}{\boldsymbol}
\newcommand{\seq}[1]{\boldsymbol{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\abs}[1]{\left\lvert{}#1\right\rvert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\cq}{\scalebox{.34}{\pscirclebox{ \textbf{?}}}}
\newcommand{\cqup}{\,$^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}$}
\newcommand{\cqupmath}{\,^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\cqupmathnospace}{^{\text{\scalebox{.2}{\pscirclebox{\textbf{?}}}}}}
\newcommand{\uspace}[1]{\underline{}}
\newcommand{\muspace}[1]{\underline{\mspace{#1 mu}}}
\newcommand{\bspace}[1]{}
\newcommand{\ie}{\emph{i}.\emph{e}.}
\newcommand{\nq}[1]{\scalebox{.34}{\pscirclebox{\textbf{#1}}}}
\newcommand{\equalwhy}{\stackrel{\cqupmath}{=}}
\newcommand{\notequalwhy}{\stackrel{\cqupmath}{\neq}}
\newcommand{\Ker}{\text{Ker}}
\newcommand{\Image}{\text{Im}}
\newcommand{\polyp}{p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots a_2x^2 + a_1x + a_0}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\lcm}{\text{lcm}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Inn}{\text{Inn}}
\newcommand{\Hol}{\text{Hol}}
\newcommand{\cl}{\text{cl}}
\newcommand{\bsq}{\hfill $\blacksquare$}
\newcommand{\NIMdot}{{ $\cdot$ }}
\newcommand{\eG}{e_{\scriptscriptstyle{G}}}
\newcommand{\eGroup}[1]{e_{\scriptscriptstyle{#1}}}
\newcommand{\Gdot}[1]{\cdot_{\scriptscriptstyle{#1}}}
\newcommand{\rbar}{\overline{r}}
\newcommand{\nuG}[1]{\nu_{\scriptscriptstyle{#1}}}
\newcommand{\rightarray}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\polymod}[1]{\mspace{5 mu}(\text{mod} #1)}
\newcommand{\ts}{\mspace{2 mu}}
\newcommand{\ds}{\displaystyle}
\newcommand{\adj}{\text{adj}}
\newcommand{\pol}{\mathbb{P}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\CB}{\mathcal{B}}
\renewcommand{\CD}{\mathcal{D}}
\newcommand{\CP}{\mathcal{P}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\rank}{\text{rank}}
\newcommand{\nullity}{\text{nullity}}
\newcommand{\trace}{\text{trace}}
\newcommand{\Area}{\text{Area}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\cov}{\text{cov}}
\newcommand{\var}{\text{var}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\vn}{\mathbf{n}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vi}{\mathbf{i}}
\newcommand{\vj}{\mathbf{j}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vP}{\mathbf{P}}
\newcommand{\nin}{}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\tr}{\mathsf{T}}
\newcommand{\proj}{\text{proj}}
\newcommand{\comp}{\text{comp}}
\newcommand{\Row}{\text{Row }}
\newcommand{\Col}{\text{Col }}
\newcommand{\Nul}{\text{Nul }}
\newcommand{\Span}{\text{Span}}
\newcommand{\Range}{\text{Range}}
\newcommand{\Domain}{\text{Domain}}
\newcommand{\hthin}{\hlinewd{.1pt}}
\newcommand{\hthick}{\hlinewd{.7pt}}
\newcommand{\pbreaks}{1}
\newcommand{\pbreak}{
}
\newcommand{\lint}{\underline{}
\int}
\newcommand{\uint}{ \underline{}
\int}


\newcommand{\Si}{\text{Si}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">An Inquiry-Based Introduction to Linear Algebra and Applications</span></a></h1>
<p class="byline">Feryal Alayont, Steven Schlicker</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="part-app-orthog.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="part-app-orthog.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="chap_principal_axis_theorem.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="part-app-orthog.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="part-app-orthog.html" title="Up">Up</a><a class="next-button button toolbar-item" href="chap_principal_axis_theorem.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul><li><a href="fm_preface.html" data-scroll="fm_preface" class="internal">Preface</a></li></ul>
</li>
<li class="link part"><a href="part-systems.html" data-scroll="part-systems" class="internal"><span class="codenumber">I</span> <span class="title">Systems of Linear Equations</span></a></li>
<li class="link">
<a href="chap_intro_linear_systems.html" data-scroll="chap_intro_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Systems of Linear Equations</span></a><ul>
<li><a href="chap_intro_linear_systems.html#sec_appl_elec_circuits" data-scroll="sec_appl_elec_circuits" class="internal">Application: Electrical Circuits</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_intro" data-scroll="sec_intro_le_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_linear_systems.html#sec_notation" data-scroll="sec_notation" class="internal">Notation and Terminology</a></li>
<li><a href="chap_intro_linear_systems.html#sec_solve_systems" data-scroll="sec_solve_systems" class="internal">Solving Systems of Linear Equations</a></li>
<li><a href="chap_intro_linear_systems.html#sec_geom_solu_sets" data-scroll="sec_geom_solu_sets" class="internal">The Geometry of Solution Sets of Linear Systems</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exam" data-scroll="sec_intro_le_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_summ" data-scroll="sec_intro_le_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_linear_systems.html#sec_intro_le_exer" data-scroll="sec_intro_le_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_linear_systems.html#sec_1_a_circuits" data-scroll="sec_1_a_circuits" class="internal">Project: Modeling an Electrical Circuit and the Wheatstone Bridge Circuit</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_representation.html" data-scroll="chap_matrix_representation" class="internal"><span class="codenumber">2</span> <span class="title">The Matrix Representation of a Linear System</span></a><ul>
<li><a href="chap_matrix_representation.html#sec_appl_area_curve" data-scroll="sec_appl_area_curve" class="internal">Application: Approximating Area Under a Curve</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_lin_intro" data-scroll="sec_mtx_lin_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_representation.html#sec_simp_mtx_sys" data-scroll="sec_simp_mtx_sys" class="internal">Simplifying Linear Systems Represented in Matrix Form</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_inf_sols" data-scroll="sec_sys_inf_sols" class="internal">Linear Systems with Infinitely Many Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_sys_no_sols" data-scroll="sec_sys_no_sols" class="internal">Linear Systems with No Solutions</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exam" data-scroll="sec_mtx_sys_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_summ" data-scroll="sec_mtx_sys_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_representation.html#sec_mtx_sys_exer" data-scroll="sec_mtx_sys_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_representation.html#sec_1_b_polynomial" data-scroll="sec_1_b_polynomial" class="internal">Project: Polynomial Interpolation to Approximate the Area Under a Curve</a></li>
</ul>
</li>
<li class="link">
<a href="chap_row_echelon_forms.html" data-scroll="chap_row_echelon_forms" class="internal"><span class="codenumber">3</span> <span class="title">Row Echelon Forms</span></a><ul>
<li><a href="chap_row_echelon_forms.html#sec_appl_chem_react" data-scroll="sec_appl_chem_react" class="internal">Application: Balancing Chemical Reactions</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_intro" data-scroll="sec_row_ech_intro" class="internal">Introduction</a></li>
<li><a href="chap_row_echelon_forms.html#sec_mtx_ech_forms" data-scroll="sec_mtx_ech_forms" class="internal">The Echelon Forms of a Matrix</a></li>
<li><a href="chap_row_echelon_forms.html#sec_num_sols_ls" data-scroll="sec_num_sols_ls" class="internal">Determining the Number of Solutions of a Linear System</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prod_ech_forms" data-scroll="sec_prod_ech_forms" class="internal">Producing the Echelon Forms</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exam" data-scroll="sec_row_ech_exam" class="internal">Examples</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_summ" data-scroll="sec_row_ech_summ" class="internal">Summary</a></li>
<li><a href="chap_row_echelon_forms.html#sec_row_ech_exer" data-scroll="sec_row_ech_exer" class="internal">Exercises</a></li>
<li><a href="chap_row_echelon_forms.html#sec_prof_chem_react" data-scroll="sec_prof_chem_react" class="internal">Project: Modeling a Chemical Reaction</a></li>
</ul>
</li>
<li class="link">
<a href="chap_vector_representation.html" data-scroll="chap_vector_representation" class="internal"><span class="codenumber">4</span> <span class="title">Vector Representation</span></a><ul>
<li><a href="chap_vector_representation.html#sec_appl_knight" data-scroll="sec_appl_knight" class="internal">Application: The Knight's Tour</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_intro" data-scroll="sec_vec_rep_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_representation.html#sec_vec_ops" data-scroll="sec_vec_ops" class="internal">Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_geom_vec_ops" data-scroll="sec_geom_vec_ops" class="internal">Geometric Representation of Vectors and Vector Operations</a></li>
<li><a href="chap_vector_representation.html#sec_lin_comb_vec" data-scroll="sec_lin_comb_vec" class="internal">Linear Combinations of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_span" data-scroll="sec_vec_span" class="internal">The Span of a Set of Vectors</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_exam" data-scroll="sec_vec_rep_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_representation.html#sec_vec_rep_summ" data-scroll="sec_vec_rep_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_representation.html#exercises-4" data-scroll="exercises-4" class="internal">Exercises</a></li>
<li><a href="chap_vector_representation.html#sec_proj_knight" data-scroll="sec_proj_knight" class="internal">Project: Analyzing Knight Moves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_vector.html" data-scroll="chap_matrix_vector" class="internal"><span class="codenumber">5</span> <span class="title">The Matrix-Vector Form of a Linear System</span></a><ul>
<li><a href="chap_matrix_vector.html#sec_appl_model_econ" data-scroll="sec_appl_model_econ" class="internal">Application: Modeling an Economy</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_intro" data-scroll="sec_mv_form_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_prod" data-scroll="sec_mv_prod" class="internal">The Matrix-Vector Product</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form" data-scroll="sec_mv_form" class="internal">The Matrix-Vector Form of a Linear System</a></li>
<li><a href="chap_matrix_vector.html#sec_homog_sys" data-scroll="sec_homog_sys" class="internal">Homogeneous and Nonhomogeneous Systems</a></li>
<li><a href="chap_matrix_vector.html#sec_geom_homog_sys" data-scroll="sec_geom_homog_sys" class="internal">The Geometry of Solutions to the Homogeneous System</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exam" data-scroll="sec_mv_form_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_summ" data-scroll="sec_mv_form_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_vector.html#sec_mv_form_exer" data-scroll="sec_mv_form_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_vector.html#sec_proj_io_models" data-scroll="sec_proj_io_models" class="internal">Project: Input-Output Models</a></li>
</ul>
</li>
<li class="link">
<a href="chap_independence.html" data-scroll="chap_independence" class="internal"><span class="codenumber">6</span> <span class="title">Linear Dependence and Independence</span></a><ul>
<li><a href="chap_independence.html#sec_appl_bezier" data-scroll="sec_appl_bezier" class="internal">Application: Bézier Curves</a></li>
<li><a href="chap_independence.html#sec_indep_intro" data-scroll="sec_indep_intro" class="internal">Introduction</a></li>
<li><a href="chap_independence.html#lin_indep_intro_new" data-scroll="lin_indep_intro_new" class="internal">Linear Independence</a></li>
<li><a href="chap_independence.html#sec_determ_lin_ind" data-scroll="sec_determ_lin_ind" class="internal">Determining Linear Independence</a></li>
<li><a href="chap_independence.html#sec_min_span_set" data-scroll="sec_min_span_set" class="internal">Minimal Spanning Sets</a></li>
<li><a href="chap_independence.html#sec_indep_exam" data-scroll="sec_indep_exam" class="internal">Examples</a></li>
<li><a href="chap_independence.html#sec_indep_summ" data-scroll="sec_indep_summ" class="internal">Summary</a></li>
<li><a href="chap_independence.html#sec_indep_exer" data-scroll="sec_indep_exer" class="internal">Exercises</a></li>
<li><a href="chap_independence.html#sec_proj_bezier" data-scroll="sec_proj_bezier" class="internal">Project: Generating Bézier Curves</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_transformations.html" data-scroll="chap_matrix_transformations" class="internal"><span class="codenumber">7</span> <span class="title">Matrix Transformations</span></a><ul>
<li><a href="chap_matrix_transformations.html#sec_appl_graphics" data-scroll="sec_appl_graphics" class="internal">Application: Computer Graphics</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_intro" data-scroll="sec_mtx_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_prop" data-scroll="sec_mtx_trans_prop" class="internal">Properties of Matrix Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_trans_onto_oto" data-scroll="sec_trans_onto_oto" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exam" data-scroll="sec_mtx_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_summ" data-scroll="sec_mtx_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_transformations.html#sec_mtx_trans_exer" data-scroll="sec_mtx_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_transformations.html#sec_proj_geom_mtx" data-scroll="sec_proj_geom_mtx" class="internal">Project: The Geometry of Matrix Transformations</a></li>
</ul>
</li>
<li class="link part"><a href="part-matrices.html" data-scroll="part-matrices" class="internal"><span class="codenumber">II</span> <span class="title">Matrices</span></a></li>
<li class="link">
<a href="chap_matrix_operations.html" data-scroll="chap_matrix_operations" class="internal"><span class="codenumber">8</span> <span class="title">Matrix Operations</span></a><ul>
<li><a href="chap_matrix_operations.html#sec_appl_mtx_mult" data-scroll="sec_appl_mtx_mult" class="internal">Application: Algorithms for Matrix Multiplication</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_intro" data-scroll="sec_mtx_ops_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_add_smult" data-scroll="sec_mtx_add_smult" class="internal">Properties of Matrix Addition and Multiplication by Scalars</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_prod" data-scroll="sec_mtx_prod" class="internal">A Matrix Product</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose" data-scroll="sec_mtx_transpose" class="internal">The Transpose of a Matrix</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_transpose_prop" data-scroll="sec_mtx_transpose_prop" class="internal">Properties of the Matrix Transpose</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exam" data-scroll="sec_mtx_ops_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_summ" data-scroll="sec_mtx_ops_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_operations.html#sec_mtx_ops_exer" data-scroll="sec_mtx_ops_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_operations.html#sec_proj_starassen" data-scroll="sec_proj_starassen" class="internal">Project: Strassen's Algorithm and Partitioned Matrices</a></li>
</ul>
</li>
<li class="link">
<a href="chap_intro_eigenvals_eigenvects.html" data-scroll="chap_intro_eigenvals_eigenvects" class="internal"><span class="codenumber">9</span> <span class="title">Introduction to Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_appl_pagerank" data-scroll="sec_appl_pagerank" class="internal">Application: The Google PageRank Algorithm</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_intro" data-scroll="sec_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigval_eigvec" data-scroll="sec_eigval_eigvec" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_dynam_sys" data-scroll="sec_dynam_sys" class="internal">Dynamical Systems</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exam" data-scroll="sec_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_summ" data-scroll="sec_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_eigen_exer" data-scroll="sec_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_intro_eigenvals_eigenvects.html#sec_proj_pagerank" data-scroll="sec_proj_pagerank" class="internal">Project: Understanding the PageRank Algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap_matrix_inverse.html" data-scroll="chap_matrix_inverse" class="internal"><span class="codenumber">10</span> <span class="title">The Inverse of a Matrix</span></a><ul>
<li><a href="chap_matrix_inverse.html#sec_appl_arms_race" data-scroll="sec_appl_arms_race" class="internal">Application: Modeling an Arms Race</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_intro" data-scroll="sec_inverse_intro" class="internal">Introduction</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_invertible" data-scroll="sec_mtx_invertible" class="internal">Invertible Matrices</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse" data-scroll="sec_mtx_inverse" class="internal">Finding the Inverse of a Matrix</a></li>
<li><a href="chap_matrix_inverse.html#sec_mtx_inverse_props" data-scroll="sec_mtx_inverse_props" class="internal">Properties of the Matrix Inverse</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exam" data-scroll="sec_inverse_exam" class="internal">Examples</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_summ" data-scroll="sec_inverse_summ" class="internal">Summary</a></li>
<li><a href="chap_matrix_inverse.html#sec_inverse_exer" data-scroll="sec_inverse_exer" class="internal">Exercises</a></li>
<li><a href="chap_matrix_inverse.html#sec_proj_arms_race" data-scroll="sec_proj_arms_race" class="internal">Project: The Richardson Arms Race Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_IMT.html" data-scroll="chap_IMT" class="internal"><span class="codenumber">11</span> <span class="title">The Invertible Matrix Theorem</span></a><ul>
<li><a href="chap_IMT.html#sec_imt_intro" data-scroll="sec_imt_intro" class="internal">Introduction</a></li>
<li><a href="chap_IMT.html#sec_imt" data-scroll="sec_imt" class="internal">The Invertible Matrix Theorem</a></li>
<li><a href="chap_IMT.html#sec_imt_exam" data-scroll="sec_imt_exam" class="internal">Examples</a></li>
<li><a href="chap_IMT.html#sec_imt_summ" data-scroll="sec_imt_summ" class="internal">Summary</a></li>
<li><a href="chap_IMT.html#sec_imt_exer" data-scroll="sec_imt_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-vector-rn.html" data-scroll="part-vector-rn" class="internal"><span class="codenumber">III</span> <span class="title">The Vector Space <span class="process-math">\(\R^n\)</span></span></a></li>
<li class="link">
<a href="chap_R_n.html" data-scroll="chap_R_n" class="internal"><span class="codenumber">12</span> <span class="title">The Structure of <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_R_n.html#sec_appl_romania" data-scroll="sec_appl_romania" class="internal">Application: Connecting GDP and Consumption in Romania</a></li>
<li><a href="chap_R_n.html#sec_rn_intro" data-scroll="sec_rn_intro" class="internal">Introduction</a></li>
<li><a href="chap_R_n.html#sec_vec_spaces" data-scroll="sec_vec_spaces" class="internal">Vector Spaces</a></li>
<li><a href="chap_R_n.html#sec_sub_space_span" data-scroll="sec_sub_space_span" class="internal">The Subspace Spanned by a Set of Vectors</a></li>
<li><a href="chap_R_n.html#sec_rn_exam" data-scroll="sec_rn_exam" class="internal">Examples</a></li>
<li><a href="chap_R_n.html#sec_rn_summ" data-scroll="sec_rn_summ" class="internal">Summary</a></li>
<li><a href="chap_R_n.html#sec_rn_exer" data-scroll="sec_rn_exer" class="internal">Exercises</a></li>
<li><a href="chap_R_n.html#sec_proj_ls_approx" data-scroll="sec_proj_ls_approx" class="internal">Project: Least Squares Linear Approximation</a></li>
</ul>
</li>
<li class="link">
<a href="chap_null_space.html" data-scroll="chap_null_space" class="internal"><span class="codenumber">13</span> <span class="title">The Null Space and Column Space of a Matrix</span></a><ul>
<li><a href="chap_null_space.html#sec_appl_lights_out" data-scroll="sec_appl_lights_out" class="internal">Application: The Lights Out Game</a></li>
<li><a href="chap_null_space.html#sec_null_intro" data-scroll="sec_null_intro" class="internal">Introduction</a></li>
<li><a href="chap_null_space.html#sec_null_kernel" data-scroll="sec_null_kernel" class="internal">The Null Space of a Matrix and the Kernel of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_column_range" data-scroll="sec_column_range" class="internal">The Column Space of a Matrix and the Range of a Matrix Transformation</a></li>
<li><a href="chap_null_space.html#sec_row_space" data-scroll="sec_row_space" class="internal">The Row Space of a Matrix</a></li>
<li><a href="chap_null_space.html#sec_null_col_base" data-scroll="sec_null_col_base" class="internal">Bases for <span class="process-math">\(\Nul A\)</span> and <span class="process-math">\(\Col A\)</span></a></li>
<li><a href="chap_null_space.html#sec_null_exam" data-scroll="sec_null_exam" class="internal">Examples</a></li>
<li><a href="chap_null_space.html#sec_null_summ" data-scroll="sec_null_summ" class="internal">Summary</a></li>
<li><a href="chap_null_space.html#sec_null_exer" data-scroll="sec_null_exer" class="internal">Exercises</a></li>
<li><a href="chap_null_space.html#sec_proj_lights_out" data-scroll="sec_proj_lights_out" class="internal">Project: Solving the Lights Out Game</a></li>
</ul>
</li>
<li class="link">
<a href="chap_eigenspaces.html" data-scroll="chap_eigenspaces" class="internal"><span class="codenumber">14</span> <span class="title">Eigenspaces of a Matrix</span></a><ul>
<li><a href="chap_eigenspaces.html#sec_appl_pop_dynam" data-scroll="sec_appl_pop_dynam" class="internal">Application: Population Dynamics</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_intro" data-scroll="sec_egspace_intro" class="internal">Introduction</a></li>
<li><a href="chap_eigenspaces.html#sec_mtx_egspace" data-scroll="sec_mtx_egspace" class="internal">Eigenspaces of Matrix</a></li>
<li><a href="chap_eigenspaces.html#sec_lin_ind_egvec" data-scroll="sec_lin_ind_egvec" class="internal">Linearly Independent Eigenvectors</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exam" data-scroll="sec_egspace_exam" class="internal">Examples</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_summ" data-scroll="sec_egspace_summ" class="internal">Summary</a></li>
<li><a href="chap_eigenspaces.html#sec_egspace_exer" data-scroll="sec_egspace_exer" class="internal">Exercises</a></li>
<li><a href="chap_eigenspaces.html#sec_proj_migration" data-scroll="sec_proj_migration" class="internal">Project: Modeling Population Migration</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases_dimension.html" data-scroll="chap_bases_dimension" class="internal"><span class="codenumber">15</span> <span class="title">Bases and Dimension</span></a><ul>
<li><a href="chap_bases_dimension.html#sec_appl_latt_crypt" data-scroll="sec_appl_latt_crypt" class="internal">Application: Lattice Based Cryptography</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_intro" data-scroll="sec_base_dim_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases_dimension.html#sec_dim_sub_rn" data-scroll="sec_dim_sub_rn" class="internal">The Dimension of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_cond_basis_subspace" data-scroll="sec_cond_basis_subspace" class="internal">Conditions for a Basis of a Subspace of <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_bases_dimension.html#sec_find_basis_subspace" data-scroll="sec_find_basis_subspace" class="internal">Finding a Basis for a Subspace</a></li>
<li><a href="chap_bases_dimension.html#sec_mtx_rank" data-scroll="sec_mtx_rank" class="internal">Rank of a Matrix</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exam" data-scroll="sec_base_dim_exam" class="internal">Examples</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_summ" data-scroll="sec_base_dim_summ" class="internal">Summary</a></li>
<li><a href="chap_bases_dimension.html#sec_base_dim_exer" data-scroll="sec_base_dim_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases_dimension.html#sec_proj_ggh_crypto" data-scroll="sec_proj_ggh_crypto" class="internal">Project: The GGH Cryptosystem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors.html" data-scroll="chap_coordinate_vectors" class="internal"><span class="codenumber">16</span> <span class="title">Coordinate Vectors and Change of Basis</span></a><ul>
<li><a href="chap_coordinate_vectors.html#sec_appl_orbits" data-scroll="sec_appl_orbits" class="internal">Application: Describing Orbits of Planets</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_intro" data-scroll="sec_cob_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors.html#sec_coor_base" data-scroll="sec_coor_base" class="internal">Bases as Coordinate Systems in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_rn" data-scroll="sec_cob_rn" class="internal">Change of Basis in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_mtx_cob" data-scroll="sec_mtx_cob" class="internal">The Change of Basis Matrix in <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_coordinate_vectors.html#sec_prop_mtx_cob" data-scroll="sec_prop_mtx_cob" class="internal">Properties of the Change of Basis Matrix</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exam" data-scroll="sec_cob_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_summ" data-scroll="sec_cob_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors.html#sec_cob_exer" data-scroll="sec_cob_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors.html#sec_proj_orbits_cob" data-scroll="sec_proj_orbits_cob" class="internal">Project: Planetary Orbits and Change of Basis</a></li>
</ul>
</li>
<li class="link part"><a href="part-eigen.html" data-scroll="part-eigen" class="internal"><span class="codenumber">IV</span> <span class="title">Eigenvalues and Eigenvectors</span></a></li>
<li class="link">
<a href="chap_determinants.html" data-scroll="chap_determinants" class="internal"><span class="codenumber">17</span> <span class="title">The Determinant</span></a><ul>
<li><a href="chap_determinants.html#sec_appl_area_vol" data-scroll="sec_appl_area_vol" class="internal">Application: Area and Volume</a></li>
<li><a href="chap_determinants.html#sec_det_intro" data-scroll="sec_det_intro" class="internal">Introduction</a></li>
<li><a href="chap_determinants.html#sec_det_square" data-scroll="sec_det_square" class="internal">The Determinant of a Square Matrix</a></li>
<li><a href="chap_determinants.html#sec_cofactors" data-scroll="sec_cofactors" class="internal">Cofactors</a></li>
<li><a href="chap_determinants.html#sec_det_3by3" data-scroll="sec_det_3by3" class="internal">The Determinant of a <span class="process-math">\(3 \times 3\)</span> Matrix</a></li>
<li><a href="chap_determinants.html#sec_det_remember" data-scroll="sec_det_remember" class="internal">Two Devices for Remembering Determinants</a></li>
<li><a href="chap_determinants.html#sec_det_exam" data-scroll="sec_det_exam" class="internal">Examples</a></li>
<li><a href="chap_determinants.html#sec_det_summ" data-scroll="sec_det_summ" class="internal">Summary</a></li>
<li><a href="chap_determinants.html#sec_det_exer" data-scroll="sec_det_exer" class="internal">Exercises</a></li>
<li><a href="chap_determinants.html#sec_proj_det_area_vol" data-scroll="sec_proj_det_area_vol" class="internal">Project: Area and Volume Using Determinants</a></li>
</ul>
</li>
<li class="link">
<a href="chap_characteristic_equation.html" data-scroll="chap_characteristic_equation" class="internal"><span class="codenumber">18</span> <span class="title">The Characteristic Equation</span></a><ul>
<li><a href="chap_characteristic_equation.html#sec_appl_thermo" data-scroll="sec_appl_thermo" class="internal">Application: Modeling the Second Law of Thermodynamics</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_intro" data-scroll="sec_chareq_intro" class="internal">Introduction</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq" data-scroll="sec_chareq" class="internal">The Characteristic Equation</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_geom" data-scroll="sec_egspace_geom" class="internal">Eigenspaces, A Geometric Example</a></li>
<li><a href="chap_characteristic_equation.html#sec_egspace_dims" data-scroll="sec_egspace_dims" class="internal">Dimensions of Eigenspaces</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exam" data-scroll="sec_chareq_exam" class="internal">Examples</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_summ" data-scroll="sec_chareq_summ" class="internal">Summary</a></li>
<li><a href="chap_characteristic_equation.html#sec_chareq_exer" data-scroll="sec_chareq_exer" class="internal">Exercises</a></li>
<li><a href="chap_characteristic_equation.html#sec_proj_ehrenfest" data-scroll="sec_proj_ehrenfest" class="internal">Project: The Ehrenfest Model</a></li>
</ul>
</li>
<li class="link">
<a href="chap_diagonalization.html" data-scroll="chap_diagonalization" class="internal"><span class="codenumber">19</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="chap_diagonalization.html#sec_appl_fib_num" data-scroll="sec_appl_fib_num" class="internal">Application: The Fibonacci Numbers</a></li>
<li><a href="chap_diagonalization.html#sec_diag_intro" data-scroll="sec_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_diagonalization.html#sec_diag" data-scroll="sec_diag" class="internal">Diagonalization</a></li>
<li><a href="chap_diagonalization.html#sec_mtx_similar" data-scroll="sec_mtx_similar" class="internal">Similar Matrices</a></li>
<li><a href="chap_diagonalization.html#sec_sim_mtx_trans" data-scroll="sec_sim_mtx_trans" class="internal">Similarity and Matrix Transformations</a></li>
<li><a href="chap_diagonalization.html#sec_diag_general" data-scroll="sec_diag_general" class="internal">Diagonalization in General</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exam" data-scroll="sec_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_diagonalization.html#sec_diag_summ" data-scroll="sec_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_diagonalization.html#sec_diag_exer" data-scroll="sec_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_diagonalization.html#sec_proj_binet_fibo" data-scroll="sec_proj_binet_fibo" class="internal">Project: Binet's Formula for the Fibonacci Numbers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_approx_eigenvalues.html" data-scroll="chap_approx_eigenvalues" class="internal"><span class="codenumber">20</span> <span class="title">Approximating Eigenvalues and Eigenvectors</span></a><ul>
<li><a href="chap_approx_eigenvalues.html#sec_appl_leslie_mtx" data-scroll="sec_appl_leslie_mtx" class="internal">Application: Leslie Matrices and Population Modeling</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_intro" data-scroll="sec_app_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method" data-scroll="sec_power_method" class="internal">The Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_power_method_inv" data-scroll="sec_power_method_inv" class="internal">The Inverse Power Method</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exam" data-scroll="sec_app_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_summ" data-scroll="sec_app_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_app_eigen_exer" data-scroll="sec_app_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_approx_eigenvalues.html#sec_proj_sheep_herd" data-scroll="sec_proj_sheep_herd" class="internal">Project: Managing a Sheep Herd</a></li>
</ul>
</li>
<li class="link">
<a href="chap_complex_eigenvalues.html" data-scroll="chap_complex_eigenvalues" class="internal"><span class="codenumber">21</span> <span class="title">Complex Eigenvalues</span></a><ul>
<li><a href="chap_complex_eigenvalues.html#sec_appl_gershgorin" data-scroll="sec_appl_gershgorin" class="internal">Application: The Gershgorin Disk Theorem</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_intro" data-scroll="sec_comp_eigen_intro" class="internal">Introduction</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen" data-scroll="sec_comp_eigen" class="internal">Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_rotate_scale" data-scroll="sec_mtx_rotate_scale" class="internal">Rotation and Scaling Matrices</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_mtx_comp_eigen" data-scroll="sec_mtx_comp_eigen" class="internal">Matrices with Complex Eigenvalues</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exam" data-scroll="sec_comp_eigen_exam" class="internal">Examples</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_summ" data-scroll="sec_comp_eigen_summ" class="internal">Summary</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_comp_eigen_exer" data-scroll="sec_comp_eigen_exer" class="internal">Exercises</a></li>
<li><a href="chap_complex_eigenvalues.html#sec_proj_gershgorin" data-scroll="sec_proj_gershgorin" class="internal">Project: Understanding the Gershgorin Disk Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_det_properties.html" data-scroll="chap_det_properties" class="internal"><span class="codenumber">22</span> <span class="title">Properties of Determinants</span></a><ul>
<li><a href="chap_det_properties.html#sec_det_prop_intro" data-scroll="sec_det_prop_intro" class="internal">Introduction</a></li>
<li><a href="chap_det_properties.html#sec_det_row_ops" data-scroll="sec_det_row_ops" class="internal">Elementary Row Operations and Their Effects on the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_mtx_elem" data-scroll="sec_mtx_elem" class="internal">Elementary Matrices</a></li>
<li><a href="chap_det_properties.html#sec_det_geom" data-scroll="sec_det_geom" class="internal">Geometric Interpretation of the Determinant</a></li>
<li><a href="chap_det_properties.html#sec_inv_cramers" data-scroll="sec_inv_cramers" class="internal">An Explicit Formula for the Inverse and Cramer's Rule</a></li>
<li><a href="chap_det_properties.html#sec_det_transpose" data-scroll="sec_det_transpose" class="internal">The Determinant of the Transpose</a></li>
<li><a href="chap_det_properties.html#sec_det_row_swap" data-scroll="sec_det_row_swap" class="internal">Row Swaps and Determinants</a></li>
<li><a href="chap_det_properties.html#sec_cofactor_expand" data-scroll="sec_cofactor_expand" class="internal">Cofactor Expansions</a></li>
<li><a href="chap_det_properties.html#sec_mtx_lu_factor" data-scroll="sec_mtx_lu_factor" class="internal">The LU Factorization of a Matrix</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exam" data-scroll="sec_det_prop_exam" class="internal">Examples</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_summ" data-scroll="sec_det_prop_summ" class="internal">Summary</a></li>
<li><a href="chap_det_properties.html#sec_det_prop_exer" data-scroll="sec_det_prop_exer" class="internal">Exercises</a></li>
</ul>
</li>
<li class="link part"><a href="part-orthog.html" data-scroll="part-orthog" class="internal"><span class="codenumber">V</span> <span class="title">Orthogonality</span></a></li>
<li class="link">
<a href="chap_dot_product.html" data-scroll="chap_dot_product" class="internal"><span class="codenumber">23</span> <span class="title">The Dot Product in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_dot_product.html#sec_appl_figs_computer" data-scroll="sec_appl_figs_computer" class="internal">Application: Hidden Figures in Computer Graphics</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_intro" data-scroll="sec_dot_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_dot_product.html#sec_dist_vec" data-scroll="sec_dist_vec" class="internal">The Distance Between Vectors</a></li>
<li><a href="chap_dot_product.html#sec_angle_vec" data-scroll="sec_angle_vec" class="internal">The Angle Between Two Vectors</a></li>
<li><a href="chap_dot_product.html#sec_orthog_proj" data-scroll="sec_orthog_proj" class="internal">Orthogonal Projections</a></li>
<li><a href="chap_dot_product.html#sec_orthog_comp" data-scroll="sec_orthog_comp" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exam" data-scroll="sec_dot_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_summ" data-scroll="sec_dot_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_dot_product.html#sec_dot_prod_exer" data-scroll="sec_dot_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_dot_product.html#sec_proj_back_face" data-scroll="sec_proj_back_face" class="internal">Project: Back-Face Culling</a></li>
</ul>
</li>
<li class="link">
<a href="chap_orthogonal_basis.html" data-scroll="chap_orthogonal_basis" class="internal"><span class="codenumber">24</span> <span class="title">Orthogonal and Orthonormal Bases in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_orthogonal_basis.html#sec_appl_3d_rotate" data-scroll="sec_appl_3d_rotate" class="internal">Application: Rotations in 3D</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_intro" data-scroll="sec_orthog_set_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_sets" data-scroll="sec_orthog_sets" class="internal">Orthogonal Sets</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_bases_prop" data-scroll="sec_orthog_bases_prop" class="internal">Properties of Orthogonal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthon_bases" data-scroll="sec_orthon_bases" class="internal">Orthonormal Bases</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_mtx" data-scroll="sec_orthog_mtx" class="internal">Orthogonal Matrices</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exam" data-scroll="sec_orthog_set_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_summ" data-scroll="sec_orthog_set_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_basis.html#sec_orthog_set_exer" data-scroll="sec_orthog_set_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_basis.html#sec_proj_3d_rotate" data-scroll="sec_proj_3d_rotate" class="internal">Project: Understanding Rotations in 3-Space</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt.html" data-scroll="chap_gram_schmidt" class="internal"><span class="codenumber">25</span> <span class="title">Projections onto Subspaces and the Gram-Schmidt Process in <span class="process-math">\(\R^n\)</span></span></a><ul>
<li><a href="chap_gram_schmidt.html#sec_mimo" data-scroll="sec_mimo" class="internal">Application: MIMO Systems</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_intro_noip" data-scroll="sec_gram_schmidt_intro_noip" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt.html#sec_proj_subsp_orth" data-scroll="sec_proj_subsp_orth" class="internal">Projections onto Subspaces and Orthogonal Projections</a></li>
<li><a href="chap_gram_schmidt.html#sec_best_approx" data-scroll="sec_best_approx" class="internal">Best Approximations</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_process" data-scroll="sec_gram_schmidt_process" class="internal">The Gram-Schmidt Process</a></li>
<li><a href="chap_gram_schmidt.html#sec_qr_fact" data-scroll="sec_qr_fact" class="internal">The QR Factorization of a Matrix</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_examples" data-scroll="sec_gram_schmidt_examples" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_summ_noips" data-scroll="sec_gram_schmidt_summ_noips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt.html#sec_gram_schmidt_exercises" data-scroll="sec_gram_schmidt_exercises" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt.html#sec_project_mimo" data-scroll="sec_project_mimo" class="internal">Project: MIMO Systems and Householder Transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_least_squares.html" data-scroll="chap_least_squares" class="internal"><span class="codenumber">26</span> <span class="title">Least Squares Approximations</span></a><ul>
<li><a href="chap_least_squares.html#sec_appl_fit_func" data-scroll="sec_appl_fit_func" class="internal">Application: Fitting Functions to Data</a></li>
<li><a href="chap_least_squares.html#sec_ls_intro" data-scroll="sec_ls_intro" class="internal">Introduction</a></li>
<li><a href="chap_least_squares.html#sec_ls_approx" data-scroll="sec_ls_approx" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_least_squares.html#sec_ls_exam" data-scroll="sec_ls_exam" class="internal">Examples</a></li>
<li><a href="chap_least_squares.html#sec_ls_summ" data-scroll="sec_ls_summ" class="internal">Summary</a></li>
<li><a href="chap_least_squares.html#sec_ls_exer" data-scroll="sec_ls_exer" class="internal">Exercises</a></li>
<li><a href="chap_least_squares.html#sec_proj_ls_approx_other" data-scroll="sec_proj_ls_approx_other" class="internal">Project: Other Least Squares Approximations</a></li>
</ul>
</li>
<li class="link part"><a href="part-app-orthog.html" data-scroll="part-app-orthog" class="internal"><span class="codenumber">VI</span> <span class="title">Applications of Orthogonality</span></a></li>
<li class="link active">
<a href="chap_orthogonal_diagonalization.html" data-scroll="chap_orthogonal_diagonalization" class="internal"><span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span></a><ul>
<li><a href="chap_orthogonal_diagonalization.html#sec_appl_mulit_2nd_deriv" data-scroll="sec_appl_mulit_2nd_deriv" class="internal">Application: The Multivariable Second Derivative Test</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_intro" data-scroll="sec_orthog_diag_intro" class="internal">Introduction</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_mtx_symm" data-scroll="sec_mtx_symm" class="internal">Symmetric Matrices</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_spec_decomp_symm_mtx" data-scroll="sec_spec_decomp_symm_mtx" class="internal">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exam" data-scroll="sec_orthog_diag_exam" class="internal">Examples</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_summ" data-scroll="sec_orthog_diag_summ" class="internal">Summary</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_orthog_diag_exer" data-scroll="sec_orthog_diag_exer" class="internal">Exercises</a></li>
<li><a href="chap_orthogonal_diagonalization.html#sec_proj_two_var_deriv" data-scroll="sec_proj_two_var_deriv" class="internal">Project: The Second Derivative Test for Functions of Two Variables</a></li>
</ul>
</li>
<li class="link">
<a href="chap_principal_axis_theorem.html" data-scroll="chap_principal_axis_theorem" class="internal"><span class="codenumber">28</span> <span class="title">Quadratic Forms and the Principal Axis Theorem</span></a><ul>
<li><a href="chap_principal_axis_theorem.html#sec_appl_tennis" data-scroll="sec_appl_tennis" class="internal">Application: The Tennis Racket Effect</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_intro" data-scroll="sec_pat_intro" class="internal">Introduction</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_eqs_quad_r2" data-scroll="sec_eqs_quad_r2" class="internal">Equations Involving Quadratic Forms in <span class="process-math">\(\R^2\)</span></a></li>
<li><a href="chap_principal_axis_theorem.html#sec_class_quad_forms" data-scroll="sec_class_quad_forms" class="internal">Classifying Quadratic Forms</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_inner_prod" data-scroll="sec_pat_inner_prod" class="internal">Inner Products</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exam" data-scroll="sec_pat_exam" class="internal">Examples</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_summ" data-scroll="sec_pat_summ" class="internal">Summary</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_pat_exer" data-scroll="sec_pat_exer" class="internal">Exercises</a></li>
<li><a href="chap_principal_axis_theorem.html#sec_proj_tennis" data-scroll="sec_proj_tennis" class="internal">Project: The Tennis Racket Theorem</a></li>
</ul>
</li>
<li class="link">
<a href="chap_SVD.html" data-scroll="chap_SVD" class="internal"><span class="codenumber">29</span> <span class="title">The Singular Value Decomposition</span></a><ul>
<li><a href="chap_SVD.html#sec_appl_search_engn" data-scroll="sec_appl_search_engn" class="internal">Application: Search Engines and Semantics</a></li>
<li><a href="chap_SVD.html#sec_svd_intro" data-scroll="sec_svd_intro" class="internal">Introduction</a></li>
<li><a href="chap_SVD.html#sec_mtx_op_norm" data-scroll="sec_mtx_op_norm" class="internal">The Operator Norm of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd" data-scroll="sec_svd" class="internal">The SVD</a></li>
<li><a href="chap_SVD.html#sec_svd_mtx_spaces" data-scroll="sec_svd_mtx_spaces" class="internal">SVD and the Null, Column, and Row Spaces of a Matrix</a></li>
<li><a href="chap_SVD.html#sec_svd_exam" data-scroll="sec_svd_exam" class="internal">Examples</a></li>
<li><a href="chap_SVD.html#sec_svd_summ" data-scroll="sec_svd_summ" class="internal">Summary</a></li>
<li><a href="chap_SVD.html#sec_svd_exer" data-scroll="sec_svd_exer" class="internal">Exercises</a></li>
<li><a href="chap_SVD.html#sec_proj_indexing" data-scroll="sec_proj_indexing" class="internal">Project: Latent Semantic Indexing</a></li>
</ul>
</li>
<li class="link">
<a href="chap_pseudoinverses.html" data-scroll="chap_pseudoinverses" class="internal"><span class="codenumber">30</span> <span class="title">Using the Singular Value Decomposition</span></a><ul>
<li><a href="chap_pseudoinverses.html#sec_appl_gps" data-scroll="sec_appl_gps" class="internal">Application: Global Positioning System</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_intro" data-scroll="sec_pseudo_intro" class="internal">Introduction</a></li>
<li><a href="chap_pseudoinverses.html#sec_img_conpress" data-scroll="sec_img_conpress" class="internal">Image Compression</a></li>
<li><a href="chap_pseudoinverses.html#sec_err_approx_img" data-scroll="sec_err_approx_img" class="internal">Calculating the Error in Approximating an Image</a></li>
<li><a href="chap_pseudoinverses.html#sec_mtx_cond_num" data-scroll="sec_mtx_cond_num" class="internal">The Condition Number of a Matrix</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudoinverses" data-scroll="sec_pseudoinverses" class="internal">Pseudoinverses</a></li>
<li><a href="chap_pseudoinverses.html#sec_ls_approx_SVD" data-scroll="sec_ls_approx_SVD" class="internal">Least Squares Approximations</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exam" data-scroll="sec_pseudo_exam" class="internal">Examples</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_summ" data-scroll="sec_pseudo_summ" class="internal">Summary</a></li>
<li><a href="chap_pseudoinverses.html#sec_pseudo_exer" data-scroll="sec_pseudo_exer" class="internal">Exercises</a></li>
<li><a href="chap_pseudoinverses.html#sec_proj_gps" data-scroll="sec_proj_gps" class="internal">Project: GPS and Least Squares</a></li>
</ul>
</li>
<li class="link part"><a href="part-vec-spaces.html" data-scroll="part-vec-spaces" class="internal"><span class="codenumber">VII</span> <span class="title">Vector Spaces</span></a></li>
<li class="link">
<a href="chap_vector_spaces.html" data-scroll="chap_vector_spaces" class="internal"><span class="codenumber">31</span> <span class="title">Vector Spaces</span></a><ul>
<li><a href="chap_vector_spaces.html#sec_appl_hat_puzzle" data-scroll="sec_appl_hat_puzzle" class="internal">Application: The Hat Puzzle</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_intro" data-scroll="sec_vec_space_intro" class="internal">Introduction</a></li>
<li><a href="chap_vector_spaces.html#sec_space_like_rn" data-scroll="sec_space_like_rn" class="internal">Spaces with Similar Structure to <span class="process-math">\(\R^n\)</span></a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space" data-scroll="sec_vec_space" class="internal">Vector Spaces</a></li>
<li><a href="chap_vector_spaces.html#sec_subspaces" data-scroll="sec_subspaces" class="internal">Subspaces</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exam" data-scroll="sec_vec_space_exam" class="internal">Examples</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_summ" data-scroll="sec_vec_space_summ" class="internal">Summary</a></li>
<li><a href="chap_vector_spaces.html#sec_vec_space_exer" data-scroll="sec_vec_space_exer" class="internal">Exercises</a></li>
<li><a href="chap_vector_spaces.html#sec_proj_hamming_hat_puzzle" data-scroll="sec_proj_hamming_hat_puzzle" class="internal">Project: Hamming Codes and the Hat Puzzle</a></li>
</ul>
</li>
<li class="link">
<a href="chap_bases.html" data-scroll="chap_bases" class="internal"><span class="codenumber">32</span> <span class="title">Bases for Vector Spaces</span></a><ul>
<li><a href="chap_bases.html#sec_img_compress" data-scroll="sec_img_compress" class="internal">Application: Image Compression</a></li>
<li><a href="chap_bases.html#sec_bases_intro" data-scroll="sec_bases_intro" class="internal">Introduction</a></li>
<li><a href="chap_bases.html#sec_lin_indep" data-scroll="sec_lin_indep" class="internal">Linear Independence</a></li>
<li><a href="chap_bases.html#sec_bases" data-scroll="sec_bases" class="internal">Bases</a></li>
<li><a href="chap_bases.html#sec_basis_vec_space" data-scroll="sec_basis_vec_space" class="internal">Finding a Basis for a Vector Space</a></li>
<li><a href="chap_bases.html#sec_bases_exam" data-scroll="sec_bases_exam" class="internal">Examples</a></li>
<li><a href="chap_bases.html#sec_bases_summ" data-scroll="sec_bases_summ" class="internal">Summary</a></li>
<li><a href="chap_bases.html#sec_bases_exer" data-scroll="sec_bases_exer" class="internal">Exercises</a></li>
<li><a href="chap_bases.html#sec_proj_img_compress" data-scroll="sec_proj_img_compress" class="internal">Project: Image Compression with Wavelets</a></li>
</ul>
</li>
<li class="link">
<a href="chap_dimension.html" data-scroll="chap_dimension" class="internal"><span class="codenumber">33</span> <span class="title">The Dimension of a Vector Space</span></a><ul>
<li><a href="chap_dimension.html#sec_appl_pca" data-scroll="sec_appl_pca" class="internal">Application: Principal Component Analysis</a></li>
<li><a href="chap_dimension.html#sec_dims_intro" data-scroll="sec_dims_intro" class="internal">Introduction</a></li>
<li><a href="chap_dimension.html#sec_finite_dim_space" data-scroll="sec_finite_dim_space" class="internal">Finite Dimensional Vector Spaces</a></li>
<li><a href="chap_dimension.html#sec_dim_subspace" data-scroll="sec_dim_subspace" class="internal">The Dimension of a Subspace</a></li>
<li><a href="chap_dimension.html#sec_cond_basis_vec_space" data-scroll="sec_cond_basis_vec_space" class="internal">Conditions for a Basis of a Vector Space</a></li>
<li><a href="chap_dimension.html#sec_dims_exam" data-scroll="sec_dims_exam" class="internal">Examples</a></li>
<li><a href="chap_dimension.html#sec_dims_summ" data-scroll="sec_dims_summ" class="internal">Summary</a></li>
<li><a href="chap_dimension.html#sec_dims_exer" data-scroll="sec_dims_exer" class="internal">Exercises</a></li>
<li><a href="chap_dimension.html#sec_proj_pca" data-scroll="sec_proj_pca" class="internal">Project: Understanding Principal Component Analysis</a></li>
</ul>
</li>
<li class="link">
<a href="chap_coordinate_vectors_vector_spaces.html" data-scroll="chap_coordinate_vectors_vector_spaces" class="internal"><span class="codenumber">34</span> <span class="title">Coordinate Vectors and Coordinate Transformations</span></a><ul>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_appl_sums" data-scroll="sec_appl_sums" class="internal">Application: Calculating Sums</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coor_vec_intro" data-scroll="sec_coor_vec_intro" class="internal">Introduction</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_trans" data-scroll="sec_coord_trans" class="internal">The Coordinate Transformation</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exam" data-scroll="sec_coord_vec_exam" class="internal">Examples</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_summ" data-scroll="sec_coord_vec_summ" class="internal">Summary</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_coord_vec_exer" data-scroll="sec_coord_vec_exer" class="internal">Exercises</a></li>
<li><a href="chap_coordinate_vectors_vector_spaces.html#sec_proj_sum_powers" data-scroll="sec_proj_sum_powers" class="internal">Project: Finding Formulas for Sums of Powers</a></li>
</ul>
</li>
<li class="link">
<a href="chap_inner_products.html" data-scroll="chap_inner_products" class="internal"><span class="codenumber">35</span> <span class="title">Inner Product Spaces</span></a><ul>
<li><a href="chap_inner_products.html#sec_appl_fourier" data-scroll="sec_appl_fourier" class="internal">Application: Fourier Series</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_intro" data-scroll="sec_inner_prod_intro" class="internal">Introduction</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_spaces" data-scroll="sec_inner_prod_spaces" class="internal">Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_vec_length" data-scroll="sec_vec_length" class="internal">The Length of a Vector</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_orthog" data-scroll="sec_inner_prod_orthog" class="internal">Orthogonality in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prog_orthog_bases" data-scroll="sec_inner_prog_orthog_bases" class="internal">Orthogonal and Orthonormal Bases in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_proj_subspace" data-scroll="sec_orthog_proj_subspace" class="internal">Orthogonal Projections onto Subspaces</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_approx" data-scroll="sec_inner_prod_approx" class="internal">Best Approximations in Inner Product Spaces</a></li>
<li><a href="chap_inner_products.html#sec_orthog_comp_ip" data-scroll="sec_orthog_comp_ip" class="internal">Orthogonal Complements</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exam" data-scroll="sec_inner_prod_exam" class="internal">Examples</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_summ" data-scroll="sec_inner_prod_summ" class="internal">Summary</a></li>
<li><a href="chap_inner_products.html#sec_inner_prod_exer" data-scroll="sec_inner_prod_exer" class="internal">Exercises</a></li>
<li><a href="chap_inner_products.html#sec_proj_fourier" data-scroll="sec_proj_fourier" class="internal">Project: Fourier Series and Musical Tones</a></li>
</ul>
</li>
<li class="link">
<a href="chap_gram_schmidt_ips.html" data-scroll="chap_gram_schmidt_ips" class="internal"><span class="codenumber">36</span> <span class="title">The Gram-Schmidt Process in Inner Product Spaces</span></a><ul>
<li><a href="chap_gram_schmidt_ips.html#sec_appl_gaussian_quad" data-scroll="sec_appl_gaussian_quad" class="internal">Application: Gaussian Quadrature</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_intro" data-scroll="sec_gram_schmidt_intro" class="internal">Introduction</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_inner_prod" data-scroll="sec_gram_schmidt_inner_prod" class="internal">The Gram-Schmidt Process using Inner Products</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exam" data-scroll="sec_gram_schmidt_exam" class="internal">Examples</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_summ_ips" data-scroll="sec_gram_schmidt_summ_ips" class="internal">Summary</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_gram_schmidt_exer" data-scroll="sec_gram_schmidt_exer" class="internal">Exercises</a></li>
<li><a href="chap_gram_schmidt_ips.html#sec_proj_gaussian_quad" data-scroll="sec_proj_gaussian_quad" class="internal">Project: Gaussian Quadrature and Legendre Polynomials</a></li>
</ul>
</li>
<li class="link part"><a href="part-lin-trans.html" data-scroll="part-lin-trans" class="internal"><span class="codenumber">VIII</span> <span class="title">Linear Transformations</span></a></li>
<li class="link">
<a href="chap_linear_transformation.html" data-scroll="chap_linear_transformation" class="internal"><span class="codenumber">37</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="chap_linear_transformation.html#sec_appl_fractals" data-scroll="sec_appl_fractals" class="internal">Application: Fractals</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_intro" data-scroll="sec_lin_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_linear_transformation.html#sec_onto_oneone" data-scroll="sec_onto_oneone" class="internal">Onto and One-to-One Transformations</a></li>
<li><a href="chap_linear_transformation.html#sec_kernel_range" data-scroll="sec_kernel_range" class="internal">The Kernel and Range of Linear Transformation</a></li>
<li><a href="chap_linear_transformation.html#sec_isomorph" data-scroll="sec_isomorph" class="internal">Isomorphisms</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exam" data-scroll="sec_lin_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_summ" data-scroll="sec_lin_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_linear_transformation.html#sec_lin_trans_exer" data-scroll="sec_lin_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_linear_transformation.html#sec_proj_fractals" data-scroll="sec_proj_fractals" class="internal">Project: Fractals via Iterated Function Systems</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformation_matrix.html" data-scroll="chap_transformation_matrix" class="internal"><span class="codenumber">38</span> <span class="title">The Matrix of a Linear Transformation</span></a><ul>
<li><a href="chap_transformation_matrix.html#sec_appl_secret" data-scroll="sec_appl_secret" class="internal">Application: Secret Sharing Algorithms</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_intro" data-scroll="sec_mtxof_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformation_matrix.html#sec_trans_rn_rm" data-scroll="sec_trans_rn_rm" class="internal">Linear Transformations from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtx_lin_trans" data-scroll="sec_mtx_lin_trans" class="internal">The Matrix of a Linear Transformation</a></li>
<li><a href="chap_transformation_matrix.html#sec_ker_mtx" data-scroll="sec_ker_mtx" class="internal">A Connection between <span class="process-math">\(\Ker(T)\)</span> and a Matrix Representation of <span class="process-math">\(T\)</span></a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exam" data-scroll="sec_mtxof_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_summ" data-scroll="sec_mtxof_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformation_matrix.html#sec_mtxof_trans_exer" data-scroll="sec_mtxof_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformation_matrix.html#sec_proj_secret" data-scroll="sec_proj_secret" class="internal">Project: Shamir's Secret Sharing and Lagrange Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="chap_transformations_eigenvalues.html" data-scroll="chap_transformations_eigenvalues" class="internal"><span class="codenumber">39</span> <span class="title">Eigenvalues of Linear Transformations</span></a><ul>
<li><a href="chap_transformations_eigenvalues.html#sec_appl_diff_eq" data-scroll="sec_appl_diff_eq" class="internal">Application: Linear Differential Equations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_intro" data-scroll="sec_eigen_trans_intro" class="internal">Introduction</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_find_eigen_trans" data-scroll="sec_find_eigen_trans" class="internal">Finding Eigenvalues and Eigenvectors of Linear Transformations</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_diagonal" data-scroll="sec_diagonal" class="internal">Diagonalization</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exam" data-scroll="sec_eigen_trans_exam" class="internal">Examples</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_summ" data-scroll="sec_eigen_trans_summ" class="internal">Summary</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_eigen_trans_exer" data-scroll="sec_eigen_trans_exer" class="internal">Exercises</a></li>
<li><a href="chap_transformations_eigenvalues.html#sec_proj_diff_eq" data-scroll="sec_proj_diff_eq" class="internal">Project: Linear Transformations and Differential Equations</a></li>
</ul>
</li>
<li class="link">
<a href="chap_JCF.html" data-scroll="chap_JCF" class="internal"><span class="codenumber">40</span> <span class="title">The Jordan Canonical Form</span></a><ul>
<li><a href="chap_JCF.html#sec_appl_epidemic" data-scroll="sec_appl_epidemic" class="internal">Application: The Bailey Model of an Epidemic</a></li>
<li><a href="chap_JCF.html#sec_jordan_intro" data-scroll="sec_jordan_intro" class="internal">Introduction</a></li>
<li><a href="chap_JCF.html#sec_eigen_dne" data-scroll="sec_eigen_dne" class="internal">When an Eigenvalue Decomposition Does Not Exist</a></li>
<li><a href="chap_JCF.html#sec_gen_eigen_jordan" data-scroll="sec_gen_eigen_jordan" class="internal">Generalized Eigenvectors and the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_jordan_geom" data-scroll="sec_mtx_jordan_geom" class="internal">Geometry of Matrix Transformations using the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_proof" data-scroll="sec_jordan_proof" class="internal">Proof of the Existence of the Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_mtx_nilpotent" data-scroll="sec_mtx_nilpotent" class="internal">Nilpotent Matrices and Invariant Subspaces</a></li>
<li><a href="chap_JCF.html#sec_jordan" data-scroll="sec_jordan" class="internal">The Jordan Canonical Form</a></li>
<li><a href="chap_JCF.html#sec_jordan_exam" data-scroll="sec_jordan_exam" class="internal">Examples</a></li>
<li><a href="chap_JCF.html#sec_jordan_summ" data-scroll="sec_jordan_summ" class="internal">Summary</a></li>
<li><a href="chap_JCF.html#sec_jordan_exer" data-scroll="sec_jordan_exer" class="internal">Exercises</a></li>
<li><a href="chap_JCF.html#sec_proj_epidemic" data-scroll="sec_proj_epidemic" class="internal">Project: Modeling an Epidemic</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="app_complex_numbers.html" data-scroll="app_complex_numbers" class="internal"><span class="codenumber">A</span> <span class="title">Complex Numbers</span></a><ul>
<li><a href="app_complex_numbers.html#sec_complex_numbers" data-scroll="sec_complex_numbers" class="internal">Complex Numbers</a></li>
<li><a href="app_complex_numbers.html#sec_conj_modulus" data-scroll="sec_conj_modulus" class="internal">Conjugates and Modulus</a></li>
<li><a href="app_complex_numbers.html#sec_complex_vect" data-scroll="sec_complex_vect" class="internal">Complex Vectors</a></li>
</ul>
</li>
<li class="link"><a href="app_answers.html" data-scroll="app_answers" class="internal"><span class="codenumber">B</span> <span class="title">Answers and Hints for Selected Exercises</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="chapter" id="chap_orthogonal_diagonalization"><h2 class="heading">
<span class="type">Section</span> <span class="codenumber">27</span> <span class="title">Orthogonal Diagonalization</span>
</h2>
<section class="introduction" id="introduction-441"><article class="objectives goal-like" id="objectives-27"><h3 class="heading"><span class="type">Focus Questions</span></h3>
<div class="introduction" id="introduction-442"><p id="p-4532">By the end of this section, you should be able to give precise and thorough answers to the questions listed below. You may want to keep these questions in mind to focus your thoughts as you complete the section.</p></div>
<ul class="disc">
<li id="li-713"><p id="p-4533">What does it mean for a matrix to be orthogonally diagonalizable and why is this concept important?</p></li>
<li id="li-714"><p id="p-4534">What is a symmetric matrix and what important property related to diagonalization does a symmetric matrix have?</p></li>
<li id="li-715"><p id="p-4535">What is the spectrum of a matrix?</p></li>
</ul></article></section><section class="section" id="sec_appl_mulit_2nd_deriv"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Application: The Multivariable Second Derivative Test</span>
</h3>
<p id="p-4536">In single variable calculus, we learn that the second derivative can be used to classify a critical point of the type where the derivative of a function is 0 as a local maximum or minimum.</p>
<article class="theorem theorem-like" id="theorem-64"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.1</span><span class="period">.</span><span class="space"> </span><span class="title">The Second Derivative Test for Single-Variable Functions.</span>
</h4>
<p id="p-4537">If <span class="process-math">\(a\)</span> is a critical number of a function <span class="process-math">\(f\)</span> so that <span class="process-math">\(f'(a)=0\)</span> and if <span class="process-math">\(f''(a)\)</span> exists, then</p>
<ul class="disc">
<li id="li-716"><p id="p-4538">if <span class="process-math">\(f''(a) \lt 0\text{,}\)</span> then <span class="process-math">\(f(a)\)</span> is a local maximum value of <span class="process-math">\(f\text{,}\)</span></p></li>
<li id="li-717"><p id="p-4539">if <span class="process-math">\(f''(a) &gt; 0\text{,}\)</span> then <span class="process-math">\(f(a)\)</span> is a local minimum value of <span class="process-math">\(f\text{,}\)</span> and</p></li>
<li id="li-718"><p id="p-4540">if <span class="process-math">\(f''(a) = 0\text{,}\)</span> this test yields no information.</p></li>
</ul></article><p id="p-4541">In the two-variable case we have an analogous test, which is usually seen in a multivariable calculus course.</p>
<article class="theorem theorem-like" id="theorem-65"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.2</span><span class="period">.</span><span class="space"> </span><span class="title">The Second Derivative Test for Functions of Two Variables.</span>
</h4>
<p id="p-4542">Suppose <span class="process-math">\((a,b)\)</span> is a critical point of the function <span class="process-math">\(f\)</span> for which <span class="process-math">\(f_x(a,b) = 0\)</span> and <span class="process-math">\(f_y(a,b) = 0\text{.}\)</span> Let <span class="process-math">\(D\)</span> be the quantity defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = f_{xx}(a,b) f_{yy}(a,b) - f_{xy}(a,b)^2\text{.}
\end{equation*}
</div>
<ul class="disc">
<li id="li-719"><p id="p-4543">If <span class="process-math">\(D&gt;0\)</span> and <span class="process-math">\(f_{xx}(a,b) \lt 0\text{,}\)</span> then <span class="process-math">\(f\)</span> has a local maximum at <span class="process-math">\((a,b)\text{.}\)</span></p></li>
<li id="li-720"><p id="p-4544">If <span class="process-math">\(D&gt;0\)</span> and <span class="process-math">\(f_{xx}(a,b) &gt; 0\text{,}\)</span> then <span class="process-math">\(f\)</span> has a local minimum at <span class="process-math">\((a,b)\text{.}\)</span></p></li>
<li id="li-721"><p id="p-4545">If <span class="process-math">\(D \lt 0\text{,}\)</span> then <span class="process-math">\(f\)</span> has a saddle point at <span class="process-math">\((a,b)\text{.}\)</span></p></li>
<li id="li-722"><p id="p-4546">If <span class="process-math">\(D = 0\text{,}\)</span> then this test yields no information about what happens at <span class="process-math">\((a,b)\text{.}\)</span></p></li>
</ul></article><p id="p-4547">A proof of this test for two-variable functions is based on Taylor polynomials, and relies on symmetric matrices, eigenvalues, and quadratic forms. The steps for a proof will be found later in this section.</p></section><section class="section" id="sec_orthog_diag_intro"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Introduction</span>
</h3>
<p id="p-4548">We have seen how to diagonalize a matrix — if we can find <span class="process-math">\(n\)</span> linearly independent eigenvectors of an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> and let <span class="process-math">\(P\)</span> be the matrix whose columns are those eigenvectors, then <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix with the eigenvalues down the diagonal in the same order corresponding to the eigenvectors placed in <span class="process-math">\(P\text{.}\)</span> We will see that in certain cases we can take this one step further and create an orthogonal matrix with eigenvectors as columns to diagonalize a matrix. This is called orthogonal diagonalization. Orthogonal diagonalizability is useful in that it allows us to find a “convenient” coordinate system in which to interpret the results of certain matrix transformations. A set of orthonormal basis vectors for an orthogonally diagonalizable matrix <span class="process-math">\(A\)</span> is called a set of <dfn class="terminology">principal axes</dfn> for <span class="process-math">\(A\text{.}\)</span> Orthogonal diagonalization will also play a crucial role in the singular value decomposition of a matrix, a decomposition that has been described by some as the “pinnacle” of linear algebra.</p>
<article class="definition definition-like" id="def_7_a_orthogonal__diagonalization"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">27.3</span><span class="period">.</span>
</h4>
<p id="p-4549">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">orthogonally diagonalizable</dfn> if there is an orthogonal matrix <span class="process-math">\(P\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{\tr}AP
\end{equation*}
</div>
<p class="continuation">is a diagonal matrix. We say that the matrix <span class="process-math">\(P\)</span> <dfn class="terminology">orthogonally diagonalizes</dfn> the matrix <span class="process-math">\(A\text{.}\)</span></p></article><article class="exploration project-like" id="pa_7_a"><h4 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">27.1</span><span class="period">.</span>
</h4>
<article class="task exercise-like" id="task-1501"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<div class="introduction" id="introduction-443"><p id="p-4550">For each matrix <span class="process-math">\(A\)</span> whose eigenvalues and corresponding eigenvectors are given, find a matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix.</p></div>
<article class="task exercise-like" id="task-1502"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-4551"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 1 \end{array} \right]\)</span> with eigenvalues <span class="process-math">\(-1\)</span> and 3 and corresponding eigenvectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -1 \\ 1 \end{array} \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 1 \\ 1 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-1503"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-4552"><span class="process-math">\(A = \left[ \begin{array}{cc} 1\amp 2 \\ 1\amp 2 \end{array} \right]\)</span> with eigenvalues <span class="process-math">\(0\)</span> and <span class="process-math">\(3\)</span> and corresponding eigenvectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -2 \\ 1 \end{array} \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{c} 1 \\ 1 \end{array} \right]\text{.}\)</span></p></article><article class="task exercise-like" id="task-1504"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-4553"><span class="process-math">\(A = \left[ \begin{array}{ccc} 1\amp 0\amp 1 \\ 0\amp 1\amp 1 \\ 1\amp 1\amp 2 \end{array} \right]\)</span> with eigenvalues <span class="process-math">\(0\text{,}\)</span> <span class="process-math">\(1\text{,}\)</span> and <span class="process-math">\(3\)</span> and corresponding eigenvectors <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -1 \\ -1 \\ 1 \end{array} \right]\text{,}\)</span> <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} -1 \\ 1 \\ 0 \end{array} \right]\text{,}\)</span> and <span class="process-math">\(\vv_3 = \left[ \begin{array}{c} 1 \\ 1 \\ 2 \end{array} \right]\text{.}\)</span></p></article></article><article class="task exercise-like" id="task-1505"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4554">Which matrices in part 1 seem to satisfy the orthogonal diagonalization requirement? Do you notice any common traits among these matrices?</p></article></article></section><section class="section" id="sec_mtx_symm"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Symmetric Matrices</span>
</h3>
<p id="p-4555">As we saw in <a href="" class="xref" data-knowl="./knowl/pa_7_a.html" title="Preview Activity 27.1">Preview Activity 27.1</a>, matrices that are not symmetric need not be orthogonally diagonalizable, but the symmetric matrix examples are orthogonally diagonalizable. We explore that idea in this section.</p>
<p id="p-4556">If <span class="process-math">\(P\)</span> is a matrix that orthogonally diagonalizes the matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(P^{\tr}AP = D\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix. Since <span class="process-math">\(D^{\tr} = D\)</span> and <span class="process-math">\(A = PDP^{\tr}\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-182">
\begin{align*}
A \amp = PDP^{\tr}\\
\amp = PD^{\tr}P^{\tr}\\
\amp = \left(P^{\tr}\right)^{\tr}D^{\tr}P^{\tr}\\
\amp = \left(PDP^{\tr}\right)^{\tr}\\
\amp = A^{\tr}\text{.}
\end{align*}
</div>
<p id="p-4557">Therefore, <span class="process-math">\(A^{\tr} = A\)</span> and matrices with this property are the only matrices that can be orthogonally diagonalized. Recall that any matrix <span class="process-math">\(A\)</span> satisfying <span class="process-math">\(A^{\tr} = A\)</span> is a symmetric matrix.</p>
<p id="p-4558">While we have just shown that the only matrices that can be orthogonally diagonalized are the symmetric matrices, the amazing thing about symmetric matrices is that <em class="emphasis">every</em> symmetric matrix can be orthogonally diagonalized. We will prove this shortly.</p>
<p id="p-4559">Symmetric matrices have useful properties, a few of which are given in the following activity (we will use some of these properties later in this section).</p>
<article class="activity project-like" id="act_7_a_symmetric"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">27.2</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-444"><p id="p-4560">Let <span class="process-math">\(A\)</span> be a symmetric <span class="process-math">\(n \times n\)</span> matrix and let <span class="process-math">\(\vx\)</span> and <span class="process-math">\(\vy\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1506"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4561">Show that <span class="process-math">\(\vx^{\tr} A \vy = (A\vx)^{\tr} \vy\text{.}\)</span></p></article><article class="task exercise-like" id="task-1507"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4562">Show that <span class="process-math">\((A\vx) \cdot \vy = \vx \cdot (A\vy)\text{.}\)</span></p></article><article class="task exercise-like" id="task-1508"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4563">Show that the eigenvalues of a <span class="process-math">\(2 \times 2\)</span> symmetric matrix <span class="process-math">\(A = \left[ \begin{array}{cc} a\amp b\\b\amp c \end{array} \right]\)</span> are real.</p></article></article><p id="p-4564"><a href="" class="xref" data-knowl="./knowl/act_7_a_symmetric.html" title="Activity 27.2">Activity 27.2</a> (c) shows that a <span class="process-math">\(2 \times 2\)</span> symmetric matrix has real eigenvalues. This is a general result about real symmetric matrices.</p>
<article class="theorem theorem-like" id="thm_7_a_symmetric_eigenvalues"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.4</span><span class="period">.</span>
</h4>
<p id="p-4565">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> symmetric matrix with real entries. Then the eigenvalues of <span class="process-math">\(A\)</span> are real.</p></article><article class="proof" id="proof-14"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-4566">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> symmetric matrix with real entries and let <span class="process-math">\(\lambda\)</span> be an eigenvalue of <span class="process-math">\(A\)</span> with eigenvector <span class="process-math">\(\vv\text{.}\)</span> To show that <span class="process-math">\(\lambda\)</span> is real, we will show that <span class="process-math">\(\overline{\lambda} = \lambda\text{.}\)</span> We know</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_symm1">
\begin{equation}
A \vv = \lambda \vv\text{.}\tag{27.1}
\end{equation}
</div>
<p id="p-4567">Since <span class="process-math">\(A\)</span> has real entries, we also know that <span class="process-math">\(\overline{\lambda}\)</span> is an eigenvalue for <span class="process-math">\(A\)</span> with eigenvector <span class="process-math">\(\overline{\vv}\text{.}\)</span> Multiply both sides of <a href="" class="xref" data-knowl="./knowl/eq_symm1.html" title="Equation 27.1">(27.1)</a> on the left by <span class="process-math">\(\overline{\vv}^{\tr}\)</span> to obtain</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_symm1.html" id="eq_symm2">
\begin{equation}
\overline{\vv}^{\tr} A \vv = \overline{\vv}^{\tr} \lambda \vv = \lambda \left(\overline{\vv}^{\tr} \vv \right)\text{.}\tag{27.2}
\end{equation}
</div>
<p id="p-4568">Now</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_symm2.html">
\begin{equation*}
\overline{\vv}^{\tr} A \vv = (A\overline{\vv})^{\tr} \vv = (\overline{\lambda} \ \overline{\vv})^{\tr} \vv = \overline{\lambda} \left(\overline{\vv}^{\tr} \vv \right)
\end{equation*}
</div>
<p class="continuation">and equation <a href="" class="xref" data-knowl="./knowl/eq_symm2.html" title="Equation 27.2">(27.2)</a> becomes</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_symm2.html">
\begin{equation*}
\overline{\lambda} \left(\overline{\vv}^{\tr} \vv \right) = \lambda \left(\overline{\vv}^{\tr} \vv \right)\text{.}
\end{equation*}
</div>
<p id="p-4569">Since <span class="process-math">\(\vv \neq \vzero\text{,}\)</span> this implies that <span class="process-math">\(\overline{\lambda} = \lambda\)</span> and <span class="process-math">\(\lambda\)</span> is real.</p></article><p id="p-4570">To orthogonally diagonalize a matrix, it must be the case that eigenvectors corresponding to different eigenvalues are orthogonal. This is an important property and it would be useful to know when it happens.</p>
<article class="activity project-like" id="act_7_a_symmetric_eigenvalues"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">27.3</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-445"><p id="p-4571">Let <span class="process-math">\(A\)</span> be a real symmetric matrix with eigenvalues <span class="process-math">\(\lambda_1\)</span> and <span class="process-math">\(\lambda_2\)</span> and corresponding eigenvectors <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\text{,}\)</span> respectively.</p></div>
<article class="task exercise-like" id="task-1509"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4572">Use <a href="" class="xref" data-knowl="./knowl/act_7_a_symmetric.html" title="Activity 27.2">Activity 27.2</a> (b) to show that <span class="process-math">\(\lambda_1 \vv_1\cdot \vv_2 = \lambda_2 \vv_1 \cdot \vv_2\text{.}\)</span></p></article><article class="task exercise-like" id="task-1510"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4573">Explain why the result of part (a) shows that <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> are orthogonal if <span class="process-math">\(\lambda_1\neq \lambda_2\text{.}\)</span></p></article></article><p id="p-4574"><a href="" class="xref" data-knowl="./knowl/act_7_a_symmetric_eigenvalues.html" title="Activity 27.3">Activity 27.3</a> proves the following theorem.</p>
<article class="theorem theorem-like" id="theorem-67"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.5</span><span class="period">.</span>
</h4>
<p id="p-4575">If <span class="process-math">\(A\)</span> is a real symmetric matrix, then eigenvectors corresponding to distinct eigenvalues are orthogonal.</p></article><p id="p-4576">Recall that the only matrices that can be orthogonally diagonalized are the symmetric matrices. Now we show that every real symmetric matrix can be orthogonally diagonalized, which completely characterizes the matrices that are orthogonally diagonalizable. The proof of the following theorem proceeds by induction. A reader who has not yet encountered this technique of proof can safely skip the proof of this theorem without loss of continuity.</p>
<article class="theorem theorem-like" id="theorem-68"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.6</span><span class="period">.</span>
</h4>
<p id="p-4577">Let <span class="process-math">\(A\)</span> be a real symmetric matrix. Then <span class="process-math">\(A\)</span> is orthogonally diagonalizable.</p></article><article class="proof" id="proof-15"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4>
<p id="p-4578">Let <span class="process-math">\(A\)</span> be a real <span class="process-math">\(n \times n\)</span> symmetric matrix. The proof proceeds by induction on <span class="process-math">\(n\text{.}\)</span> If <span class="process-math">\(n = 1\text{,}\)</span> then <span class="process-math">\(A\)</span> is diagonal and orthogonally diagonalizable. So assume that any real <span class="process-math">\((n-1) \times (n-1)\)</span> symmetric matrix is orthogonally diagonalizable. Assume that <span class="process-math">\(A\)</span> is a real <span class="process-math">\(n \times n\)</span> symmetric matrix. By Theorem 25.4 (find reference), the eigenvalues of <span class="process-math">\(A\)</span> are real. Let <span class="process-math">\(\lambda_1\)</span> be a real eigenvalue of <span class="process-math">\(A\)</span> with corresponding unit eigenvector <span class="process-math">\(\vp_1\text{.}\)</span> We can use the Gram-Schmidt process to extend <span class="process-math">\(\{\vp_1\}\)</span> to an orthonormal basis <span class="process-math">\(\{\vp_1, \vp_2, \ldots, \vp_n\}\)</span> for <span class="process-math">\(\R^n\text{.}\)</span> Let <span class="process-math">\(P_1 = [\vp_1 \ \vp_2 \ \ldots \ \vp_n]\text{.}\)</span> Then <span class="process-math">\(P_1\)</span> is an orthogonal matrix. Also,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-183">
\begin{align*}
P_1^{-1}AP_1 \amp = P_1^{\tr}AP_1\\
\amp = P_1^{\tr} [A\vp_1 \ A\vp_2 \ \ldots \ A\vp_n]\\
\amp = \left[ \begin{array}{c} \vp_1^{\tr}\\
\vp_2^{\tr}\\
\vdots\\
\vp_n^{\tr} \end{array} \right]  [\lambda \vp_1 \ A\vp_2 \ \ldots \ A\vp_n]\\
\amp = \left[ \begin{array}{ccccc} \vp_1^{\tr} \lambda_1 \vp_1 \amp  \vp_1^{\tr} A\vp_2 \amp  \vp_1 A\vp_3 \amp  \cdots \amp  \vp_1^{\tr} A \vp_n\\
\vp_2^{\tr} \lambda_1 \vp_1 \amp  \vp_2^{\tr} A\vp_2 \amp  \vp_2 A\vp_3 \amp \cdots \amp  \vp_2^{\tr} A \vp_n\\
\amp   \amp  \vdots   \amp  \amp\\
\vp_n^{\tr} \lambda_1 \vp_1 \amp  \vp_n^{\tr} A\vp_2 \amp  \vp_n A\vp_3 \amp \cdots \amp  \vp_n^{\tr} A \vp_n \end{array} \right]\\
\amp = \left[ \begin{array}{ccccc} \lambda_1\amp  \vp_1^{\tr} A\vp_2 \amp  \vp_1 A\vp_3 \amp  \cdots \amp  \vp_1^{\tr} A \vp_n\\
0 \amp  \vp_2^{\tr} A\vp_2 \amp  \vp_2 A\vp_3 \amp \cdots \amp  \vp_2^{\tr} A \vp_n\\
\amp   \amp  \vdots   \amp  \amp\\
0 \amp  \vp_n^{\tr} A\vp_2 \amp  \vp_n A\vp_3 \amp \cdots \amp  \vp_n^{\tr} A \vp_n \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
\vzero \amp  A_1 \end{array} \right]
\end{align*}
</div>
<p class="continuation">where <span class="process-math">\(\vx\)</span> is a <span class="process-math">\((n-1)\times 1\)</span> vector, <span class="process-math">\(\vzero\)</span> is the zero vector in <span class="process-math">\(\R^{n-1}\text{,}\)</span> and <span class="process-math">\(A_1\)</span> is an <span class="process-math">\((n-1) \times (n-1)\)</span> matrix. Letting <span class="process-math">\(R = P_1^{\tr}AP_1\)</span> we have that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
R^{\tr} = \left(P_1^{\tr}AP_1\right)^{\tr} = P_1^{\tr}A^{\tr}P_1 = P_1^{\tr}AP_1 = R\text{,}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(R\)</span> is a symmetric matrix. Therefore, <span class="process-math">\(\vx = \vzero\)</span> and <span class="process-math">\(A_1\)</span> is a symmetric matrix. By our induction hypothesis, <span class="process-math">\(A_1\)</span> is orthogonally diagonalizable. That is, there exists an <span class="process-math">\((n-1) \times (n-1)\)</span> orthogonal matrix <span class="process-math">\(Q\)</span> such that <span class="process-math">\(Q^{\tr}A_1Q = D_1\text{,}\)</span> where <span class="process-math">\(D_1\)</span> is a diagonal matrix. Now define <span class="process-math">\(P_2\)</span> by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_2 = \left[ \begin{array}{cc} 1\amp \vzero^{\tr} \\ \vzero \amp  Q \end{array}  \right]\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\vzero\)</span> is the zero vector in <span class="process-math">\(\R^{n-1}\text{.}\)</span> By construction, the columns of <span class="process-math">\(P_2\)</span> are orthonormal, so <span class="process-math">\(P_2\)</span> is an orthogonal matrix. Since <span class="process-math">\(P_1\)</span> is also an orthogonal matrix,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{\tr} = (P_1P_2)^{\tr} = P_2^{\tr}P_1^{\tr} = P_2^{-1}P_1^{-1} = (P_1P_2)^{-1}  = P^{-1}
\end{equation*}
</div>
<p class="continuation">and <span class="process-math">\(P\)</span> is an orthogonal matrix. Finally,</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-184">
\begin{align*}
P^{\tr}AP \amp = (P_1P_2)^{\tr}A(P_1P_2)\\
\amp = P_2^{\tr}\left(P_1^{\tr}AP_1\right)P_2\\
\amp = \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]^{\tr} \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
0 \amp  A_1 \end{array} \right] \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q^{\tr} \end{array} \right] \left[ \begin{array}{cc} \lambda_1\amp \vx^{\tr}\\
0 \amp  A_1 \end{array} \right]\left[ \begin{array}{cc} 1\amp \vzero^{\tr}\\
\vzero \amp  Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vzero^{\tr}\\
\vzero \amp  Q^{\tr}A_1Q \end{array} \right]\\
\amp = \left[ \begin{array}{cc} \lambda_1\amp \vzero^{\tr}\\
\vzero \amp  D_1 \end{array} \right]\text{.}
\end{align*}
</div>
<p id="p-4579">Therefore, <span class="process-math">\(P^{\tr}AP\)</span> is a diagonal matrix and <span class="process-math">\(P\)</span> orthogonally diagonalizes <span class="process-math">\(A\text{.}\)</span> This completes our proof.</p></article><p id="p-4580"> The set of eigenvalues of a matrix <span class="process-math">\(A\)</span> is called the <dfn class="terminology">spectrum</dfn> of <span class="process-math">\(A\)</span> and we have just proved the following theorem.</p>
<article class="theorem theorem-like" id="theorem-69"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.7</span><span class="period">.</span><span class="space"> </span><span class="title">The Spectral Theorem for Real Symmetric Matrices.</span>
</h4>
<p id="p-4581">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> symmetric matrix with real entries. Then</p>
<ol class="decimal">
<li id="li-723"><p id="p-4582"><span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> real eigenvalues (counting multiplicities)</p></li>
<li id="li-724"><p id="p-4583">the dimension of each eigenspace of <span class="process-math">\(A\)</span> is the multiplicity of the corresponding eigenvalue as a root of the characteristic polynomial</p></li>
<li id="li-725"><p id="p-4584">eigenvectors corresponding to different eigenvalues are orthogonal</p></li>
<li id="li-726"><p id="p-4585"><span class="process-math">\(A\)</span> is orthogonally diagonalizable.</p></li>
</ol></article><p id="p-4586">So <em class="emphasis">any</em> real symmetric matrix is orthogonally diagonalizable. We have seen examples of the orthogonal diagonalization of <span class="process-math">\(n \times n\)</span> real symmetric matrices with <span class="process-math">\(n\)</span> distinct eigenvalues, but how do we orthogonally diagonalize a symmetric matrix having eigenvalues of multiplicity greater than 1? The next activity shows us the process.</p>
<article class="activity project-like" id="act_7_a_3"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">27.4</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-446"><p id="p-4587">Let <span class="process-math">\(A = \left[ \begin{array}{ccc} 4\amp 2\amp 2 \\ 2\amp 4\amp 2 \\ 2\amp 2\amp 4 \end{array} \right]\text{.}\)</span> The eigenvalues of <span class="process-math">\(A\)</span> are 2 and 8, with eigenspace of dimension 2 and dimension 1, respectively.</p></div>
<article class="task exercise-like" id="task-1511"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4588">Explain why <span class="process-math">\(A\)</span> can be orthogonally diagonalized.</p></article><article class="task exercise-like" id="task-1512"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4589">Two linearly independent eigenvectors for <span class="process-math">\(A\)</span> corresponding to the eigenvalue 2 are <span class="process-math">\(\vv_1 = \left[ \begin{array}{r} -1 \\ 0 \\ 1 \end{array} \right]\)</span> and <span class="process-math">\(\vv_2 = \left[ \begin{array}{r} -1 \\ 1 \\ 0 \end{array} \right]\text{.}\)</span> Note that <span class="process-math">\(\vv_1, \vv_2\)</span> are not orthogonal, so cannot be in an orthogonal basis of <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span> So find a set <span class="process-math">\(\{\vw_1, \vw_2\}\)</span> of orthogonal eigenvectors of <span class="process-math">\(A\)</span> so that <span class="process-math">\(\Span\{\vw_1, \vw_2\} = \Span\{\vv_1, \vv_2\}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1513"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4590">The vector <span class="process-math">\(\vv_3=\left[ \begin{array}{c} 1 \\ 1 \\ 1 \end{array} \right]\)</span> is an eigenvector for <span class="process-math">\(A\)</span> corresponding to the eigenvalue 8. What can you say about the orthogonality relationship between <span class="process-math">\(\vw_i\)</span>'s and <span class="process-math">\(\vv_3\text{?}\)</span></p></article><article class="task exercise-like" id="task-1514"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4591">Find a matrix <span class="process-math">\(P\)</span> that orthogonally diagonalizes <span class="process-math">\(A\text{.}\)</span> Verify your work.</p></article></article></section><section class="section" id="sec_spec_decomp_symm_mtx"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">The Spectral Decomposition of a Symmetric Matrix <span class="process-math">\(A\)</span></span>
</h3>
<p id="p-4592">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> symmetric matrix with real entries. The Spectral Theorem tells us we can find an orthonormal basis <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_n\}\)</span> of eigenvectors of <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(A \vu_i = \lambda_i \vu_i\)</span> for each <span class="process-math">\(1 \leq i \leq n\text{.}\)</span> If <span class="process-math">\(P = [ \vu_1 \  \vu_2 \  \vu_3 \  \cdots \ \vu_n]\text{,}\)</span> then we know that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{\tr}AP = P^{-1}AP = D\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(D\)</span> is the <span class="process-math">\(n \times n\)</span> diagonal matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{cccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0\amp 0 \\ 0\amp \lambda_2\amp 0\amp \cdots\amp 0\amp 0 \\ \vdots\amp \vdots\amp \vdots\amp \amp \vdots\amp \vdots \\ 0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda_n \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4593"> Since <span class="process-math">\(A = PDP^{\tr}\)</span> we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_7_a_product.html ./knowl/eq_spec_decomp.html" id="mdn-20">
\begin{align}
A \amp = [ \vu_1 \ \vu_2 \ \vu_3 \ \cdots \ \vu_n] \left[ \begin{array}{cccccc} \lambda_1\amp 0\amp 0\amp \cdots\amp 0\amp 0\notag\\
0\amp \lambda_2\amp 0\amp \cdots\amp 0\amp 0\notag\\
\vdots\amp \vdots\amp \vdots\amp \amp \vdots\amp \vdots\notag\\
0\amp 0\amp 0\amp \cdots\amp 0\amp \lambda_n \end{array} \right] \left[ \begin{array}{c} \vu_1^{\tr}\notag\\
\vu_2^{\tr}\notag\\
\vu_3^{\tr}\notag\\
\vdots\notag\\
\vu_n^{\tr} \end{array} \right]\notag\\
\amp = [ \lambda_1\vu_1 \ \lambda_2\vu_2 \ \lambda_3\vu_3 \ \cdots \ \lambda_n\vu_n] \left[ \begin{array}{c} \vu_1^{\tr}\notag\\
\vu_2^{\tr}\notag\\
\vu_3^{\tr}\notag\\
\vdots\notag\\
\vu_n^{\tr} \end{array} \right]\notag\\
\amp = \lambda_1 \vu_1\vu_1^{\tr} + \lambda_2 \vu_2\vu_2^{\tr} + \lambda_3 \vu_3\vu_3^{\tr} + \cdots + \lambda_n \vu_n\vu_n^{\tr}\text{,}\tag{27.3}
\end{align}
</div>
<p class="continuation">where the last product follows from <a href="" class="xref" data-knowl="./knowl/ex_7_a_product.html" title="Exercise 4">Exercise 4</a>. The expression in <a href="" class="xref" data-knowl="./knowl/eq_spec_decomp.html" title="Equation 27.3">(27.3)</a> is called a <dfn class="terminology">spectral decomposition</dfn> of the matrix <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(P_i = \vu_i\vu_i^{\tr}\)</span> for each <span class="process-math">\(i\text{.}\)</span> The matrices <span class="process-math">\(P_i\)</span> satisfy several special conditions given in the next theorem. The proofs are left to the exercises.</p>
<article class="theorem theorem-like" id="thm_7_a_spectral_decomposition"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">27.8</span><span class="period">.</span>
</h4>
<p id="p-4594">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> symmetric matrix with real entries, and let <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_n\}\)</span> be an orthonormal basis of eigenvectors of <span class="process-math">\(A\)</span> with <span class="process-math">\(A \vu_i = \lambda_i \vu_i\)</span> for each <span class="process-math">\(i\text{.}\)</span> For each <span class="process-math">\(i\text{,}\)</span> let <span class="process-math">\(P_i = \vu_i\vu_i^{\tr}\text{.}\)</span> Then</p>
<ol class="decimal">
<li id="li-727"><p id="p-4595"><span class="process-math">\(A = \lambda_1 P_1 + \lambda_2 P_2 + \cdots + \lambda_n P_n\text{,}\)</span></p></li>
<li id="li-728"><p id="p-4596"><span class="process-math">\(P_i\)</span> is a symmetric matrix for each <span class="process-math">\(i\text{,}\)</span></p></li>
<li id="li-729"><p id="p-4597"><span class="process-math">\(P_i\)</span> is a rank 1 matrix for each <span class="process-math">\(i\text{,}\)</span></p></li>
<li id="li-730"><p id="p-4598"><span class="process-math">\(P_i^2 = P_i\)</span> for each <span class="process-math">\(i\text{,}\)</span></p></li>
<li id="li-731"><p id="p-4599"><span class="process-math">\(P_i P_j = 0\)</span> if <span class="process-math">\(i \neq j\text{,}\)</span></p></li>
<li id="li-732"><p id="p-4600"><span class="process-math">\(P_i \vu_i = \vu_i\)</span> for each <span class="process-math">\(i\text{,}\)</span></p></li>
<li id="li-733"><p id="p-4601"><span class="process-math">\(P_i \vu_j = \vzero\)</span> if <span class="process-math">\(i \neq j\text{,}\)</span></p></li>
<li id="li-734"><p id="p-4602">For any vector <span class="process-math">\(\vv\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> <span class="process-math">\(P_i \vv = \text{ proj } _{\Span\{\vu_i\}} \vv\text{.}\)</span></p></li>
</ol></article><p id="p-4603">The consequence of <a href="" class="xref" data-knowl="./knowl/thm_7_a_spectral_decomposition.html" title="Theorem 27.8">Theorem 27.8</a> is that any symmetric matrix can be written as the sum of symmetric, rank 1 matrices. As we will see later, this kind of decomposition contains much information about the matrix product <span class="process-math">\(A^{\tr}A\)</span> for any matrix <span class="process-math">\(A\text{.}\)</span></p>
<article class="activity project-like" id="act_7_a_4"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">27.5</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-447"><p id="p-4604">Let <span class="process-math">\(A = \left[ \begin{array}{ccc} 4\amp 2\amp 2 \\ 2\amp 4\amp 2 \\ 2\amp 2\amp 4 \end{array} \right]\text{.}\)</span> Let <span class="process-math">\(\lambda_1 = 2\text{,}\)</span> <span class="process-math">\(\lambda_2 = 2\text{,}\)</span> and <span class="process-math">\(\lambda_3 = 8\)</span> be the eigenvalues of <span class="process-math">\(A\text{.}\)</span> A basis for the eigenspace <span class="process-math">\(E_8\)</span> of <span class="process-math">\(A\)</span> corresponding to the eigenvalue 8 is <span class="process-math">\(\{[1 \ 1\ 1]^{\tr}\}\)</span> and a basis for the eigenspace <span class="process-math">\(E_2\)</span> of <span class="process-math">\(A\)</span> corresponding to the eigenvalue 2 is <span class="process-math">\(\{[1 \ -1\ 0]^{\tr}, [1 \ 0 \ -1]^{\tr}\}\text{.}\)</span> (Compare to <a href="" class="xref" data-knowl="./knowl/act_7_a_3.html" title="Activity 27.4">Activity 27.4</a>.)</p></div>
<article class="task exercise-like" id="task-1515"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4605">Find orthonormal eigenvectors <span class="process-math">\(\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> and <span class="process-math">\(\vu_3\)</span> of <span class="process-math">\(A\)</span> corresponding to <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> and <span class="process-math">\(\lambda_3\text{,}\)</span> respectively.</p></article><article class="task exercise-like" id="task-1516"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4606">Compute <span class="process-math">\(\lambda_1 \vu_1\vu_1^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1517"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4607">Compute <span class="process-math">\(\lambda_2 \vu_2\vu_2^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1518"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4608">Compute <span class="process-math">\(\lambda_3 \vu_3\vu_3^{\tr}\)</span></p></article><article class="task exercise-like" id="task-1519"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-4609">Verify that <span class="process-math">\(A = \lambda_1 \vu_1\vu_1^{\tr} + \lambda_2 \vu_2\vu_2^{\tr} + \lambda_3 \vu_3\vu_3^{\tr}\text{.}\)</span></p></article></article></section><section class="section" id="sec_orthog_diag_exam"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Examples</span>
</h3>
<p id="p-4610">What follows are worked examples that use the concepts from this section.</p>
<article class="example example-like" id="example-54"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">27.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-448"><p id="p-4611">For each of the following matrices <span class="process-math">\(A\text{,}\)</span> determine if <span class="process-math">\(A\)</span> is diagonalizable. If <span class="process-math">\(A\)</span> is not diagonalizable, explain why. If <span class="process-math">\(A\)</span> is diagonalizable, find a matrix <span class="process-math">\(P\)</span> so that <span class="process-math">\(P^{-1}AP\)</span> is a diagonal matrix. If the matrix is diagonalizable, is it orthogonally diagonalizable? If orthogonally diagonalizable, find an orthogonal matrix that diagonalizes <span class="process-math">\(A\text{.}\)</span> Use appropriate technology to find eigenvalues and eigenvectors.</p></div>
<article class="task exercise-like" id="task-1520"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4612"><span class="process-math">\(A = \left[ \begin{array}{rrc} 2 \amp 0 \amp 0 \\ -1 \amp 3 \amp 2 \\ 1 \amp -1 \amp 0 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-160">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4613">Recall that an <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors, and <span class="process-math">\(A\)</span> is orthogonally diagonalizable if and only if <span class="process-math">\(A\)</span> is symmetric. Since <span class="process-math">\(A\)</span> is not symmetric, <span class="process-math">\(A\)</span> is not orthogonally diagonalizable. Technology shows that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(2\)</span> and <span class="process-math">\(1\)</span> and bases for the corresponding eigenspaces are <span class="process-math">\(\{ [1 \ 1\ 0]^{\tr}, [2 \ 0 \ 1]^{\tr} \}\)</span> and <span class="process-math">\(\{[0 \ -1 \ 1]^{\tr}\}\text{.}\)</span> So <span class="process-math">\(A\)</span> is diagonalizable and if <span class="process-math">\(P = \left[ \begin{array}{rcr} 1\amp 2\amp 0\\1\amp 0\amp -1\\0\amp 1\amp 1 \end{array}  \right]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = \left[ \begin{array}{ccc} 2\amp 0\amp 0\\0\amp 2\amp 0\\0\amp 0\amp 1 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article><article class="task exercise-like" id="task-1521"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4614"><span class="process-math">\(A = \left[ \begin{array}{ccc} 1 \amp 1 \amp 0 \\ 0 \amp 1 \amp 0 \\ 0 \amp 0 \amp 0 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-161">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4615">Since <span class="process-math">\(A\)</span> is not symmetric, <span class="process-math">\(A\)</span> is not orthogonally diagonalizable. Technology shows that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(0\)</span> and <span class="process-math">\(1\)</span> and bases for the corresponding eigenspaces are <span class="process-math">\(\{[0 \ 0 \ 1]^{\tr}\}\)</span> and <span class="process-math">\(\{ [1 \ 0\ 0]^{\tr} \}\text{.}\)</span> We cannot create a basis of <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{,}\)</span> so <span class="process-math">\(A\)</span> is not diagonalizable.</p>
</div></article><article class="task exercise-like" id="task-1522"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4616"><span class="process-math">\(A = \left[ \begin{array}{ccc} 4 \amp 2 \amp 1 \\ 2 \amp 7 \amp 2 \\ 1 \amp 2 \amp 4 \end{array} \right]\)</span></p>
<div class="solution solution-like" id="solution-162">
<h5 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h5>
<p id="p-4617">Since <span class="process-math">\(A\)</span> is symmetric, <span class="process-math">\(A\)</span> is orthogonally diagonalizable. Technology shows that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(3\)</span> and <span class="process-math">\(9\)</span> and bases for the eigenspaces <span class="process-math">\(\{[-1 \ 0 \ 1]^{\tr}, [-2 \ 1 \ 0]^{\tr}\}\)</span> and <span class="process-math">\(\{ [1 \ 2 \ 1]^{\tr} \}\text{,}\)</span> respectively. To find an orthogonal matrix that diagonalizes <span class="process-math">\(A\text{,}\)</span> we must find an orthonormal basis of <span class="process-math">\(\R^3\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span> To do that, we use the Gram-Schmidt process to obtain an orthogonal basis for the eigenspace of <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(3\text{.}\)</span> Doing so gives an orthogonal basis <span class="process-math">\(\{\vv_1, \vv_2\}\text{,}\)</span> where <span class="process-math">\(\vv_1 = [-1 \ 0 \ 1]^{\tr}\)</span> and</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-185">
\begin{align*}
\vv_2 \amp =  [-2 \ 1 \ 0]^{\tr} - \frac{ [-2 \ 1 \ 0]^{\tr} \cdot [-1 \ 0 \ 1]^{\tr}}{[-1 \ 0 \ 1]^{\tr} \cdot [-1 \ 0 \ 1]^{\tr}} [-1 \ 0 \ 1]^{\tr}\\
\amp =  [-2 \ 1 \ 0]^{\tr} - [-1 \ 0 \ 1]^{\tr}\\
\amp = [ -1 \ 1 \ -1]^{\tr}\text{.}
\end{align*}
</div>
<p class="continuation">So an orthonormal basis for <span class="process-math">\(\R^3\)</span> of eigenvectors of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{\frac{1}{\sqrt{2}} [-1 \ 0 \ 1]^{\tr}, \frac{1}{\sqrt{3}}[ -1 \ 1 \ -1]^{\tr}, \frac{1}{\sqrt{6}}[1 \ 1 \ 1]^{\tr} \right\}\text{.}
\end{equation*}
</div>
<p class="continuation">Therefore, <span class="process-math">\(A\)</span> is orthogonally diagonalizable and if <span class="process-math">\(P\)</span> is the matrix <span class="process-math">\(\left[{ \begin{array}{rrc} -\frac{1}{\sqrt{2}}\amp -\frac{1}{\sqrt{3}}\amp \frac{1}{\sqrt{6}}\\0\amp \frac{1}{\sqrt{3}}\amp \frac{2}{\sqrt{6}}\\\frac{1}{\sqrt{2}}\amp -\frac{1}{\sqrt{3}}\amp \frac{1}{\sqrt{6}} \end{array} } \right]\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = \left[ \begin{array}{ccc} 3\amp 0\amp 0\\0\amp 3\amp 0\\0\amp 0\amp 9 \end{array}  \right]\text{.}
\end{equation*}
</div>
</div></article></article><article class="example example-like" id="example-55"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">27.10</span><span class="period">.</span>
</h4>
<p id="p-4618">Let <span class="process-math">\(A = \left[ \begin{array}{cccc} 0\amp 0\amp 0\amp 1 \\ 0\amp 0\amp 1\amp 0 \\ 0\amp 1\amp 0\amp 0 \\ 1\amp 0\amp 0\amp 0 \end{array} \right]\text{.}\)</span> Find an orthonormal basis for <span class="process-math">\(\R^4\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span></p>
<div class="solution solution-like" id="solution-163">
<h4 class="heading">
<span class="type">Solution</span><span class="period">.</span>
</h4>
<p id="p-4619">Since <span class="process-math">\(A\)</span> is symmetric, there is an orthogonal matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{-1}AP\)</span> is diagonal. The columns of <span class="process-math">\(P\)</span> will form an orthonormal basis for <span class="process-math">\(\R^4\text{.}\)</span> Using a cofactor expansion along the first row shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-186">
\begin{align*}
\det(A-\lambda I_4) \amp = \det\left(\left[ \begin{array}{rrrr} -\lambda\amp 0\amp 0\amp 1\\
0\amp -\lambda\amp 1\amp 0\\
0\amp 1\amp -\lambda\amp 0\\
1\amp 0\amp 0\amp -\lambda \end{array} \right] \right)\\
\amp = \left(\lambda^2-1\right)^2\\
\amp = (\lambda+1)^2(\lambda-1)^2\text{.}
\end{align*}
</div>
<p id="p-4620">So the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{.}\)</span> The reduced row echelon forms of <span class="process-math">\(A-I_4\)</span> and <span class="process-math">\(A+I_4\)</span> are, respectively,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{ccrr} 1\amp 0\amp 0\amp -1 \\ 0\amp 1\amp -1\amp 0 \\0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right] \ \text{ and }  \ \left[ \begin{array}{cccc} 1\amp 0\amp 0\amp 1 \\ 0\amp 1\amp 1\amp 0 \\0\amp 0\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 0 \end{array}  \right]\text{.}
\end{equation*}
</div>
<p id="p-4621">Thus, a basis for the eigenspace <span class="process-math">\(E_{1}\)</span> of <span class="process-math">\(A\)</span> is <span class="process-math">\(\{[0 \ 1 \ 1 \ 0]^{\tr}, [1 \ 0 \ 0 \ 1]^{\tr}\}\)</span> and a basis for the eigenspace <span class="process-math">\(E_{-1}\)</span> of <span class="process-math">\(A\)</span> is <span class="process-math">\(\{[0 \ 1 \ -1 \ 0]^{\tr}, [1 \ 0 \ 0 \ -1]^{\tr}\}\text{.}\)</span> The set <span class="process-math">\(\{[0 \ 1 \ 1 \ 0]^{\tr}, [1 \ 0 \ 0 \ 1]^{\tr}, [0 \ 1 \ -1 \ 0]^{\tr}, [1 \ 0 \ 0 \ -1]^{\tr}\}\)</span> is an orthogonal set, so an orthonormal basis for <span class="process-math">\(\R^4\)</span> consisting of eigenvectors of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left\{\frac{1}{\sqrt{2}} [0 \ 1 \ 1 \ 0]^{\tr}, \frac{1}{\sqrt{2}}[1 \ 0 \ 0 \ 1]^{\tr}, \frac{1}{\sqrt{2}}[0 \ 1 \ -1 \ 0]^{\tr}, \frac{1}{\sqrt{2}}[1 \ 0 \ 0 \ -1]^{\tr}\right\}\text{.}
\end{equation*}
</div>
</div></article></section><section class="section" id="sec_orthog_diag_summ"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Summary</span>
</h3>
<ul class="disc">
<li id="li-735"><p id="p-4622">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is orthogonally diagonalizable if there is an orthogonal matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(P^{\tr}AP\)</span> is a diagonal matrix. Orthogonal diagonalizability is useful in that it allows us to find a “convenient” coordinate system in which to interpret the results of certain matrix transformations. Orthogonal diagonalization also a plays a crucial role in the singular value decomposition of a matrix.</p></li>
<li id="li-736"><p id="p-4623">An <span class="process-math">\(n \times n\)</span> matrix <span class="process-math">\(A\)</span> is symmetric if <span class="process-math">\(A^{\tr} = A\text{.}\)</span> The symmetric matrices are exactly the matrices that can be orthogonally diagonalized.</p></li>
<li id="li-737"><p id="p-4624">The spectrum of a matrix is the set of eigenvalues of the matrix.</p></li>
</ul></section><section class="exercises" id="sec_orthog_diag_exer"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-266"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-449"><p id="p-4625">For each of the following matrices, find an orthogonal matrix <span class="process-math">\(P\)</span> so that <span class="process-math">\(P^{\tr}AP\)</span> is a diagonal matrix, or explain why no such matrix exists.</p></div>
<article class="task exercise-like" id="task-1523"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4626"><span class="process-math">\(A = \left[ \begin{array}{rr} 3\amp -4 \\ -4\amp -3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1524"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4628"><span class="process-math">\(A = \left[ \begin{array}{ccc} 4\amp 1\amp 1 \\ 1\amp 1\amp 4 \\ 1\amp 4\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1525"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4630"><span class="process-math">\(A = \left[ \begin{array}{cccc} 1\amp 2\amp 0\amp 0 \\ 0\amp 1\amp 2\amp 1 \\ 1\amp 1\amp 1\amp 1 \\ 3\amp 0\amp 5\amp 2 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-267"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-450"><p id="p-4632">For each of the following matrices find an orthonormal basis of eigenvectors of <span class="process-math">\(A\text{.}\)</span> Then find a spectral decomposition of <span class="process-math">\(A\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1526"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4633"><span class="process-math">\(A = \left[ \begin{array}{rr} 3\amp -4 \\ -4\amp -3 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1527"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4634"><span class="process-math">\(A = \left[ \begin{array}{ccc} 4\amp 1\amp 1 \\ 1\amp 1\amp 4 \\ 1\amp 4\amp 1 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1528"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4635"><span class="process-math">\(A = \left[ \begin{array}{rrr} -4\amp 0\amp -24 \\ 0\amp -8\amp 0 \\ -24\amp 0\amp 16 \end{array} \right]\)</span></p></article><article class="task exercise-like" id="task-1529"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4636"><span class="process-math">\(A = \left[ \begin{array}{ccr} 1\amp 0\amp 0 \\ 0\amp 0\amp 2 \\ 0\amp 2\amp -3 \end{array} \right]\)</span></p></article></article><article class="exercise exercise-like" id="exercise-268"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-4637">Find a non-diagonal <span class="process-math">\(4 \times 4\)</span> matrix with eigenvalues 2, 3 and 6 which can be orthogonally diagonalized.</p></article><article class="exercise exercise-like" id="ex_7_a_product"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-4639">Let <span class="process-math">\(A = [a_{ij}] = [ \vc_1 \ \vc_2 \ \cdots \ \vc_m]\)</span> be an <span class="process-math">\(k \times m\)</span> matrix with columns <span class="process-math">\(\vc_1\text{,}\)</span> <span class="process-math">\(\vc_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vc_m\text{,}\)</span> and let <span class="process-math">\(B = [b_{ij}] = \left[ \begin{array}{c} \vr_1 \\ \vr_2 \\ \vdots \\ \vr_m \end{array}  \right]\)</span> be an <span class="process-math">\(m \times n\)</span> matrix  with rows <span class="process-math">\(\vr_1\text{,}\)</span> <span class="process-math">\(\vr_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vr_m\text{.}\)</span> Show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AB = [ \vc_1 \ \vc_2 \ \cdots \ \vc_m]\left[\begin{array}{c} \vr_1 \\ \vr_2 \\ \vdots \\ \vr_m \end{array}  \right] = \vc_1\vr_1 + \vc_2\vr_2 + \cdots + \vc_m \vr_m\text{.}
\end{equation*}
</div></article><article class="exercise exercise-like" id="ex_7_a_spectral_decomposition"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-451"><p id="p-4640">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> symmetric matrix with real entries and let <span class="process-math">\(\{\vu_1, \vu_2, \ldots, \vu_n\}\)</span> be an orthonormal basis of eigenvectors of <span class="process-math">\(A\text{.}\)</span> For each <span class="process-math">\(i\text{,}\)</span> let <span class="process-math">\(P_i = \vu_i\vu_i^{\tr}\text{.}\)</span> Prove <a href="" class="xref" data-knowl="./knowl/thm_7_a_spectral_decomposition.html" title="Theorem 27.8">Theorem 27.8</a> — that is, verify each of the following statements.</p></div>
<article class="task exercise-like" id="task-1530"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4641">For each <span class="process-math">\(i\text{,}\)</span> <span class="process-math">\(P_i\)</span> is a symmetric matrix.</p></article><article class="task exercise-like" id="task-1531"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4643">For each <span class="process-math">\(i\text{,}\)</span> <span class="process-math">\(P_i\)</span> is a rank 1 matrix.</p></article><article class="task exercise-like" id="task-1532"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4645">For each <span class="process-math">\(i\text{,}\)</span> <span class="process-math">\(P_i^2 = P_i\text{.}\)</span></p></article><article class="task exercise-like" id="task-1533"><h5 class="heading"><span class="codenumber">(d)</span></h5>
<p id="p-4647">If <span class="process-math">\(i \neq j\text{,}\)</span> then <span class="process-math">\(P_iP_j = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-1534"><h5 class="heading"><span class="codenumber">(e)</span></h5>
<p id="p-4649">For each <span class="process-math">\(i\text{,}\)</span> <span class="process-math">\(P_i \vu_i = \vu_i\text{.}\)</span></p></article><article class="task exercise-like" id="task-1535"><h5 class="heading"><span class="codenumber">(f)</span></h5>
<p id="p-4651">If <span class="process-math">\(i \neq j\text{,}\)</span> then <span class="process-math">\(P_i \vu_j = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-1536"><h5 class="heading"><span class="codenumber">(g)</span></h5>
<p id="p-4653">If <span class="process-math">\(\vv\)</span> is in <span class="process-math">\(\R^n\text{,}\)</span> show that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_i \vv = \proj_{\Span\{\vu_i\} } \vv\text{.}
\end{equation*}
</div>
<p class="continuation">For this reason we call <span class="process-math">\(P_i\)</span> an <dfn class="terminology">orthogonal projection matrix</dfn>.</p></article></article><article class="exercise exercise-like" id="exercise-271"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-4655">Show that if <span class="process-math">\(M\)</span> is an <span class="process-math">\(n \times n\)</span> matrix and <span class="process-math">\((M\vx) \cdot \vy = \vx \cdot (M\vy)\)</span> for every <span class="process-math">\(\vx, \vy\)</span> in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(M\)</span> is a symmetric matrix.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-56" id="hint-56"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-56"><div class="hint solution-like"><p id="p-4656">Try <span class="process-math">\(\vx = \textbf{e}_i\)</span> and <span class="process-math">\(\vy = \textbf{e}_j\text{.}\)</span></p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-272"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-452"><p id="p-4657">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> symmetric matrix and assume that <span class="process-math">\(A\)</span> has an orthonormal basis <span class="process-math">\(\{\vu_1\text{,}\)</span> <span class="process-math">\(\vu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_n\}\)</span> of eigenvectors of <span class="process-math">\(A\)</span> so that <span class="process-math">\(A \vu_i = \lambda_i \vu_i\)</span> for each <span class="process-math">\(i\text{.}\)</span> Let <span class="process-math">\(P_i = \vu_i\vu_i^{\tr}\)</span> for each <span class="process-math">\(i\text{.}\)</span> It is possible that not all of the eigenvalue of <span class="process-math">\(A\)</span> are distinct. In this case, some of the eigenvalues will be repeated in the spectral decomposition of <span class="process-math">\(A\text{.}\)</span> If we want only distinct eigenvalues to appear, we might do the following. Let <span class="process-math">\(\mu_1\text{,}\)</span> <span class="process-math">\(\mu_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\mu_k\)</span> be the distinct eigenvalues of <span class="process-math">\(A\text{.}\)</span> For each <span class="process-math">\(j\)</span> between 1 and <span class="process-math">\(k\text{,}\)</span> let <span class="process-math">\(Q_j\)</span> be the sum of all of the <span class="process-math">\(P_i\)</span> that have <span class="process-math">\(\mu_j\)</span> as eigenvalue.</p></div>
<article class="task exercise-like" id="task-1537"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4658">The eigenvalues for the matrix <span class="process-math">\(A = \left[ \begin{array}{cccc} 0\amp 2\amp 0\amp 0 \\ 2\amp 3\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 2 \\ 0\amp 0\amp 2\amp 3 \end{array} \right]\)</span> are <span class="process-math">\(-1\)</span> and <span class="process-math">\(4\text{.}\)</span> Find a basis for each eigenspace and determine each <span class="process-math">\(P_i\text{.}\)</span> Then find <span class="process-math">\(k\text{,}\)</span> <span class="process-math">\(\mu_1\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\mu_k\text{,}\)</span> and each <span class="process-math">\(Q_j\text{.}\)</span></p></article><article class="task exercise-like" id="task-1538"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<div class="introduction" id="introduction-453"><p id="p-4660">Show in general (not just for the specific example in part (a), that the <span class="process-math">\(Q_j\)</span> satisfy the same properties as the <span class="process-math">\(P_i\text{.}\)</span> That is, verify the following.</p></div>
<article class="task exercise-like" id="task-1539"><h6 class="heading"><span class="codenumber">(i)</span></h6>
<p id="p-4661"><span class="process-math">\(A = \mu_1 Q_1 + \mu_2 Q_2 + \cdots \mu_k Q_k\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-57" id="hint-57"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-57"><div class="hint solution-like"><p id="p-4662">Collect matrices with the same eigenvalues.</p></div></div>
</div></article><article class="task exercise-like" id="task-1540"><h6 class="heading"><span class="codenumber">(ii)</span></h6>
<p id="p-4663"><span class="process-math">\(Q_j\)</span> is a symmetric matrix for each <span class="process-math">\(j\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-58" id="hint-58"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-58"><div class="hint solution-like"><p id="p-4664">Use the fact that each <span class="process-math">\(P_i\)</span> is a symmetric matrix.</p></div></div>
</div></article><article class="task exercise-like" id="task-1541"><h6 class="heading"><span class="codenumber">(iii)</span></h6>
<p id="p-4665"><span class="process-math">\(Q_j^2 = Q_j\)</span> for each <span class="process-math">\(j\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-59" id="hint-59"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-59"><div class="hint solution-like"><p id="p-4666">Use Theorem 31.8.</p></div></div>
</div></article><article class="task exercise-like" id="task-1542"><h6 class="heading"><span class="codenumber">(iv)</span></h6>
<p id="p-4667"><span class="process-math">\(Q_j Q_{\ell} = 0\)</span> when <span class="process-math">\(j \neq \ell\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-60" id="hint-60"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-60"><div class="hint solution-like"><p id="p-4668">Use Theorem 31.8.</p></div></div>
</div></article><article class="task exercise-like" id="task-1543"><h6 class="heading"><span class="codenumber">(v)</span></h6>
<p id="p-4669">if <span class="process-math">\(E_{\mu_j}\)</span> is the eigenspace for <span class="process-math">\(A\)</span> corresponding to the eigenvalue <span class="process-math">\(\mu_j\text{,}\)</span> and if <span class="process-math">\(\vv\)</span> is in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(Q_j \vv = \proj_{E_{\mu_j}} \vv\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-61" id="hint-61"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-61"><div class="hint solution-like"><p id="p-4670">Explain why <span class="process-math">\(\{\vu_{1_j}\text{,}\)</span> <span class="process-math">\(\vu_{2_j}\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\vu_{m_j}\}\)</span> is a orthonormal basis for <span class="process-math">\(E_{\mu_j}\text{.}\)</span></p></div></div>
</div></article></article><article class="task exercise-like" id="task-1544"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4671">What is the rank of <span class="process-math">\(Q_j\text{?}\)</span> Verify your answer.</p></article></article><article class="exercise exercise-like" id="exercise-273"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="introduction" id="introduction-454"><p id="p-4673">Label each of the following statements as True or False. Provide justification for your response.</p></div>
<article class="task exercise-like" id="task-1545"><h5 class="heading">
<span class="codenumber">(a)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4674">Every real symmetric matrix is diagonalizable.</p></article><article class="task exercise-like" id="task-1546"><h5 class="heading">
<span class="codenumber">(b)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4676">If <span class="process-math">\(P\)</span> is a matrix whose columns are eigenvectors of a symmetric matrix, then the columns of <span class="process-math">\(P\)</span> are orthogonal.</p></article><article class="task exercise-like" id="task-1547"><h5 class="heading">
<span class="codenumber">(c)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4677">If <span class="process-math">\(A\)</span> is a symmetric matrix, then eigenvectors of <span class="process-math">\(A\)</span> corresponding to distinct eigenvalues are orthogonal.</p></article><article class="task exercise-like" id="task-1548"><h5 class="heading">
<span class="codenumber">(d)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4679">If <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> are distinct eigenvectors of a symmetric matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\vv_1\)</span> and <span class="process-math">\(\vv_2\)</span> are orthogonal.</p></article><article class="task exercise-like" id="task-1549"><h5 class="heading">
<span class="codenumber">(e)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4680">Any symmetric matrix can be written as a sum of symmetric rank 1 matrices.</p></article><article class="task exercise-like" id="task-1550"><h5 class="heading">
<span class="codenumber">(f)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4682">If <span class="process-math">\(A\)</span> is a matrix satisfying <span class="process-math">\(A^{\tr} = A\text{,}\)</span> and <span class="process-math">\(\vu\)</span> and <span class="process-math">\(\vv\)</span> are vectors satisfying <span class="process-math">\(A \vu = 2 \vu\)</span> and <span class="process-math">\(A \vv = -2 \vv\text{,}\)</span> then <span class="process-math">\(\vu \cdot \vv = 0\text{.}\)</span></p></article><article class="task exercise-like" id="task-1551"><h5 class="heading">
<span class="codenumber">(g)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4683">If an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> orthogonal eigenvectors, then <span class="process-math">\(A\)</span> is a symmetric matrix.</p></article><article class="task exercise-like" id="task-1552"><h5 class="heading">
<span class="codenumber">(h)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4685">If an <span class="process-math">\(n\times n\)</span> matrix has <span class="process-math">\(n\)</span> real eigenvalues (counted with multiplicity), then <span class="process-math">\(A\)</span> is a symmetric matrix.</p></article><article class="task exercise-like" id="task-1553"><h5 class="heading">
<span class="codenumber">(i)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4686">For each eigenvalue of a symmetric matrix, the algebraic multiplicity equals the geometric multiplicity.</p></article><article class="task exercise-like" id="task-1554"><h5 class="heading">
<span class="codenumber">(j)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4688">If <span class="process-math">\(A\)</span> is invertible and orthogonally diagonalizable, then so is <span class="process-math">\(A^{-1}\text{.}\)</span></p></article><article class="task exercise-like" id="task-1555"><h5 class="heading">
<span class="codenumber">(k)</span><span class="space"> </span><span class="title">True/False.</span>
</h5>
<p id="p-4689">If <span class="process-math">\(A, B\)</span> are orthogonally diagonalizable <span class="process-math">\(n\times n\)</span> matrices, then so is <span class="process-math">\(AB\text{.}\)</span></p></article></article></section><section class="section" id="sec_proj_two_var_deriv"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Project: The Second Derivative Test for Functions of Two Variables</span>
</h3>
<p id="p-4691">In this project we will verify the Second Derivative Test for functions of two variables.<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-49" id="fn-49"><sup> 49 </sup></a> This test will involve Taylor polynomials and linear algebra. As a quick review, recall that the second order Taylor polynomial for a function <span class="process-math">\(f\)</span> of a single variable <span class="process-math">\(x\)</span> at <span class="process-math">\(x = a\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_Taylor_2">
\begin{equation}
P_2(x) = f(a)+f'(a)(x-a)+\frac{f''(a)}{2}(x-a)^2\text{.}\tag{27.4}
\end{equation}
</div>
<p id="p-4692">As with the linearization of a function, the second order Taylor polynomial is a good approximation to <span class="process-math">\(f\)</span> around <span class="process-math">\(a\)</span> — that is <span class="process-math">\(f(x) \approx P_2(x)\)</span> for <span class="process-math">\(x\)</span> close to <span class="process-math">\(a\text{.}\)</span> If <span class="process-math">\(a\)</span> is a critical number for <span class="process-math">\(f\)</span> with <span class="process-math">\(f'(a) = 0\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_2(x) = f(a) + \frac{f''(a)}{2}(x-a)^2\text{.}
\end{equation*}
</div>
<p id="p-4693">In this situation, if <span class="process-math">\(f''(a) \lt 0\text{,}\)</span> then <span class="process-math">\(\frac{f''(a)}{2}(x-a)^2 \leq 0\)</span> for <span class="process-math">\(x\)</span> close to <span class="process-math">\(a\text{,}\)</span> which makes <span class="process-math">\(P_2(x) \leq f(a)\text{.}\)</span> This implies that <span class="process-math">\(f(x) \approx P_2(x) \leq f(a)\)</span> for <span class="process-math">\(x\)</span> close to <span class="process-math">\(a\text{,}\)</span> which makes <span class="process-math">\(f(a)\)</span> a relative maximum value for <span class="process-math">\(f\text{.}\)</span> Similarly, if <span class="process-math">\(f''(a) &gt; 0\text{,}\)</span> then <span class="process-math">\(f(a)\)</span> is a relative minimum.</p>
<p id="p-4694">We now need a Taylor polynomial for a function of two variables. The complication of the additional independent variable in the two variable case means that the Taylor polynomials will need to contain all of the possible monomials of the indicated degrees. Recall that the linearization (or tangent plane) to a function <span class="process-math">\(f = f(x,y)\)</span> at a point <span class="process-math">\((a,b)\)</span> is given by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P_1(x,y) = f(a,b) + f_x(a,b)(x-a) + f_y(a,b)(y-b)\text{.}
\end{equation*}
</div>
<p id="p-4695">Note that <span class="process-math">\(P_1(a,b) = f(a,b)\text{,}\)</span> <span class="process-math">\(\frac{\partial P_1}{\partial x}(a,b) = f_x(a,b)\text{,}\)</span> and <span class="process-math">\(\frac{\partial P_1}{\partial y}(a,b) = f_y(a,b)\text{.}\)</span> This makes <span class="process-math">\(P_1(x,y)\)</span> the best linear approximation to <span class="process-math">\(f\)</span> near the point <span class="process-math">\((a,b)\text{.}\)</span> The polynomial <span class="process-math">\(P_1(x,y)\)</span> is the first order Taylor polynomial for <span class="process-math">\(f\)</span> at <span class="process-math">\((a,b)\text{.}\)</span></p>
<p id="p-4696">Similarly, the second order Taylor polynomial <span class="process-math">\(P_2(x,y)\)</span> centered at the point <span class="process-math">\((a,b)\)</span> for the function <span class="process-math">\(f\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-187">
\begin{align*}
P_2(x,y) = f(a,b) \amp + f_x(a,b)(x-a) + f_y(a,b)(y-b) + \frac{f_{xx}(a,b)}{2}(x-a)^2\\
\amp + f_{xy}(a,b)(x-a)(y-b) + \frac{f_{yy}(a,b)}{2}(y-b)^2\text{.}
\end{align*}
</div>
<article class="project project-like" id="project-85"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">27.6</span><span class="period">.</span>
</h4>
<p id="p-4697">To see that <span class="process-math">\(P_2(x,y)\)</span> is the best approximation for <span class="process-math">\(f\)</span> near <span class="process-math">\((a,b)\text{,}\)</span> we need to know that the first and second order partial derivatives of <span class="process-math">\(P_2\)</span> agree with the corresponding partial derivatives of <span class="process-math">\(f\)</span> at the point <span class="process-math">\((a,b)\text{.}\)</span> Verify that this is true.</p></article><p id="p-4698">We can rewrite this second order Taylor polynomial using matrices and vectors so that we can apply techniques from linear algebra to analyze it. Note that</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="mdn-21">
\begin{align}
P_2(x,y) \amp = f(a,b) + \nabla f(a,b)^{\tr} \left[ \begin{array}{c} x-a\notag\\
y-b \end{array} \right]\notag\\
\amp \qquad + \frac{1}{2}\left[ \begin{array}{c} x-a\notag\\
y-b \end{array} \right]^{\tr} \left[ \begin{array}{cc} f_{xx}(a,b)\amp f_{xy}(a,b)\notag\\
f_{xy}(a,b)\amp  f_{yy}(a,b) \end{array} \right] \left[ \begin{array}{c} x-a\notag\\
y-b \end{array} \right]\text{,}\tag{27.5}
\end{align}
</div>
<p class="continuation">where <span class="process-math">\(\nabla f(x,y) = \left[ \begin{array}{c} f_x(x,y)\\f_y(x,y) \end{array}  \right]\)</span> is the gradient of <span class="process-math">\(f\)</span> and <span class="process-math">\(H\)</span> is the <dfn class="terminology">Hessian</dfn> of <span class="process-math">\(f\text{,}\)</span> where <span class="process-math">\(H(x,y) = \left[ \begin{array}{cc} f_{xx}(x,y)\amp f_{xy}(x,y) \\ f_{yx}(x,y)\amp  f_{yy}(x,y) \end{array}  \right]\text{.}\)</span><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-50" id="fn-50"><sup> 50 </sup></a></p>
<article class="project project-like" id="ex_example_1"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">27.7</span><span class="period">.</span>
</h4>
<p id="p-4699">Use Equation <a href="" class="xref" data-knowl="./knowl/eq_Taylor_2_vector.html" title="Equation 27.5">(27.5)</a> to compute <span class="process-math">\(P_2(x,y)\)</span> for <span class="process-math">\(f(x,y)=x^4+y^4-4xy+1\)</span> at <span class="process-math">\((a, b)=(2,3)\text{.}\)</span></p></article><p id="p-4700">The important idea for us is that if <span class="process-math">\((a, b)\)</span> is a point at which <span class="process-math">\(f_x\)</span> and <span class="process-math">\(f_y\)</span> are zero, then <span class="process-math">\(\nabla f\)</span> is the zero vector and Equation <a href="" class="xref" data-knowl="./knowl/eq_Taylor_2_vector.html" title="Equation 27.5">(27.5)</a> reduces to</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_Taylor_2_vector.html" id="eq_Taylor_2_vector_2">
\begin{equation}
P_2(x,y) = f(a,b) +  \frac{1}{2}\left[ \begin{array}{c} x-a\\y-b \end{array}  \right]^{\tr} \left[ \begin{array}{cc} f_{xx}(a,b)\amp f_{xy}(a,b) \\ f_{xy}(a,b)\amp  f_{yy}(a,b) \end{array}  \right] \left[ \begin{array}{c} x-a\\y-b \end{array}  \right]\text{,}\tag{27.6}
\end{equation}
</div>
<p id="p-4701">To make the connection between the multivariable second derivative test and properties of the Hessian, <span class="process-math">\(H(a,b)\text{,}\)</span> at a critical point of a function <span class="process-math">\(f\)</span> at which <span class="process-math">\(\nabla f = \vzero\text{,}\)</span> we will need to connect the eigenvalues of a matrix to the determinant and the trace.</p>
<p id="p-4702">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n \times n\)</span> matrix with eigenvalues <span class="process-math">\(\lambda_1\text{,}\)</span> <span class="process-math">\(\lambda_2\text{,}\)</span> <span class="process-math">\(\ldots\text{,}\)</span> <span class="process-math">\(\lambda_n\)</span> (not necessarily distinct). <a href="" class="xref" data-knowl="./knowl/ex_determinant_eigenvalues.html" title="Exercise 1">Exercise 1</a> in <a href="chap_characteristic_equation.html" class="internal" title="Section 18: The Characteristic Equation">Section 18</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_determinant_eigenvalues.html ./knowl/chap_characteristic_equation.html" id="eq_evals_det">
\begin{equation}
\det(A) = \lambda_1 \lambda_2 \cdots \lambda_n\text{.}\tag{27.7}
\end{equation}
</div>
<p id="p-4703">In other words, the determinant of a matrix is equal to the product of the eigenvalues of the matrix. In addition, <a href="" class="xref" data-knowl="./knowl/ex_trace_eigenvalues.html" title="Exercise 9">Exercise 9</a> in <a href="chap_diagonalization.html" class="internal" title="Section 19: Diagonalization">Section 19</a> shows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_trace_eigenvalues.html ./knowl/chap_diagonalization.html ./knowl/eq_evals_trace.html" id="eq_evals_trace">
\begin{equation}
\trace(A) = \lambda_1 +  \lambda_2 + \cdots + \lambda_n\text{.}\tag{27.8}
\end{equation}
</div>
<p class="continuation">for a diagonalizable matrix, where <span class="process-math">\(\trace(A)\)</span> is the sum of the diagonal entries of <span class="process-math">\(A\text{.}\)</span> Equation <a href="" class="xref" data-knowl="./knowl/eq_evals_trace.html" title="Equation 27.8">(27.8)</a> is true for any square matrix, but we don't need the more general result for this project.</p>
<p id="p-4704">The fact that the Hessian is a symmetric matrix makes it orthogonally diagonalizable. We denote the eigenvalues of <span class="process-math">\(H(a,b)\)</span> as <span class="process-math">\(\lambda_1\)</span> and <span class="process-math">\(\lambda_2\text{.}\)</span> Thus there exists an orthogonal matrix <span class="process-math">\(P\)</span> and a diagonal matrix <span class="process-math">\(D = \left[ \begin{array}{cc} \lambda_1\amp 0 \\ 0\amp \lambda_2 \end{array}  \right]\)</span> such that <span class="process-math">\(P^{\tr}H(a,b)P=D\text{,}\)</span> or <span class="process-math">\(H(a,b) = PDP^{\tr}\text{.}\)</span> Equations <a href="" class="xref" data-knowl="./knowl/eq_evals_det.html" title="Equation 27.7">(27.7)</a> and <a href="" class="xref" data-knowl="./knowl/eq_evals_trace.html" title="Equation 27.8">(27.8)</a> show that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_evals_det.html ./knowl/eq_evals_trace.html">
\begin{equation*}
\lambda_1\lambda_2 = f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2 \ \text{ and  }  \ \lambda_1 + \lambda_2 = f_{xx}(a,b) + f_{yy}(a,b)\text{.}
\end{equation*}
</div>
<p id="p-4705">Now we have the machinery to verify the Second Derivative Test for Two-Variable Functions. We assume <span class="process-math">\((a,b)\)</span> is a point in the domain of a function <span class="process-math">\(f\)</span> so that <span class="process-math">\(\nabla f(a,b) = \vzero\text{.}\)</span> First we consider the case where <span class="process-math">\(f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2\lt 0\text{.}\)</span></p>
<article class="project project-like" id="project-87"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">27.8</span><span class="period">.</span>
</h4>
<p id="p-4706">Explain why if <span class="process-math">\(f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2\lt 0\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left[ \begin{array}{c} x-a \\ y-b \end{array}  \right]^{\tr} H(a,b) \left[ \begin{array}{c} x-a \\ y-b \end{array}  \right]
\end{equation*}
</div>
<p class="continuation">is indefinite. Explain why this implies that <span class="process-math">\(f\)</span> is “saddle-shaped” near <span class="process-math">\((a,b)\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-62" id="hint-62"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-62"><div class="hint solution-like"><p id="p-4707">Substitute <span class="process-math">\(\vw = \left[ \begin{array}{c} w_1\\w_2 \end{array} \right] = P^{\tr}\left[ \begin{array}{c} x-a \\ y-b \end{array} \right]\text{.}\)</span> What does the graph of <span class="process-math">\(f\)</span> look like in the <span class="process-math">\(w_1\)</span> and <span class="process-math">\(w_2\)</span> directions?</p></div></div>
</div></article><p id="p-4708">Now we examine the situation when <span class="process-math">\(f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2&gt;0\text{.}\)</span></p>
<article class="project project-like" id="project-88"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">27.9</span><span class="period">.</span>
</h4>
<div class="introduction" id="introduction-455"><p id="p-4709">Assume that <span class="process-math">\(f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2&gt;0\text{.}\)</span></p></div>
<article class="task exercise-like" id="task-1556"><h5 class="heading"><span class="codenumber">(a)</span></h5>
<p id="p-4710">Explain why either both <span class="process-math">\(f_{xx}(a,b)\)</span> and <span class="process-math">\(f_{yy}(a,b)\)</span> are positive or both are negative.</p></article><article class="task exercise-like" id="task-1557"><h5 class="heading"><span class="codenumber">(b)</span></h5>
<p id="p-4711">If <span class="process-math">\(f_{xx}(a,b)&gt;0\)</span> and <span class="process-math">\(f_{yy}(a,b)&gt;0\text{,}\)</span> explain why <span class="process-math">\(\lambda_1\)</span> and <span class="process-math">\(\lambda_2\)</span> must be positive.</p></article><article class="task exercise-like" id="task-1558"><h5 class="heading"><span class="codenumber">(c)</span></h5>
<p id="p-4712">Explain why, if <span class="process-math">\(f_{xx}(a,b)&gt;0\)</span> and <span class="process-math">\(f_{yy}(a,b)&gt;0\text{,}\)</span> then <span class="process-math">\(f(a,b)\)</span> is a local minimum value for <span class="process-math">\(f\text{.}\)</span></p></article></article><p id="p-4713">When <span class="process-math">\(f_{xx}(a,b)f_{yy}(a,b)-f_{xy}(a,b)^2&gt;0\)</span> and either <span class="process-math">\(f_{xx}(a,b)\)</span> or <span class="process-math">\(f_{yy}(a,b)\)</span> is negative, a slight modification of the preceding argument leads to the fact that <span class="process-math">\(f\)</span> has a local maximum at <span class="process-math">\((a,b)\)</span> (the details are left to the reader). Therefore, we have proved the Second Derivative Test for functions of two variables!</p>
<article class="project project-like" id="project-89"><h4 class="heading">
<span class="type">Project Activity</span><span class="space"> </span><span class="codenumber">27.10</span><span class="period">.</span>
</h4>
<p id="p-4714">Use the Hessian to classify the local maxima, minima, and saddle points of <span class="process-math">\(f(x,y)=x^4+y^4-4xy+1\text{.}\)</span> Draw a graph of <span class="process-math">\(f\)</span> to illustrate.</p></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-49"><div class="fn">Many thanks to Professor Paul Fishback for sharing his activity on this topic. Much of this project comes from his activity.</div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-50"><div class="fn">Note that under reasonable conditions (e.g., that <span class="process-math">\(f\)</span> has continuous second order mixed partial derivatives in some open neighborhood containing <span class="process-math">\((x,y)\)</span>) we have that <span class="process-math">\(f_{xy}(x,y) = f_{yx}(x,y)\)</span> and <span class="process-math">\(H(x,y) = \left[ \begin{array}{cc} f_{xx}(a,b)\amp f_{xy}(a,b) \\ f_{xy}(a,b)\amp  f_{yy}(a,b) \end{array}  \right]\)</span> is a symmetric matrix. We will only consider functions that satisfy these reasonable conditions.</div></div>
</div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
