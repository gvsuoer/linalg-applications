<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_orthog_sets">
  <title>Orthogonal Sets</title>
  <p>
    We defined orthogonal sets in <m>\R^n</m> and bases of subspaces of <m>\R^n</m> in <xref ref="def_6_b_orthogonal_set_Rn">Definitions</xref>
    and <xref ref="def_6_b_orthogonal_basis_Rn"></xref>.
    We saw that the standard basis in <m>\R^3</m> is an orthogonal set and an orthogonal basis of <m>\R^3</m> <mdash/> there are many other examples as well.
  </p>

  <activity xml:id="act_6_b_orthog">
    <introduction>
    <p>
      Let <m>\vw_1 = \left[ \begin{array}{r} -2 \\ 1 \\ -1 \end{array} \right]</m>,
      <m>\vw_2 = \left[ \begin{array}{r} 0 \\ 1 \\ 1 \end{array} \right]</m>,
      and <m>\vw_3 = \left[ \begin{array}{r} 1 \\ 1 \\ -1 \end{array} \right]</m>.
      In the same manner as in <xref ref="pa_6_b"></xref>,
      we can show that the set <m>S_1 = \left\{ \vw_1, \vw_2, \vw_3 \right\}</m> is an orthogonal subset of <m>\R^3</m>.
    </p>
    </introduction>
      <task>
        <statement>
          <p>
            Is the set <m>S_2 = \left\{ \left[ \begin{array}{r} -2 \\ 1 \\ -1 \end{array} \right], \left[ \begin{array}{r} 0 \\ 1 \\ 1 \end{array} \right], \left[ \begin{array}{r} 1 \\ 1 \\ -1 \end{array} \right], \left[ \begin{array}{r} 1 \\ 2 \\ 0 \end{array} \right] \right\}</m> an orthogonal subset of <m>\R^3</m>?
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Suppose a vector <m>\vv</m> is a vector so that
            <m>S_1 \cup \{\vv\}</m> is an orthogonal subset of <m>\R^3</m>.
            Then <m>\vw_i \cdot \vv = 0</m> for each <m>i</m>.
            Explain why this implies that <m>\vv</m> is in <m>\Nul A</m>,
            where <m>A = \left[ \begin{array}{rcr} -2\amp 1\amp -1 \\ 0\amp 1\amp 1 \\ 1\amp 1\amp -1 \end{array} \right]</m>.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Assuming that the reduced row echelon form of the matrix <m>A</m> is <m>I_3</m>,
            explain why it is not possible to find a nonzero vector <m>\vv</m> so that
            <m>S_1 \cup \{\vv\}</m> is an orthogonal subset of <m>\R^3</m>.
          </p>
        </statement>
      </task>
    
  </activity>

  <p>
    The example from <xref ref="act_6_b_orthog"></xref>
    suggests that we can have three orthogonal nonzero vectors in <m>\R^3</m>,
    but no more.
    Orthogonal vectors are, in a sense,
    as far apart as they can be.
    So we might expect that there is no linear relationship between orthogonal vectors.
    The following theorem makes this clear.
  </p>

  <theorem xml:id="thm_6_b_Orth_li">
    <statement>
      <p>
        Let <m>\{\vv_1, \vv_2, \ldots, \vv_m\}</m> be a set of nonzero orthogonal vectors in <m>\R^n</m>.
        Then the vectors <m>\vv_1, \vv_2, \ldots, \vv_m</m> are linearly independent.
      </p>
    </statement>
  
  <proof>
    <p>
      Let <m>S = \{\vv_1, \vv_2, \ldots, \vv_m\}</m> be a set of nonzero orthogonal vectors in <m>\R^n</m>.
      To show that <m>\vv_1</m>, <m>\vv_2</m>,
      <m>\ldots</m>, <m>\vv_m</m> are linearly independent, assume that
      <men xml:id="eq_6_b_orthog">
        x_1\vv_1 + x_2\vv_2 + \cdots + x_m \vv_m = \vzero
      </men>
      for some scalars <m>x_1</m>, <m>x_2</m>,
      <m>\ldots</m>, <m>x_m</m>.
      We will show that <m>x_i = 0</m> for each <m>i</m> from 1 to <m>m</m>.
      Since the vectors in <m>S</m> are orthogonal to each other,
      we know that <m>\vv_i \cdot \vv_j = 0</m> whenever <m>i \neq j</m>.
      Fix an index <m>k</m> between 1 and <m>m</m>.
      We evaluate the dot product of both sides of <xref ref="eq_6_b_orthog"/> with <m>\vv_k</m> and simplify using the dot product properties:
      <mdn>
        <mrow number="no">\vv_k \cdot (x_1\vv_1 + x_2\vv_2 + \cdots + x_m \vv_m) \amp = \vv_k \cdot \vzero</mrow>
        <mrow number="no">(\vv_k \cdot x_1\vv_1) + (\vv_k \cdot x_2\vv_2) + \cdots + (\vv_k \cdot x_m \vv_m) \amp = 0</mrow>
        <mrow xml:id="eq_6_b_orthog2">x_1(\vv_k \cdot \vv_1) + x_2(\vv_k \cdot \vv_2) + \cdots + x_m(\vv_k \cdot  \vv_m) \amp = 0</mrow>
      </mdn>.
    </p>
    <p>
      Now all of the dot products on the left are 0 except for <m>\vv_k \cdot \vv_k</m>,
      so <xref ref="eq_6_b_orthog2"/> becomes
      <me>
        x_k (\vv_k \cdot \vv_k) = 0
      </me>.
    </p>
    <p>
      We assumed that <m>\vv_k \neq \vzero</m> and since <m>\vv_k \cdot \vv_k = || \vv_k ||^2 \neq 0</m>,
      we conclude that <m>x_k = 0</m>.
      We chose <m>k</m> arbitrarily,
      so we have shown that <m>x_k =0</m> for each <m>k</m> between 1 and <m>m</m>.
      Therefore, the only solution to equation <xref ref="eq_6_b_orthog"/> is the trivial solution with
      <m>x_1 = x_2 = \cdots = x_m = 0</m> and the set <m>S</m> is linearly independent.
    </p>
  </proof>
  </theorem>
</section>