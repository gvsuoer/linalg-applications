<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_orthog_diag_intro">
  <title>Introduction</title>
  <p>
    We have seen how to diagonalize a matrix <mdash/> if we can find <m>n</m> linearly independent eigenvectors of an
    <m>n\times n</m> matrix <m>A</m> and let <m>P</m> be the matrix whose columns are those eigenvectors,
    then <m>P^{-1}AP</m> is a diagonal matrix with the eigenvalues down the diagonal in the same order corresponding to the eigenvectors placed in <m>P</m>.
    We will see that in certain cases we can take this one step further and create an orthogonal matrix with eigenvectors as columns to diagonalize a matrix.
    This is called orthogonal diagonalization.
    Orthogonal diagonalizability is useful in that it allows us to find a
    <q>convenient</q>
    coordinate system in which to interpret the results of certain matrix transformations.
    A set of orthonormal basis vectors for an orthogonally diagonalizable matrix <m>A</m> is called a set of
    <term>principal axes</term> for <m>A</m>.
    Orthogonal diagonalization will also play a crucial role in the singular value decomposition of a matrix,
    a decomposition that has been described by some as the
    <q>pinnacle</q>
    of linear algebra.
  </p>

  <definition xml:id="def_7_a_orthogonal__diagonalization">
  <idx><h>orthogonal diagonalization</h></idx>
    <statement>
      <p>
        An <m>n \times n</m> matrix <m>A</m> is
        <term>orthogonally diagonalizable</term> if there is an orthogonal matrix <m>P</m> such that
        <me>
          P^{\tr}AP
        </me>
        is a diagonal matrix.
        We say that the matrix <m>P</m>
        <term>orthogonally diagonalizes</term> the matrix <m>A</m>.
      </p>
    </statement>
  </definition>

  <exploration xml:id="pa_7_a">
    
      <task>
        <introduction>
          <p>
            For each matrix <m>A</m> whose eigenvalues and corresponding eigenvectors are given,
            find a matrix <m>P</m> such that
            <m>P^{-1}AP</m> is a diagonal matrix.
          </p>
        </introduction>
            <task>
              <statement>
                <p>
                  <m>A = \left[ \begin{array}{cc} 1\amp 2 \\ 2\amp 1 \end{array} \right]</m> with eigenvalues <m>-1</m> and 3 and corresponding eigenvectors
                  <m>\vv_1 = \left[ \begin{array}{r} -1 \\ 1 \end{array} \right]</m> and <m>\vv_2 = \left[ \begin{array}{c} 1 \\ 1 \end{array} \right]</m>.
                </p>
              </statement>
            </task>
            <task>
              <statement>
                <p>
                  <m>A = \left[ \begin{array}{cc} 1\amp 2 \\ 1\amp 2 \end{array} \right]</m> with eigenvalues <m>0</m> and <m>3</m> and corresponding eigenvectors
                  <m>\vv_1 = \left[ \begin{array}{r} -2 \\ 1 \end{array} \right]</m> and <m>\vv_2 = \left[ \begin{array}{c} 1 \\ 1 \end{array} \right]</m>.
                </p>
              </statement>
            </task>
            <task>
              <statement>
                <p>
                  <m>A = \left[ \begin{array}{ccc} 1\amp 0\amp 1 \\ 0\amp 1\amp 1 \\ 1\amp 1\amp 2 \end{array} \right]</m> with eigenvalues <m>0</m>,
                  <m>1</m>,
                  and <m>3</m> and corresponding eigenvectors <m>\vv_1 = \left[ \begin{array}{r} -1 \\ -1 \\ 1 \end{array} \right]</m>,
                  <m>\vv_2 = \left[ \begin{array}{r} -1 \\ 1 \\ 0 \end{array} \right]</m>,
                  and <m>\vv_3 = \left[ \begin{array}{c} 1 \\ 1 \\ 2 \end{array} \right]</m>.
                </p>
              </statement>
            </task>
      </task>
      <task>
        <statement>
          <p>
            Which matrices in part 1 seem to satisfy the orthogonal diagonalization requirement?
            Do you notice any common traits among these matrices?
          </p>
        </statement>
      </task>
    
  </exploration>
</section>