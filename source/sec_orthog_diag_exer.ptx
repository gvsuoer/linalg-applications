<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_orthog_diag_exer">
  <title>Exercises</title>
  <ol>
    <li>
      <p>
        For each of the following matrices,
        find an orthogonal matrix <m>P</m> so that
        <m>P^{\tr}AP</m> is a diagonal matrix,
        or explain why no such matrix exists.
        <ul>
          \begin{minipage}{1.4in}
          <li>
            <p>
              <m>A = \left[ \begin{array}{rr} 3\amp -4 \\ -4\amp -3 \end{array} \right]</m> \end{minipage} \begin{minipage}{1.4in}
            </p>
          </li>
          <li>
            <p>
              <m>A = \left[ \begin{array}{ccc} 4\amp 1\amp 1 \\ 1\amp 1\amp 4 \\ 1\amp 4\amp 1 \end{array} \right]</m> \end{minipage} \begin{minipage}{1.4in}
            </p>
          </li>
          <li>
            <p>
              <m>A = \left[ \begin{array}{cccc} 1\amp 2\amp 0\amp 0 \\ 0\amp 1\amp 2\amp 1 \\ 1\amp 1\amp 1\amp 1 \\ 3\amp 0\amp 5\amp 2 \end{array} \right]</m> \end{minipage}
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        For each of the following matrices find an orthonormal basis of eigenvectors of <m>A</m>.
        Then find a spectral decomposition of <m>A</m>.
        <ul>
          \begin{minipage}{2.0in}
          <li>
            <p>
              <m>A = \left[ \begin{array}{rr} 3\amp -4 \\ -4\amp -3 \end{array} \right]</m> \end{minipage} \begin{minipage}{2.0in}
            </p>
          </li>
          <li>
            <p>
              <m>A = \left[ \begin{array}{ccc} 4\amp 1\amp 1 \\ 1\amp 1\amp 4 \\ 1\amp 4\amp 1 \end{array} \right]</m> \end{minipage} \begin{minipage}{2.0in}
            </p>
          </li>
          <li>
            <p>
              <m>A = \left[ \begin{array}{rrr} -4\amp 0\amp -24 \\ 0\amp -8\amp 0 \\ -24\amp 0\amp 16 \end{array} \right]</m> \end{minipage} \begin{minipage}{2.0in}
            </p>
          </li>
          <li>
            <p>
              <m>A = \left[ \begin{array}{ccr} 1\amp 0\amp 0 \\ 0\amp 0\amp 2 \\ 0\amp 2\amp -3 \end{array} \right]</m> \end{minipage}
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        Find a non-diagonal <m>4 \times 4</m> matrix with eigenvalues 2, 3 and 6 which can be orthogonally diagonalized.
      </p>
    </li>
    <li xml:id="ex_7_a_product">
      <p>
        Let <m>A = [a_{ij}] = [ \vc_1 \ \vc_2 \ \cdots \ \vc_m]</m> be an
        <m>k \times m</m> matrix with columns <m>\vc_1</m>,
        <m>\vc_2</m>, <m>\ldots</m>, <m>\vc_m</m>,
        and let <m>B = [b_{ij}] = \left[ \begin{array}{c} \vr_1 \\ \vr_2 \\ \vdots \\ \vr_m \end{array}  \right]</m> be an
        <m>m \times n</m> matrix  with rows <m>\vr_1</m>, <m>\vr_2</m>,
        <m>\ldots</m>, <m>\vr_m</m>.
        Show that
        <me>
          AB = [ \vc_1 \ \vc_2 \ \cdots \ \vc_m]\left[\begin{array}{c} \vr_1 \\ \vr_2 \\ \vdots \\ \vr_m \end{array}  \right] = \vc_1\vr_1 + \vc_2\vr_2 + \cdots + \vc_m \vr_m
        </me>.
      </p>
    </li>
    <li xml:id="ex_7_a_spectral_decomposition">
      <p>
        Let <m>A</m> be an <m>n \times n</m> symmetric matrix with real entries and let
        <m>\{\vu_1, \vu_2, \ldots, \vu_n\}</m> be an orthonormal basis of eigenvectors of <m>A</m>.
        For each <m>i</m>, let <m>P_i = \vu_i\vu_i^{\tr}</m>.
        Prove <xref ref="thm_7_a_spectral_decomposition"></xref> <mdash/> that is,
        verify each of the following statements.
        <ul>
          <li>
            <p>
              For each <m>i</m>, <m>P_i</m> is a symmetric matrix.
            </p>
          </li>
          <li>
            <p>
              For each <m>i</m>, <m>P_i</m> is a rank 1 matrix.
            </p>
          </li>
          <li>
            <p>
              For each <m>i</m>, <m>P_i^2 = P_i</m>.
            </p>
          </li>
          <li>
            <p>
              If <m>i \neq j</m>, then <m>P_iP_j = 0</m>.
            </p>
          </li>
          <li>
            <p>
              For each <m>i</m>, <m>P_i \vu_i = \vu_i</m>.
            </p>
          </li>
          <li>
            <p>
              If <m>i \neq j</m>, then <m>P_i \vu_j = 0</m>.
            </p>
          </li>
          <li>
            <p>
              If <m>\vv</m> is in <m>\R^n</m>, show that
              <me>
                P_i \vv = \proj_{\Span\{\vu_i\} } \vv
              </me>.
              For this reason we call <m>P_i</m> an
              <em>orthogonal projection matrix</em>.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        Show that if <m>M</m> is an <m>n \times n</m> matrix and
        <m>(M\vx) \cdot \vy = \vx \cdot (M\vy)</m> for every <m>\vx, \vy</m> in <m>\R^n</m>,
        then <m>M</m> is a symmetric matrix.
        <hint>
          <p>
            Try <m>\vx = \textbf{e}_i</m> and <m>\vy = \textbf{e}_j</m>.
          </p>
        </hint>
      </p>
    </li>
    <li>
      <p>
        Let <m>A</m> be an <m>n \times n</m> symmetric matrix and assume that <m>A</m> has an orthonormal basis <m>\{\vu_1</m>,
        <m>\vu_2</m>, <m>\ldots</m>,
        <m>\vu_n\}</m> of eigenvectors of <m>A</m> so that <m>A \vu_i = \lambda_i \vu_i</m> for each <m>i</m>.
        Let <m>P_i = \vu_i\vu_i^{\tr}</m> for each <m>i</m>.
        It is possible that not all of the eigenvalue of <m>A</m> are distinct.
        In this case,
        some of the eigenvalues will be repeated in the spectral decomposition of <m>A</m>.
        If we want only distinct eigenvalues to appear,
        we might do the following.
        Let <m>\mu_1</m>, <m>\mu_2</m>, <m>\ldots</m>,
        <m>\mu_k</m> be the distinct eigenvalues of <m>A</m>.
        For each <m>j</m> between 1 and <m>k</m>,
        let <m>Q_j</m> be the sum of all of the <m>P_i</m> that have <m>\mu_j</m> as eigenvalue.
        <ul>
          <li>
            <p>
              The eigenvalues for the matrix
              <m>A = \left[ \begin{array}{cccc} 0\amp 2\amp 0\amp 0 \\ 2\amp 3\amp 0\amp 0 \\ 0\amp 0\amp 0\amp 2 \\ 0\amp 0\amp 2\amp 3 \end{array} \right]</m> are <m>-1</m> and <m>4</m>.
              Find a basis for each eigenspace and determine each <m>P_i</m>.
              Then find <m>k</m>, <m>\mu_1</m>, <m>\ldots</m>,
              <m>\mu_k</m>, and each <m>Q_j</m>.
            </p>
          </li>
          <li>
            <p>
              Show in general (not just for the specific example in part (a),
              that the <m>Q_j</m> satisfy the same properties as the <m>P_i</m>.
              That is, verify the following.
              <ol label="i">
                <li>
                  <p>
                    <m>A = \mu_1 Q_1 + \mu_2 Q_2 + \cdots \mu_k Q_k</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>Q_j</m> is a symmetric matrix for each <m>j</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>Q_j^2 = Q_j</m> for each <m>j</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>Q_j Q_{\ell} = 0</m> when <m>j \neq \ell</m>
                  </p>
                </li>
                <li>
                  <p>
                    if <m>E_{\mu_j}</m> is the eigenspace for <m>A</m> corresponding to the eigenvalue <m>\mu_j</m>,
                    and if <m>\vv</m> is in <m>\R^n</m>,
                    then <m>Q_j \vv = \proj_{E_{\mu_j}} \vv</m>.
                  </p>
                </li>
              </ol>
            </p>
          </li>
          <li>
            <p>
              What is the rank of <m>Q_j</m>?
              Verify your answer.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        Label each of the following statements as True or False.
        Provide justification for your response.
        <ul>
          <li>
            <p>
              <em>True/False</em> Every real symmetric matrix is diagonalizable.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>P</m> is a matrix whose columns are eigenvectors of a symmetric matrix,
              then the columns of <m>P</m> are orthogonal.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A</m> is a symmetric matrix,
              then eigenvectors of <m>A</m> corresponding to distinct eigenvalues are orthogonal.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>\vv_1</m> and <m>\vv_2</m> are distinct eigenvectors of a symmetric matrix <m>A</m>,
              then <m>\vv_1</m> and <m>\vv_2</m> are orthogonal.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> Any symmetric matrix can be written as a sum of symmetric rank 1 matrices.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A</m> is a matrix satisfying <m>A^{\tr} = A</m>,
              and <m>\vu</m> and <m>\vv</m> are vectors satisfying
              <m>A \vu = 2 \vu</m> and <m>A \vv = -2 \vv</m>,
              then <m>\vu \cdot \vv = 0</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If an <m>n\times n</m> matrix <m>A</m> has <m>n</m> orthogonal eigenvectors,
              then <m>A</m> is a symmetric matrix.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If an <m>n\times n</m> matrix has <m>n</m> real eigenvalues
              (counted with multiplicity),
              then <m>A</m> is a symmetric matrix.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> For each eigenvalue of a symmetric matrix,
              the algebraic multiplicity equals the geometric multiplicity.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A</m> is invertible and orthogonally diagonalizable,
              then so is <m>A^{-1}</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A, B</m> are orthogonally diagonalizable
              <m>n\times n</m> matrices, then so is <m>AB</m>.
            </p>
          </li>
        </ul>
      </p>
    </li>
  </ol>
</section>