<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_qr_fact">
  <title>The QR Factorization of a Matrix</title>
  <p>
    There are several different factorizations, or decompositions,
    of matrices where each matrix is written as a product of certain types of matrices: LU decomposition using lower and upper triangular matrices
    (see <xref ref="chap_det_properties"></xref>),
    EVD (EigenVector Decomposition) decomposition using eigenvectors and diagonal matrices
    (see <xref ref="chap_diagonalization"></xref>),
    and in this section we will introduce the QR decomposition of a matrix.
    The QR decomposition is one of the most important tools for matrix computations.
    Jack Dongarra and Francis Sullivan<fn>
    Jack Dongarra and Francis Sullivan.
    Introduction to the top 10 algorithms.
    Computing in Science and Engineering, 2: 22-23, 2000.
    </fn> nominated the QR decomposition as one of the
    <q>10 algorithms with the greatest influence on the development and practice of science and engineering in the 20th century.</q>
    The QR algorithm's importance stems from the fact that is a
    <q>genuinely new contribution to the field of numerical analysis and not just a refinement of ideas given by Newton, Gauss, Hadamard,
    or Schur.</q><fn>
    [3] Beresford N. Parlett.
    The QR algorithm.
    Computing in Science and Engineering, 2:38-42, 2000.
    </fn> Most computer algebra systems (e.g., MATLAB) use a variant of the QR decomposition to compute eigenvalues.
    While there are other methods for approximating eigenvalues,
    the QR algorithm stands out.
    For example,
    the power method is useful when a matrix is large and contains a lot of zero entries
    (such matrices are called <term>sparse</term>).
    When most of the entries of a matrix are nonzero,
    the power method is not recommended.
    The better, more sophisticated,
    alternative in these situations is to use the QR decomposition.
    The QR factorization has applications to solving least squares problems and approximating eigenvalues of matrices.
  </p>

  <activity xml:id="act_6_e_QR">
    <introduction>
    <p>
      Let <m>A = \left[ \begin{array}{cc} 1\amp 0 \\ 0\amp 0 \\ 0\amp 2 \end{array} \right]</m>.
    </p>
    </introduction>
      <task>
        <statement>
          <p>
            Find an orthonormal basis <m>\CB</m> for <m>\Col A</m>.
            Let <m>Q</m> be the matrix whose columns are these orthonormal basis vectors.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Write the columns of <m>A</m> as linear combinations of the columns of <m>Q</m>.
            That is, if <m>A = [\va_1 \ \va_2]</m>,
            find <m>[\va_1]_{\CB}</m> and <m>[\va_2]_{\CB}</m>.
            Let <m>R = [[\va_1]_{\CB} \ [\va_2]_{\CB}]</m>.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Find the product <m>QR</m> and compare to <m>A</m>.
          </p>
        </statement>
      </task>
    
  </activity>

  <p>
    <xref ref="act_6_e_QR"></xref>
    contains the main ideas to find the QR factorization of a matrix.
    Let
    <me>
      A = [\va_1  \ \va_2  \ \va_3  \ \cdots  \ \va_n ]
    </me>
    be an <m>m \times n</m> matrix with rank<fn>
    Recall that the rank of a matrix <m>A</m> is the dimension of the column space of <m>A</m>.
    </fn> <m>n</m>.
    We can use the Gram-Schmidt process to find an orthonormal basis <m>\{\vu_1, \vu_2, \ldots, \vu_n\}</m> for <m>\Col A</m>.
    Recall also that <m>\Span\{\vu_1, \vu_2, \ldots, \vu_k\}  = \Span\{\va_1, \va_2, \ldots, \va_k\}</m> for any <m>k</m> between 1 and <m>n</m>.
    Let
    <me>
      Q = [\vu_1 \   \vu_2 \  \vu_3 \  \cdots \  \vu_n ]
    </me>.
  </p>
  <p>
    If <m>k</m> is between 1 and <m>n</m>,
    then <m>\va_k</m> is in <m>\Span\{\vu_1, \vu_2, \ldots, \vu_k\}</m> and
    <me>
      \va_k = r_{1k}\vu_1 + r_{2k}\vu_2 + \cdots + r_{kk}\vu_k
    </me>
    for some scalars <m>r_{1k}</m>,
    <m>r_{2k}</m>, <m>\ldots</m>, <m>r_{kk}</m>.
    Then
    <me>
      Q \left[ \begin{array}{c} r_{1k} \\ r_{2k} \\ \vdots \\ r_{kk} \\ 0 \\ \vdots \\ 0 \end{array}  \right] = \va_k
    </me>.
  </p>
  <p>
    If we let <m>\vr_k = \left[ \begin{array}{c} r_{1k} \\ r_{2k} \\ \vdots \\ r_{kk} \\ 0 \\ \vdots \\ 0 \end{array}  \right]</m> for <m>k</m> from 1 to <m>n</m>, then
    <me>
      A = [Q\vr_1  \ Q\vr_2  \ Q\vr_3  \ \cdots  \ Q\vr_k]
    </me>.
  </p>
  <p>
    This is the QR factorization of <m>A</m> into the product
    <me>
      A = QR
    </me>
    where the columns of <m>Q</m> form an orthonormal basis for <m>\Col A</m> and
    <me>
      R = [\vr_1  \ \vr_2  \ \vr_3  \ \cdots  \ \vr_n ] = \left[ \begin{array}{cccccc} r_{11}\amp r_{12}\amp r_{13}\amp  \cdots \amp r_{1n-1}\amp r_{1n} \\ 0\amp r_{22}\amp r_{23}\amp  \cdots \amp r_{2n-1}\amp r_{2n} \\ 0\amp 0\amp r_{33}\amp  \cdots \amp r_{3n-1}\amp r_{3n} \\ \vdots\amp \vdots \amp \vdots \amp \vdots \amp \vdots \amp \vdots \\ 0\amp 0\amp 0\amp  \cdots \amp 0\amp r_{nn} \end{array}  \right]
    </me>
    is an upper triangular matrix.
    Note that <m>Q</m> is an <m>m \times n</m> matrix and <m>R = [r_{ij}]</m> is an
    <m>n \times n</m> matrix with <m>r_{ii} \neq 0</m> for each <m>i</m>.
  </p>

  <activity>
    <statement>
    <p>
      The set <m>\{\vu_1, \vu_2\}</m>,
      where <m>\vu_1 = [1 \ 1 \ 1 \ 1]^{\tr}</m> and
      <m>\vu_2 = [1 \ -1 \ 1 \ -1]^{\tr}</m> is an orthogonal basis for the column space of a
      <m>4 \times 2</m> matrix <m>A = [\va_1 \ \va_2]</m>.
      Moreover, <m>\va_1 = 2\vu_1</m> and <m>\va_2 = 3\vu_2+4\vu_2</m>.
      What is <m>A</m>?
    </p>
    </statement>
  </activity>

  <p>
    The QR factorization provides a widely used algorithm
    (the QR algorithm)
    for approximating all of the eigenvalues of a matrix.
    The computer system MATLAB utilizes four versions of the QR algorithm to approximate the eigenvalues of real symmetric matrices,
    eigenvalues of real nonsymmetric matrices,
    eigenvalues of pairs of complex matrices,
    and singular values of general matrices.
  </p>
  <p>
    The algorithm works as follows.
    <ul>
      <li>
        <p>
          Start with an <m>n \times n</m> matrix <m>A</m>.
          Let <m>A_1 = A</m>.
        </p>
      </li>
      <li>
        <p>
          Find the QR factorization for <m>A_1</m> and write it as <m>A_1 = Q_1R_1</m>,
          where <m>Q_1</m> is orthogonal and <m>R_1</m> is upper triangular.
        </p>
      </li>
      <li>
        <p>
          Let <m>A_2 = Q_1^{-1}A_1Q_1 = Q_1^{\tr}AQ_1 = R_1Q_1</m>.
          Find the QR factorization of <m>A_2</m> and write it as <m>A_2 = Q_2R_2</m>.
        </p>
      </li>
      <li>
        <p>
          Let <m>A_3 = Q_2^{-1}A_2Q_2 = Q_2^{\tr}AQ_2 = R_2Q_2</m>.
          Find the QR factorization of <m>A_3</m> and write it as <m>A_3 = Q_3R_3</m>.
        </p>
      </li>
      <li>
        <p>
          Continue in this manner to obtain a sequence <m>\{A_k\}</m> where
          <m>A_k = Q_kR_k</m> and <m>A_{k+1} = R_kQ_k</m>.
        </p>
      </li>
    </ul>
  </p>
  <p>
    Note that <m>A_{k+1} = Q_k^{-1}A_kQ_k</m> and so all of the matrices <m>A_k</m> are similar to each other and therefore all have the same eigenvalues.
    We won't go into the details,
    but it can be shown that if the eigenvalues of <m>A</m> are real and have distinct absolute values,
    then the sequence <m>\{A_i\}</m> converges to an upper triangular matrix with the eigenvalues of <m>A</m> as the diagonal entries.
    If some of the eigenvalues of <m>A</m> are complex,
    then the sequence <m>\{A_i\}</m> converges to a block upper triangular matrix,
    where the diagonal blocks are either <m>1 \times 1</m>
    (approximating the real eigenvalues of <m>A</m>)
    or <m>2 \times 2</m>
    (which provide a pair of conjugate complex eigenvalues of <m>A</m>).
  </p>
</section>