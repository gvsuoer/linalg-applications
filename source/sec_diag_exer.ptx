<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_diag_exer">
  <title>Exercises</title>
  <ol>
    <li>
      <p>
        Determine if each of the following matrices is diagonalizable or not.
        For diagonalizable matrices,
        clearly identify a matrix <m>P</m> which diagonalizes the matrix,
        and what the resulting diagonal matrix is.
        <ul>
          <li>
            <p>
              <m>A=\left[ \begin{array}{cr} 2\amp -1\\ 1\amp 4 \end{array} \right]</m>
            </p>
          </li>
          <li>
            <p>
              <m>A=\left[ \begin{array}{rcr} -1 \amp 4 \amp -2 \\ -3 \amp 4 \amp 0 \\ -3 \amp 1 \amp 3 \end{array} \right]</m>
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        The <m>3\times 3</m> matrix <m>A</m> has two eigenvalues
        <m>\lambda_1=2</m> and <m>\lambda_2=3</m>.
        The vectors <m>\left[ \begin{array}{c} 1\\2\\1 \end{array} \right]</m>,
        <m>\left[ \begin{array}{r} 1\\-1\\2 \end{array} \right]</m>,
        and <m>\left[ \begin{array}{c} 2\\4\\2 \end{array} \right]</m> are eigenvectors for <m>\lambda_1=2</m>,
        while the vectors <m>\left[ \begin{array}{c} 1\\1\\1 \end{array} \right], \left[ \begin{array}{c} 2\\2\\2 \end{array} \right]</m> are eigenvectors for <m>\lambda_2=3</m>.
        Find the matrix <m>A</m>.
      </p>
    </li>
    <li>
      <p>
        Find a <m>2\times 2</m> non-diagonal matrix <m>A</m> and two different pairs of <m>P</m> and <m>D</m> matrices for which <m>A=PDP^{-1}</m>.
      </p>
    </li>
    <li>
      <p>
        Find a <m>2\times 2</m> non-diagonal matrix <m>A</m> and two different <m>P</m> matrices for which
        <m>A=PDP^{-1}</m> with the same <m>D</m>.
      </p>
    </li>
    <li>
      <p>
        Suppose a <m>4\times 4</m> matrix <m>A</m> has eigenvalues 2, 3 and 5 and the eigenspace for the eigenvalue 3 has dimension 2.
        Do we have enough information to determine if <m>A</m> is diagonalizable?
        Explain.
      </p>
    </li>
    <li xml:id="ex_4_c_diagonal_converse">
      <p>
        Let <m>A</m> be a diagonalizable <m>n \times n</m> matrix.
        Show that <m>A</m> has <m>n</m> linearly independent eigenvectors.
      </p>
    </li>
    <li>
      <p>
        <nbsp/>
        <ul>
          <li>
            <p>
              Let <m>A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 1 \end{array} \right]</m> and <m>B = \left[ \begin{array}{cc} 1\amp 2\\0\amp 1 \end{array} \right]</m>.
              Find the eigenvalues and eigenvectors of <m>A</m> and <m>B</m>.
              Conclude that it is possible for two different
              <m>n \times n</m> matrices <m>A</m> and <m>B</m> to have exactly the same eigenvectors and corresponding eigenvalues.
            </p>
          </li>
          <li>
            <p>
              A natural question to ask is if there are any conditions under which
              <m>n \times n</m> matrices that have exactly the same eigenvectors and corresponding eigenvalues must be equal.
              Determine the answer to this question if <m>A</m> and <m>B</m> are both diagonalizable.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        <nbsp/>
        <ul>
          <li>
            <p>
              Show that if <m>D</m> and <m>D'</m> are
              <m>n \times n</m> diagonal matrices, then <m>DD' = D'D</m>.
            </p>
          </li>
          <li>
            <p>
              Show that if <m>A</m> and <m>B</m> are
              <m>n \times n</m> matrices and <m>P</m> is an invertible
              <m>n \times n</m> matrix such that <m>P^{-1}AP = D</m> and
              <m>P^{-1}BP = D'</m> with <m>D</m> and <m>D'</m> diagonal matrices,
              then <m>AB = BA</m>.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li xml:id="ex_trace_eigenvalues">
      <p>
        <xref ref="ex_determinant_eigenvalues">Exercise</xref>
        in <xref ref="sec_characteristic_equation">Section</xref>
        shows that the determinant of a matrix is the product of its eigenvalues.
        In this exercise we show that the trace of a diagonalizable matrix is the sum of its eigenvalues.<fn>
        This result is true for any matrix,
        but the argument is more complicated.
        </fn> First we define the trace of a matrix.
        <definition xml:id="def_trace">
          <statement>
            <p>
              The <term>trace</term>
    <idx><h>trace</h></idx>
              of an <m>n \times n</m> matrix
              <m>A = [a_{ij}]</m> is the sum of the diagonal entries of <m>A</m>.
              That is,
              <me>
                \trace(A) = a_{11} + a_{22} + \cdots + a_{nn} = \sum_{i=1}^n a_{ii}
              </me>.
            </p>
          </statement>
        </definition>
        <ul>
          <li>
            <p>
              Show that if <m>R = [r_{ij}]</m> and
              <m>S = [s_{ij}]</m> are <m>n \times n</m> matrices,
              then <m>\trace(RS) = \trace(SR)</m>.
            </p>
          </li>
          <li>
            <p>
              Let <m>A</m> be a diagonalizable <m>n \times n</m> matrix,
              and let <m>p(\lambda) = \det(A - \lambda I_n)</m> be the characteristic polynomial of <m>A</m>.
              Let <m>P</m> be an invertible matrix such that <m>P^{-1}AP = D</m>,
              where <m>D</m> is the diagonal matrix whose diagonal entries are <m>\lambda_1</m>,
              <m>\lambda_2</m>, <m>\ldots</m>,
              <m>\lambda_n</m>, the eigenvalues of <m>A</m>
              (note that these eigenvalues may not all be distinct).
              <ol label="i">
                <li>
                  <p>
                    Explain why <m>\trace(A) = \trace(D)</m>.
                  </p>
                </li>
                <li>
                  <p>
                    Show that the trace of an <m>n \times n</m> diagonalizable matrix is the sum of the eigenvalues of the matrix.
                  </p>
                </li>
              </ol>
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li xml:id="ex_4_c_matrix_exponential">
      <p>
        In this exercise we generalize the result of <xref ref="ex_2_a_matrix_exponential">Exercise</xref>
        in <xref ref="sec_matrix_operations">Section</xref>
        to arbitrary diagonalizable matrices.
        <ul>
          <li>
            <p>
              Show that if
              <me>
                D=\left[ \begin{array}{ccccc} \lambda_1\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  \lambda_2\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  \lambda_n \end{array}  \right]
              </me>,
              then
              <me>
                e^D =  \left[ \begin{array}{ccccc} e^{\lambda_1}\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  e^{\lambda_2}\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  e^{\lambda_n} \end{array}  \right]
              </me>.
            </p>
          </li>
          <li>
            <p>
              Now suppose that an <m>n \times n</m> matrix <m>A</m> is diagonalizable,
              with <m>P^{-1}AP</m> equal to a diagonal matrix <m>D</m>.
              Show that <m>e^A = Pe^DP^{-1}</m>.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li xml:id="ex_4_c_matrix_exponential_examples">
      <p>
        Let <m>A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 0 \end{array} \right]</m> and let <m>B = \left[ \begin{array}{cr} 0\amp -1 \\ 0\amp 0 \end{array} \right]</m>.
        <ul>
          <li>
            <p>
              Use the result of <xref ref="ex_4_c_matrix_exponential">Exercise</xref> to calculate <m>e^A</m>.
            </p>
          </li>
          <li>
            <p>
              Calculate <m>e^B</m>.
              <hint>
                <p>
                  Explain why <m>B</m> is not diagonalizable.
                </p>
              </hint>
            </p>
          </li>
          <li>
            <p>
              Use the result of <xref ref="ex_4_c_matrix_exponential">Exercise</xref> to calculate <m>e^{A+B}</m>.
            </p>
          </li>
          <li>
            <p>
              The real exponential function satisfies some familiar properties.
              For example, <m>e^xe^y = e^ye^x</m> and
              <m>e^{x+y} = e^x e^y</m> for any real numbers <m>x</m> and <m>y</m>.
              Does the matrix exponential satisfy the corresponding properties.
              That is, if <m>X</m> and <m>Y</m> are <m>n \times n</m> matrices,
              must <m>e^Xe^Y = e^Ye^X</m> and <m>e^{X+Y} = e^X e^Y</m>?
              Explain.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        In <xref ref="ex_4_c_matrix_exponential_examples">Exercise</xref>
        we see that we cannot conclude that <m>e^{X+Y} = e^X e^Y</m> for
        <m>n \times n</m> matrices <m>X</m> and <m>Y</m>.
        However, a more limited property is true.
        <ul>
          <li>
            <p>
              Follow the steps indicated to show that if <m>A</m> is an
              <m>n \times n</m> matrix and <m>s</m> and <m>t</m> are any scalars,
              then <m>e^{As} e^{At} = e^{A(s+t)}</m>.
              (Although we will not use it,
              you may assume that the series for <m>e^A</m> converges for any square matrix <m>A</m>.)
              <ol label="i">
                <li>
                  <p>
                    Use the definition to show that
                    <me>
                      e^{As}e^{At} = \sum_{k \geq 0} \sum_{m \geq 0} \frac{s^kt^m}{k!}m! A^{k+m}
                    </me>.
                  </p>
                </li>
                <li>
                  <p>
                    Relabel and reorder terms with <m>n = k+m</m> to show that
                    <me>
                      e^{As}e^{At} = sum_{n \geq 0} \frac{1}{n!} A^n \sum_{m = 0}^n \frac{n!}{(n-m)!m!} s^{n-m}t^m
                    </me>.
                  </p>
                </li>
                <li>
                  <p>
                    Complete the problem using the Binomial Theorem that says
                    <me>
                      (s+t)^n =  \sum_{m = 0}^n \frac{n!} {(n-m)!m!} s^{n-m}t^m
                    </me>.
                  </p>
                </li>
              </ol>
            </p>
          </li>
          <li>
            <p>
              Use the result of part (a) to show that <m>e^A</m> is an invertible matrix for any <m>n \times n</m> matrix <m>A</m>.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        There is an interesting connection between the determinant of a matrix exponential and the trace of the matrix.
        Let <m>A</m> be a diagonalizable
        <m>n \times n</m> matrix with real entries.
        Let <m>D = P^{-1}AP</m> for some invertible matrix <m>P</m>,
        where <m>D</m> is the diagonal matrix with entries <m>\lambda_1</m>,
        <m>\lambda_2</m>,
        <m>\ldots</m>, <m>\lambda_n</m> the eigenvalues of <m>A</m>.
        <ul>
          <li>
            <p>
              Show that <m>e^A = Pe^DP^{-1}</m>.
            </p>
          </li>
          <li>
            <p>
              Use <xref ref="ex_trace_eigenvalues">Exercise</xref> to show that
              <me>
                \det\left(e^A\right) = e^{\trace(A)}
              </me>.
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li xml:id="ex_Cayley-Hamilton">
      <p>
        There is interesting relationship between a matrix and its characteristic equation that we explore in this exercise.
        <ul>
          <li>
            <p>
              We first illustrate with an example.
              Let <m>B = \left[ \begin{array}{cr} 1\amp 2\\ 1\amp -2 \end{array} \right]</m>.
              <ol label="i">
                <li>
                  <p>
                    Show that <m>\lambda^2 + \lambda - 4</m> is the characteristic polynomial for <m>B</m>.
                  </p>
                </li>
                <li>
                  <p>
                    Calculate <m>B^2</m>.
                    Then compute <m>B^2 + B - 4I_2</m>.
                    What do you get?
                  </p>
                </li>
              </ol>
            </p>
          </li>
          <li>
            <p>
              The first part of this exercise presents an example of a matrix that satisfies its own characteristic equation.
              Show that if <m>A</m> is an
              <m>n \times n</m> <em>diagonalizable</em>
              matrix with characteristic polynomial <m>p(x)</m>, then <m>p(A) = 0</m>.<fn>
              This result is known as the Cayley-Hamilton Theorem and is one of the fascinating results in linear algebra.
              This result is true for any square matrix.
              </fn> That is,
              if <m>p(x) = a_nx^n+a_{n-1}x^{n-1} + \cdots + a_1x + a_0</m>,
              then <m>p(A) = a_nA^n+a_{n-1}A^{n-1} + \cdots + a_1A + a_0 = 0</m>. (Hint: If
              <m>A = PDP^{-1}</m> for some diagonal matrix <m>D</m>,
              show that <m>p(A) = Pp(D)P^{-1}</m>.
              Then determine <m>p(D)</m>.)
            </p>
          </li>
        </ul>
      </p>
    </li>
    <li>
      <p>
        Label each of the following statements as True or False.
        Provide justification for your response.
        <ul>
          <li>
            <p>
              <em>True/False</em> If matrix <m>A</m> is diagonalizable,
              then so is <m>A^T</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If matrix <m>A</m> is diagonalizable,
              then <m>A</m> is invertible.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If an <m>n\times n</m> matrix <m>A</m> is diagonalizable,
              then <m>A</m> has <m>n</m> distinct eigenvalues.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If matrix <m>A</m> is invertible and diagonalizable,
              then so is <m>A^{-1}</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If an <m>n \times n</m> matrix <m>C</m> is diagonalizable,
              then there exists a basis of <m>\R^n</m> consisting of the eigenvectors of <m>C</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> An <m>n\times n</m> matrix with <m>n</m> distinct eigenvalues is diagonalizable.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A</m> is an
              <m>n\times n</m> diagonalizable matrix,
              then there is a unique diagonal matrix such that
              <m>P^{-1}AP = D</m> for some invertible matrix <m>P</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>A</m> is an
              <m>n\times n</m> matrix with eigenvalue <m>\lambda</m>,
              then the dimension of the eigenspace of <m>A</m> corresponding to the eigenvalue <m>\lambda</m> is <m>n - \rank(A - \lambda I_n)</m>.
            </p>
          </li>
          <li>
            <p>
              <em>True/False</em> If <m>\lambda</m> is an eigenvalue of an <m>n \times n</m> matrix <m>A</m>,
              then <m>e^\lambda</m> is an eigenvalue of <m>e^A</m>.
              (See <xref ref="ex_2_a_matrix_exponential">Exercise</xref>
              in <xref ref="sec_matrix_operations">Section</xref>
              for information on the matrix exponential.)
            </p>
          </li>
        </ul>
      </p>
    </li>
  </ol>
</section>