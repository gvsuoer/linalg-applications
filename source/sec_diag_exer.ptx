<?xml version="1.0" encoding="UTF-8" ?>
<exercises xml:id="sec_diag_exer">
  
  <exercise>
    <introduction>
      <p>
        Determine if each of the following matrices is diagonalizable or not.
        For diagonalizable matrices,
        clearly identify a matrix <m>P</m> which diagonalizes the matrix,
        and what the resulting diagonal matrix is.
      </p>
    </introduction>
        <task>
          <statement>
            <p>
              <m>A=\left[ \begin{array}{cr} 2\amp -1\\ 1\amp 4 \end{array} \right]</m>
            </p>
          </statement>
          <answer>
            <p>
              Not diagonalizable.
            </p>
          </answer>
        </task>
        <task>
          <statement>
            <p>
              <m>A=\left[ \begin{array}{rcr} -1 \amp 4 \amp -2 \\ -3 \amp 4 \amp 0 \\ -3 \amp 1 \amp 3 \end{array} \right]</m>
            </p>
          </statement>
          <answer>
            <p>
              Diagonalizable by <m>P = \left[ \begin{array}{ccc} 1\amp 2\amp 1\\1\amp 3\amp 3\\1\amp 3\amp 4 \end{array} \right]</m>
            </p>
          </answer>
        </task>
  </exercise>

  <exercise>
    <statement>
      <p>
        The <m>3\times 3</m> matrix <m>A</m> has two eigenvalues
        <m>\lambda_1=2</m> and <m>\lambda_2=3</m>.
        The vectors <m>\left[ \begin{array}{c} 1\\2\\1 \end{array} \right]</m>,
        <m>\left[ \begin{array}{r} 1\\-1\\2 \end{array} \right]</m>,
        and <m>\left[ \begin{array}{c} 2\\4\\2 \end{array} \right]</m> are eigenvectors for <m>\lambda_1=2</m>,
        while the vectors <m>\left[ \begin{array}{c} 1\\1\\1 \end{array} \right], \left[ \begin{array}{c} 2\\2\\2 \end{array} \right]</m> are eigenvectors for <m>\lambda_2=3</m>.
        Find the matrix <m>A</m>.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Find a <m>2\times 2</m> non-diagonal matrix <m>A</m> and two different pairs of <m>P</m> and <m>D</m> matrices for which <m>A=PDP^{-1}</m>.
      </p>
    </statement>
    <answer>
      <p>
        <m>A = \left[ \begin{array}{cc} 1\amp 2\\0\amp 2 \end{array} \right]</m>,
        <m>P_1 = \left[ \begin{array}{cc} 1\amp 2 \\ 0\amp 1 \end{array} \right]</m>,
        we have <m>D_1 = \left[ \begin{array}{cc} 1\amp 0 \\ 0\amp 2 \end{array} \right]</m>,
        <m>P_2 = \left[ \begin{array}{cc} 2\amp 1 \\ 1\amp 0 \end{array} \right]</m>,
        <m>D_2 = \left[ \begin{array}{cc} 2\amp 0 \\ 0\amp 1 \end{array} \right]</m>
      </p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p>
        Find a <m>2\times 2</m> non-diagonal matrix <m>A</m> and two different <m>P</m> matrices for which
        <m>A=PDP^{-1}</m> with the same <m>D</m>.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Suppose a <m>4\times 4</m> matrix <m>A</m> has eigenvalues 2, 3 and 5 and the eigenspace for the eigenvalue 3 has dimension 2.
        Do we have enough information to determine if <m>A</m> is diagonalizable?
        Explain.
      </p>
    </statement>
    <answer>
      <p>
        Yes
      </p>
    </answer>
  </exercise>

  <exercise xml:id="ex_4_c_diagonal_converse">
    <statement>
      <p>
        Let <m>A</m> be a diagonalizable <m>n \times n</m> matrix.
        Show that <m>A</m> has <m>n</m> linearly independent eigenvectors.
      </p>
    </statement>
  </exercise>

  <exercise>
    
        <task>
          <statement>
            <p>
              Let <m>A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 1 \end{array} \right]</m> and <m>B = \left[ \begin{array}{cc} 1\amp 2\\0\amp 1 \end{array} \right]</m>.
              Find the eigenvalues and eigenvectors of <m>A</m> and <m>B</m>.
              Conclude that it is possible for two different
              <m>n \times n</m> matrices <m>A</m> and <m>B</m> to have exactly the same eigenvectors and corresponding eigenvalues.
            </p>
          </statement>
          <answer>
            <p>
              Eigenvalues, 1; eigenvectors : <m>\Span \{[1 \ 0]^{\tr}</m>
            </p>
          </answer>
        </task>
        <task>
          <statement>
            <p>
              A natural question to ask is if there are any conditions under which
              <m>n \times n</m> matrices that have exactly the same eigenvectors and corresponding eigenvalues must be equal.
              Determine the answer to this question if <m>A</m> and <m>B</m> are both diagonalizable.
            </p>
          </statement>
          <answer>
            <p>
              Diagonalizable
            </p>
          </answer>
        </task>
  </exercise>

  <exercise>
    
        <task>
          <statement>
            <p>
              Show that if <m>D</m> and <m>D'</m> are
              <m>n \times n</m> diagonal matrices, then <m>DD' = D'D</m>.
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              Show that if <m>A</m> and <m>B</m> are
              <m>n \times n</m> matrices and <m>P</m> is an invertible
              <m>n \times n</m> matrix such that <m>P^{-1}AP = D</m> and
              <m>P^{-1}BP = D'</m> with <m>D</m> and <m>D'</m> diagonal matrices,
              then <m>AB = BA</m>.
            </p>
          </statement>
        </task>
  </exercise>

  <exercise xml:id="ex_trace_eigenvalues">
    <introduction>
      <p>
        <xref ref="ex_determinant_eigenvalues"></xref>
        in <xref ref="chap_characteristic_equation"></xref>
        shows that the determinant of a matrix is the product of its eigenvalues.
        In this exercise we show that the trace of a diagonalizable matrix is the sum of its eigenvalues.<fn>
        This result is true for any matrix,
        but the argument is more complicated.
        </fn> First we define the trace of a matrix.
        </p>
        <definition xml:id="def_trace">
        <idx><h>trace</h></idx>
          <statement>
            <p>
              The <term>trace</term>
              of an <m>n \times n</m> matrix
              <m>A = [a_{ij}]</m> is the sum of the diagonal entries of <m>A</m>.
              That is,
              <me>
                \trace(A) = a_{11} + a_{22} + \cdots + a_{nn} = \sum_{i=1}^n a_{ii}
              </me>.
            </p>
          </statement>
        </definition>
        </introduction>

        <task>
          <statement>
            <p>
              Show that if <m>R = [r_{ij}]</m> and
              <m>S = [s_{ij}]</m> are <m>n \times n</m> matrices,
              then <m>\trace(RS) = \trace(SR)</m>.
            </p>
          </statement>
          <answer>
            <p>
              The <m>ii</m> entry of <m>RS</m> is <m>r_{i1}s_{1i} + r_{i2}s_{2i} + \cdots + r_{in}s_{ni}</m>.
              The <m>jj</m> entry of <m>SR</m> is <m>s_{j1}r_{1j} + s_{j2}r_{2j} + \cdots + s_{jn}r_{nj}</m>.
              Sum as <m>i</m> and <m>j</m> go from <m>1</m> to <m>n</m>.
            </p>
          </answer>
        </task>
        <task>
          <introduction>
            <p>
              Let <m>A</m> be a diagonalizable <m>n \times n</m> matrix,
              and let <m>p(\lambda) = \det(A - \lambda I_n)</m> be the characteristic polynomial of <m>A</m>.
              Let <m>P</m> be an invertible matrix such that <m>P^{-1}AP = D</m>,
              where <m>D</m> is the diagonal matrix whose diagonal entries are <m>\lambda_1</m>,
              <m>\lambda_2</m>, <m>\ldots</m>,
              <m>\lambda_n</m>, the eigenvalues of <m>A</m>
              (note that these eigenvalues may not all be distinct).
            </p>
            </introduction>
              <task>
                <statement>
                  <p>
                    Explain why <m>\trace(A) = \trace(D)</m>.
                  </p>
                </statement>
                <answer>
                  <p>
                    <m>\trace(D) = \trace\left(P^{-1}(AP)\right) = \trace\left((AP)P^{-1}\right) = \trace(A)</m>
                  </p>
                </answer>
              </task>
              <task>
                <statement>
                  <p>
                    Show that the trace of an <m>n \times n</m> diagonalizable matrix is the sum of the eigenvalues of the matrix.
                  </p>
                </statement>
                <answer>
                  <p>
                    <m>\trace\left(A\right) = \trace(D) = \sum_{i=1}^n \lambda_i</m>
                  </p>
                </answer>
              </task>
         
        </task>
  </exercise>

  <exercise xml:id="ex_4_c_matrix_exponential">
    <introduction>
      <p>
        In this exercise we generalize the result of <xref ref="ex_2_a_matrix_exponential"></xref>
        in <xref ref="chap_matrix_operations"></xref>
        to arbitrary diagonalizable matrices.
      </p>
    </introduction>
        <task>
          <statement>
            <p>
              Show that if
              <me>
                D=\left[ \begin{array}{ccccc} \lambda_1\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  \lambda_2\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  \lambda_n \end{array}  \right]
              </me>,
              then
              <me>
                e^D =  \left[ \begin{array}{ccccc} e^{\lambda_1}\amp  0 \amp 0\amp  \cdots \amp 0 \\ 0 \amp  e^{\lambda_2}\amp  0 \amp \cdots \amp  0 \\ \vdots \amp \vdots \amp \vdots \amp  \ddots \amp  \vdots \\ 0 \amp  0\amp  0 \amp \cdots \amp  e^{\lambda_n} \end{array}  \right]
              </me>.
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              Now suppose that an <m>n \times n</m> matrix <m>A</m> is diagonalizable,
              with <m>P^{-1}AP</m> equal to a diagonal matrix <m>D</m>.
              Show that <m>e^A = Pe^DP^{-1}</m>.
            </p>
          </statement>
        </task>
  </exercise>

  <exercise xml:id="ex_4_c_matrix_exponential_examples">
    <introduction>
      <p>
        Let <m>A = \left[ \begin{array}{cc} 1\amp 1\\0\amp 0 \end{array} \right]</m> and let <m>B = \left[ \begin{array}{cr} 0\amp -1 \\ 0\amp 0 \end{array} \right]</m>.
      </p>
    </introduction>
        <task>
          <statement>
            <p>
              Use the result of <xref ref="ex_4_c_matrix_exponential"></xref> to calculate <m>e^A</m>.
            </p>
          </statement>
          <answer>
            <p>
              <m>e^A = \left[ \begin{array}{cc} e\amp e-1\\0\amp 1 \end{array} \right]</m>
            </p>
          </answer>
        </task>
        <task>
          <statement>
            <p>
              Calculate <m>e^B</m>.
              
            </p>
          </statement>
          <answer>
            <p>
              <m>e^B = I_2 + B = \left[ \begin{array}{cr} 1\amp -1 \\ 0\amp 1 \end{array} \right]</m>.
            </p>
          </answer>
          <hint>
            <p>
              Explain why <m>B</m> is not diagonalizable.
            </p>
          </hint>
        </task>
        <task>
          <statement>
            <p>
              Use the result of <xref ref="ex_4_c_matrix_exponential"></xref> to calculate <m>e^{A+B}</m>.
            </p>
          </statement>
          <answer>
            <p>
              <m>e^{A+B} = \left[ \begin{array}{cc} e\amp 0 \\ 0\amp 1 \end{array} \right]</m>
            </p>
          </answer>
        </task>
        <task>
          <statement>
            <p>
              The real exponential function satisfies some familiar properties.
              For example, <m>e^xe^y = e^ye^x</m> and
              <m>e^{x+y} = e^x e^y</m> for any real numbers <m>x</m> and <m>y</m>.
              Does the matrix exponential satisfy the corresponding properties.
              That is, if <m>X</m> and <m>Y</m> are <m>n \times n</m> matrices,
              must <m>e^Xe^Y = e^Ye^X</m> and <m>e^{X+Y} = e^X e^Y</m>?
              Explain.
            </p>
          </statement>
          <answer>
            <p>
              No
            </p>
          </answer>
        </task>
  </exercise>

  <exercise>
    <introduction>
      <p>
        In <xref ref="ex_4_c_matrix_exponential_examples"></xref>
        we see that we cannot conclude that <m>e^{X+Y} = e^X e^Y</m> for
        <m>n \times n</m> matrices <m>X</m> and <m>Y</m>.
        However, a more limited property is true.
      </p>
    </introduction>
        <task>
          <introduction>>
            <p>
              Follow the steps indicated to show that if <m>A</m> is an
              <m>n \times n</m> matrix and <m>s</m> and <m>t</m> are any scalars,
              then <m>e^{As} e^{At} = e^{A(s+t)}</m>.
              (Although we will not use it,
              you may assume that the series for <m>e^A</m> converges for any square matrix <m>A</m>.)
            </p>
          </introduction>
              <task>
                <statement>
                  <p>
                    Use the definition to show that
                    <me>
                      e^{As}e^{At} = \sum_{k \geq 0} \sum_{m \geq 0} \frac{s^kt^m}{k!}m! A^{k+m}
                    </me>.
                  </p>
                </statement>
              </task>
              <task>
                <statement>
                  <p>
                    Relabel and reorder terms with <m>n = k+m</m> to show that
                    <me>
                      e^{As}e^{At} = sum_{n \geq 0} \frac{1}{n!} A^n \sum_{m = 0}^n \frac{n!}{(n-m)!m!} s^{n-m}t^m
                    </me>.
                  </p>
                </statement>
              </task>
              <task>
                <statement>
                  <p>
                    Complete the problem using the Binomial Theorem that says
                    <me>
                      (s+t)^n =  \sum_{m = 0}^n \frac{n!} {(n-m)!m!} s^{n-m}t^m
                    </me>.
                  </p>
                </statement>
              </task>
        </task>
        <task>
          <statement>
            <p>
              Use the result of part (a) to show that <m>e^A</m> is an invertible matrix for any <m>n \times n</m> matrix <m>A</m>.
            </p>
          </statement>
        </task>
  </exercise>

  <exercise>
    <introduction>
      <p>
        There is an interesting connection between the determinant of a matrix exponential and the trace of the matrix.
        Let <m>A</m> be a diagonalizable
        <m>n \times n</m> matrix with real entries.
        Let <m>D = P^{-1}AP</m> for some invertible matrix <m>P</m>,
        where <m>D</m> is the diagonal matrix with entries <m>\lambda_1</m>,
        <m>\lambda_2</m>,
        <m>\ldots</m>, <m>\lambda_n</m> the eigenvalues of <m>A</m>.
      </p>
    </introduction>
        <task>
          <statement>
            <p>
              Show that <m>e^A = Pe^DP^{-1}</m>.
            </p>
          </statement>
          <answer>
            <p>
              <md>
                <mrow>e^A \amp = e^{PDP^{-1}}</mrow>
                <mrow>\amp = \sum_{k \geq 0} \frac{1}{k!} \left(PDP^{-1}\right)^k</mrow>
                <mrow>\amp =  \sum_{k \geq 0} \frac{1}{k!} PD^kP^{-1}</mrow>
                <mrow>\amp =  P\left(\sum_{k \geq 0} \frac{1}{k!} D^k\right) P^{-1}</mrow>
                <mrow>\amp = Pe^DP^{-1}</mrow>
              </md>.
            </p>
          </answer>
        </task>
        <task>
          <statement>
            <p>
              Use <xref ref="ex_trace_eigenvalues"></xref> to show that
              <me>
                \det\left(e^A\right) = e^{\trace(A)}
              </me>.
            </p>
          </statement>
          <answer>
            <p>
              <md>
                <mrow>\det\left(e^A\right) \amp = \det\left(Pe^DP^{-1}\right)</mrow>
                <mrow>\amp =  \det\left(e^D\right)</mrow>
                <mrow>\amp = e^{\lambda_1}e^{\lambda^2} \cdots e^{\lambda_n}</mrow>
                <mrow>\amp = e^{\lambda_1+\lambda^2+ \cdots + \lambda_n}</mrow>
                <mrow>\amp = e^{\trace(A)}</mrow>
              </md>.
            </p>
          </answer>
        </task>
  </exercise>

  <exercise xml:id="ex_Cayley-Hamilton">
    <introduction>
      <p>
        There is interesting relationship between a matrix and its characteristic equation that we explore in this exercise.
      </p>
    </introduction>
        <task>
          <introduction>
            <p>
              We first illustrate with an example.
              Let <m>B = \left[ \begin{array}{cr} 1\amp 2\\ 1\amp -2 \end{array} \right]</m>.
            </p>
          </introduction>
              <task>
                <statement>
                  <p>
                    Show that <m>\lambda^2 + \lambda - 4</m> is the characteristic polynomial for <m>B</m>.
                  </p>
                </statement>
              </task>
              <task>
                <statement>
                  <p>
                    Calculate <m>B^2</m>.
                    Then compute <m>B^2 + B - 4I_2</m>.
                    What do you get?
                  </p>
                </statement>
              </task>
          </task>
        <task>
          <statement>
            <p>
              The first part of this exercise presents an example of a matrix that satisfies its own characteristic equation.
              Show that if <m>A</m> is an
              <m>n \times n</m> <em>diagonalizable</em>
              matrix with characteristic polynomial <m>p(x)</m>, then <m>p(A) = 0</m>.<fn>
              This result is known as the Cayley-Hamilton Theorem and is one of the fascinating results in linear algebra.
              This result is true for any square matrix.
              </fn> That is,
              if <m>p(x) = a_nx^n+a_{n-1}x^{n-1} + \cdots + a_1x + a_0</m>,
              then <m>p(A) = a_nA^n+a_{n-1}A^{n-1} + \cdots + a_1A + a_0 = 0</m>. (Hint: If
              <m>A = PDP^{-1}</m> for some diagonal matrix <m>D</m>,
              show that <m>p(A) = Pp(D)P^{-1}</m>.
              Then determine <m>p(D)</m>.)
            </p>
          </statement>
        </task>
  </exercise>

  <exercise>
    <introduction>
      <p>
        Label each of the following statements as True or False.
        Provide justification for your response.
      </p>
    </introduction>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If matrix <m>A</m> is diagonalizable,
              then so is <m>A^T</m>.
            </p>
          </statement>
          <answer>
            <p>
              T
            </p>
          </answer>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If matrix <m>A</m> is diagonalizable,
              then <m>A</m> is invertible.
            </p>
          </statement>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If an <m>n\times n</m> matrix <m>A</m> is diagonalizable,
              then <m>A</m> has <m>n</m> distinct eigenvalues.
            </p>
          </statement>
          <answer>
            <p>
              F
            </p>
          </answer>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If matrix <m>A</m> is invertible and diagonalizable,
              then so is <m>A^{-1}</m>.
            </p>
          </statement>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If an <m>n \times n</m> matrix <m>C</m> is diagonalizable,
              then there exists a basis of <m>\R^n</m> consisting of the eigenvectors of <m>C</m>.
            </p>
          </statement>
          <answer>
            <p>
              T
            </p>
          </answer>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              An <m>n\times n</m> matrix with <m>n</m> distinct eigenvalues is diagonalizable.
            </p>
          </statement>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If <m>A</m> is an
              <m>n\times n</m> diagonalizable matrix,
              then there is a unique diagonal matrix such that
              <m>P^{-1}AP = D</m> for some invertible matrix <m>P</m>.
            </p>
          </statement>
          <answer>
            <p>
              F
            </p>
          </answer>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If <m>A</m> is an
              <m>n\times n</m> matrix with eigenvalue <m>\lambda</m>,
              then the dimension of the eigenspace of <m>A</m> corresponding to the eigenvalue <m>\lambda</m> is <m>n - \rank(A - \lambda I_n)</m>.
            </p>
          </statement>
        </task>
        <task>
          <title>True/False</title>
          <statement>
            <p>
              If <m>\lambda</m> is an eigenvalue of an <m>n \times n</m> matrix <m>A</m>,
              then <m>e^\lambda</m> is an eigenvalue of <m>e^A</m>.
              (See <xref ref="ex_2_a_matrix_exponential"></xref>
              in <xref ref="chap_matrix_operations"></xref>
              for information on the matrix exponential.)
            </p>
          </statement>
          <answer>
            <p>
              T
            </p>
          </answer>
        </task>
      
  </exercise>
</exercises>