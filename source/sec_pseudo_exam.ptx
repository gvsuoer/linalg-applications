<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_pseudo_exam">
  <title>Examples</title>
  <p>
    What follows are worked examples that use the concepts from this section.
  </p>
  <example>
    <statement>
      <p>
        Let
        <me>
          A = \left[ \begin{array}{ccc} 2\amp 5\amp 4\\6\amp 3\amp 0\\6\amp 3\amp 0\\2\amp 5\amp 4 \end{array}  \right]
        </me>.
      </p>
      <p>
        The eigenvalues of <m>A^{\tr}A</m> are
        <m>\lambda_1 = 144</m>, <m>\lambda_2 = 36</m>,
        and <m>\lambda_3=0</m> with corresponding eigenvectors
        <me>
          \vw_1 = \left[ \begin{array}{c} 2\\2\\1 \end{array}  \right], \ \vw_1 = \left[ \begin{array}{r} -2\\1\\2 \end{array}  \right], \ \text{ and }  \ \vw_1 = \left[ \begin{array}{r} 1\\-2\\2 \end{array}  \right]
        </me>.
      </p>
      <p>
        In addition,
        <me>
          A \vw_1 = \left[ \begin{array}{c} 18\\18\\18\\18 \end{array}  \right] \ \text{ and }  A \vw_2 = \left[ \begin{array}{r} 9\\-9\\-9\\9 \end{array}  \right]
        </me>.
        <ul>
          <li>
            <p>
              Find orthogonal matrices <m>U</m> and <m>V</m>,
              and the matrix <m>\Sigma</m>,
              so that <m>U \Sigma V^{\tr}</m> is a singular value decomposition of <m>A</m>.
            </p>
          </li>
          <li>
            <p>
              Determine the best rank 1 approximation to <m>A</m>.
              Give an appropriate numerical estimate as to how good this approximation is to <m>A</m>.
            </p>
          </li>
          <li>
            <p>
              Find the pseudoinverse <m>A^+</m> of <m>A</m>.
            </p>
          </li>
          <li>
            <p>
              Let <m>\vb = \left[ \begin{array}{c} 1\\0\\1\\0 \end{array}  \right]^{\tr}</m>.
              Does the matrix equation
              <me>
                A \vx = \vb
              </me>
              have a solution?
              If so, find the solution.
              If not, find the best approximation you can to a solution to this matrix equation.
            </p>
          </li>
          <li>
            <p>
              Use the orthogonal basis <m>\{\frac{1}{2}[1 \ 1 \ 1 \ 1]^{\tr}, \frac{1}{2}[1 \ -1 \ -1 \ 1]^{\tr}\}</m> of <m>\Col A</m> to find the projection of <m>\vb</m> onto <m>\Col A</m>.
              Compare to your solution in part (c).
            </p>
          </li>
        </ul>
      </p>
      <p>
        <em>Example Solution. </em>
        <ul>
          <li>
            <p>
              Normalizing the eigenvectors <m>\vw_1</m>, <m>\vw_2</m>,
              and <m>\vw_3</m> to normal eigenvectors <m>\vv_1</m>, <m>\vv_2</m>,
              and <m>\vv_3</m>, respectively,
              gives us an orthogonal matrix
              <me>
                V = \left[  \begin{array}{crr} \frac{2}{3}\amp -\frac{2}{3}\amp \frac{1}{3}\\ \frac{2}{3}\amp \frac{1}{3}\amp - \frac{2}{3}\\  \frac{1}{3}\amp \frac{2}{3}\amp \frac{2}{3} \end{array}  \right]
              </me>.
              Now <m>A \vv_i = A \frac{\vw_i}{||\vw_i||} = \frac{1}{||\vw_i||} A \vw_i</m>,
              so normalizing the vectors <m>A \vw_1</m> and <m>A \vw_2</m> gives us vectors
              <me>
                \vu_1 = \frac{1}{2} \left[ \begin{array}{c} 1\\1\\1\\1 \end{array}  \right] \ \text{ and }  \ \vu_2 = \frac{1}{2} \left[ \begin{array}{r} 1\\-1\\-1\\1 \end{array}  \right]
              </me>
              that are the first two columns of our matrix <m>U</m>.
              Given that <m>U</m> is a <m>4 \times 4</m> matrix,
              we need to find two other vectors orthogonal to <m>\vu_1</m> and <m>\vu_2</m> that will combine with <m>\vu_1</m> and <m>\vu_2</m> to form an orthogonal basis for <m>\R^4</m>.
              Letting <m>\vz_1 = [1 \ 1 \ 1 \ 1]^{\tr}</m>,
              <m>\vz_2 = [1 \ -1 \ -1 \ 1]^{\tr}</m>,
              <m>\vz_3 = [1 \ 0 \ 0 \ 0]^{\tr}</m>,
              and <m>\vz_4 = [0 \ 1 \ 0 \ 1]^{\tr}</m>,
              a computer algebra system shows that the reduced row echelon form of the matrix <m>[\vz_1 \ \vz_2 \ \vz_3 \ \vz_4]</m> is <m>I_4</m>,
              so that vectors <m>\vz_1</m>,
              <m>\vz_2</m>,
              <m>\vz_3</m>, <m>\vz_4</m> are linearly independent.
              Letting <m>\vw_1 = \vz_1</m> and <m>\vw_2 = \vz_2</m>,
              the Gram-Schmidt process shows that the set
              <m>\{\vw_1, \vw_2, \vw_3, \vw_4\}</m> is an orthogonal basis for <m>\R^4</m>,
              where <m>\vw_3 = \frac{1}{4} [2 \ 0 \ 0 \ -2]^{\tr}</m> and
              (using <m>[1 \ 0 \ 0 \ -1]^{\tr}</m> for <m>\vw_3</m>)
              <m>\vw_4 = \frac{1}{4} [0 \ 2 \ -2 \ 0]^{\tr}</m>.
              The set <m>\{\vu_1, \vu_2, \vu_3, \vu_4\}</m> where <m>\vu_1 = \frac{1}{2}[1 \ 1 \ 1 \ 1]^{\tr}</m>,
              <m>\vu_2 = \frac{1}{2}[1 \ -1 \ -1 \ 1]^{\tr}</m>,
              <m>\vu_3 = \frac{1}{\sqrt{2}}[1 \ 0 \ 0 \ -1]^{\tr}</m> and
              <m>\vu_4 = \frac{1}{\sqrt{2}}[0 \ 1 \ -1 \ 0]^{\tr}</m> is an orthonormal basis for <m>\R^4</m> and we can let
              <me>
                U = \left[  \begin{array}{crrr} \frac{1}{2} \amp  \frac{1}{2} \amp  \frac{1}{\sqrt{2}} \amp  0 \\ \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  \frac{1}{\sqrt{2}} \\  \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  -\frac{1}{\sqrt{2}} \\ \frac{1}{2} \amp  \frac{1}{2} \amp  -\frac{1}{\sqrt{2}} \amp  0 \end{array}  \right]
              </me>.
              The singular values of <m>A</m> are
              <m>\sigma_1 = \sqrt{\lambda_1} = 12</m> and <m>\sigma_2 = \sqrt{\lambda_2} = 6</m>, and so
              <me>
                \Sigma = \begin{bmatrix}12\amp 0\amp 0 \\ 0\amp 6\amp 0 \\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{bmatrix}
              </me>.
              Therefore, a singular value decomposition of <m>A</m> is <m>U \Sigma V^{\tr}</m> of
              <me>
                \left[ \begin{array}{crrr} \frac{1}{2} \amp  \frac{1}{2} \amp  \frac{1}{\sqrt{2}} \amp  0 \\ \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  \frac{1}{\sqrt{2}} \\  \frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  -\frac{1}{\sqrt{2}} \\ \frac{1}{2} \amp  \frac{1}{2} \amp  -\frac{1}{\sqrt{2}} \amp  0 \end{array}  \right] \begin{bmatrix}12\amp 0\amp 0 \\ 0\amp 6\amp 0 \\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{bmatrix}  \left[ \begin{array}{rrc} \frac{2}{3}\amp \frac{2}{3}\amp \frac{1}{3}\\ \noalign{}-\frac{2}{3}\amp \frac{1}{3}\amp \frac{2}{3}\\ \noalign{} \frac{1}{3}\amp -\frac{2}{3}\amp \frac{2}{3} \end{array}  \right]
              </me>.
            </p>
          </li>
          <li>
            <p>
              The outer product decomposition of <m>A</m> is
              <me>
                A = \sigma_1 \vu_1 \vv_1^{\tr} + \sigma_2 \vu_2 \vv_2^{\tr}
              </me>.
              So the rank one approximation to <m>A</m> is
              <me>
                \sigma_1 \vu_1 \vv_1^{\tr} = 12 \left(\frac{1}{2}\right) \left[ \begin{array}{c} 1\\1\\1\\1 \end{array}  \right] \left[ \begin{array}{ccc} \frac{2}{3} \amp  \frac{2}{3} \amp  \frac{1}{3} \end{array}  \right] = \left[ \begin{array}{ccc} 4\amp 4\amp 2\\ \noalign{}4\amp 4\amp 2 \\ \noalign{}4\amp 4\amp 2\\ \noalign{}4\amp 4\amp 2 \end{array}   \right]
              </me>.
              The error in approximating <m>A</m> with this rank one approximation is
              <me>
                \sqrt{\frac{\sigma_2^2}{\sigma_1^2+\sigma_2^2}} = \sqrt{\frac{36}{180}} = \sqrt{\frac{1}{5}} \approx 0.447
              </me>.
            </p>
          </li>
          <li>
            <p>
              Given that <m>A = U \Sigma V^{\tr}</m>,
              we use the pseudoinverse <m>\Sigma^+</m> of <m>\Sigma</m> to find the pseudoinverse <m>A^+</m> of <m>A</m> by
              <me>
                A^+ = V \Sigma^+ U^{\tr}
              </me>.
              Now
              <me>
                \Sigma^+ = \left[  \begin{array}{ccc} \frac{1}{12}\amp 0\amp 0 \\ 0\amp \frac{1}{6}\amp 0 \\0\amp 0\amp 0 \\ 0\amp 0\amp 0 \end{array}  \right]
              </me>,
              so
              <md>
                <mrow>A^+ \amp = \left[  \begin{array}{crr} \frac{2}{3}\amp -\frac{2}{3}\amp \frac{1}{3}</mrow>
                <mrow>\frac{2}{3}\amp \frac{1}{3}\amp - \frac{2}{3}</mrow>
                <mrow>\frac{1}{3}\amp \frac{2}{3}\amp \frac{2}{3}\end{array} \right] \left[  \begin{array}{ccc} \frac{1}{12}\amp 0\amp 0</mrow>
                <mrow>0\amp \frac{1}{6}\amp 0</mrow>
                <mrow>0\amp 0\amp 0</mrow>
                <mrow>0\amp 0\amp 0 \end{array} \right] \left[  \begin{array}{crrr} \frac{1}{2} \amp  \frac{1}{2} \amp  \frac{1}{\sqrt{2}} \amp  0</mrow>
                <mrow>\frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  \frac{1}{\sqrt{2}}</mrow>
                <mrow>\frac{1}{2} \amp  -\frac{1}{2} \amp  0 \amp  -\frac{1}{\sqrt{2}}</mrow>
                <mrow>\frac{1}{2} \amp  \frac{1}{2} \amp  -\frac{1}{\sqrt{2}} \amp  0 \end{array} \right]^{\tr}</mrow>
                <mrow>\amp =  \frac{1}{72} \left[ \begin{array}{rrrr} -2\amp 6\amp 6\amp -2</mrow>
                <mrow>4\amp 0\amp 0\amp 4</mrow>
                <mrow>5\amp -3\amp -3\amp 5 \end{array} \right]</mrow>
              </md>.
            </p>
          </li>
          <li>
            <p>
              Augmenting <m>A</m> with <m>\vb</m> and row reducing shows that
              <me>
                [A \ \vb ] \sim  \left[ \begin{array}{crrr} 2\amp 5\amp 4\amp 1\\ 0\amp -12\amp -12\amp -3 \\ 0\amp 0\amp 0\amp 1\\ 0\amp 0\amp 0\amp 0 \end{array}   \right]
              </me>,
              so <m>\vb</m> is not in <m>\Col A</m> and the equation <m>A\vx = \vb</m> has no solution.
              However, the best approximation to a solution to
              <m>A \vx = \vb</m> is found using the pseudoinverse <m>A^+</m> of <m>A</m>.
              That best solution is
              <md>
                <mrow>\vx^*\amp = AA^+ \vb</mrow>
                <mrow>\amp = \left[ \begin{array}{ccc} 2\amp 5\amp 4</mrow>
                <mrow>6\amp 3\amp 0</mrow>
                <mrow>6\amp 3\amp 0</mrow>
                <mrow>2\amp 5\amp 4 \end{array} \right] \frac{1}{72} \left[ \begin{array}{rrrr} -2\amp 6\amp 6\amp -2</mrow>
                <mrow>4\amp 0\amp 0\amp 4</mrow>
                <mrow>5\amp -3\amp -3\amp 5 \end{array} \right] \left[ \begin{array}{c} 1</mrow>
                <mrow>0</mrow>
                <mrow>1</mrow>
                <mrow>0 \end{array} \right]</mrow>
                <mrow>\amp = \frac{1}{2} \left[ \begin{array}{c} 2</mrow>
                <mrow>1</mrow>
                <mrow>1</mrow>
                <mrow>2 \end{array} \right]</mrow>
              </md>.
            </p>
          </li>
          <li>
            <p>
              The rank of <m>A</m> is 2 and an orthonormal basis for <m>\Col A</m> is <m>\{\vu_1, \vu_2\}</m>,
              where <m>\vu_1 = \frac{1}{2}[1 \ 1 \ 1 \ 1]^{\tr}</m> and <m>\vu_2 = \frac{1}{2}[1 \ -1 \ -1 \ 1]^{\tr}</m>.
              So
              <md>
                <mrow>\proj_{\Col A} \vb \amp = (\vb \cdot \vu_1) \vu_1 + (\vb \cdot \vu_2) \vu_2</mrow>
                <mrow>\amp = \left(\frac{3}{2}\right)\left(\frac{1}{2}\right)[1 \ 1 \ 1 \ 1]^{\tr} + \left(\frac{1}{2}\right)\left(\frac{1}{2}\right)[1 \ -1 \ -1 \ 1]^{\tr}</mrow>
                <mrow>\amp = \frac{1}{2}[2 \ 1 \ 1 \ 2]^{\tr}</mrow>
              </md>
              as expected from part (c).
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </example>
  <example>
    <statement>
      <p>
        <xref ref="T_Debt_per_capita"></xref>
        shows the per capita debt in the U.S. in from 2014 to 2019
        (source statistica.com at \url{https://www.statista.com/statistics/203064/national-debt-of-the-united-states-per-capita/}).
      </p>
      <table xml:id="T_Debt_per_capita">
        <title>U.S. per capita debt</title>
        <tabular>
          <row>
            <cell>Year</cell>
            <cell>2014</cell>
            <cell>2015</cell>
            <cell>2016</cell>
            <cell>2017</cell>
            <cell>2018</cell>
            <cell>2019</cell>
          </row>
          <row>
            <cell>Debt</cell>
            <cell>55905</cell>
            <cell>56513</cell>
            <cell>60505</cell>
            <cell>62174</cell>
            <cell>65697</cell>
            <cell>69064</cell>
          </row>
        </tabular>
      </table>
      <ul>
        <li>
          <p>
            Set up a linear system of the form
            <m>A \vx = \vb</m> whose least squares solution provides a linear fit to the data.
          </p>
        </li>
        <li>
          <p>
            Use technology to approximate a singular value decomposition
            (round to four decimal places).
            Use this svd to approximate the pseudoinverse of <m>A</m>.
            Then use this pseudoinverse to approximate the least squares linear approximation to the system.
          </p>
        </li>
        <li>
          <p>
            Calculate <m>\left(A^{\tr}A\right)^{-1}A^{\tr}</m> directly and compare to the pseudoinverse you found in part (b).
          </p>
        </li>
        <li>
          <p>
            Use your approximation to estimate the U.S. per capita debt in 2020.
          </p>
        </li>
      </ul>
      <p>
        <em>Example Solution. </em>
        <ul>
          <li>
            <p>
              A linear approximation <m>f(x) = a_0 + a_1x</m> to the system would satisfy the equation <m>A \vx = \vb</m>,
              where <m>A = \left[ \begin{array}{cc} 1\amp 2014 \\ 1\amp 2015 \\ 1\amp 2016 \\ 1\amp 2017 \\ 1\amp 2018 \\ 1\amp 2019 \end{array} \right]</m>,
              <m>\vx = \left[ \begin{array}{c} a_0 \\ a_1 \end{array} \right]</m>,
              and <m>\vb = \left[ \begin{array}{c} 55905 \\ 56513 \\ 60505 \\ 62174 \\ 65697 \\ 69064 \end{array} \right]</m>.
            </p>
          </li>
          <li>
            <p>
              Technology shows that a singular value decomposition of <m>A</m> is approximately <m>U \Sigma V^{\tr}</m>, where
              <md>
                <mrow>U \amp = \left[\begin{array}{rrrrrr} 0.4077 \amp  0.5980 \amp  -0.3997 \amp  -0.3615 \amp  -0.3233 \amp  -0.2851</mrow>
                <mrow>0.4079 \amp  0.3589 \amp  -0.0621 \amp  0.1880 \amp  0.4381 \amp  0.6882</mrow>
                <mrow>0.4081 \amp  0.1199 \amp  0.8817 \amp  -0.1181 \amp  -0.1178 \amp  -0.1176</mrow>
                <mrow>0.4083 \amp  -0.1192 \amp  -0.1291 \amp  0.8229 \amp  -0.2251 \amp  -0.2730</mrow>
                <mrow>0.4085 \amp  -0.3582 \amp  -0.1400 \amp  -0.2361 \amp  0.6677 \amp  -0.4285</mrow>
                <mrow>0.4087 \amp  -0.5973 \amp  -0.1508 \amp  -0.2952 \amp  -0.4396 \amp  0.4160 \end{array}\right]</mrow>
                <mrow>\Sigma \amp =  \left[\begin{array}{cc} 4939.3984 \amp  0.0</mrow>
                <mrow>0.0 \amp  0.0021</mrow>
                <mrow>0.0 \amp  0.0</mrow>
                <mrow>0.0 \amp  0.0</mrow>
                <mrow>0.0 \amp  0.0</mrow>
                <mrow>0.0 \amp  0.0 \end{array}\right]</mrow>
                <mrow>V \amp = \left[\begin{array}{cr} 0.0005 \amp  1.0000</mrow>
                <mrow>1.0000 \amp  -0.0005 \end{array}\right]</mrow>
              </md>.
              Thus, with <m>\Sigma^+ = \left[  \begin{array}{cccccc} \frac{1}{4939.3984}\amp 0\amp 0\amp 0\amp 0\amp 0 \\ 0\amp \frac{1}{0.0021}\amp 0\amp 0\amp 0\amp 0 \end{array}  \right]</m>,
              we have that the pseudoinverse of <m>A</m> is approximately
              <me>
                A^+ = V \Sigma^+ U^{\tr} = \left[\begin{array}{rrrrrr} 288.2381 \amp  173.0095 \amp  57.7809 \amp  -57.4476 \amp  -172.6762 \amp  -287.9048 \\ -0.14286 \amp  -0.0857 \amp  -0.0286 \amp  0.02857 \amp  0.0857 \amp  0.14286 \end{array} \right]
              </me>.
              So our least squares linear approximation is found by
              <me>
                A^{+} \vb = \left[ \begin{array}{r} -5412635.9714 \\ 2714.7429 \end{array}  \right]
              </me>.
              This makes our least squares linear approximation to be (to four decimal places)
              <me>
                f(x) = -5412635.9714 + 2714.7429x
              </me>.
            </p>
          </li>
          <li>
            <p>
              Calculating <m>\left(A^{\tr}A\right)^{-1}A^{\tr}</m> gives the same matrix as <m>A^+</m>,
              so we obtain the same linear approximation.
            </p>
          </li>
          <li>
            <p>
              The approximate U.S. per capita debt in 2020 is
              <me>
                f(2020) = -5412635.9714 + 2714.7429(2020) = 71144.60
              </me>.
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </example>
</section>