<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="sec_appl_mtx_mult">
  <title>Application: Algorithms for Matrix Multiplication</title>
  <p>
    Matrix multiplication is widely used in applications ranging from scientific computing 
    and pattern recognition to counting paths in graphs.
    As a consequence,
    much work is being done in developing efficient algorithms for matrix multiplication.
  </p>
  <p>
    We will see that a matrix product can be calculated through the row-column method.
    Recall that the product of two <m>2 \times 2</m> matrices
    <m>A = \left[ \begin{array}{cc} a_{11}\amp a_{12}\\a_{21}\amp a_{22} \end{array}  \right]</m> 
    and <m>B = \left[ \begin{array}{cc} b_{11}\amp b_{12}\\b_{21}\amp b_{22} \end{array}  \right]</m> is given by
    <me>
      AB = \left[ \begin{array}{cc} a_{11}b_{11}+a_{12}b_{21} \amp  a_{11}b_{12}+a_{12}b_{22} \\ a_{21}b_{11}+a_{22}b_{21} \amp  a_{21}b_{12}+a_{22}b_{22} \end{array}  \right]
    </me>,
  </p>
  <p>
    This product involves eight scalar multiplications and some scalar additions.
    As we will see,
    multiplication is more computationally expensive than addition,
    so we will focus on multiplication.
    In 1969, a German mathematician named Volker Strassen showed<fn>
    Strassen, Volker, Gaussian Elimination is not Optimal, Number.
    Math. 13, p. 354-356, 1969
    </fn> that the product of two
    <m>2 \times 2</m> matrices can be calculated using only seven multiplications.
    While this is not much of an improvement,
    the Strassen algorithm can be applied to larger matrices,
    using matrix partitions
    (which allow for parallel computation),
    and its publication led to additional research on faster algorithms for matrix multiplication.
    More details are provided later in this section.
  </p>
</section>